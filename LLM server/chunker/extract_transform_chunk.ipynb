{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm0_jSD4hGcZ"
      },
      "source": [
        "# collab connection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uNjpOpxrrv03",
        "outputId": "6a671764-a710-42c5-bf02-35732f891ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFwo2M9AfOJz"
      },
      "source": [
        "\n",
        "# Virtual env setup\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l-etvQhpm_XI",
        "outputId": "e205e61a-e8de-4125-bc1a-932974fb2b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z4lNNRPohZH",
        "outputId": "09150ff6-533d-434b-c070-271f5dcd2e8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv(dotenv_path=\"/content/drive/MyDrive/p2m/.env\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEfsZ1B7f5nU"
      },
      "source": [
        "# openAI key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J-UOmwoEnhVa"
      },
      "outputs": [],
      "source": [
        "api_key = os.getenv(\"OPENROUTER_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: openai in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.74.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (4.7.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\rimba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dht_XQu9OrW8"
      },
      "outputs": [
        {
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://openrouter.ai/api/v1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_client.py:116\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    114\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    118\u001b[39m     )\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=api_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1LYv4UEgPoH"
      },
      "source": [
        "# Text image splitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUlsyYsSgchZ"
      },
      "source": [
        "## path,setup,extentions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nQroe-pmrJ_L",
        "outputId": "8e0b40df-01b7-4fbc-e412-d1f95b39a411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: marker-pdf[full] in /usr/local/lib/python3.11/dist-packages (1.6.2)\n",
            "Requirement already satisfied: Pillow<11.0.0,>=10.1.0 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (10.4.0)\n",
            "Requirement already satisfied: anthropic<0.47.0,>=0.46.0 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (0.46.0)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (8.1.8)\n",
            "Requirement already satisfied: ebooklib<0.19,>=0.18 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (0.18)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.2.0)\n",
            "Requirement already satisfied: ftfy<7.0.0,>=6.1.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (6.3.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.10.0)\n",
            "Requirement already satisfied: mammoth<2.0.0,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.9.0)\n",
            "Requirement already satisfied: markdown2<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2.5.3)\n",
            "Requirement already satisfied: markdownify<0.14.0,>=0.13.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (0.13.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.65.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.72.0)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (3.1.5)\n",
            "Requirement already satisfied: pdftext<0.7.0,>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (0.6.2)\n",
            "Requirement already satisfied: pre-commit<5.0.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (4.2.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2.11.3)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2.8.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.1.0)\n",
            "Requirement already satisfied: python-pptx<2.0.0,>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.0.2)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (3.13.0)\n",
            "Requirement already satisfied: regex<2025.0.0,>=2024.4.28 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.6.1)\n",
            "Requirement already satisfied: surya-ocr<0.14.0,>=0.13.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (0.13.1)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (4.67.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.45.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (4.51.1)\n",
            "Requirement already satisfied: weasyprint<64.0,>=63.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (63.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (4.13.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from ebooklib<0.19,>=0.18->marker-pdf[full]) (5.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from ebooklib<0.19,>=0.18->marker-pdf[full]) (1.17.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0.0,>=6.1.1->marker-pdf[full]) (0.2.13)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (2.38.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (15.0.1)\n",
            "Requirement already satisfied: cobble<0.2,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from mammoth<2.0.0,>=1.9.0->marker-pdf[full]) (0.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /usr/local/lib/python3.11/dist-packages (from markdownify<0.14.0,>=0.13.1->marker-pdf[full]) (4.13.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->marker-pdf[full]) (2.0.0)\n",
            "Requirement already satisfied: pypdfium2==4.30.0 in /usr/local/lib/python3.11/dist-packages (from pdftext<0.7.0,>=0.6.2->marker-pdf[full]) (4.30.0)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full]) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full]) (2.6.9)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full]) (1.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full]) (6.0.2)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full]) (20.30.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->marker-pdf[full]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->marker-pdf[full]) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->marker-pdf[full]) (0.4.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx<2.0.0,>=1.0.2->marker-pdf[full]) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (3.6.0)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from surya-ocr<0.14.0,>=0.13.1->marker-pdf[full]) (4.11.0.86)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=4.3.6 in /usr/local/lib/python3.11/dist-packages (from surya-ocr<0.14.0,>=0.13.1->marker-pdf[full]) (4.3.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.5.1->marker-pdf[full]) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (0.5.3)\n",
            "Requirement already satisfied: pydyf>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (0.11.0)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (1.17.1)\n",
            "Requirement already satisfied: tinyhtml5>=2.0.0b1 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (2.0.0)\n",
            "Requirement already satisfied: tinycss2>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (1.4.0)\n",
            "Requirement already satisfied: cssselect2>=0.1 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (0.8.0)\n",
            "Requirement already satisfied: Pyphen>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (0.17.2)\n",
            "Requirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint<64.0,>=63.1->marker-pdf[full]) (4.57.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.9->markdownify<0.14.0,>=0.13.1->marker-pdf[full]) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=0.6->weasyprint<64.0,>=63.1->marker-pdf[full]) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from cssselect2>=0.1->weasyprint<64.0,>=63.1->marker-pdf[full]) (0.5.1)\n",
            "Requirement already satisfied: brotli>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint<64.0,>=63.1->marker-pdf[full]) (1.1.0)\n",
            "Requirement already satisfied: zopfli>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint<64.0,>=63.1->marker-pdf[full]) (0.2.3.post1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (4.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (2.3.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit<5.0.0,>=4.2.0->marker-pdf[full]) (0.3.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install marker-pdf[full]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jc_qOXMWOmWt"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "# Liste des extensions considérées comme des images\n",
        "IMAGE_EXTENSIONS = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".tiff\", \".webp\"]\n",
        "raw_data_folder = \"/content/drive/MyDrive/p2m/datas\"\n",
        "marker_data_folder = \"/content/drive/MyDrive/p2m/output_marker\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se1UcyLPgxfT"
      },
      "source": [
        "## image to txt , docx to md\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtMStUeDglrY"
      },
      "source": [
        "## image description with llma4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "phOBiI1uORlJ",
        "outputId": "344f5dc7-9d59-46d6-f30a-d49b0dc5b3c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-15 15:22:00.548114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744730520.787812    1803 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744730520.851262    1803 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-15 15:22:01.344527: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Downloading layout model...: 100% 5/5 [00:04<00:00,  1.14it/s]\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Downloading texify model...: 100% 9/9 [00:01<00:00,  5.53it/s]\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Downloading text_recognition model...: 100% 9/9 [00:21<00:00,  2.42s/it]\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Downloading table_recognition model...: 100% 5/5 [00:03<00:00,  1.44it/s]\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Downloading text_detection model...: 100% 6/6 [00:00<00:00, 11.54it/s]\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Downloading inline_math_detection model...: 100% 5/5 [00:00<00:00, 11.79it/s]\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n",
            "Downloading ocr_error_detection model...: 100% 8/8 [00:04<00:00,  1.90it/s]\n",
            "Converting 1 pdfs in chunk 1/1 with 1 processes and saving to /content/drive/MyDrive/p2m/output_marker\n",
            "2025-04-15 15:23:01.307673: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744730581.343293    2162 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744730581.353419    2162 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Processing PDFs:   0% 0/1 [00:00<?, ?pdf/s]cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "cannot find loader for this WMF file\n",
            "WARNING:weasyprint:Ignored `word-break: break-word` at 16:5, invalid value.\n",
            "WARNING:weasyprint:Ignored `src: url(/usr/local/lib/python3.11/dist-packages/static/fonts/GoNotoCurrent-Regular.ttf)` at 4:17, Relative URI reference without a base URI: '/usr/local/lib/python3.11/dist-packages/static/fonts/GoNotoCurrent-Regular.ttf'.\n",
            "WARNING:weasyprint:Missing src descriptor in '@font-face' rule at 2:13\n",
            "WARNING:weasyprint:Ignored `text-rendering: optimizeLegibility` at 11:17, unknown property.\n",
            "Processing PDFs: 100% 1/1 [03:33<00:00, 213.49s/pdf]\n",
            "[W415 15:26:44.877489395 CudaIPCTypes.cpp:96] Producer process tried to deallocate over 1000 memory blocks referred by consumer processes. Deallocation might be significantly slowed down. We assume it will never going to be the case, but if it is, please file but to https://github.com/pytorch/pytorch\n",
            "[W415 15:26:49.965323891 CudaIPCTypes.cpp:16] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n"
          ]
        }
      ],
      "source": [
        "!marker \"$raw_data_folder\" --output_dir \"$marker_data_folder\" --output_format 'markdown' --workers 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEgdTDgf7EBO"
      },
      "outputs": [],
      "source": [
        "def image_to_text(image_path: str) -> str:\n",
        "    # Convertir l'image en base64\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "    # Envoyer la requête à l'API\n",
        "    completion = client.chat.completions.create(\n",
        "        extra_headers={\n",
        "            \"HTTP-Referer\": \"<YOUR_SITE_URL>\",\n",
        "            \"X-Title\": \"<YOUR_SITE_NAME>\",\n",
        "        },\n",
        "        model=\"meta-llama/llama-4-maverick\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Describe the image in detail. For context,the image is part of a research paper explaining the transformers architecture. Be specific about graphs, such as bar plots.\"},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Récupérer la réponse\n",
        "    description = completion.choices[0].message.content\n",
        "\n",
        "    # Créer le chemin vers le fichier texte\n",
        "    txt_path = os.path.splitext(image_path)[0] + \".txt\"\n",
        "\n",
        "    # Écrire la description dans le fichier texte\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
        "        txt_file.write(description)\n",
        "\n",
        "    # Supprimer l'image originale\n",
        "    os.remove(image_path)\n",
        "\n",
        "    return \"OK\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_ma5bjUOHRh"
      },
      "outputs": [],
      "source": [
        "\n",
        "def process_all_images_in_directory(root_dir: str):\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for filename in filenames:\n",
        "            ext = os.path.splitext(filename)[1].lower()\n",
        "            if ext in IMAGE_EXTENSIONS:\n",
        "                image_path = os.path.join(dirpath, filename)\n",
        "                try:\n",
        "                    result = image_to_text(image_path)\n",
        "                    print(f\"{image_path} => {result}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Erreur lors du traitement de {image_path} : {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aPTmx2NiOhnQ",
        "outputId": "636be9ab-d83a-40fc-d6dc-8994b1e4f739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/output_marker/26.258-i00/_page_58_Figure_1.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_0_Picture_1.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_8_Figure_5.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_10_Picture_5.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_10_Picture_7.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_22_Figure_0.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_25_Figure_1.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_28_Figure_1.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_32_Picture_0.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_33_Figure_0.jpeg => OK\n",
            "/content/drive/MyDrive/output_marker/22847-i20/_page_34_Figure_1.jpeg => OK\n"
          ]
        }
      ],
      "source": [
        "process_all_images_in_directory(marker_data_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL6icGMuhA86"
      },
      "source": [
        "# chunker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y62fjL-phP17"
      },
      "source": [
        "## requirments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02yc10UXFYPh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnqnWOiUejV-",
        "outputId": "ee329b0b-2c70-458e-bf5a-a1b9829305f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required libraries for Google Colab\n",
        "!pip install --quiet langchain>=0.0.302 python-docx>=0.8.11 nltk>=3.8.1 tiktoken>=0.5.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqOyPydthWn0"
      },
      "source": [
        "## md fils to chunks txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "YS3eisl8emDU",
        "outputId": "aaacd793-f68d-4b58-a6b0-812afc5400b1"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'docx'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c1603c4eaf0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDocxReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Import section\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from docx import Document as DocxReader\n",
        "from langchain.schema import Document\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import os\n",
        "\n",
        "# Constants and configuration\n",
        "CHUNK_SIZE = 2000\n",
        "CHUNK_OVERLAP = 200\n",
        "DEFAULT_WINDOW_SIZE = 5\n",
        "DEFAULT_STEP_SIZE = 2\n",
        "SEPARATORS = [\"\\n\\n\", \"\\n\"]\n",
        "\n",
        "def download_nltk_dependencies():\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "def load_documents(directory):\n",
        "    documents = []\n",
        "    for filename in os.listdir(directory):\n",
        "        path = os.path.join(directory, filename)\n",
        "\n",
        "        if filename.endswith(\".docx\"):\n",
        "            docx = DocxReader(path)\n",
        "            text = \"\\n\".join([para.text for para in docx.paragraphs])\n",
        "            documents.append(Document(page_content=text, metadata={\"source\": filename}))\n",
        "\n",
        "        elif filename.endswith(\".md\"):\n",
        "            with open(path, 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "                documents.append(Document(page_content=text, metadata={\"source\": filename}))\n",
        "\n",
        "    return documents\n",
        "\n",
        "def create_text_splitter():\n",
        "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "        chunk_size=CHUNK_SIZE,\n",
        "        chunk_overlap=CHUNK_OVERLAP,\n",
        "        disallowed_special=(),\n",
        "        separators=SEPARATORS\n",
        "    )\n",
        "    return splitter\n",
        "\n",
        "def apply_sentence_windows(doc, window_size, step_size):\n",
        "    windows = []\n",
        "    text = doc.page_content\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    if len(sentences) <= window_size:\n",
        "        new_doc = doc.copy()\n",
        "        new_doc.page_content = \" \".join(sentences)\n",
        "        windows.append(new_doc)\n",
        "    else:\n",
        "        for i in range(0, len(sentences) - window_size + 1, step_size):\n",
        "            window = sentences[i:i + window_size]\n",
        "            new_doc = doc.copy()\n",
        "            new_doc.page_content = \" \".join(window)\n",
        "            windows.append(new_doc)\n",
        "\n",
        "    return windows\n",
        "\n",
        "def save_documents_to_folder(documents, output_folder, prefix=\"doc\", include_metadata=True):\n",
        "    \"\"\"\n",
        "    Save processed documents to a folder for later use in embedding or other steps.\n",
        "\n",
        "    Args:\n",
        "        documents (list): List of Document objects (from LangChain) to save\n",
        "        output_folder (str): Path to the folder where documents will be saved\n",
        "        prefix (str): Prefix for the document filenames\n",
        "        include_metadata (bool): Whether to include metadata in the saved files\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the output folder\n",
        "    \"\"\"\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Save each document\n",
        "    saved_count = 0\n",
        "    for i, doc in enumerate(documents):\n",
        "        try:\n",
        "            # Create a filename\n",
        "            filename = f\"{prefix}_{i+1}.txt\"\n",
        "            file_path = os.path.join(output_folder, filename)\n",
        "\n",
        "            # Save the document content\n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                # Ensure we have page_content\n",
        "                if hasattr(doc, 'page_content'):\n",
        "                    f.write(doc.page_content)\n",
        "                else:\n",
        "                    f.write(str(doc))\n",
        "\n",
        "            saved_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving document {i+1}: {str(e)}\")\n",
        "\n",
        "    print(f\"Saved {saved_count} documents to {output_folder}\")\n",
        "    return output_folder, saved_count == len(documents)\n",
        "\n",
        "def prepare_and_split_docs_by_sentence(directory, output_folder=\"processed_docs\", window_size=DEFAULT_WINDOW_SIZE,\n",
        "                                       step_size=DEFAULT_STEP_SIZE, prefix=\"window\", save=True):\n",
        "    \"\"\"\n",
        "    Process documents from a directory, split them into sentence-level chunks with sliding window,\n",
        "    and optionally save them to disk.\n",
        "\n",
        "    Args:\n",
        "        directory (str): Path to the directory containing documents\n",
        "        output_folder (str): Path where processed documents will be saved\n",
        "        window_size (int): Number of sentences per window\n",
        "        step_size (int): Number of sentences to slide the window for each chunk\n",
        "        prefix (str): Prefix for saved document filenames\n",
        "        save (bool): Whether to save the documents to disk\n",
        "\n",
        "    Returns:\n",
        "        tuple: (list of Document objects or output directory path, success status)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Download NLTK dependencies\n",
        "        download_nltk_dependencies()\n",
        "\n",
        "        # Create and use document loaders\n",
        "        documents = load_documents(directory)\n",
        "\n",
        "        if not documents:\n",
        "            print(\"No documents were found or loaded.\")\n",
        "            return None, False\n",
        "\n",
        "        # Apply initial chunking\n",
        "        pre_splitter = create_text_splitter()\n",
        "        pre_split_docs = pre_splitter.split_documents(documents)\n",
        "\n",
        "        # Apply sentence-level sliding window\n",
        "        sentence_windows = []\n",
        "        for doc in pre_split_docs:\n",
        "            windows = apply_sentence_windows(doc, window_size, step_size)\n",
        "            sentence_windows.extend(windows)\n",
        "\n",
        "        print(f\"Documents are split into {len(sentence_windows)} sentence windows\")\n",
        "\n",
        "        # Save documents if requested\n",
        "        if save and sentence_windows:\n",
        "            output_path, success = save_documents_to_folder(\n",
        "                sentence_windows,\n",
        "                output_folder,\n",
        "                prefix=prefix\n",
        "            )\n",
        "            return output_path, success\n",
        "\n",
        "        # Return the documents if not saving\n",
        "        return sentence_windows\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in document processing: {str(e)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eOdwtpYepee"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#from chunk import prepare_and_split_docs_by_sentence\n",
        "\n",
        "def main():\n",
        "    # Debug: Print starting message\n",
        "    print(\"Starting the document processing script...\")\n",
        "\n",
        "    base_dir = marker_data_folder\n",
        "\n",
        "    # Define input and output paths\n",
        "    data_dir = os.path.join(base_dir, \"test\")\n",
        "    output_folder = os.path.join(base_dir, \"processed_data\")\n",
        "\n",
        "    # Check if data directory exists\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Error: Data directory '{data_dir}' does not exist\")\n",
        "\n",
        "    # Debug: Print data directory path\n",
        "    print(f\"Data directory exists: {data_dir}\")\n",
        "\n",
        "    # Run the document processing\n",
        "    print(\"Running the document processing function...\")\n",
        "    result, success = prepare_and_split_docs_by_sentence(\n",
        "        directory=data_dir,\n",
        "        output_folder=output_folder,\n",
        "        window_size=5,\n",
        "        step_size=2,\n",
        "        prefix=\"chunk\",\n",
        "        save=True\n",
        "    )\n",
        "\n",
        "    # Report results\n",
        "    if success:\n",
        "        print(\"Document processing completed successfully!\")\n",
        "        print(f\"Processed documents saved to: {result}\")\n",
        "    else:\n",
        "        print(\"Document processing failed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7yYnKgzjb8y"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "    print(\"Starting the document processing script...\")\n",
        "\n",
        "    base_dir = marker_data_folder\n",
        "\n",
        "    # Loop over all subfolders in base_dir\n",
        "    for folder_name in os.listdir(base_dir):\n",
        "        data_dir = os.path.join(base_dir, folder_name)\n",
        "        output_folder = os.path.join(base_dir, folder_name)\n",
        "        result, success = prepare_and_split_docs_by_sentence(\n",
        "                directory=data_dir,\n",
        "                output_folder=output_folder,\n",
        "                window_size=5,\n",
        "                step_size=2,\n",
        "                prefix=\"chunk\",\n",
        "                save=True\n",
        "            )\n",
        "\n",
        "            if success:\n",
        "                print(f\"Document processing completed successfully for '{folder_name}'Processed documents saved to: {result}\")\n",
        "            else:\n",
        "                print(f\"Document processing failed for '{folder_name}'.\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
