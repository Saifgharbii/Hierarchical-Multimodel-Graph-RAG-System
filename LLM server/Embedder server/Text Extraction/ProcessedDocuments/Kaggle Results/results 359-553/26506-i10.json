{
    "document_name": "26506-i10.docx",
    "content": [
        {
            "title": "Foreword",
            "description": "This Technical Specification has been produced by the 3rd Generation Partnership Project (3GPP).\nThe contents of the present document are subject to continuing work within the TSG and may change following formal TSG approval. Should the TSG modify the contents of the present document, it will be re-released by the TSG with an identifying change of release date and an increase in version number as follows:\nVersion x.y.z\nwhere:\nx\tthe first digit:\n1\tpresented to TSG for information;\n2\tpresented to TSG for approval;\n3\tor greater indicates TSG approved document under change control.\ny\tthe second digit is incremented for all changes of substance, i.e. technical enhancements, corrections, updates, etc.\nz\tthe third digit is incremented when editorial only changes have been incorporated in the document.\nIn the present document, modal verbs have the following meanings:\nshall\t\tindicates a mandatory requirement to do something\nshall not\tindicates an interdiction (prohibition) to do something\nThe constructions \"shall\" and \"shall not\" are confined to the context of normative provisions, and do not appear in Technical Reports.\nThe constructions \"must\" and \"must not\" are not used as substitutes for \"shall\" and \"shall not\". Their use is avoided insofar as possible, and they are not used in a normative context except in a direct citation from an external, referenced, non-3GPP document, or so as to maintain continuity of style when extending or modifying the provisions of such a referenced document.\nshould\t\tindicates a recommendation to do something\nshould not\tindicates a recommendation not to do something\nmay\t\tindicates permission to do something\nneed not\tindicates permission not to do something\nThe construction \"may not\" is ambiguous and is not used in normative elements. The unambiguous constructions \"might not\" or \"shall not\" are used instead, depending upon the meaning intended.\ncan\t\tindicates that something is possible\ncannot\t\tindicates that something is impossible\nThe constructions \"can\" and \"cannot\" are not substitutes for \"may\" and \"need not\".\nwill\t\tindicates that something is certain or expected to happen as a result of action taken by an agency the behaviour of which is outside the scope of the present document\nwill not\t\tindicates that something is certain or expected not to happen as a result of action taken by an agency the behaviour of which is outside the scope of the present document\nmight\tindicates a likelihood that something will happen as a result of action taken by some agency the behaviour of which is outside the scope of the present document\nmight not\tindicates a likelihood that something will not happen as a result of action taken by some agency the behaviour of which is outside the scope of the present document\nIn addition:\nis\t(or any other verb in the indicative mood) indicates a statement of fact\nis not\t(or any other negative verb in the indicative mood) indicates a statement of fact\nThe constructions \"is\" and \"is not\" do not indicate requirements.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Introduction",
            "description": "\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "1\tScope",
            "description": "The present document specifies the architecture for real-time media communication. To support MNO and third-party services for real-time media, it is specified the essential functionalities and interfaces. The primary scope of this Technical Specification is the documentation of the following aspects:\n-\tA real-time media communication architecture mapped to the 5GS architecture and any SA2 stage 2 architecture additions, with relevant core building blocks, reference point, and interfaces to support modern operator and third-party media services, based on the 5GMS architecture\n-\tProvide all relevant reference points and interfaces to support different collaboration scenarios between 5G System operator and third-party media communication service provider, including but not limited to an AR media communication service provider.\n-\tCall flows and procedures for different real-time communication service types,\n-\tSpecify support for AR relevant functionalities such as split-rendering or spatial computing on top of a 5G System based on this architecture\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "2\tReferences",
            "description": "The following documents contain provisions which, through reference in this text, constitute provisions of the present document.\n-\tReferences are either specific (identified by date of publication, edition number, version number, etc.) or non-specific.\n-\tFor a specific reference, subsequent revisions do not apply.\n-\tFor a non-specific reference, the latest version applies. In the case of a reference to a 3GPP document (including a GSM document), a non-specific reference implicitly refers to the latest version of that document in the same Release as the present document.\n[1]\t3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".\n[2]\t3GPP TR 26.998: \"Support of 5G glass-type Augmented Reality / Mixed Reality (AR/MR) devices\".\n[3]\t3GPP TS 26.119: \"Media Capabilities for Augmented Reality\".\n[4]\t3GPP TS 26.113: \"Enabler for Immersive Real-time Communication\".\n[5]\t3GPP TR 26.930: \"Study on the enhancement for Immersive Real-Time communication for WebRTC\".\n[6]\t3GPP TS 26.501: \"5G Media Streaming (5GMS); General description and architecture\".\n[7]\t3GPP TS 23.558: \"Architecture for enabling Edge Applications\".\n[8]\t3GPP TS 38.321: \"NR; Medium Access Control (MAC) protocol specification\".\n[9]\t3GPP TS 36.321: \"LTE; Medium Access Control (MAC) protocol specification\".\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "3\tDefinitions of terms, symbols and abbreviations",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "3.1\tTerms",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the terms given in 3GPP TR 21.905 [1] and the following apply. A term defined in the present document takes precedence over the definition of the same term, if any, in 3GPP TR 21.905 [1].\nDefinition format (Normal)\n<defined term>: <definition>.\nexample: text used to clarify abstract rules by applying them literally.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "3.2\tSymbols",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the following symbols apply:\nSymbol format (EW)\n<symbol>\t<Explanation>\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "3.3\tAbbreviations",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the abbreviations given in 3GPP TR 21.905 [1] and the following apply. An abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in 3GPP TR 21.905 [1].\nAR\tAugmented Reality\nEAS\tEdge Application Server\nECS\tEdge Configuration Server\nEEC\tEdge Enabler Client\nEES\tEdge Enabler Server\nIETF\tInternet Engineering Task Force\nICE\tInteractive Connectivity Establishment\nIMS\tIP Multimedia Subsystem\nMCU\tMulti-point Control Unit\nMR\tMixed Reality\nMSH\tMedia Session Handler\nMTSI\tMultimedia Telephony Service for IMS\nNAT\tNetwork Address Translation\nRTC\tReal-Time Media Communication\nSDP\t\tSession Description Protocol\nSFU\tSelective Forwarding Unit\nSTUN\tSession Traversal Utilities for NAT\nTURN\tTraversal Using Relays around NAT\nW3C\tWorld Wide Web Consortium\nWebRTC\tWeb Real-Time Communication\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "4\tReal-time Media Communication Architecture",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "4.1\tOverall architecture for Real-Time Media Communication (RTC)",
                    "description": "",
                    "summary": "",
                    "text_content": "Real-Time media Communication (RTC) over 5G system in the context of this specification is defined as the delivery of delay-sensitive media from one peer to another with support of 5G network. AR conversational service described in TR 26.998 [2] is a typical use cases for RTC, which enables end-users to directly communicate real-time media including AR/MR media contents as specified in TS 26.119 [3]. As identified in clause 8.4 of TR 26.998, there may be different options to enable such AR conversational service, for example re-use of parts of MTSI such as the IMS data channel or 5G Media Streaming for managed services.\nThe overall RTC architecture is shown in Figure 4.1-1 as below.\nRTC in 5G System: Real-time media communication (RTC) is a crucial component of 5G networks, enabling seamless communication between devices and services. In this figure, we see a simplified representation of a 5G system, highlighting the importance of RTC in ensuring high-speed data transmission. The figure shows a network with multiple layers, including base stations (BTS), user equipment (UE), and distributed nodes. Redundancy paths are depicted in dashed lines, ensuring that the system can maintain connectivity in the event of network failures. The figure also highlights the use of SDN principles, which are essential for managing and optimizing the network's resources.\nFigure 4.1-1: Real-time media communication (RTC) in 5G System\nNOTE:\tThe functions indicated by the yellow filled boxes are in scope of the present document for RTC. The functions indicated by the grey boxes are defined in 5G System specifications. The functions indicated by the blue boxes are neither in scope of 5G RTC nor 5G System specifications.\nThe media data is exchanged between two or more RTC endpoints over 5G System. The RTC endpoint is an endpoint configured by RTC architecture in the present document. It is typically a UE, but an edge computing server can also be the RTC endpoint. The Application Provider provides a RTC Aware-Application on the UE to make use of RTC endpoint and network functions using interfaces and APIs. RTC architecture provides the core functions and entities to support WebRTC-based service over 5G System, two main functions are defined in trusted DN.\n-\tRTC AF: An Application Function similar to that defined in TS 26.501 [6], dedicated to real-time media communication\n-\tRTC AS: An Application Server dedicated to real-time media communication\nNOTE:\tBoth RTC AF and RTC AS in external DN are out of scope of the present specification.\nThe detailed RTC architecture mapping to the overall high-level architecture in Figure 4.1-1 is shown in Figure 4.1-2 below. Note that Figure 4.1-2 illustrates only the half portion of Figure 4.1-1 (the link from one RTC endpoint to RTC AF and RTC AS), as the rest of portion is symmetric.\n\nThe figure depicts the general architecture of a Real-Time Clock (RTC) system, including its components and their interconnections. The RTC is a critical component in many real-time systems, responsible for maintaining accurate timekeeping. The figure shows the various components, such as the main clock, time-keeping circuits, and power supply, as well as their interconnections. The figure also includes a schematic representation of the system's architecture, highlighting the importance of proper design and component selection for reliable timekeeping.\nFigure 4.1-2: RTC General Architecture\nNOTE1:\tSome of functions may not be required depending on the collaboration scenario. Description of collaboration scenario and its architecture variant are specified in Annex A.\nNOTE2:\tThe WebRTC framework is a WebRTC protocol stack and its implementation, defined in W3C and IETF. Media codecs and other media processing functions are specified in TS 26.119 [3].\nNOTE3:\tRed ovals indicate API provider functions.\nThe subfunctions inside RTC AF, RTC AS, and RTC endpoint are defined in clause 4.2 and the interfaces shown in Figure 4.1-2 are defined in clause 4.3.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "4.2\tFunctions and entities",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "4.2.1\tGeneral",
                            "text_content": "This clause defines minimal and essential functions and extra functions and entities may appear in some cases. The definitions of extra functions and entities are specified in TS 26.113 [4] and TR 26.930 [5].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.2\tProvisioning function",
                            "text_content": "The provisioning function may enable an application provider to perform provisioning of the following functionalities:\n-\tQoS support provisioning for WebRTC sessions\n-\tCharging provisioning for WebRTC sessions\n-\tCollection of consumption and QoE metrics data provisioning related to WebRTC sessions\n-\tOffering ICE functionality provisioning such as STUN and TURN servers\n-\tOffering WebRTC signalling servers provisioning, potentially with interoperability to other signalling servers.\nThe provisioning function may not be relevant to all collaboration scenarios and some of the 5G support functionality may be offered without application provider provisioning.\nNOTE:\tThe integration/collocation of this RTC AF and WebRTC signalling function is possible. Co-located WebRTC signalling function is able to act as a RTC AF which is accessible to 5GC, and replace some of this RTC AF’s interfaces and APIs with WebRTC signalling function. For example, interfaces and APIs between this RTC AF and UE will be replaced to avoid concurrent/redundant requests from UE.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.3\tConfiguration function",
                            "text_content": "The configuration function stores WebRTC-related configuration information and makes them accessible to the UE. It stores information and recommendations to operate network-assisted WebRTC sessions over 5G system.\nThe configuration information may consist of static information such as the following:\n-\tRecommendations for media configurations\n-\tConfigurations of STUN and TURN server locations\n-\tConfiguration about consumption and QoE reporting\n-\tDiscovery information for WebRTC signalling and data channel servers and their capabilities in static and/or dynamic way.\nNOTE:\tThe integration/collocation of this RTC AF and WebRTC signalling function is possible. Co-located WebRTC signalling function is able to act as a RTC AF which is accessible to 5GC, and replace some of this RTC AF’s interfaces and APIs with WebRTC signalling function. For example, interfaces and APIs between this RTC AF and UE will be replaced to avoid concurrent/redundant requests from UE.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.4\tRTC Media Session Handler (MSH)",
                            "text_content": "The RTC MSH is an entity running on the UE, which assists with the 5G integration of the WebRTC application. It exchanges, on behalf of the application, information about the WebRTC sessions with the network.\nThe RTC MSH receives information about a new WebRTC session from the application. It relays the information to the Network Support Function. It also receives events and other network information about the WebRTC session from the Network Support Function, which it may relay to the application.\nIn addition, one of subfunction in RTC MSH is the metric collection and reporting. It executes the collection of QoS and QoE metrics measurements from the WebRTC Framework and the WebRTC application and sends metrics reports to the RTC AF for the purpose of metrics analysis or to enable potential transport optimizations by the network.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.5\tNetwork support function",
                            "text_content": "The support functionality includes the following:\n-\tNetwork Support Function receives information from the UE and/or other ASs about a WebRTC session and its state\n-\tNetwork Support Function requests the network that QoS should be allocated (or satisfied) for a starting or modified session\n-\tNetwork Support Function receives notification from the network about changes to the QoS allocation for the ongoing WebRTC session\n-\tNetwork Support Function exchanges information about the WebRTC session with the trusted STUN/TURN/Signalling function, e.g. to identify a WebRTC session and associate it with a QoS template.\nNOTE:\tThe integration/collocation of this RTC AF and WebRTC signalling function is possible. Co-located WebRTC signalling function is able to act as a RTC AF which is accessible to 5GC, and replace some of this RTC AF’s interfaces and APIs with WebRTC signalling function. For example, interfaces and APIs between this RTC AF and UE will be replaced to avoid concurrent/redundant requests from UE.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.6\tTrusted ICE functions",
                            "text_content": "The MNO may offer trusted ICE functions to the WebRTC application to be used during the WebRTC ICE gathering phase. These functions may be STUN and TURN servers that facilitate NAT and firewall traversal.\nThe MNO-operated trusted ICE functions may assist with the 5G integration of the WebRTC application. This could be done by triggering network assistance to starting or ongoing WebRTC sessions.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.7\tTrusted WebRTC signalling function",
                            "text_content": "The trusted WebRTC signalling function is used to setup and manage MNO-operated WebRTC applications. They offer a standardized signalling protocol for the session setup to both parties of the WebRTC session. The WebRTC signalling function handles the offer/answer exchange and has an access to the SDP in both directions.\nThe WebRTC signalling function may use that knowledge to offer network assistance and other 5G features to the endpoints of the WebRTC session.\nThe WebRTC signalling function manages media flow sessions in both uplink and downlink directions.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.8\tTrusted inter-working function",
                            "text_content": "This function provides inter-working functionality to enable MNO-facilitated WebRTC sessions that involve endpoints across different MNOs. They may for example provide cross-network signalling functionality to allow WebRTC signalling server that are hosted in different networks to communicate, in order to establish and manage the WebRTC sessions.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.9\tTrusted transport gateway function",
                            "text_content": "A transport gateway function may be offered by the MNO to support cross-operator WebRTC sessions. It may offer the border control function for user plane (e.g., topology hiding, IPv4-IPv6 translation) as a gateway, which is located at the network boundary where different operators or third-party network connects. It works under the control of the trusted inter-working function.\nNote:\tDetailed functionality is specified in TR 26.930 [5].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.10\tTrusted media function",
                            "text_content": "A media server may be offered by the MNO to support WebRTC sessions. It may offer a wide range of functionality such as:\n-\ta content server that serves content to the WebRTC application, e.g. through a data channel\n-\tmedia processing functionality: may be used by the WebRTC application as a relay that performs some media processing function such as transcoding, recording, 3D reconstruction, etc.\n-\tscene composition functionality: the server may compose a 3D scene and distribute it to several point-to-point WebRTC sessions\n-\tMulti-point Control Unit (MCU) functionality: the server may offer multi-party conferencing functionality to merge a number of point-to-point WebRTC sessions\n-\tSelective Forwarding Unit (SFU) functionality: the server may offer the selection, copy, and forwarding functionality of IP steams produced by multiple RTC endpoints (i.e., participants).\n-\tMaintain uplink and downlink flow context (QoS, remote control and etc.) by interacting with the WebRTC signalling function.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.2.11\tTrusted application supporting web function",
                            "text_content": "A web server may be offered by the MNO to support applications by providing web service entry point, authorization/authentication, sharing files, or scheduling conferencing sessions.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "4.3\tInterfaces",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "4.3.1\tRTC-1: Provisioning interface",
                            "text_content": "The RTC-1 interface allows the Application Provider to provision support for RTC sessions that are offered by it. The provisioning may cover the following aspects:\n-\tQoS support for WebRTC sessions\n-\tCharging provisioning for WebRTC sessions\n-\tCollection of consumption and QoE metrics data related to WebRTC sessions\n-\tOffering ICE functionality such as STUN and TURN servers\n-\tOffering WebRTC signalling function, potentially with interoperability to other signalling servers\nThe provisioning interface is not relevant to all collaboration scenarios and some of the 5G support functionality may be offered without application provider provisioning.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.3.2\tRTC-3: RTC AS to RTC AF interface",
                            "text_content": "The RTC AS may exchange information regarding the RTC session with the RTC AF. This information may cover QoS flow information and QoS allocation as well as QoE and consumption reports. The RTC AF may subscribe to information about the status of the QoS flow, which it may share with the RTC AS, e.g. in form of bitrate recommendations.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.3.3\tRTC-4: Media-centric transport interface",
                            "text_content": "This interface is used to exchange the WebRTC traffic with the other endpoint as well as to exchange signalling information related to the WebRTC session with the trusted application servers.\nThe traffic includes:\n-\tMedia streams sent over RTP\n-\tApplication data sent over data channel\n-\tWebRTC Signalling data along with STUN and TURN servers\n-\tOther application data\nRTC-4 may further be grouped into two sub-interfaces as follows.\nRTC-4s:\nThe RTC-4s interface is an interface between the WebRTC framework and the RTC AS such as WebRTC Signalling function. This interface is used for the exchange of signalling information related to the WebRTC session between two or more WebRTC endpoints using trusted application servers. In some cases where the signalling is not handled by WebRTC framework, the RTC-4s interface is an interface between the native WebRTC applications and the WebRTC Signalling server.\nRTC-4m:\nThis interface is used for transmission of media and other related data between two or more RTC endpoints.\nThe traffic includes\n-\tMedia data transmitted over RTP\n-\tApplication data transmitted using Data channel\n-\tMedia related meta-data transmitted using Data channel\nNOTE 1:\tThe Media Server should maintain the status for both uplink and downlink traffic and a separate interface for supporting downlink and uplink is expected to be defined in this specification.\nNOTE 2:\tWebRTC-enabled UE should support streaming functions for uplink and downlink traffic. Therefore a new entity in UE may be defined.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.3.4\tRTC-5: Control transport interface",
                            "text_content": "The RTC-5 interface is an interface between the RTC MSH and the RTC AF. It is used to convey configuration information from the RTC AF to the RTC MSH and to request support for a starting/ongoing WebRTC session. The configuration information may consist of static information such as the following:\n-\tRecommendations for media configurations\n-\tConfigurations of STUN and TURN server locations\n-\tConfiguration about consumption and QoE reporting\n-\tDiscovery information for WebRTC signalling and data channel servers and their capabilities\nThe support functionality includes the following:\n-\tRTC MSH receives the configuration information\n-\tRTC MSH informs the RTC AF about a WebRTC session and its state\n-\tRTC MSH requests QoS allocation for a starting or modified session\n-\tRTC MSH receives notification about changes to the QoS allocation for the ongoing WebRTC session\n-\tRTC MSH receives the updated information about the WebRTC session with the RTC STUN/TURN/Signalling function, e.g. to identify a WebRTC session and associate it with a QoS template\nThe RTC functionality that offer application functions to the WebRTC application may equally be provided by Application Servers (RTC AS) instead of RTC AF. These then use a dedicated interface RTC-3 to request configurations and network support for the ongoing WebRTC sessions from the RTC AF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.3.5\tRTC-6: Client API",
                            "text_content": "The RTC MSH is a function in the UE that provides access to RTC support functions to the native WebRTC applications. These functions may be offered on request, i.e., through the RTC-6 interface, or transparently without direct involvement of the application. The RTC MSH may assist indirectly in the ICE negotiation by providing a list of STUN and TURN server candidates that offer RTC functionality. The RTC MSH also collects QoE metric reports and submits consumption reports. It may also offer media configuration recommendations to the application through RTC-6.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.3.6\tRTC-7: Client interface",
                            "text_content": "This is an interface between WebRTC framework and the native WebRTC Application to directly communicate media-specific information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.3.7\tRTC-8: Application interface",
                            "text_content": "This is a proprietary interface between the application and the application provider, which may be used to exchange configuration information related to the RTC session or the application.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.3.8\tRTC-11: UE configuration interface",
                            "text_content": "The RTC-11 is an interface between the RTC MSH and the WebRTC framework, both in the RTC endpoint, to configure media session handling and/or media access. It may not be exposed as an API to application developers but may be in form of a direct communication. The WebRTC framework hides away all details of the QoS allocation and network support from the application. It autonomously and transparently invokes the functions offered by the RTC MSH to provide support for the RTC session.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "4.4\tRTC Architecture extension",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "4.4.1\tIntroduction",
                            "text_content": "This clause defines an architecture that enables a RTC Application Provider to provision resources in the Edge Data Network (EDN) for an application through the RTC-1 interface.\nMedia processing in the edge may be achieved in one of two different ways at the application layer:\n1.\tClient-driven management. RTC Applications that are aware of the edge processing can directly request an edge resource and discover the Edge Application Server (EAS) that is best suited to serve the application.\n2.\tApplication Function-driven management. The RTC AF automatically allocates edge resources for new streaming sessions on behalf of the application using information in the RTC provisioning session.\nAn Edge-enabled RTC Client leverages the Edge Computing capabilities as defined in TS 23.558 [7].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "4.4.2\tExtended RTC architecture for Edge Computing",
                            "text_content": "The RTC architecture can be extended to add support for media processing in the edge. The extended architecture is an integration of the RTC architecture defined in TS 26.506 with the architecture for enabling Edge Applications defined in TS 23.558 [7] and TS 26.501 [6].\nThe extended RTC architecture supports both client-driven as well as Application Function-driven management of the edge processing session.\nThe RTC Application Provider may request the deployment of edge resources as part of the Provisioning Session.\n-\tThe RTC Application Provider provisions the edge provisioning through RTC-1, a similar fashion as defined in TS 26.512 clause 7.10, enabling client-driven and/or Application Function driven edge configuration.\n-\tIn the client-driven approach, the WebRTC Application becomes aware of the support of edge processing in the network and takes steps, such as using the EDGE-5 APIs, to discover and locate a suitable RTC AS instance in the Edge DN, similar to the process defined in TS 26.501 clause 8.1.\n-\tIn the Application Function driven approach, the RTC Application Provider requests RTC AF to deploy edge processing for the media sessions of the corresponding Provisioning Session, similar to the process defined in TS 26.501 clause 8.2. The WebRTC Application may get aware of the deployed EAS through the Application Service Provider through RTC-8 or through the RTC MSH through RTC-5 (and possibly RTC-6). The EAS is provided together such that the associated can be made by UE between two set of data. Additionally, the EAS may also be discovered through other means, such as DNS resolution with support from the DNS server (e.g., EASDF/DNS resolver) as specified in 3GPP TS 23.548 .\nWhen the WebRTC application is a web application, the implementation of the EDGE-5 interface to discover the RTC AS/EAS location by accessing the EEC is difficult as the Web browser providers may not implement interfaces necessary for supporting edge enabled RTC applications/services. Also, in the Application Function-driven approach the Application Client (AC) and EEC are not used to discover the RTC AS/EAS location.\nTo resolve the above EAS discovery issue in the Application Function-driven approach and when the WebRTC application is a web application, the EAS information can be shared with the RTC MSH by the RTC AF using RTC-5 interface.\nNOTE:\tOther methods that can be used for sharing EAS information (e.g., sharing EAS hostname to the WebRTC application by RTC-8 or by other means and then using DNS resolution) are FFS.\nThe figure depicts an edge-enabled RTC (Remote Terminal Unit) architecture, illustrating the various components and their interconnections. The architecture is designed to support remote monitoring and control of devices, ensuring efficient and secure communication.\nFigure 4.4.2-1: Edge-enabled RTC architecture\nNOTE:\tThis architecture diagram is an example for CS-2 scenario.\nEAS is the application server resident in the EDN, performing edge-based processing for AR functionalities such as split rendering and spatial computing. The Application Client (AC) connects to the EAS in order to avail the services of the application with the benefits of Edge Computing.\nIt is possible that the server functions of an application are available only as an EAS.\nHowever, it is also possible that certain server functions are available both at the edge and in the cloud as an EAS and an Application Server resident in the cloud.\nThe EAS can use the 3GPP Core Network capabilities in the following ways, all of which are optional to support:\na)\tinvoking 3GPP Core Network capabilities via the edge enabler layer through the Edge Enabler Server (EES)\nb)\tinvoking 3GPP Core Network function (e.g., PCF) APIs directly, if it is an entity trusted by the 3GPP Core Network; and\nc)\tinvoking the 3GPP Core Network capabilities through the capability exposure functions, i.e., SCEF/NEF/SCEF+NEF.\nThe functions of Edge enabler Client (EEC), Edge Enabler Server (EES), Edge Configuration Server (ECS) are as defined in TS 23.558 [7].\nBased on the extended architecture, the following interfaces are defined for performing edge-based processing for AR functionalities such as split rendering and spatial computing:\n1.\tA RTC AF that is edge-enabled shall support EES functionality including:\n-\tEDGE-1 API for supporting registration and provisioning of EEC functions, and discovery by them of EAS instances.\n-\tEDGE-3 API towards the EAS function of RTC AS instances.\n-\tEDGE-6 API for registering with an ECS function.\n-\tEDGE-9 API for media session relocation.\n2.\tA RTC AS that is edge-enabled shall support EAS functionality including the EDGE-3 API for registration with the EES.\n3.\tA RTC MSH that is edge-enabled should support EEC functionality including:\n-\tInvoking the EES function using the EDGE-1 API.\n-\tInvoking the ECS function using the EDGE-4 API.\n-\tEDGE-5 API exposed to the Application Client.\n4.\tA WebRTC Application that is edge-enabled shall support Application Client functionality and should invoke the ECS function using the EDGE-5 API.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "5\tProcedures for basic RTC architecture",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "5.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "The RTC procedures that are defined in this clause are classified based on the collaboration scenarios that are described in Annex A. Depending on the scenario, only a subset of the functions that are defined in clause 4.2 may be involved.\nIn general, the RTC call flow may consist of the following procedures.\n-\tProvisioning\n-\tConfiguration\n-\tICE candidates discovery\n-\tSession establishment\n-\tQoS request (either client-driven or WebRTC signalling function/server-driven)\n-\tWebRTC traffic delivery\n-\tQoS updates\n-\tSession termination\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "5.2\tCommon Procedure",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.2.1\tProvisioning",
                            "text_content": "An application provider may use the RTC-1 interface to provision network assistance and other resources for its RTC sessions.\nThis procedure is common to the different collaboration scenarios.\nThe figure depicts a provisioning procedure for a network, with various steps and components highlighted. The diagram illustrates the process of setting up a network, including the selection of network elements, the configuration of network parameters, and the establishment of network connections. The figure is a visual representation of the complex process of network provisioning, highlighting the importance of proper planning and execution to ensure the smooth operation of a network.\nFigure 5.2.1-1: Provisioning procedure\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.2.2\tConfiguration",
                            "text_content": "The Configuration procedure is used to pre-configure the RTC MSH with information that it makes available to RTC applications through the RTC-6 interface.\nThis information includes the following:\n-\tThe location and capabilities of trusted ICE functions\n-\tThe location and capabilities of trusted WebRTC Signaling functions\n-\tThe edge configuration as defined in clause 6.\nThe RTC MSH retrieves the configuration information from the RTC AF.\nThe configuration procedure is illustrated in Figure 5.2.2-1:\nThe figure depicts a configuration procedure for a 2.2-1 network, illustrating the steps involved in setting up the network infrastructure. The diagram includes various components such as the network switch, router, and firewall, as well as the necessary cables and connectors. The figure provides a clear visual representation of the network's structure and components, making it easier for network administrators to understand the process and ensure proper setup.\nFigure 5.2.2-1: Configuration procedure\nThe steps are as follows:\n1.\tAn ASP provisions resources for its RTC sessions\n2.\tA single retrieval of the configuration information is done:\na.\tThe RTC MSH requests the configuration information for RTC sessions. It may provide the application identifier to retrieve configuration information specific to that application.\nb.\tThe RTC AF provides the requested configuration information.\nThe RTC MSH makes the information available to the Application through the RTC-6 interface.\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.3\tCall flow for Over-the-top (OTT) RTC sessions (CS#1)",
                    "description": "",
                    "summary": "",
                    "text_content": "The RTC session is established between two RTC endpoints using external signalling mechanisms. Each endpoint of the connection that is using the 5G system may benefit from 5G network support for the network path within that 5G network.\nThe following call flow applies to this scenario.\nThe figure depicts a call flow for Over-the-top (OTT) Real-Time Communication (RTC) sessions in collaboration scenario 1, illustrating the flow of data between the two parties involved. The flow includes the initiation of a call, the exchange of messages, and the conclusion of the call. The figure provides a visual representation of the communication process, highlighting the importance of collaboration and the need for clear communication channels in real-time communication scenarios.\nFigure 5.3-1: Call flow for Over-the-top (OTT) RTC sessions (collaboration scenario 1)\nThe working assumptions are:\n-\tThe application on UE1 and the remote endpoint (e.g., UE2 or server for edge computing) use an external WebRTC signalling function to establish the WebRTC session.\n0.\tA provisioning session may have been created by the AP with the MNO.\nNetwork assistance for the RTC session is achieved through the following steps:\n1.\tThe application on UE1 uses application-specific signalling functions to establish a WebRTC session with remote endpoint.\n2.\tThe application informs the RTC MSH about the new RTC session and shares information about the media streams and their associated 5-Tuples.\n3.\tThe RTC MSH requests network assistance for the RTC session and provides the transport and bandwidth information to the Network Support AF.\n4.\tThe Network Support AF uses the N5 or N33 interface to request QoS allocation. It may request differential charging based on pre-existing provisioning for these sessions.\n5.\tConfirmation of QoS allocation is notified to the Network Support AF and the RTC MSH.\n6.\tThe Network Support AF will also subscribe to events related to the QoS flows of the RTC session with the PCF and SMF.\n7.\tThe Network Support AF receives notifications about any changes to the QoS flows of the RTC session from the PCF or the SMF.\n8.\tThe Network Support AF sends notifications to the RTC MSH about changes to the session. This information may contain for example be bitrate recommendations.\n9.\tAlternatively, the MSH may interact with the UE Modem to trigger to query the recommended bitrate on the uplink or downlink direction.\n10.\tThe UE Modem then sends the ANBRQ (Access Network Bit Rate Query) signalling to the RAN as defined in TS 38.321 [8] for NR access and TS 36.321[9] for LTE access.\n11.\tThe RAN, based on the network status, returns the recommended bitrate to the UE modem as requested. The recommended bit rate is in kbps at the physical layer at the time when the decision is made.\nNOTE 1: The UE may determine the corresponding IP layer bitrate based on the long-term average of the IP packet sizes, L2 header sizes, and ROHC header sizes, but the translation methodologies and the estimation error levels required to implement accurate media bitrate adaptation have not been specified. The UE may determine the corresponding IP layer bitrate based on the long-term average of the IP packet sizes, L2 header sizes, and ROHC header sizes, but the translation methodologies and the estimation error levels required to implement accurate media bitrate adaptation have not been specified.\nNOTE 2: The eNodeB may determine the corresponding IP layer bitrate based on the long-term average of the IP packet sizes, L2 header sizes, and ROHC header sizes, but the translation methodologies and the estimation error levels required to implement accurate media bitrate adaptation have not been specified.\nNOTE 3:\tThe recommended/queried bitrate as signalled over the LTE and NR access is defined to be in kbps at the physical layer. The uplink/downlink bitrate at the physical layer is , where is the bit-length of the k-th successfully transmitted/received TB by the UE within the window T. In TS 36.321[9] and 38.321[8], a window length of 2000 ms is applied.\n12.\tThe RTC MSH forwards the bitrate recommendation to the RTC application.\n13.\tThe application may act on the bitrate recommendation, e.g. by reducing the uplink media bitrate.\n14.\tThe application may request remote endpoint to adjust the bitrate of the downlink media.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "5.4\tCall flow for Network-supported RTC sessions (CS#2)",
                    "description": "",
                    "summary": "",
                    "text_content": "The MNO offers access to trusted ICE functionality to UEs that wish to participate in RTC sessions. The session establishment takes into account the configured trusted ICE functions.\nThe call flow is as follows.\nThe figure depicts a call flow for Network-supported RTC (Remote Team Collaboration) sessions in a collaboration scenario 2. It illustrates the flow of calls between two teams, with each team having a dedicated call center. The flow includes the initiation of a call, the routing of the call to the appropriate team, and the completion of the call. The figure also shows the flow of calls between the two teams, with each team having a dedicated call center. The flow includes the initiation of a call, the routing of the call to the appropriate team, and the completion of the call.\nFigure 5.4-1: Call flow for Network-supported RTC sessions (collaboration scenario 2)\nThe working assumptions are:\n-\tThe application on UE1 and remote endpoint use an external WebRTC signalling function to establish the WebRTC session.\n0.\tA provisioning session may have been created by the AP with the MNO.\nCall flow using network-supported RTC session is achieved through the following steps:\n1.\tThe RTC AF uses the RTC-5 interface to provide the RTC MSH with a list of trusted STUN/TURN servers that the UE may use for establishing RTC sessions.\n2.\tThe application queries the RTC MSH for the list of trusted ICE servers.\n3.\tThe UE discovers and tests the ICE candidates to validate that they are suitable for the connection.\n4.\tThe application on UE1 and the remote endpoint use an external RTC signalling function to exchange information about ICE candidates and to exchange the SDP offer/answer.\nThen, the WebRTC session is established using the most suitable ICE candidate.\n5.\tThe STUN or TURN server in ICE function, upon reception of the allocation request by the application (or WebRTC framework) may extract the 5-Tuple information for each of the media sessions and convey the information to the Network Support AF in RTC AF for requesting QoS assistance.\n6.\tThe Network Support AF uses the N5 interface to request QoS allocation. It may request differential charging based on pre-existing provisioning for these sessions.\n7.\tConfirmation of QoS allocation is notified to the Network Support AF and the RTC MSH.\n8.\tThe Network Support AF will also subscribe to events related to the QoS flows of the WebRTC session with the PCF and SMF.\n9.\tThe Network Support AF receives notifications about any changes to the QoS flows of the WebRTC session from the PCF or the SMF. Then, the Network Support AF sends notifications to the ICE function (STUN/TURN server).\n10.\tThe STUN/TURN server may forward the bitrate recommendation to the RTC MSH, if the allocation session is still active.\n11. Alternatively, the MSH may interact with the UE Modem to trigger to query the recommended bitrate on the uplink or downlink direction.\n12.\tThe UE Modem then sends the ANBRQ (Access Network Bit Rate Query) signalling to the RAN as defined in TS 38.321 [8] for NR access and TS 36.321 [9] for LTE access.\n13.\tThe RAN, based on the network status, returns the recommended bitrate to the UE modem as requested. The recommended bit rate is in kbps at the physical layer at the time when the decision is made.\nNOTE 1: The UE may determine the corresponding IP layer bitrate based on the long-term average of the IP packet sizes, L2 header sizes, and ROHC header sizes, but the translation methodologies and the estimation error levels required to implement accurate media bitrate adaptation have not been specified. The UE may determine the corresponding IP layer bitrate based on the long-term average of the IP packet sizes, L2 header sizes, and ROHC header sizes, but the translation methodologies and the estimation error levels required to implement accurate media bitrate adaptation have not been specified.\nNOTE 2: The eNodeB may determine the corresponding IP layer bitrate based on the long-term average of the IP packet sizes, L2 header sizes, and ROHC header sizes, but the translation methodologies and the estimation error levels required to implement accurate media bitrate adaptation have not been specified.\nNOTE 3:\tThe recommended/queried bitrate as signalled over the LTE and NR access is defined to be in kbps at the physical layer. The uplink/downlink bitrate at the physical layer is , where is the bit-length of the k-th successfully transmitted/received TB by the UE within the window T. In TS 36.321[9] and 38.321[8], a window length of 2000 ms is applied.\n14.\tThe application may act on the bitrate recommendation, e.g. by reducing the uplink media bitrate.\n15.\tMedia traffic is delivered to remote endpoint. If TURN server is present in the configuration, RTC-4m interface is involved.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "5.5\tCall flow for MNO-Facilitated RTC sessions (CS#3)",
                    "description": "",
                    "summary": "",
                    "text_content": "In collaboration scenario 3, MNO hosts the WebRTC sessions by providing a trusted WebRTC signalling function in the RTC AS. In addition, a trusted media server is also present in RTC AS to support SFU and MCU functionality. Note that, when the WebRTC application is a web-based application, the RTC MSH function is not supported.\nThe call flows for this scenario when RTC MSH is involved are as shown in Figure 5.5.1.\nThe figure depicts a call flow for a multi-operator (MNO) facilitated remote training (RTC) session, illustrating the collaboration scenario 3. The flow includes various call types, such as voice, video, and data, and the use of different codecs, such as H.264 and H.265, to ensure high-quality video and audio transmission. The figure also highlights the use of virtual network functions (VNFs) and network functions virtualization (NFV) to optimize network resources and improve efficiency.\nFigure 5.5.1: Call flows for MNO facilitated RTC sessions (collaboration scenario 3)\nThe RTC Application Provider may create a Provisioning Session with the RTC AF and starts provisioning the usage of the RTC Streaming session between two endpoints. During the establishment phase, the used features such as content consumption measurement, logging, collection and reporting; QoE metrics measurement, logging, collection and reporting; dynamic policy; network assistance; are negotiated and detailed configurations are exchanged.\nThe RTC Application Provider Provisioning Session phase is optionally performed prior to the establishment of any related WebRTC sessions by the RTC Application Provider. Detailed procedure is addressed in clause 5.2.1.\nThe ICE candidate discovery phase is performed with the following steps in an MNO-facilitated RTC system:\n1.\tConfiguration information: The RTC AF uses the RTC-5 interface to provide the RTC MSH with a list of trusted STUN/TURN servers, trusted WebRTC signalling function and data channel servers and their capabilities. The UE may use this configuration information for establishing RTC sessions.\n2.\tICE Servers request: The application queries the RTC MSH for the list of trusted ICE servers.\n3.\tICE candidate validation: The UE discovers and tests the ICE candidates to validate that they are suitable for the connection.\nThe WebRTC session establishment phase is performed with the following steps in an MNO-facilitated RTC system:\n4.\tQuery configuration information: The WebRTC framework queries the RTC MSH for the WebRTC signalling function information. In some cases where the signalling is not handled by WebRTC framework, the native WebRTC application queries the RTC MSH for the WebRTC Signalling server information.\n5.\tConfiguration information: RTC MSH sends the WebRTC signalling function and data channel servers and their capabilities information to WebRTC framework or in some cases with native WebRTC application.\nIn SDP exchange phase, two or more WebRTC endpoints exchange signalling information related to the WebRTC session such as ICE candidates, SDP offer/answer using the trusted WebRTC signalling function.\nNOTE:\tFigure 5.5.1 illustrates that SDP offer is generated by the WebRTC Framework or native WebRTC Application. However, in SFU/MCU mode, SDP offer is generated by Media Function in RTC AS.\n6.\tSDP offer: The WebRTC Framework or native WebRTC Application creates a request with SDP offer which includes the ICE candidates and sends it to the WebRTC signalling function.\n7.\tDetermine remote endpoint location: The WebRTC signalling function uses the registration information to locate the remote endpoint\n8.\tSDP offer: The WebRTC signalling function forwards the request to remote endpoint.\n9.\tSDP answer: Upon accepting the offer, remote endpoint responds to signalling function with SDP answer.\n10.\tSDP answer: WebRTC signalling function sends the SDP answer to the UE1.\nWith this, a WebRTC session is established between RTC endpoints using the most suitable ICE candidate and the WebRTC signalling function.\nThe Dynamic policy phase is then performed to allocate QoS for the media streams of the RTC session with the following steps:\n11.\tQoS request: The WebRTC signalling function sends a request to RTC AF for the allocation of QoS for the session. The RTC AF sends a request to the PCF to allocate QoS for the media streams of the RTC session\n12.\tConfirmation: PCF or SMF confirms the successful allocation of network support or QoS allocation.\nIf the Network support function feature is supported in the RTC AF, then the Network Support Function AF (NS-AF) offers the bitrate recommendation request API based on existing policy templates, through the usage of either the Npcf_PolicyAuthorization API over N5 interface, or the Nnef_AFSessionWithQoS over N33 interface to the PCF. If no corresponding AF application session context already exists, the NS-AF uses the Npcf_PolicyAuthorization_Create method over N5 interface with the appropriate service information to create and provision an application session context. The Network assistance phase is performed with the following steps in an MNO-facilitated RTC system.\n13.\tSubscribe to QoS events: The NS-AF also subscribes to events related to the QoS flows of the WebRTC session with the PCF and SMF.\n14.\tQoS events: The NS-AF receives notifications about any changes to the QoS flows of the WebRTC session from the PCF or the SMF.\n15.\tQoS notifications/ Bitrate recommendations: The NS-AF may send notifications to the RTC MSH about the changes in QoS flow. When the allocated session is active, the RTC MSH forwards the bitrate recommendation to the application.\n16.\tAdjust media bitrate: The WebRTC application may act on adjusting the bitrate recommendation, e.g., by reducing the uplink media bitrate.\nAfter successful creation of a WebRTC session and the bitrate negotiations, the actual WebRTC session over 5G may start:\n17.\tMedia transfer:\na)\tThe WebRTC Application may connect to the selected TURN server and/or Media Function in the RTC AS through the RTC-4m interface and real-time communication starts, and the media is delivered to the remote endpoint.\nb)\tIn some cases, a peer-to-peer connection is also possible and the media is delivered directly to the remote endpoint.\n18.\tMethod calls and notifications: Supporting information about the WebRTC session is passed from the WebRTC framework to the RTC MSH.\n19.\tReporting, network assistance, and dynamic policy: The RTC MSH exchanges supporting information about the WebRTC session with the RTC AF.\n20.\tEnd session: The WebRTC Application informs the WebRTC framework that the RTC session has ended. It is also sent to the WebRTC Signalling Function to terminate the session.\n21.\tSession ending event: The WebRTC framework informs the RTC MSH about the end of the RTC session.\n22.\tFinal reporting: The RTC MSH performs any final reporting to the RTC AF.\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "6\tProcedures for Edge Processing",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "6.1\tClient-driven Management of RTC Edge Processing",
                    "description": "",
                    "summary": "",
                    "text_content": "The detailed call flow for client-driven management of edge processing session is shown in Figure 6.1-1.\nThe figure depicts a client-driven management system for edge processing in a Real-Time Communication (RTC) system. It illustrates the process of managing edge processing tasks, including the selection of edge devices, the execution of edge processing algorithms, and the monitoring and control of edge processing resources. The figure shows a graphical representation of the system, with various components such as edge devices, edge processing algorithms, and edge processing resources. The system is designed to be flexible and scalable, allowing for the addition or removal of edge devices and the adjustment of edge processing algorithms as needed. The figure provides a visual representation of the system's architecture and components, making it easier to understand and manage the edge processing tasks in a RTC system.\nFigure 6.1-1. Client-driven management of RTC edge processing\nThe Edge Computing Provisioning phase is a provisioning phase, that may be repeated several times (e.g., to extend edge processing coverage to new geographical areas or to increase the capacity of an already provisioned area). All steps in this phase are optional and performed on need basis. The steps are:\n1.\tSpawn ECS: In this step, a new ECS instance is instantiated to manage new or increased demand for edge processing.\n2.\tSpawn RTC AF: In this step, a new RTC AF that is edge-enabled is instantiated to handle new or increased demand for WebRTC sessions with edge processing.\n3.\tEES Configuration: The EES is configured for a specific Edge Data Network (EDN).\n4.\tEES Registration with ECS: The EES registers with the ECS that is in authority over the target EDN.\nThe RTC Application Provider Provisioning phase is performed prior to the establishment of any related WebRTC sessions by the RTC Application Provider. Subsequent updates to the provisioning session are possible.\n5.\tCreate Provisioning Session: In this step, the RTC Application Provider creates a new provisioning session.\n6.\tProvision RTC features: In this step, the RTC Application Provider may create different configurations such as QoS support, charging, collection of consumption, offering STUN/TURN servers, WebRTC signalling function, Edge Processing, etc.\nThe WebRTC Application initiates a new RTC session:\n7.\tApplication Initialization: The user launches the WebRTC Application. The WebRTC application performs any required initialization steps.\n8.\tStart session: The WebRTC Application invokes the WebRTC framework with appropriate real-time streaming access parameters.\n9.\tSession starting event: The application informs the RTC MSH about the start of a new WebRTC session over 5G.\n10.\tRetrieve service access information: The RTC MSH retrieves Service Access Information from the RTC AF appropriate to the WebRTC session.\n11.\tDetermine eligibility for requesting edge resources: Using information from the Service Access Information, the RTC MSH determines whether the WebRTC session is eligible for requesting edge resources.\nIf the eligibility criteria are met in the previous step, the UE discovers an EAS instance offering RTC AS functionality in the Client-based Edge Computing Discovery phase:\n12.\tLocate EAS instances: The RTC MSH asks the EEC to discover the location of one or more suitable EAS instances offering the RTC AS capability that can serve the application.\n13.\tLocate local EES: The EEC queries the ECS for a suitable EES (EDGE-4 API).\n14.\tRegister with EES: The EEC registers with the selected EES (EDGE-1 API).\n15.\tRequest list of “RTC AS” EAS instances: The EEC queries the EES for one or more EAS instances offering the “RTC AS” capability that can serve the session, using EAS discovery filters (see Table 8.5.3.2-2 in [2]) provided by the Application Client, e.g. “RTC AS” for EAS type, appropriate values for service feature(s), and other EAS characteristics.\nThe optional sub-flow RTC AS Provisioning is for provisioning an additional RTC AS instance if a suitable EAS instance offering the \"RTC AS\" capability cannot be located. The steps are:\n16.\tCheck resource template: The RTC AF checks the provisioned edge processing resource template for the related application to determine the requirements of the application.\n17.\tInstantiate new EAS/RTC AS: The RTC AF requests the MnS to instantiate a new RTC AS EAS instance with the specified requirements and considering parameters provided in the query by the EEC.\n18.\tSpawn RTC AS instance: The MnS creates a new instance of the EAS offering RTC AS capability with the requested placement and resources.\n19.\tEAS configuration: The newly instantiated RTC AS EAS instance is configured.\n20.\tRegister EAS with EES: The newly instantiated EAS instance registers itself with the triggering EES.\n21.\tConfigure provisioned features: This may include configuring and launching the server-side application in the RTC AS.\nCompletion of UE Edge Computing Discovery phase:\n22.\tList of suitable “-RTC AS” EAS instances: The EES/RTC AF responds to the EEC with a list of “RTC AS” EAS instances and their characteristics in an EAS discovery response (see Table 8.5.3.3-1 in [16]).\n23.\tSelect preferred “RTC AS” EAS instance: The AC and/or EEC select(s) a “RTC AS” EAS instance from the provided list, based on the AC’s desired criteria.\nAfter successful discovery of a “RTC AS” EAS instance, the actual WebRTC session over 5G may start:\n24.\tMedia transfer: The WebRTC Application connects to the selected EAS “RTC AS” and the real-time streaming starts.\n25.\tMethod calls and notifications: Supporting information about the WebRTC session is passed from the WebRTC framework to the RTC MSH.\n26.\tReporting, network assistance, and dynamic policy: The RTC MSH exchanges supporting information about the WebRTC session with the RTC AF.\n27.\tEnd session: The WebRTC Application informs the WebRTC framework that the RTC session has ended.\n28.\tSession ending event: The WebRTC framework informs the RTC MSH about the end of the RTC session.\n29.\tFinal reporting: The RTC MSH performs any final reporting to the RTC AF.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "6.2\tAF-driven Management of RTC Edge Processing",
                    "description": "",
                    "summary": "",
                    "text_content": "The detailed call flow for AF-driven management of edge processing session by using the RTC MSH is shown in Figure 6.2-1.\nThe figure depicts a schematic representation of the AF-driven management of RTC edge processing, illustrating the various components and their interactions. The figure includes a central processing unit (CPU), an area for edge processing, and a management unit (MU). The CPU is responsible for executing the RTC edge processing tasks, while the MU manages the edge processing resources and ensures the efficient allocation of resources. The figure also includes a communication link between the CPU and the MU, allowing for real-time data exchange. The figure is a crucial visual aid in understanding the complex system architecture of the AF-driven management of RTC edge processing.\nFigure 6.2-1. AF-driven management of RTC edge processing\nThe steps are:\n1.\tSteps 1-4 as described in TS 26.501 clause 8.1.\n2.\tCreate Provisioning Session: In this step, the RTC Application Provider creates a new provisioning session.\n3.\tProvision RTC features: In this step, the RTC Application Provider may create different configurations such as QoS support, charging, collection of consumption, offering STUN/TURN servers, WebRTC signalling function, edge processing, etc.\n4.\tRTC AS provisioning if need, as described in Figure 6.1-1, steps 16-21.\nThe WebRTC Application initiates a new RTC session:\n5.\tStart session: The WebRTC Application invokes the WebRTC framework with appropriate real-time streaming access parameters.\n6.\tSession starting event: The application informs the RTC MSH about the start of a new WebRTC session over 5G.\n7.\tRetrieve Service Access Information: The RTC MSH retrieves Service Access Information from the RTC AF appropriate to the WebRTC session.\n8.\tDetermine eligibility for requesting edge resources: Using information from the Service Access Information, the RTC MSH determines whether the WebRTC session is eligible for requesting edge resources.\n9.\tStart the media streaming as defined in Figure 6.1-1, steps 24-26.\n10.\tContinue the final steps as defined in Figure 6.1-1, steps 27-29.\n\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.1\tGeneral",
            "description": "This clause addresses the derivative architecture for each of the collaboration scenarios. The four collaboration scenarios are summarized below and further details is specified in Annex A.\nThe four collaboration scenarios are specified based on the location of required functional entities in trusted domain as defined as follows.\n-\t5G support for OTT WebRTC: in this scenario the WebRTC session runs completely over the top. However, the MNO may offer support in form of QoS allocation, bitrate recommendations, and QoE report collection based on request by the UE.\n-\tMNO-provided trusted WebRTC functions: in this scenario the MNO offers trusted support functions such as ICE servers to the WebRTC application on the UE.\n-\tMNO-facilitated WebRTC services: the MNO hosts and facilitates WebRTC sessions by providing a trusted WebRTC signalling function, which may also offer 5G network assistance.\n-\tInter-operable WebRTC services: collaboration scenario 3 is extended with functions to support MNO to MNO inter-operability.\nNOTE:\tCollaboration scenario 4 is in the scope of this specification. Some of its details, which are not specified in the current version of the document, will be specified, after the relevant works are finished.\nThe list of key functional entities in trusted domain differs from collaboration scenarios as described in Table A.1-1.\nTable A.1-1: Mapping of key functions to each collaboration scenarios\nNOTE:\tThe collaboration scenario 3 may further split depending on the role of MNO, as addressed in TR 26.930.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.1-1: Mapping of key functions to each collaboration scenarios",
                    "table number": 3,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.2\tCollaboration scenario 1:",
            "description": "Figure A.2-1 shows the architecture variant for the collaboration scenario 1 when the WebRTC session is completely running over the top. For this case, many of WebRTC-related entities are not the scope of this specification. However, Network Support Function is present in the trusted domain to support QoS allocation, bitrate recommendations, and QoE report collection.\nThe figure depicts a derivative version of the Real-Time Collaboration (RTC) architecture for collaboration scenario 1, illustrating the components and their interactions.\nFigure A.2-1: Derivative RTC architecture for collaboration scenario 1\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.3\tCollaboration scenario 2:",
            "description": "Figure A.3-1 shows the architecture variant for the collaboration scenario 2 when MNO provides the trusted WebRTC functions such as ICE function. It also contains the configuration function to support the network-assisted WebRTC sessions over 5G system.\nThe figure depicts a derivative RTC architecture for collaboration scenario 2, illustrating the various components and their interactions. The architecture includes a central server, a collaborative workspace, and a collaborative workspace client. The central server manages the collaboration, while the collaborative workspace client facilitates communication and collaboration between the participants. The figure also includes a visual representation of the communication paths and the flow of data between the components.\nFigure A.3-1: Derivative RTC architecture for collaboration scenario 2\nNOTE:\tRTC-4m interface is present only when the ICE function contains the TURN server in this scenario.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.4\tCollaboration scenario 3:",
            "description": "Figure A.4-1 shows the architecture variant for the collaboration scenario 3 when MNO hosts the WebRTC sessions by providing the trusted WebRTC signalling server in RTC AS. In addition, trusted media server is present in RTC AS to support SFU and MCU functionality.\nThe figure depicts a derivative RTC architecture for collaboration scenario 3, illustrating the various components and their interconnections. The architecture includes a central server, multiple collaborative devices, and a communication network. The figure highlights the use of a distributed architecture, with each device having its own role in the system. The collaboration scenario involves multiple users working together, and the architecture is designed to ensure efficient communication and data sharing.\nFigure A.4-1: Derivative RTC architecture for collaboration scenario 3\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.5\tCollaboration scenario 4:",
            "description": "NOTE:\tThis scenario is extended from collaboration scenario 3 by supporting interoperability between multiple MNOs. The details are FFS.\n\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "",
                    "table number": 4,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        }
    ]
}