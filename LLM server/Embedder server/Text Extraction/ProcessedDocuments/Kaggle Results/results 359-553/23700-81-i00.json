{
    "document_name": "23700-81-i00.docx",
    "content": [
        {
            "title": "Foreword",
            "description": "This Technical Report has been produced by the 3rd Generation Partnership Project (3GPP).\nThe contents of the present document are subject to continuing work within the TSG and may change following formal TSG approval. Should the TSG modify the contents of the present document, it will be re-released by the TSG with an identifying change of release date and an increase in version number as follows:\nVersion x.y.z\nwhere:\nx\tthe first digit:\n1\tpresented to TSG for information;\n2\tpresented to TSG for approval;\n3\tor greater indicates TSG approved document under change control.\ny\tthe second digit is incremented for all changes of substance, i.e. technical enhancements, corrections, updates, etc.\nz\tthe third digit is incremented when editorial only changes have been incorporated in the document.\nIn the present document, certain modal verbs have the following meanings:\nshall\tindicates a mandatory requirement to do something\nshall not\tindicates an interdiction (prohibition) to do something\nNOTE 1:\tThe constructions \"shall\" and \"shall not\" are confined to the context of normative provisions, and do not appear in Technical Reports.\nNOTE 2:\tThe constructions \"must\" and \"must not\" are not used as substitutes for \"shall\" and \"shall not\". Their use is avoided insofar as possible, and they are not used in a normative context except in a direct citation from an external, referenced, non-3GPP document, or so as to maintain continuity of style when extending or modifying the provisions of such a referenced document.\nshould\tindicates a recommendation to do something\nshould not\tindicates a recommendation not to do something\nmay\tindicates permission to do something\nneed not\tindicates permission not to do something\nNOTE 3:\tThe construction \"may not\" is ambiguous and is not used in normative elements. The unambiguous constructions \"might not\" or \"shall not\" are used instead, depending upon the meaning intended.\ncan\tindicates that something is possible\ncannot\tindicates that something is impossible\nNOTE 4:\tThe constructions \"can\" and \"cannot\" shall not to be used as substitutes for \"may\" and \"need not\".\nwill\tindicates that something is certain or expected to happen as a result of action taken by an agency the behaviour of which is outside the scope of the present document\nwill not\tindicates that something is certain or expected not to happen as a result of action taken by an agency the behaviour of which is outside the scope of the present document\nmight\tindicates a likelihood that something will happen as a result of action taken by some agency the behaviour of which is outside the scope of the present document\nmight not\tindicates a likelihood that something will not happen as a result of action taken by some agency the behaviour of which is outside the scope of the present document\nIn addition:\nis\t(or any other verb in the indicative mood) indicates a statement of fact\nis not\t(or any other negative verb in the indicative mood) indicates a statement of fact\nNOTE 5:\tThe constructions \"is\" and \"is not\" do not indicate requirements.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "1\tScope",
            "description": "This study focuses on key issue description, solution and evaluation/conclusion on further enhancement for network automation, as documented in TS 23.288 [5], by covering the following objectives:\n-\tStudy possible mechanisms for improved correctness of NWDAF analytics;\n-\tInvestigate whether and how NWDAF can assist application detection;\n-\tInvestigate whether and how to support data and analytics exchange in roaming case;\n-\tInvestigate data collection and data storage enhancements (including DCCF and ADRF enhancements, e.g. DCCF relocation, ADRF selection, ML model storage);\n-\tStudy whether and how to enhance trained ML Model sharing for different vendors;\n-\tStudy whether and how interactions between NWDAF can leverage MDAS/MDAF functionality for data collection and analytics;\n-\tInvestigate NWDAF-assisted URSP;\n-\tStudy whether and how to enhance the QoS sustainability analytics with finer granularity and additional input data;\n-\tStudy whether and how to enhance architecture to support federated learning in the 5GC; and\n-\tStudy NWDAF enhancements considering the finer granularity of location information than TA and cell level.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "2\tReferences",
            "description": "The following documents contain provisions which, through reference in this text, constitute provisions of the present document.\n-\tReferences are either specific (identified by date of publication, edition number, version number, etc.) or non-specific.\n-\tFor a specific reference, subsequent revisions do not apply.\n-\tFor a non-specific reference, the latest version applies. In the case of a reference to a 3GPP document (including a GSM document), a non-specific reference implicitly refers to the latest version of that document in the same Release as the present document.\n[1]\t3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".\n[2]\t3GPP TS 23.501: \"System Architecture for the 5G System; Stage 2\".\n[3]\t3GPP TS 23.502: \"Procedures for the 5G system, Stage 2\".\n[4]\t3GPP TS 23.503: \"Policy and Charging Control Framework for the 5G System\".\n[5]\t3GPP TS 23.288: \"Architecture enhancements for 5G System (5GS) to support network data analytics services\".\n[6]\t3GPP TS 22.071: \"Location Services (LCS); Service description; Stage 1\".\n[7]\t3GPP TS 28.552: \"Management and orchestration; 5G performance measurements\".\n[8]\tITU-T Y.1540: \"Internet protocol data communication service - IP packet transfer and availability performance parameters\".\n[9]\t3GPP TS 28.554: \"5G end to end Key Performance Indicators (KPI)\".\n[10]\t3GPP TS 23.003: \"Numbering, addressing and identification\".\n[11]\t3GPP TS 29.510: \"5G System; Network Function Repository Services; Stage 3\".\n[12]\t3GPP TS 33.501: \"Security architecture and procedures for 5G System\".\n[13]\t3GPP TS 23.273: \"5G System (5GS) Location Services (LCS)\".\n[14]\t3GPP TS 23.032: \"Universal Geographical Area Description (GAD)\".\n[15]\t3GPP TS 28.104: \"Management and orchestration; Management Data Analytics (MDA)\".\n[16]\t3GPP TS 38.314: \"NR; Layer 2 Measurements\".\n[17]\t3GPP TS 29.508: \"5G System; Session Management Event Exposure Service; Stage 3\".\n[18]\t3GPP TS 29.572: \"5G System; Location Management Services; Stage 3\".\n[19]\t3GPP TS 23.008: \"Organization of subscriber data\".\n[20]\t3GPP TS 37.320: \"Radio measurement collection for Minimization of Drive Tests (MDT); Overall description; Stage 2\".\n[21]\t3GPP TS 38.331: \"NR; Radio Resource Control (RRC); Protocol specification\".\n[22]\t3GPP TS 32.422: \"Telecommunication management; Subscriber and equipment trace; Trace control and configuration management\".\n[23]\t3GPP TS 32.423: \"Telecommunication management; Subscriber and equipment trace; Trace data definition and management\".\n[24]\t3GPP TS 28.405: \"Telecommunication management; Quality of Experience (QoE) measurement collection; Control and configuration\".\n[25]\t3GPP TS 28.406: \"Telecommunication management; Quality of Experience (QoE) measurement collection; Information definition and transport\".\n[26]\t3GPP TS 28.532: \" Management and orchestration; Generic management services\".\n[27]\t3GPP TS 28.533: \"Management and orchestration; Architecture framework\".\n[28]\t3GPP TS 28.537: \"Management and orchestration; Management capabilities\".\n[29]\t3GPP TS 28.541: \"Management and orchestration; 5G Network Resource Model (NRM); Stage 2 and stage 3\".\n[30]\t3GPP TR 23.700-71: \"Study on enhancement to the 5GC LoCation Services (LCS); Phase 3\".\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "3\tDefinitions of terms and abbreviations",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "3.1\tTerms",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the terms given in TR 21.905 [1], TS 23.501 [2] and TS 23.503 [4] and the following apply. A term defined in the present document takes precedence over the definition of the same term, if any, in TR 21.905 [1], TS 23.501 [2] and TS 23.503 [4].\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "3.2\tAbbreviations",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the abbreviations given in TR 21.905 [1], TS 23.501 [2] and TS 23.503 [4] and the following apply. An abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in TR 21.905 [1], TS 23.501 [2] and TS 23.503 [4].\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "4\tArchitectural Assumptions and Principles",
            "description": "The architecture for the present study shall be based on the existing NWDAF framework as specified in TS 23.288 [5], TS 23.501 [2], TS 23.502 [3] and TS 23.503 [4].\nSolutions shall comply with the 5G System architectural principles in TS 23.501 [2], and network data analytics principles in TS 23.288 [5].\nIn addition, the following architectural assumptions are followed:\n-\tIn terms of user data privacy and security improvement, the cooperation with SA WG3 is needed;\n-\tFor how to collect user plane data, the cooperation with FS_UPEAS is needed.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "5\tKey Issues",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "5.1\tKey Issue #1: How to improve correctness of NWDAF analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.1.1\tDescription",
                            "text_content": "Correctness of predictions is usually associated to accuracy, which represents the most prominent KPI to rate ML models. However, the accuracy can be corrupted by a wrong calculation and/or unfair feedback collection. It is thus of utmost importance to ensure that the accuracy is meaningful, consistent, and comparable.\nIncorrect predictions can be due to the fact that the accuracy of an ML model during inference may be lower than the accuracy of the same ML model during training. This is likely to happen if the training data set differs significantly in terms of distribution and features from the input data that the ML model is fed with during inference. Knowing how the ML model is meant to be used would help to train the ML model efficiently and effectively.\nThe following aspects need to be studied:\n-\tHow to detect that improving the correctness of an Analytics ID is needed?\n-\tHow and what information is required to compute and represent the correctness of NWDAF analytics in a reliable way?\nNOTE:\tWhether the information is used to represent correctness of NWDAF analytics may depend on the use case.\n-\tWhether and what action(s) should be taken when the NWDAF Analytics are considered incorrect, whether and how a NF can continue consuming an Analytics ID for which the need for improvement has been detected?\n-\tWhether and which action(s) should be taken by consumer NF to help improve correctness of NWDAF Analytics.\n-\tWhether and how the NWDAF can improve correctness of NWDAF Analytics (e.g. which existing and/or additional information may be used by the NWDAF to improve the correctness of NWDAF Analytics)?\n-\tWhether there is a need for architectural and/or functional enhancements for improving correctness of NWDAF Analytics, if there is additional signalling load caused by any new functional enhancement and how to mitigate the signalling?\n-\tHow and which information is needed to enhance the ML model provisioning to improve the correctness of NWDAF Analytics.\n-\tStudy mechanisms to detect that degradation on an ML model has happened and whether and which actions should be triggered.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.2\tKey Issue #2: NWDAF-assisted application detection",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.2.1\tDescription",
                            "text_content": "This key issue proposes to study whether and how the NWDAF can assist the detection of the traffic generated by an application. This KI corresponds to WT#2.1: NWDAF assisted application detection.\nThe detection of traffic generated by an application can be performed using the application detection filters in the UPF/SMF and those application detection filters may include Packet Flow Description(s), i.e. PFD(s). Depending on service level agreements between the operator and the Application Service Provider (ASP), the ASP may provide PFD(s) for each application identifier maintained by the ASP.\nIt will be studied whether and how the NWDAF can assist to identify the traffic specific to a certain application at the UPF.\nThe following issues shall be studied:\n-\tHow to consider the consent of user and ASP (i.e. no privacy and regulatory issue) for performing and exposing the analytics for application detection?\n-\tWhether and how the NWDAF can assist the application detection, considering the following aspects:\n-\tStudy use cases where the NWDAF can assist the application detection, for instance how to detect the application traffic if the ASP provides initial PFD information but does not update it in time or does not update it anymore, or if the ASP does not provide any PFD information.\n-\tIf NWDAF provides analytics to assist the application detection performed at the UPF. What is the potential consumer of these analytics (e.g. NEF/PFDF) and how does that consumer use these analytics?\n-\tWhether new input data needs to be collected by NWDAF to assist the application detection performed at the UPF?\n-\tWhether existing or new Analytics ID(s) are needed to be provided by NWDAF to assist the application detection performed at the UPF?\nSolutions for this key issue shall not cause degradation of UPF performance.\nNOTE:\tCoordination with FS_ UPEAS / Study on UPF enhancement for Exposure and SBA may be needed.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.3\tKey Issue #3: Data and analytics exchange in roaming case",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.3.1\tDescription",
                            "text_content": "In roaming scenario, the HPLMN/VPLMN may need to collect data or consume analytics from the VPLMN/HPLMN. The data or analytics may relate to particular UEs or contain information about all UEs or groups of UEs. Both PLMNs (VPLMN, HPLMN) need the ability to control the amount of data exposed and to abstract or hide network-internal aspects based on user consent, operator policy, regulatory constraints and/or roaming agreements. Use cases for data exchange and analytics exposure between HPLMN and VPLMN require further investigation.\nThe technical aspects to be studied include the following:\n-\tIdentification of use cases and requirements for data and/or analytics exchange between PLMNs (i.e. HPLMN and VPLMN(s)) in roaming scenario. For each use case, identify what raw data, existing or new Analytics IDs needs to be exchanged, and which existing Analytics ID can be enhanced or new Analytics ID can be generated for the roaming user based on the exchanged data\n-\tDetermination of possible architecture enhancements to support this exchange in roaming scenarios and of any necessary enhancements to related NFs in HPLMN and VPLMN, e.g. possible enhancement on data collection using DCCF, or possible enhancement on data storage using ADRF, or possible enhancement on security and privacy of the data and analytics exchange between PLMNs.\nNOTE 1:\tWhere possible, existing capabilities of the 5GC for inter-PLMN communication should be reused, for instance NRF capabilities to authorize access to services, and capabilities of Security Edge Protection Proxy (SEPP) defined in TS 33.501 [12] to manipulate data and to secure the confidentiality, integrity and authenticity of data exchange over the N32 interface between PLMNs.\nNOTE 2:\tCoordination with SA3 on security aspects is required.\nNOTE 3:\tCoordination with GSMA on sharing of user data while roaming may be required.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.4\tKey Issue #4: How to Enhance Data collection and Storage",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.4.1\tDescription",
                            "text_content": "For this Key Issue the following aspects will be studied:\n-\tInteraction between multiple DCCFs and MFAFs (e.g. DCCF or MFAF relocation) if multiple DCCFs are deployed in one PLMN, to facilitate and improve data collection coordination.\n-\tWhether and how to enhance ADRF selection in case of multiple ADRF deployed in the network and whether and how to support ADRF relocation.\n-\tWhether and how the ADRF should store types of data other than historical data and analytics (e.g. ML models, analytics context) for network analytics.\n-\tWhether and what other enhancements are required for storage of data and/or analytics in ADRF, NWDAF and/or data source NF.\n-\tWhether and what other enhancements can be made to further reduce signalling and data traffic and the impact of obtaining data on data sources related to network analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.5\tKey Issue #5: Enhance trained ML Model sharing",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.5.1\tDescription",
                            "text_content": "As described in the below note from clause 5.1, TS 23.288 [5] that in Rel-17 the ID(s) of the NWDAF containing MTLF(s) is locally configured in the NWDAF containing AnLF, and the NWDAF containing AnLF is only allowed to retrieve trained ML model(s) from the configured NWDAF containing MTLF(s).\nNOTE 3:\tIn this Release of the specification an NWDAF containing AnLF is locally configured with (a set of) IDs of NWDAFs containing MTLF and the Analytics ID(s) supported by each NWDAF containing MTLF to retrieve trained ML models. An NWDAF containing AnLF uses NWDAF discovery for NWDAF containing MTLF within the set of configured IDs of NWDAFs containing MTLF, if necessary. ML Model provisioning/sharing between multiple MTLFs is not supported in this Release of the specification.\nIn Rel-18, the following aspects are to be studied to enhance trained ML Model sharing between NWDAFs from different vendors:\n-\tHow to discover and select a NWDAF containing MTLF even from different vendors which can provide interoperable trained ML model(s), and how to retrieve interoperable trained ML model(s) from it, by a NWDAF containing AnLF, including:\n-\tWhether and what new functionality / function(s) is needed for support of trained ML model interoperability?\n-\tWhat additional information should be exchanged between the NWDAF containing MTLF and the NWDAF containing AnLF, for support of trained ML model interoperability.\n-\tWhether and how to define common characteristics for trained ML models from different vendors?\nNOTE 1:\tCoordination with SA5 is needed for ML model sharing aspects.\nNOTE 2:\tCoordination with SA3 is needed for security aspects related to ML model sharing (e.g. ML model integrity, authorization of use, etc.) as investigated by this Key Issue.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.6\tKey issue #6: NWDAF-assisted URSP",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.6.1\tDescription",
                            "text_content": "NWDAF can already provide some network analytics to PCF for policy decisions as described in clause 6.1.1.3 in TS 23.503 [4]. However, further investigation is required on whether and how analytics can be used to assist in the generation of URSP Rules.\nIn this key issue, the following aspects need to be studied:\n-\tWhether any and which components of the URSP rules can benefit from analytics.\n-\tWhether and how existing Analytics IDs, or new Analytics ID(s) can be used to assist in the generation of URSP Rules.\n-\tWhat procedures trigger the subscription to these Analytics IDs.\n-\tWhether new (set of) interactions(s) are required to assist in the generation of URSP Rules as defined in Rel17, and how to define the new interactions if needed.\n-\tWhat information should be collected (or provided) as input (or output) by the NWDAF for these Analytics IDs.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.7\tKey Issue #7: Enhancements on QoS Sustainability analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.7.1\tDescription",
                            "text_content": "Currently, NWDAF can provide Cell level QoS Sustainability analytics with limited QoS parameters, i.e. RAN UE Throughput and QoS Flow retainability. More KPIs reporting for QoS Sustainability analytics would benefit, e.g. for V2X use cases as defined by 5GAA.\nTherefore, the following aspects are needed to be studied for QoS Sustainability analytics enhancement:\n-\tWhether and how to enhance the QoS Sustainability analytics with a finer granularity area (e.g. below Cell level)? Or alternatively if a new Analytics ID is required for the finer granularity area for this purpose?\n-\tWhether and how to enhance the QoS Sustainability analytics (or a new Analytics ID) with additional input and/or output data?\n-\tWhether and how to enhance the request for QoS Sustainability analytics (or a new Analytics ID)?\nNOTE:\tCoordinated activities with 5GAA are needed.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.8\tKey Issue #8: Supporting Federated Learning in 5GC",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.8.1\tDescription",
                            "text_content": "This contribution is related to WT # 4.1.\nCurrent enablers for network automation architecture by NWDAF still faces some major challenges as follows:\n-\tUser data privacy and security (protected by e.g. GDPR) has become a worldwide issue, it is also difficult for NWDAF to collect UE level network data.\n-\tWith the introduction of MTLF in Rel-17, various data from wide area is needed to train an ML model for NWDAF containing MTLF. However, it is difficult for NWDAF containing MTLF to collect all the raw data from distributed data source in different areas.\nIn order to address the challenges, 3GPP tries to adopt Federated Learning (also called Federated Machine Learning) technique in NWDAF containing MTLF to train an ML model, in which there is no need for raw data transferring (e.g. centralized into NWDAF) but only need for cooperation among multiple NWDAFs (MTLF) i.e. sharing of ML model and of the learning results among multiple NWDAFs (MTLF). In Rel-17, however, the cooperation of multiple NWDAF containing MTLF is explicitly prohibited and it is only allowed for NWDAF containing AnLF to subscribe or request the ML model from the configured NWDAF containing MTLF\nThis Key Issue is aim to study architecture enhancement to support Federated Learning which allows the cooperation of multiple NWDAF containing MTLF to train an ML model in 3GPP network with the following aspects:\n-\tIdentify the use cases that required Federated learning in 5GC;\n-\tStudy the registration and discovery of the NWDAF supporting Federated Learning;\n-\tStudy how to decide whether Federated Learning is required or not for an existing Analytics ID or a new Analytics ID;\n-\tStudy how to coordinate multiple NWDAFs including selection of participant NWDAF instances in the Federated Learning group, e.g. assistance information (if any) to perform the selection, and decision of role for the participant NWDAF;\n-\tStudy whether and how to perform performance (e.g. network performance and model performance) monitoring of the NWDAF Federated Learning operation.\nNOTE 1:\tPerformance monitoring of Federated Learning operation should be aligned with mechanisms for improved correctness of analytics defined in WT#1.2.\nNOTE 2:\tIn terms of user data privacy and security improvement, the cooperation with SA3 is needed.\nNOTE 3:\tThe impact on UE and RAN shall be avoided for this Key Issue.\nNOTE 4:\tSolutions requiring model distribution for FL should be aligned with mechanism for model sharing defined in WT#3.2.\nNOTE 5:\tServer NWDAF connects to one layer of Client NWDAFs, and any of the Client NWDAFs cannot cascade more sublayers.\nNOTE 6:\tAll the NWDAFs attending the Federated Learning should belong to the same PLMN.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.9\tKey Issue #9: Enhancement of NWDAF with finer granularity of location information",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.9.1\tDescription",
                            "text_content": "The NWDAF can retrieve and collect UE location information and then provide some analytic(s) to NWDAF consumer(s), e.g. UE mobility analytics, QoS Sustainability Analytics as defined in TS 23.288 [5]. However, the UE location information that NWDAF can obtain is only TA/cell granularity in Rel-17.\nThe horizontal accuracy and the vertical accuracy of the existing location service can reach a granularity level finer than TA and cell level. Meanwhile, some extra information (e.g. speed, heading) could possibly also be provided by the location service. But whether such LCS related information is beneficial for the NWDAF is not clear, and it also needs to be studied how the NWDAF can obtain such LCS related information. Therefore, a KI to study whether and how the NWDAF can provide additional benefits from location service is required.\nIn this key issue, the following aspects will be studied:\n-\tIdentify use case(s) and corresponding existing or new Analytics ID(s) where the analytics require location information with finer granularity than TA/cell level, and how to enhance related existing Analytics ID(s).\n-\tIdentify how an NWDAF determines that location information with finer granularity than cell/TA level is required in output analytics.\n-\tIdentify what input data needs to be collected to deliver analytics with fine granularity location information.\n-\tIdentify how NWDAF acquires the input data to deliver finer granularity location information. Whether and how the functionality and services of NWDAF or other NF(s) need to be enhanced.\nNOTE 1:\tCoordinated activities with the eLCS_ph3 study are needed.\nNOTE 2:\tSome examples of UE location different than cell/TA level are described in clause 4.2 and 4.3, TS 22.071 [6].\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.10\tKey Issue #10: Interactions with MDAS/MDAF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.10.1\tDescription",
                            "text_content": "MDAS/MDAF functionality enables a service consumer to obtain management data analytics, and NWDAF can be one of such service consumers. The following aspects shall be studied:\n-\tIdentify which use case(s) should be applied for the interactions between NWDAF and MDAS/MDAF.\n-\tWhether and how NWDAF can leverage MDAS/MDAF functionality, for producing Analytics ID(s) given in TS 23.288 [5].\n-\tWhether and how NWDAF can leverage MDAS/MDAF functionality for data collection.\n-\tHow MDAS/MDAF instances are discovered and selected by NWDAF.\nNOTE 1:\tSolution impacts to MDAS/MDAF need SA5 to give inputs before conclusions are made.\nNOTE 2:\tStudying the MDAS/MDAF output is out scope of this KI.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "6\tSolutions",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "6.0\tMapping Solutions to Key Issues",
                    "description": "",
                    "summary": "",
                    "text_content": "Table 6.0-1: Mapping of solutions to key issues\n\n",
                    "tables": [
                        {
                            "description": "Table 6.0-1: Mapping of solutions to key issues",
                            "table number": 3,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "6.1\tSolution #1: Improving Correctness using multiple ML models for an analytics report",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.1.1\tDescription",
                            "text_content": "TS 23.288 [5] assumes that the NWDAF containing AnLF has a single ML model for inferring analytics, at a given time, after applying any potential analytics filter. However, in many scenarios, it is possible that the NWDAF containing AnLF may have multiple ML models at its disposal, and therefore, multiple ML models can be used to generate the analytic reports provided by a given Analytics ID.\nHaving the NWDAF containing AnLF multiple ML models to choose from, enables use cases where an ML model can be selected depending on, e.g. the UE location, time of day, network load, level of accuracy or any other filter of information. NWDAF containing AnLF could indicate e.g. list of time period of Interest, list of accuracy level of Interest to NWDAF containing MTLF, which could be used by NWDAF containing MTLF to filter out the corresponding multiple models accordingly.\nThis solution is based on the existence of several models to draw a prediction for a single Analytics ID. In all these scenarios, the following functionalities needs to be taken into consideration:\n-\tEach ML model needs to have a unique identifier within the PLMN which is assigned by the ML model creator, i.e. an NWDAF containing MTLF. The ML Model unique identifier may be created, e.g. upon the NF Instance ID of the NWDAF containing an MTLF and a serial number. The exact format and encoding of the ML model unique identifier is left to stage 3.\n-\tAn NWDAF containing AnLF should be able to get all available ML models for a specific Analytics ID, from an NWDAF containing MTLF.\n-\tFor the case of ML model provisioning, an NWDAF containing AnLF should be able to request ML model information (i.e. the parameters described in clause 6.2A.2 of TS 23.288 [5]) for an Analytics ID, from an NWDAF containing MTLF, and be able to receive responses including more than one ML model for the same Analytics ID.\n-\tUpon reception of multiple ML model information for the same Analytics ID, the NWDAF containing AnLF should be able to choose and download the model(s) of its choice.\nFigure 6.1.1-1 presents an example of an NWDAF containing AnLF that collects multiple data, feeds each data to a multiple and different ML models, and uses three ML models for generating predictions for the same Analytics ID. Once a given ML model has generated a prediction, an internal logic in the aggregation/voting unit selects the best prediction and delivers it to the consumer. Therefore, the consumer is provided with the best of the three predictions or an optimized aggregated prediction.\nThe figure depicts a voting system where the aggregation process chooses the best prediction. Aggregation is a process that combines multiple predictions to produce a single output. In this case, the aggregation process is shown in Figure 6.1.1-1, where the best prediction is chosen from the aggregated predictions. This system is based on the concept of voting, where each prediction is given a weight based on its likelihood, and the aggregation process selects the prediction with the highest weight. This process is crucial in decision-making systems, as it ensures that the best possible prediction is chosen, leading to more accurate and reliable outcomes.\nFigure 6.1.1-1: Aggregation/voting chooses the best prediction\nNOTE:\tThe aggregation/voting function in Figure 6.1.1-1 is for illustration purposes and is left to implementation logic.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.1.2\tProcedures",
                            "text_content": "This solution does not require new procedures. However, the existing procedures for provisioning an ML model are extended to allow the description of multiple ML models: the data of several service operations are modified to accommodate the reference to multiple ML models and the delivery of multiple predictions.\nAfter the NWDAF containing AnLF selects the proper NWDAF containing MTLF via the NRF procedures, figure 6.1.2.2-1 illustrates a subscription using the Nnwdaf_MLModelProvision_Subscribe service operation for a given Analytics ID. This service operation is enhanced with an indication from the consumer declaring support for multiple ML models.\nThen an Nnwdaf_MLModelProvision_Notify request is enhanced with the capability of including, for a given Analytics ID, pairs of unique identifiers of the ML model and its corresponding ML model information (as per clause 6.2A.2 of TS 23.288 [5]).\nThen, the NWDAF containing AnLF can find out whether it has already downloaded any of the ML models identified by the unique identifier and may decide to request, from the NWDAF containing MTLF, one or more ML models of its choice which has not already downloaded.\nThe NWDAF containing MTLF analyses the ML Model data privacy, and if the NWDAF containing AnLF is authorized to receive the requested ML Models, the NWDAF containing MTLF provide the authorized pairs of unique identifiers of the ML model and its corresponding ML model information to the NWDAF containing AnLF.\nNOTE:\tThe ML Model data privacy may determine that one or more requested ML Models cannot be provided to this NWDAF containing AnLF.\nThe figure depicts enhancements to the Nnwdaf_MLModelProvision services, including the addition of a new service called Nnwdaf_MLModelProvision_ML, which provides a more advanced model for provisioning ML models. The figure also includes a new service called Nnwdaf_MLModelProvision_ML_ML, which provides a more advanced model for provisioning ML models. The figure also includes a new service called Nnwdaf_MLModelProvision_ML_ML, which provides a more advanced model for provisioning ML models. The figure also includes a new service called Nnwdaf_MLModelProvision_ML_ML, which provides a more advanced model for provisioning ML models. The figure also includes a new service called Nnwdaf_MLModelProvision_ML_ML, which provides a more advanced model for provisioning ML models. The figure also includes a new service called Nnwdaf_MLModelProvision_ML_ML, which provides a more advanced model for provisioning ML models. The figure also includes a new service called Nnwdaf_MLModelProvision_ML_ML, which provides a more advanced model for provisioning ML models. The figure also includes a new service called Nnwdaf_MLModelProvision_ML\nFigure 6.1.2.2-1: Enhancements to Nnwdaf_MLModelProvision services\nFigure 6.1.2.2-2 illustrates an NWDAF containing AnLF sending an Nnwdaf_MLModelInfo_Request request for a given Analytics ID to an NWDAF containing MTLF. This service operation is enhanced with an indication from the consumer declaring support for multiple ML models.\nThe NWDAF containing MTLF sends an enhanced response including, for a given Analytics ID, pairs of unique identifiers of the ML model and its corresponding ML model information (the ML model information is described in clause 6.2A.2 of TS 23.288 [5]).\nThe figure depicts an enhanced version of the Nnwdaf_MLModelInfo service, which includes improved performance and enhanced functionality. The service now supports multiple models and includes a new feature for model selection. The figure also highlights the importance of data quality and data consistency in the model selection process.\nFigure 6.1.2.2-2: Enhancements to Nnwdaf_MLModelInfo service\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.1.3\tImpacts on existing nodes and functionality",
                            "text_content": "The interfaces related to ML Model provisioning are updated to support multiple ML model in the following ways:\n-\tNnwdaf_MLModelProvision_Subscribe and Nnwdaf_MLModelInfo_Request are enhanced with an indication, inserted by the consumer, indicating whether the consumer supports multiple ML models for the same Analytics ID.\n-\tNnwdaf_MLModelProvision_Notify and the response to Nnwdaf_MLModelInfo_Request are enhanced for supporting the provisioning of data related to multiple ML models for the same Analytics ID, including pairs of unique identifiers of the ML Model together with its corresponding ML Model information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.2\tSolution #2: Improving the Correctness of Service Experience Predictions with Contribution Weights",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.2.1\tDescription",
                            "text_content": "This solution addresses the following aspects of Key Issue #1 for the Service Experience Analytics ID.\n-\tHow and what information is required to compute and represent the correctness of NWDAF analytics in a reliable way?\n-\tWhether and how the NWDAF can improve correctness of NWDAF Analytics (e.g. which existing and/or additional information may be used by the NWDAF to improve the correctness of NWDAF Analytics)?\nWhen Service Experience information is provided to the NWDAF for multiple UEs, the NWDAF does not know the relative importance of the Service Experience value (i.e. MOS) that was provided by each UE. For example, it might be that one the Service Experience of one UE is not very important because the UE is an infrequent user of the service, or the UE does not use all features that are associated with the service. Whereas another UE might be a frequent user of the service or a \"power user\" who uses many features that are associated with the service.\nThis solution proposes that, when the AF provides Service Experience Information for a group UEs, the AF can also provide a \"Service Experience Contribution Weight\" with each UE's Service Experience value. The \"Service Experience Contribution Weight\" is determined by the AF and indicates the relative importance of each UE's Service Experience. The NWDAF can then use this information to derive more accurate predictions and confidence values. For example, the NWDAF may choose to give less weight, or importance to a Service Experience value that is associated with a \"Service Experience Contribution Weight\" that is lower than other \"Service Experience Contribution Weights\". The format of the \"Service Experience Contribution Weight\" may be defined by stage-3 but an example is that the \"Service Experience Contribution Weight\" may be an integer value with a range that is agreed on between the MNO and AF where a higher value indicates more importance than a lower value. The NWDAF may use the \"Service Experience Contribution Weight\" values the improve the correctness of its Service Experience predictions and confidence values calculations (e.g. giving less weight to less important values will result in improved correctness of its predictions).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.2\tProcedures",
                            "text_content": "The NWDAF subscribes to the service data from the AF (i.e. the information in the Table 6.4.2-1 of TS 23.288 [5]) either directly for trusted AFs by invoking Naf_EventExposure_Subscribe service (Event ID = Service Experience information, Event Filter information = Area of Interest, Application ID) as defined in TS 23.502 [3], or indirectly for untrusted AFs via NEF by invoking Nnef_EventExposure_Subscribe service (Event ID = Service Experience information, Event Filter information = Area of Interest, Application ID).\nWhen the AF provides the Service Experience Information (i.e. the information in the Table 6.4.2-1 of TS 23.288 [5]) the AF can also provide a \"Service Experience Contribution Weight\" for each Service Experience value.\nThe NWDAF considers the \"Service Experience Contribution Weight\" values when calculating Service Experience predictions and confidence values. How the NWDAF uses the \"Service Experience Contribution Weight\" values when calculating Service Experience predictions and confidence values is left to NWDAF implementation and is not in scope of 3GPP.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.3\tImpacts on existing nodes and functionality",
                            "text_content": "AF:\n-\tSends the \"Service Experience Contribution Weight\" when sending a notification in response to an Naf_EventExposure_Subscribe service invocation (Event ID = Service Experience information).\nNWDAF:\n-\tReceives the \"Service Experience Contribution Weight\" when receiving a notification in response to an Naf_EventExposure_Subscribe service invocation (Event ID = Service Experience information).\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.3\tSolution #3: Accuracy based NWDAF Analytics Correctness Improvement",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.3.1\tDescription",
                            "text_content": "This solution is about KI #1: How to improve correctness of NWDAF analytics to address how to improve correctness of NWDAF analytics.\nIn AI community, there is a concept called 'accuracy' which is used to indicate the correctness of an AI/ML model's predictions. The Accuracy is the percentage of correct predictions in all predictions. One of methods to determines a prediction is correct is to compare the prediction with its corresponding ground truth data i.e. the label data.\nFor the regression problems, the predictions and the ground truth data may be not same but similar, and their difference can be calculated by other methods e.g. Mean Absolute Error (MAE). If this difference is smaller than a threshold, this prediction should be considered as correct.\nThe figure depicts a graph with various data points representing different aspects of AI community accuracy. The axes represent different metrics such as accuracy, precision, recall, and F1 score, with different colors and shapes indicating different levels of accuracy. The legend provides a clear explanation of the axes and the data points, making it easy to understand the trends and patterns in the data. The figure provides a comprehensive overview of the AI community's performance in different aspects of accuracy, highlighting the challenges and opportunities in the field.\nFigure 6.3.1-1: Accuracy in AI Community\nAs shown in Figure 6.3.1-2, Accuracy in Training (AiT) and Accuracy in Use (AiU) can be used to measure the correctness of a ML model, the Accuracy in Use should be observed/monitored by the NWDAF/network, which could be a trigger for NWDAF(MTLF) to re-train the ML Model if Accuracy in Use cross a threshold:\nThe figure depicts the accuracy of training with a training dataset and the accuracy of use with a live network dataset. It shows that the training dataset has a higher accuracy than the use dataset, indicating that the model is more accurate when trained on a real-world dataset.\nFigure 6.3.1-2: Accuracy in Training with Training dataset vs Accuracy in Use with live network dataset\nAs shown in left side of the Figure, a NWDAF(MTLF) trained a ML Model with Training dataset (input data, ground truth data) and the Accuracy in Training is to indicate the performance of ML model in training stage by comparing prediction with ground truth data in validation dataset reserved from training dataset.\nThe NWDAF(MTLF) deliver the trained ML Model to a NWDAF(AnLF), which will be used by the NWDAF(AnLF) to perform inference with input data from live network.\n1)\tAs shown in right side of the Figure, Accuracy in Use is to indicate the performance of ML model used in live network by comparing prediction with the observed label data i.e. ground truth from the live network.\nPlease note that the NWDAF(AnLF) performs inference with live network input data to get the prediction and also retrieves the label data from live network.\n2)\tHowever, due to some reasons, e.g. different data distribution between training data set and data in live network, poor model generalization ability, etc. there may be a gap between Accuracy in Training and Accuracy in Use, and the Accuracy in Use usually is not as good as Accuracy in Training especially as times goes by.\nThe NWDAF(AnLF) decides to indicate the NWDAF(MTLF) to re-train the AI/ML model e.g. if Accuracy in Use crosses a threshold or the gap between Accuracy in Training and Accuracy in Use crosses a threshold.\nIn order to improve training data quality e.g. the data distribution, the NWDAF(AnLF) also provides the input data, ground truth data, where prediction is regarded as incorrect prediction by comparing with ground truth data, to help the NWDAF(MTLF) to re-train a better AI/ML Model e.g. with model generalization ability.\nOn the other hand, based on local configuration, the NWDAF(MTLF) could decide to calculate the Accuracy/MAE in Use after collecting the data (the input data, predictions and the corresponding ground truth data) from the NWDAF(AnLF) or ADRF, and decides to re-train models.\nNote:\tInput data is the necessary data which is collected by AnLF to perform inference to generate prediction and the ground truth data is the actual measured data of the prediction. In other words, the \"ground truth data\" is the measured data that corresponds or relates to the one predicted.\nSimilarly, regarding regression, MAE in training and MAE in use is introduced to measure the ML model correctness.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.3.2\tProcedures",
                            "text_content": "Figure 6.3.2-1 depicts the procedure for the proposed solution that the AnLF collects the ground truth data and calculates the AiU.\nThe figure depicts a collection of ground truth data and calculates the Accuracy/MAE in use, illustrating the process of collecting and analyzing data for an LF (Local Frequency) system.\nFigure 6.3.2-1: AnLF collect ground truth data and calculate Accuracy/MAE in use\n1.\tThe NWDAF(AnLF) service consumer subscribes to analytics information by invoking the Nnwdaf_AnalyticsSubscription_Subscribe service operation. The parameters that can be provided by the NWDAF service consumer are listed in clause 6.1.3 of TS 23.288 [5].\n2.\tThe NWDAF(AnLF) subscribes to a NWDAF(MTLF) a trained ML Model by invoking the Nnwdaf_MLModelProvision (Analytics ID, ML Model Filter Information, Accuracy/MAE requirement) service operation.\n3~4.\tThe MTLF trains the model according to the requirement from AnLF and notifies the AnLF with the ML model information by invoking Nnwdaf_MLModelProvision_Notify (Analytic ID, the file address of the trained ML model, Accuracy in Training (AiT) or MAE in Training) service operation.\n5~8.\tThe AnLF collects the input data from data providers, e.g. OAM, NFs, makes predictions and sends the predictions to the NF consumer. The AnLF also collects the ground truth data, which is actual measured data and corresponding to the prediction calculated by AnLF (based on the trained ML Model provided by the MTLF).\n9.\tThe AnLF calculates the Accuracy in Use or the MAE in Use, which reflects the performance of ML model used in live network by comparing prediction with the corresponding ground truth data retrieved from the live network by the AnLF in step 6.\n10.\tThe AnLF compares the Accuracy in Use with the Accuracy in Training and/or MAE in Use with MAE in Training and decide whether or not to send notification to MTLF to re-train the AI/ML model e.g. if Accuracy in Use cross a threshold or by comparing the Accuracy in Training and Accuracy in Use.\n11~12.\tThe AnLF reuse MLModelProvision service (subscription Correlation ID, Analytic ID, AiU or MAE in Use, the corresponding time scale, input data and ground truth data) to modify of the original ML model subscription in step 2, indicating to the MTLF that the Accuracy in Use or MAE in Use is not good as the Accuracy in Training or MAE in Training and the MTLF retrains the model with new data from the AnLF.\nBoth AiU or MAE in Use and the corresponding time scale are indicated to MTLF, indicating AiU or MAE in Use is calculated within the corresponding time scale.\nIn order to improve training data quality e.g. the data distribution, the AnLF provides the input data, ground truth, where prediction is regarded as incorrect prediction by comparing with the ground truth:\n-\tIn the case of classification, if the prediction is not same with its corresponding ground truth data retrieved from live network then this prediction should be considered as incorrect.\n-\tIn the case of regression, if the difference e.g. Mean Absolute Error (MAE) between the prediction and its corresponding ground truth data is greater than a threshold, this prediction should be considered as incorrect.\n14~15.\tThe AnLF notifies the consumer that the Accuracy in Use is not as good as the Accuracy in Training to consequently stop using the provided analytic result by invoking the Nnwdaf_AnalyticInfo_Notify (Analytic ID, AiU, Disable notification).\nFigure 6.3.2-2 depicts the procedure for the proposed solution that the AnLF collects the ground truth data but MTLF calculates the AiU.\nThe figure depicts the calculation of MTLF (Mean Absolute Error) accuracy/MAE (Mean Absolute Error) in use with collected data by AnLF (Anomaly Localization Framework). The MTLF is a metric used to evaluate the performance of anomaly detection algorithms, and the accuracy/MAE is a measure of the precision of the detection. The figure shows the calculation process, including the input data, the calculation of MTLF, and the output results.\nFigure 6.3.2-2: MTLF calculate Accuracy/MAE in use with collected data by AnLF\n1-8.\tThe procedures are same as described in step 1-8 of clause 6.3.2.1 except in step 4 the MTLF in addition indicates that the MTLF need data (input data, prediction and its corresponding ground truth data) to monitor the performance of the ML model.\n9.\tThe AnLF sends the data to the MTLF by reusing the MLModelProvision service (subscription Correlation ID, Analytic ID, input data, prediction and its corresponding ground truth data).\nAlternatively, the AnLF could store the data in the ADRF by using Nadrf_DataManagement_StorageRequest , which could be retrieved by MTLF to calculate Accuracy/MAE in use.\n10-11.\tThe MTLF calculates the Accuracy/MAE in Use by comparing predictions and the corresponding ground truth data retrieved from the AnLF in step 9, and compares the Accuracy/MAE in Use with the Accuracy/MAE in Training and decide whether or not to re-train the ML model.\n12.\tThe MTLF may collect the new data for re-training from data providers, e.g. OAM, NFs.\n13.\tThe MTLF re-trains the ML model with the data collected in step 9 and step 12, and notifies the AnLF with the re-trained model and accuracy report (Accuracy/MAE in Use and/or Accuracy/MAE in re-training).\n14-15.\tThe procedures are same as described in step 13-14 of clause 6.3.2.1.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.3.3\tImpacts on services, entities and interfaces",
                            "text_content": "The solution has the following impacts:\nNWDAF(AnLF):\n-\tCollects data from corresponding data provider(s) to calculate the Accuracy in Use and MAE in Use.\n-\tSends the notifications to the NWDAF(MTLF) and consumer to inform the Accuracy in Use or MAE in Use has decreased.\n-\tSends data (input data, prediction and its corresponding ground truth data) to the MTLF or ADRF.\nNWDAF(MTLF):\n-\tReceives the notification that the Accuracy in Use or MAE in Use has decreased from NWDAF(AnLF) and re-trains the AI/ML Model.\n-\tReceives data from the AnLF to calculate Accuracy/MAE in Use, which are notified to NWDAF(AnLF).\nNWDAF service Consumer:\n-\tReceives the notification that the Accuracy in Use or MAE in Use has decreased from NWDAF(AnLF) and stops using the analytics provided by the NWDAF(AnLF).\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.4\tSolution #4: Determining ML model drift for improving analytics accuracy",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.4.1\tDescription",
                            "text_content": "The accuracy of analytic output from an NWDAF depends very much on the accuracy of the ML model provided by the MTLF NWDAF.\nThe training data that are used to train an ML model are usually historical data (data stored in the ADRF). The validity/accuracy of the ML model depends on whether the training data used are up to date with the real-time network configuration/behaviour. For example, compared to when the training data were collected the network operator may configure additional network resources to a network slice, or the number of users accessing services via the core network may considerably increase (e.g. tourist season in the summer). Such use case may cause a model drift given that ML model was not trained with up-to-date data.\nThere are many reasons that ML model drift can occur but the main cause is a change of the data with time. A simple solution to this problem is to re-train an ML model periodically. Such approach will ensure that the NWDAF always uses an up-to-date training data for an ML model. However, such approach requires considerable resources and is not energy efficient. Hence a solution is required to allow the network (i.e. NWDAF) to determine when an ML model requires re-training.\nThe solution proposed in this paper focuses on the NWDAF to evaluate if an action taken by a consumer would result in a model drift and then evaluate if the training data are up-to-date.\nA general procedure is provided in the figure below.\nThe figure depicts a model drift detected at the NWDAF MTLF, highlighting the importance of maintaining accurate model updates to ensure accurate and reliable communication systems.\nFigure 6.4.1-1: Model drift detected at NWDAF MTLF\nThe general steps followed are:\n-\tA consumer of analytics determines an action and optionally provides the action taken to the MTLF\n-\tThe MTLF determines if the action taken would significantly change the behaviour of one or more NFs and determine if there could be a data drift\n-\tThe MTLF compares the training data with real-time (or near-real time) data and evaluate if (any) data drift detected would result in an ML model drift that would reduce the accuracy of the analytics.\nNOTE:\tThe MTLF can use statistical methods to determine if there is data drift. Such approach is out of scope of 3GPP.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.4.2\tProcedures",
                            "text_content": "The procedure is shown below:\nThe figure depicts a model drift determined at the Multi-Layer Distribution Antenna (MTLDAF) of the 6.4 GHz band, highlighting the importance of maintaining accurate model accuracy in wireless communication systems.\nFigure 6.4.2-1: Model drift determined at MTLF NWDAF\n1.\tA consumer requests analytics including an Analytics ID as per TS 23.288 [5]. For example, a consumer can request analytics for an Analytics ID for NF load. The request may include a minimum accuracy may denote a confidence level of the analytics requested. The consumer may include an indication that it can provide feedback on an action taken.\n2.\tThe AnLF request an ML model from the MTLF NWDAF to derive analytics for the Analytics ID requested if the AnLF has no ML model available for the requested Analytics ID.\n3.\tThe MTLF NWDAF provides the current trained ML model for the Analytics ID.\n4.\tThe MTLF provides the requested ML model to the AnLF NWDAF. Based on the feedback indication provided by the consumer the MTLF may include in the request to provide feedback when a consumer determines an action based on analytics provided by the AnLF. The feedback is used to determine whether drift detection should be carried out for an ML model (see step 10). The MTLF includes a notification correlation ID in the request.\n5.\tThe AnLF NWDAF derives analytics.\n6.\tThe AnLF NWDAF provides requested analytics to the consumer. The AnLF also forwards the feedback request received from the MTLF.\n7.\tThe consumer may determine an action based on the received analytics. For example, if the analytics indicate a high load at a UPF function the consumer, i.e. SMF, may select a less loaded UPF.\n8.\t[CONDITIONAL] Based on the feedback indication the consumer determines to report a network behaviour change including a time where the action was taken.\nNOTE:\tHow the consumer determines that the action taken changes the behaviour of the network is implementation specific.\n9.\t[CONDITIONAL] The consumer reports to the AnLF/MTLF that the action t will change the behaviour of the network.\nEditor's note:\tThe type of actions that the consumer can provide is FFS.\n10.\tThe MTLF determines based on the received feedback to evaluate the accuracy of the ML model. Alternatively, the MTLF at regular intervals initiates an ML model drift detection as described in steps 12-14.\n11.\tThe MTLF NWDAF subscribes to historical data that were used to train the ML model for the specific Analytic ID from the ADRF.\n12.\tThe MTLF NWDAF subscribes to real-time data (or near real time data) from the 5GC NFs, AF, OAM that are required to derive analytics for an Analytic ID (as described for each Analytic ID in TS 23.288 [5].\n13.\tThe MTLF NWDAF determines model drift by comparing historical data with near real time data. The MTLF NWDAF may use statistical analysis or use AI/ML procedures to determine data/model drift (out of scope of 3GPP).\n14.\tIf the MTLF NWDAF determines that Model drift exceed a threshold the MTLF retrains the ML model.\n15.\tThe MTLF NWDAF may notify the AnLF that the ML model drift exceeds a threshold. The notification may notify the AnLF to stop using the ML model to provide analytics. The MTLF NWDAF may also provide an indication on when the updated ML model will be available.\n16.\tBased on the indication received from the MTLF the AnLF may indicate to the analytics consumer a pause in the subscription because an ML model requires retraining. The AnLF may also indicate the time new analytics will be available.\n17.\tThe MTLF NWDAF provides the re-trained ML model to the AnLF NWDAF.\n18.\tThe AnLF notifies the consumer to resume subscription indicating analytics are available.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.4.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tMTLF: Identifying ML model drift by comparing historical data with real-time data.\n-\tConsumer of analytics: Providing feedback to AnLF/MTLF on an action taken.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.5\tSolution #5: Enhancements on ML model provision to improve correctness of NWDAF analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.5.1\tDescription",
                            "text_content": "This is a solution for Key Issue #1: \"How to improve correctness of NWDAF analytics\".\nThis solution introduces several options for improving the correctness of NWDAF analytics by enabling the ability of self-correction on NWDAF based on closed-loop control.\nSpecifically, in case of analytics for prediction, the provided analytics (i.e. desired data and events for prediction) by an NWDAF can be different to actual data or events occurred in analytics target period and it may become significant faults on the consumer NF action. In order to address the potential faults on NF action, this solution proposes that the procedures for NWDAF: i) to monitor the accuracy of the provided analytics; and ii) to correct potential errors on analytics; as described in clause 6.5.2.\nFor details, NWDAF is decomposed into AnLF and MTLF which provide analytics and ML model, respectively. Since AnLF generates analytics inferred by the provisioned ML model from MTLF, the error on analytics could be incurred by inappropriate ML model provision. Thus, MTLF should monitor the error on analytics for checking accuracy of the provisioned ML model. However, the current specification does not allow that MTLF monitors the analytics generated by AnLF as well as the actual data and events during Analytics target period. To that end, this solution proposes two options: i) AnLF based error monitoring; and ii) MTLF based error monitoring; as described in clauses 6.5.2.1 and 6.5.2.2, respectively.\nAlso, in current specification the MTLF provides ML model relying on the belief that the 5GS will be in similar state during Analytics target period as the period when the trained data had been sampled. In fact, however, the configuration updates, policy changes, and various unexpected events on 5GS would continuously occur during the analytics target period and it could incur the dynamics that the provisioned ML model have not been trained. In case, consequently, the accuracy of NWDAF analytics will be significantly degraded. In order to address the problem, this solution proposes to enable MTLF to detect the dynamics and to provide a better ML model for the system as described in clause 6.5.2.3.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.5.2\tProcedures",
                            "text_content": "Figure 6.5.2-1 depicts the general procedures for this solution to enhance the accuracy of NWDAF analytics.\nThe figure depicts a general procedure for enhancing the accuracy of NWDAF (Non-Wavelength-Division Multiplexing) analytics. It illustrates the steps involved in analyzing NWDAF data, including data collection, preprocessing, and model training. The figure includes a flowchart and a list of steps, providing a clear and concise guide for users to follow.\nFigure 6.5.2-1: General procedures for enhancing the accuracy of NWDAF analytics\n0.\tThe consumer NF subscribes to AnLF services (via DCCF) to provide a (set of) analytics.\n1.\tThe NWDAF containing AnLF subscribes to a (set of) trained ML model(s) associated with a (set of) Analytics ID(s) by invoking Nnwdaf_MLModelProvision_Subscribe service operation.\n2.\tThe NWDAF containing AnLF monitors error between generated analytics by the ML model and actual events, and sends the monitoring results to the NWDAF containing MTLF as described in clause 6.5.2.1.\n3.\tThe NWDAF containing MTLF monitors difference between the data for training the ML model and the actual data as described in clause 6.5.2.2.\n4.\tThe NWDAF containing MTLF detects the dynamics on 5GS associated with the analytics as described in clause 6.5.2.3.\n5.\tThe NWDAF containing MTLF determines to re-select a (set of) trained ML model(s) associated with a (set of) analytics and/or to re-train the trained ML model(s) based on the retrieved results of step 2-4.\nNOTE:\tEach result of steps (i.e. step 2, step 3, and step 4) can trigger the decision of reselection and retraining of ML model.\n6.\tIf the NWDAF containing MTLF select a novel trained ML model and/or re-trains the ML model, then send the ML model to the NWDAF containing AnLF by invoking Nnwdaf_MLModelProvision_Notify service operation.\nFigure 6.5.2.1-1 describes the procedures that NWDAF containing AnLF monitors the error on the provided analytics from the ML model.\nThe figure depicts the procedures for AnLF-based error monitoring and handling in a telecommunications system. It illustrates the steps involved in identifying and correcting errors, such as packet loss, latency, and packet fragmentation. The figure includes a flowchart and a list of steps, providing a clear and concise visual representation of the process.\nFigure 6.5.2.1-1: The procedures for AnLF based error monitoring and handling\n0.\tThe NWDAF containing AnLF subscribes to a (set of) trained ML model(s) associated with a (set of) Analytics ID(s) by invoking Nnwdaf_MLModelProvision_Subscribe service operation as described in step 1 of Figure 6.5.2-1.\n1.\tThe NWDAF containing MTLF provides a (set of) trained ML model(s) associated with a (set of) Analytics ID(s) and may indicate a (set of) threshold(s) for accuracy of the trained ML model by invoking Nnwdaf_MLModelProvision_Notify service operation.\n2a-2b.\tThe NWDAF containing AnLF generates a (set of) Analytics and provide the Analytics to the consumer NF according to the service operation as described in step 0 of Figure 6.5.2-1, and store the provided Analytics to measure the accuracy compared to the actual data. The NWDAF containing AnLF may request that the ADRF stores the events and data used for generating analytics by triggering Nadrf_DataManagement_StorageRequest.\n3.\tThe NWDAF containing AnLF continues to collect actual events and data related to the provided analytics during the analytics target period by triggering the procedures in clause 6.2 of TS 23.288 [5]. The NWDAF containing AnLF may request that the ADRF stores the actual events and data related to the provided analytics during the analytics target period by triggering Nadrf_DataManagement_StorageRequest.\n4.\tThe NWDAF containing AnLF measures the accuracy of the provided analytics at step 2a-2b by compared to the collected events/data at step 3.\n5.\tWhen the measured accuracy at step 4 is lower than the target accuracy of the analytics on the NWDAF containing AnLF and/or lower than the threshold for accuracy of the provided ML model, if provided at step 1, the NWDAF containing AnLF sends the errors by invoking Nnwdaf_MLModelProvision_Subscribe with the indication of cause = \"inaccuracy\". If the NWDWAF containing AnLF requests to store the actual events and data related to the provided analytics at ADRF at step 3, the AnLF may include ADRF information (i.e. ADRF ID, Storage Transaction Identifier, Notification Correlation ID) in Nnwdaf_MLModelProvision_Subscribe operation.\n6.\tThe NWDAF containing MTLF may retrieve the events and data used for generating analytics and, the actual events and data related to the provided analytics during the analytics target period from the ADRF by invoking Nadrf_DataManagementRetrievalRequest service operation. The NWDAF containing MTLF may re-evaluate the provisioned ML model by compared the retrieved events and data to the trained data.\nNOTE:\tStep 6 can be triggered by the NWDAF containing MTLF internal logic or when the NWDAF containing MTLF get notification from ADRF, i.e. Nadrf_DataManagement_RetrievalNotify in which includes Fetch Instruction and the Notification Correlation ID.\nFigure 6.5.2.2-1 describes the procedures that NWDAF containing MTLF monitors expected error on the analytics by the provisioned ML model.\nThe figure depicts the procedures for MTLF based expected error monitoring, which is a crucial aspect of network reliability and performance. It illustrates the steps involved in monitoring and managing expected errors in a multi-technology, multi-layer, and multi-service network. The figure includes various components such as the network architecture, the expected error monitoring system, and the monitoring and management tools. This figure is crucial for ensuring the smooth operation of the network and maintaining its reliability.\nFigure 6.5.2.2-1: The procedures for MTLF based expected error monitoring\n0a.\tThe NWDAF containing MTLF trains an ML model with a set of trained data and stores the set of trained data or the characteristics of trained data (e.g. mean, variance, etc.) for step 3.\n0b.\tThe NWDAF containing AnLF subscribes to a (set of) trained ML model(s) associated with a (set of) Analytics ID(s) by invoking Nnwdaf_MLModelProvision_Subscribe service operation as described in step 1 of Figure 6.5.2-1. If the NWDAF containing AnLF stores the events and data used for generating an Analytics at the ADRF, the NWDAF containing AnLF may provide the ADRF information (i.e. ADRF ID, Storage Transaction Identifier, Notification Correlation ID).\n1.\tThe NWDAF containing MTLF provides a (set of) trained ML model(s) associated with a (set of) Analytics ID(s) to the NWDAF containing AnLF by invoking Nnwdaf_MLModelProvision_Notify service operation.\n2.\tThe NWDAF containing MTLF discovers date source NFs by exploiting ML Model Filter Information and Target of ML Model Reporting, and collects actual events and data related to the analytics for the ML model during the ML Model Target Period by triggering the procedures in clause 6.2 of TS 23.288 [5]. If the NWDAF containing AnLF provides ADRF information at step 0b, the NWDAF containing MTLF may retrieve the events and data for generating an Analytics from the ADRF.\nNOTE:\tStep 6 can be triggered by the NWDAF containing MTLF internal logic or when the NWDAF containing MTLF get notification from ADRF, i.e. Nadrf_DataManagement_RetrievalNotify in which includes Fetch Instruction and the Notification Correlation ID.\n3.\tThe NWDAF containing MTLF measures the differences between the set of trained data at step 0a and the collected events/data at step 2.\nFigure 6.5.2.3-1 describes the procedures that NWDAF containing MTLF detect crucial changes in 5GS which impact on the ML model provision.\nThe figure depicts a series of steps for detecting dynamics in analytics, with a focus on the use of machine learning algorithms. The steps include data collection, preprocessing, feature extraction, model training, and model evaluation. The figure illustrates the importance of data quality, the choice of machine learning algorithm, and the importance of cross-validation in model evaluation.\nFigure 6.5.2.3-1: The procedures for detection of dynamics on the analytics\n0a.\tThe NWDAF containing MTLF may have classes of 5GS state, which consist of e.g. set of configurations related to Target of Analytics Reporting, set of applied policies related to Target of Analytics Reporting, and set of expected events related to Target of Analytics Reporting, for ML Model provision, and may apply it to ML model selection for a certain analytics.\nNOTE 1:\tThe classes of 5GS state may be set by operator's configuration or may be determined by the internal logic of NWDAF containing MTLF and it is out of SA2 scope.\n0b.\tThe NWDAF containing AnLF subscribes to a (set of) trained ML model(s) associated with a (set of) Analytics ID(s) by invoking Nnwdaf_MLModelProvision_Subscribe service operation as described in step 1 of Figure 6.5.2-1.\n1.\tThe NWDAF containing MTLF provides a (set of) trained ML model(s) associated with a (set of) Analytics ID(s) to the NWDAF containing AnLF according to the criteria and the classes of 5GS state by invoking Nnwdaf_MLModelProvision_Notify service operation.\n2a-2d.\tThe NWDAF containing MTLF subscribes at least one of the services which provide the notification of changes on 5GS state which was set by the classes at step 0a (e.g. occurrence of changes on UE subscription data, occurrence of changed on UE policy, occurrence of changed on access and mobility related policy, occurrence of changed on session management related policy, configuration update by OAM, etc.) for the specific targets for analytics (e.g. the combination of S-NSSAI(s), UE IDs (SUPI), UE group ID(s), application ID(s), PDU Session ID(s), Serving AMF ID(s), Serving SMF ID(s), etc.). For details, the NWDAF containing MTLF may subscribe to Npcf_EventExposure_Subscribe operation with a new Event ID(s), i.e. UE policy update, AM policy update, and SM policy update. When the PCF invokes Npcf_UE/AM/SMPolicyControl_Update_response or Npcf_UE/AM/SMPolicyControl_UpdateNotify service operation, the new event ID(s) of PCF notifies the occurrence of UE, AM, and SM policy changes to the NWDAF containing MTLF, respectively. Also, the NWDAF containing MTLF may further subscribe to Nudm_SDM_Subscribe service in order to track the occurrence of the changes in UE subscription data (e.g. Access and Mobility Subscription data, Session Management Subscription data, Slice Selection Subscription data, etc.). UDM may subscribe to notifications from UDR for tracking the occurrence of changes on UE subscription data by Nudr_DM_Subscribe.\n3a-3c.\tAccording to the subscription at step 2a-2d, the NWDAF containing MTLF receives the information of the occurrence of changes on 5GS state which was set by the classes at step 0a.\n4.\tIn order to evaluate the impacts of 5GS state changes at step 3a-3c on the performance of provisioned ML model, the NWDAF containing MTLF may collect the event and data related to the ML model and the analytics during ML Model Target Period by triggering the procedures in clause 6.2 of TS 23.288 [5].\n5.\tThe NWDAF containing MTLF evaluates the inconsistency of the provisioned ML model for the changed 5GS state at steps 3a-3d with compared to the classes of 5GS state at step 0a and/or the actual data and events at step 4. According to the results of evaluation, the NWDAF containing MTLF may update the classes of 5GS state for ML model provision.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.5.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF containing AnLF:\n-\tAnLF can measure the error between the provided analytics and actual data/events.\n-\tAnLF is able to store the events and data related to the provided analytics during the analytics target period in ADRF and to send ADRF information to the MTLF.\n-\tAnLF is able to store events and data used for generating an Analytics in ADRF and to send ADRF information to the MTLF.\nNWDAF containing MTLF:\n-\tMTLF can measure differences between the trained data set for the provisioned ML model and the actual data/events.\n-\tMTLF should consider the errors on analytics, the differences between actual data/events and the trained data set, and/or the impact of the configuration updates, policy changes and various unexpected events to improve ML model provision services.\n-\tSome additional parameters will be added to Nnwdaf_MLModel_Provision_Subscribe/Notify service operation to support the procedure as described in clause 6.5.2.1.\nNF:\n-\tIn order to track the occurrence of changes on 5GS state, PCF supports new event ID (s), i.e. UE policy update, AM policy update, SM policy update for event exposure.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.6\tSolution #6: Correctness improvement of NWDAF by determining ML model performance",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.6.1\tDescription",
                            "text_content": "This solution addresses Key Issue #1 \"How to improve correctness of NWDAF\".\nAfter the Analytics consumer NF consumes the analytics from the NWDAF containing AnLF, some network data are generated. The NWDAF shall collect these network data from the Analytics consumer NF after the Analytics consumer NF consumed the Analytics results. The network data are used to detect that improving the correctness of an Analytics ID is needed. And the network data will be used for the NWDAF to determine the ML model performance and/or re-train the ML model.\nThis solution provides the following functionalities:\n-\tThe NWDAF collects network data of consumer NFs to support NWDAF perceive the correctness and ML model performance.\n-\tThe NWDAF calculates network data to evaluate ML model performance and trigger further ML model training to improve the accuracy of NWDAF.\n-\tThe NWDAF can reduce the signalling load of data collection through data collection function NF such as DCCF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.6.2\tProcedures",
                            "text_content": "The following figure presents an example procedure of correctness improvement of NWDAF by determining ML model performance.\nThe figure depicts a procedure for improving the model performance of NWDAF (Non-Widely Applicable Data Association Function) by determining the ML model's performance. The figure includes a flowchart with steps for data association, model selection, and model training, as well as a comparison of the model's performance with the original NWDAF. The figure is crucial for understanding the process of improving the model's accuracy and reliability.\nFigure 6.6.2-1: Procedure for correctness improvement of NWDAF by determining ML model performance\n1.\tSteps 1 specified in TS 23.288 [5] are reused to perform network data analytics for the analytics consumer and data collection for the data consumer.\n2-3.\tAfter the analytics consumer NF consumes the analytics, the NWDAF containing AnLF collects the network data by invoking the Nnf_EventExposure_Subscribe service operation or via DCCF by invoking the Ndccf_DataManagement_Subscribe service operation, the network data may include the data from analytics consumer NF and/or data source. This step is skipped if the NWDAF containing AnLF was subscribed to the analytics consumer NF and/or data source directly or via DCCF in step 1.\n4.\tThe NWDAF containing AnLF determines ML model performance (e.g. accuracy, precision or recall) by comparing the network data and the analytics provided to the Analytics consumer NF in step 1.\nThe NWDAF containing AnLF determines whether further training of the ML Model is needed based on the ML model performance and internal strategies.\nIf further training of the ML Model is needed, the NWDAF containing AnLF subscribes ML model associated with the Analytics ID in step 1 by invoking the Nnwdaf_MLModelProvision_Subscribe to get the re-trained ML model, the subscribe information may include the ML model performance.\nThe NWDAF containing MTLF determines that further training is needed, this NWDAF may initiate data collection from NFs, (e.g. AMF/DCCF/ADRF), UE Application (via AF) or OAM as described in TS 23.288, to re-train the ML model.\nIn addition, the NWDAF containing MTLF may collect the network data from the NWDAF containing AnLF for re-training the ML model.\nThe NWDAF containing MTLF notifies the NWDAF containing AnLF with the re-trained ML Model Information (containing a (set of) file address of the trained ML model) by invoking Nnwdaf_MLModelProvision_Notify service operation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.6.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF containing AnLF:\n-\tSupports collecting the network data after the analytics consumer NF consumes the analytics.\n-\tSupports determining ML model performance.\n-\tSupports triggering further training of the ML Model based on the ML model performance.\nNWDAF containing MTLF:\n-\tSupports further training of the ML Model based on the ML model performance.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.7\tSolution #7: Enhancements to NWDAF analytics services",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.7.1\tDescription",
                            "text_content": "In general, the ability for a service consumer to use a performance score to select an NWDAF Analytics and/or ML model may help such service consumer to obtain the desired level of correctness. This solution proposes to associate a score attribute to NWDAF Analytics and ML models, which, similarly to what happens with popular recommendation systems, can be used in the selection of NWDAF Analytics and ML models.\nIn particular, the solution allows service consumers to rate ML models and/or NWDAF analytics from different providers (or by the same provider offering multiple ML models for the same NWDAF analytics). Also, the solution allows service consumers to retrieve the score associated to the NWDAF Analytics and ML models. The rating can be used to improve the correctness of analytics, e.g. an NWDAF with low rating can trigger re-training of the ML models used by that NWDAF.\nTwo scenarios are envisioned in this solution:\n1.\tAn analytics consumer rates an analytics service (i.e. Analytics ID) from an NWDAF (see procedure in clause 6.7.2.1);\n2.\tan NWDAF containing AnLF rates an ML model provided by an NWDAF containing MTLF (see procedure in clause 6.7.2.2).\nIn both scenarios, a consumer from the same vendor of the analytics service or model provisioning service is allowed to rate the analytics service or the used ML model, while the entity producing/exposing the analytics service or ML model is not allowed to self-rate it. For example, an analytics consumer from the same vendor as the NWDAF containing AnLF producer can rate the analytics service, while self-ratings from the NWDAF containing AnLF are not accepted. The rating is based on a metric associated to both the Analytics ID and the corresponding ML model. Such metric is stored in the NF profile at the NRF.\nThe solution leverages on the introduction of:\n-\tA Trusted Rating Logical Function (TRLF) that manages the rating provided by the service consumers. Furthermore, it ensures that only verified consumers (i.e. consumers that really have had access to the ML model and/or Analytics services) can rate the ML model and/or the Analytic service. For example, it prevents rating (of its own) by the producer of the ML model and/or analytics service while an analytics consumer from the same vendor is still able to rate the analytics service. For example, NWDAF(MTLF) that has produced the ML model is forbidden to rate such ML model, while NWDAF(AnLF) from the same vendor could rate the ML model if it has used the ML model.\n-\tA rating format that includes key information regarding the usage of the Analytics service provided or not by using an ML model and that can be exploited by other consumers as well as by other producers/vendors.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.7.2\tProcedures",
                            "text_content": "The figure depicts a procedure for analyzing a consumer's rating of an NWDAF analytics provided by an NWDAF containing AnLF. The figure illustrates the steps involved in evaluating the effectiveness of the analytics, including the selection of the appropriate NWDAF, the evaluation of the analytics, and the conclusion of the rating.\nFigure 6.7.2.1-1: Procedure for analytics consumer rating an NWDAF analytics provided by an NWDAF containing AnLF\nPre-condition: NF profile of the NWDAF in NRF contains a metric that should be utilized to rate the analytics service. A metric is associated to each analytics service (i.e. Analytics ID).\n1.\tAn Analytics Consumer sends a discovery request to NRF looking for NWDAFs providing the Analytics ID(s) and other input parameters as specified in clause 6.1.3 of TS 23.288 [5].\n2.\tThe NRF returns to the Analytics consumer the list of available NWDAFs matching the filter parameters along with the metrics to rate the analytics.\n3.\tThe Analytics Consumer requests, for the discovered NWDAFs, the ratings of the Analytics ID from the Trusted Rating Logical Function (TRLF) through a Ntrlf_RatingDiscovery service. In the request, the Analytics Consumer specifies the NWDAF(s) and the Analytics ID(s). The Analytics Consumer sets the \"rating aggregation level\" request parameter according to its preferred value: \"Global Average\" to receive an aggregated model rating (i.e. a single value), \"average per vendor\" to receive a single average value for each vendor which issued a rating, or \"detailed\" in case it is interested to receive the rating from each service consumer which casted a rating.\nThe aggregated rating is a value, e.g. between 0 (very bad performance) to 5 (very good performance) derived by the TRLF by an average over all ratings. Along with the aggregated rating, the Analytics Consumer receives also the total number of ratings submitted, so that the consumer can derive the accuracy of the rating.\nThe Analytics consumer may also implement a local cache for such ratings, in order to avoid the need to query TRLF for each NWDAF discovery request. In this case, steps 2 and 3 may be skipped for future requests.\n4.\tThe TRLF returns to the Analytics Consumer the requested ratings according to the specified \"rating aggregation level\". Based on the \"average per vendor\" or \"detailed\" model rating, the analytics consumer can identify how ratings were casted by each vendor.\n5.\tThe Analytics consumer selects the NWDAF providing the best performance for the specific use case and scenario. The Analytics consumer requests the analytics service to the selected NWDAF specifying also its Consumer ID comprising the NF (instance or Set) ID and Vendor ID.\n6.\tThe NWDAF generates a token that can be used by the Analytics consumer to rate the analytics service.\nNOTE:\tThe normative aspects about token generation, and how it is used for verification and communicated to other NFs should be carried out in coordination with SA WG3.\n7.\tThe NWDAF sends through the Ntrlf_AnalyticsServiceConsumed service to the TRLF information about the Consumer ID, Analytics ID, information on the ML model used for producing the analytics (if any), its own NWDAF (instance or Set) ID and the token generated for the Analytics consumer. In this way, the TRLF can associate the rating from the Consumer to the analytics service provided by the NWDAF and, implicitly, to the ML model used to generate it in case the analytics service is based on an ML model.\n8.\tThe TRLF sends an acknowledgement to the NWDAF.\n9.\tThe NWDAF sends the analytics response to the Analytics consumer along with the token generated for allowing only verified consumers (i.e. only the ones that really have consumed the service) to evaluate the analytics service.\nIn case the analytics consumer subscribed to the analytics service, the token is valid for the entire subscription duration and the consumer may update its rating by sending another Ntrlf_AnalyticsRating request. Once the subscription is terminated, the NWDAF shall inform the TRLF about it, such that only a final rating can be provided by the consumer after which the token is revoked.\n10.\tThe analytics consumer evaluates the performance of the analytics service utilizing the metric obtained by NRF during the discovery procedure.\n11.\tThe analytics consumer through the Ntrlf_AnalyticsRating service sends its rating to the TRLF. The request also includes the Consumer ID of the analytics consumer and the received token.\n12.\tThe TRLF, in case the token matches and the analytics consumer is not the model producer, accepts and updates the rating. The TRLF stores the rating per Analytics ID and for each Consumer ID.\n13.\tThe TRLF sends to the analytics consumer a confirmation regarding the update of the rating.\nThis procedure, depicted in Figure 6.7.2.2-1, enables an NWDAF containing AnLF to rate an ML model received by NWDAF containing MTLF.\nThe figure depicts a procedure for NWDAF (Non-Wavelength-Division Multiplexing) containing AnLF (Anomalous Low Frequency) rating and NWDAF analytics provided by an NWDAF containing MTLF (Multi-Tiered Low Frequency). The figure illustrates the steps involved in analyzing the NWDAF analytics, including the use of AnLF to enhance the performance of the NWDAF.\nFigure 6.7.2.2-1: Procedure for NWDAF containing AnLF rating an NWDAF analytics provided by an NWDAF containing MTLF\n1.\tThe NWDAF containing AnLF requests, for the NWDAFs that support the Analytics ID for the desired AOI) the rating(s) of the employed ML model(s) from the Trusted Rating Logical Function (TRLF) through a Ntrlf_RatingDiscovery service. In the request, the NWDAF containing AnLF specifies the NWDAF(s) and the Analytics ID(s). The NWDAF containing AnLF sets the \"rating aggregation level\" request parameter according to its preferred value: \"Global Average\" to receive an aggregated model rating (i.e. a single value), \"average per vendor\" to receive a single average value for each vendor which issued a rating, or \"detailed\" in case it is interested to receive the rating from each service consumer which casted a rating.\n2.\tThe TRLF returns to the NWDAF containing AnLF the requested ratings per model ID and per Analytics ID, according to the specified \"rating aggregation level\". Based on the \"average per vendor\" or \"detailed\" model rating, the analytics consumer can identify how ratings were casted by each vendor.\n3.\tThe NWDAF containing AnLF selects the NWDAF containing MTLF providing the required performance of the ML model for the specific use case and scenario. The NWDAF containing AnLF subscribes to ML model provisioning service to the selected NWDAF specifying also its Consumer ID comprising the NF (instance or Set) ID and Vendor ID.\n4.\tThe NWDAF containing MTLF generates a token that can be used by the NWDAF containing AnLF to rate the ML model.\n5.\tThe NWDAF sends through the Ntrlf_AnalyticsServiceConsumed service to the TRLF information about the Consumer ID, Model ID and version used for producing the analytics, its NWDAF ID and version and the token generated for the NWDAF containing AnLF.\n6.\tThe TRLF sends an acknowledgement to the NWDAF containing MTLF.\n7.\tThe NWDAF containing MTLF sends the subscription notification to the NWDAF containing AnLF along with the token generated.\n8.\tThe NWDAF containing AnLF evaluates the performance of the ML model utilizing the metric obtained by NRF during the discovery procedure.\n9.\tThe NWDAF containing AnLF through the Ntrlf_AnalyticsRating service sends its rating to the TRLF. The request also includes the Consumer ID of the NWDAF containing AnLF and the received token.\n10.\tThe TRLF, in case the token matches and the NWDAF containing AnLF is not the model producer, accepts and updates the rating. The TRLF stores the rating per Analytics ID and for each Consumer ID.\n11.\tThe TRLF sends to the NWDAF containing AnLF a confirmation regarding the update of the rating.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.7.3\tImpacts on services, entities and interfaces",
                            "text_content": "This solution introduces the Trusted Rating Logical Function (TRLF), which exposes the following services:\n-\tNtrlf_RatingDiscovery service.\n-\tNtrlf_AnalyticsServiceConsumed service.\n-\tNtrlf_AnalyticsRating service.\nNRF\n-\tSupport for the metric parameter associated to the Analytics IDs and ML models in the Nnrf_discovery service.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.8\tSolution #8: NWDAF assisted service type detection",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.8.1\tDescription",
                            "text_content": "This solution is for Key Issue#2: NWDAF-assisted application detection.\nThe application detection is an important mechanism for the operator e.g. to optimize its user's service experience; relieve the load of the network function; etc.\n-\tFor example, for XR service delivered over HTTPS, it is not able to leverage DPI to get XR related information to assist smart scheduling as proposed in XR study and it is interesting to discuss how to leverage AI/ML e.g. DFI to get some XR related information.\n-\tAnother example, it is useful for the operator to monitor which application (e.g. a video service which is relatively not urgent) lead to the heavy load of an NF or a network slice then make decisions to relieve the NF load or NSI Load e.g. reduce the Session-AMBR for the PDU Session who serves the application.\nTraditionally, the application traffic detection in user plane is depend on DPI (deep packet inspection) function installed in UPF. However, the DPI in only suitable for plaintext traffic (i.e. original readable text in the packet) but not for the encrypted traffic.\nTo help the encrypted application traffic detection, as defined in clause 6.1.2.3 of TS 23.503 [4], ASP may provide the PFD (packet flow description) information including Application ID, 3-tuple(s) etc. to the UPF via NEF (PFDF)/SMF. Then the UPF can determine the Application ID for the encrypted traffic based on the PFD information and the 5-tuple of the encrypted traffic. However, it is the ASP who determines if the PFD information is provided or not, which may be out of control for the Operator.\nIf no any PFD information from the ASP, it is possible for NWDAF to derive Service Type analytics (including e.g. Service Type and its corresponding IP 3-tuple and/or Traffic characteristics) to help the traffic detection in UPF.\nThis solution proposes to define a new terminology i.e. Service Type including Browsing, Video Streaming, Audio Streaming, File Sharing, Multimedia, Interactive Messages, Video call over IP, Voice call over IP and so on. Alternatively, the definition of the current Application ID in clause 3.1 of TS 23.503 [4] can be enhanced to support these service types.\nEditor's note:\tWhether there is a need for a Service Type or the Application ID can cover is FFS.\nAs a potential consumer NF, the PFDF may subscribe or request the Service Type analytics and locally store the analytics as new PFD information, and then the PFDF pushes the new PFD information to SMF and UPF to identify the Service Type of the traffic flows based on the new PFD information and the 3-tuple of traffic in the UPF.\n-\tFor any UE, based on operator policy, PCF may trigger the Service Type detection in a specific area of interest and requests the NEF(PFDF) to push the new PFD information (including the Service Type related information) to the UPFs located in the AoI. Then the UPF may report the service type detection result for this AoI to PCF for QoS control.\n-\tFor a single UE, PCF may get the service type detection requirement per UE/per AF session from AF, then SMF may pull the PFD information from the NEF(PFDF) to the UPF. Then the UPF may report the service type detection result for this UE to PCF for QoS control.\nEditor's note:\tHow the new PDR is activated and the reporting from UDR to PCF is done is FFS.\nEditor's note:\tHow the Service Type detection and Service Type QoS control coexist with the existing SDF detection and QoS control define in TS 23.503 [4] is FFS.\nThe input data for the Service Type analytics is shown in Table 6.8.1-1.\nTable 6.8.1-1: Service flow level Data from UPF and/or AF related to a particular Service Type\n\nEditor's note:\tWhether the Service Type or the AF-Application ID is reported by the AF and why a new identifier is needed is FFS.\nNOTE 1:\tHow to collect the QoS flow level Network Data from UPF is depend on the conclusion of FS_UPEAS.\nTo collect the UL/DL Packet Delay, the current QoS Monitoring Event (including end to end delay i.e. Uu+N3/N9 delay for specific QoS flow or for specific PDU session) by UPF as defined in clause 5.2.26.2 of TS 23.502 [3] can be re-used.\nNOTE 2:\tThe current Packet delay detection and reporting in R17 is only supported for URLLC but how NWDAF collects the UL/DL Packet Delay from UPF will be defined in FS_UPEAS.\nEditor's note:\tExtensive reporting of all traffic flows may conflicts with requirement to avoid extra UPF load in the key issue. How to avoid the degradation of UPF Load because of the extensive reporting of all traffic flows should be aligned with the conclusion of KI#2: Support UPF expose information to other NFs in FS_UPEAS.\nWith the input data, NWDAF uses the ML algorithm (e.g. K-Means) to cluster the data set to derive one or more 3-tuple(s) for a Service Type. The statistics and prediction types of Service Type analytics are shown in Table 6.8.1-2 and Table 6.8.1-3, respectively.\nTable 6.8.1-2: Service Type statistics\n\nTable 6.8.1-3: Service Type predictions\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.8.1-1: Service flow level Data from UPF and/or AF related to a particular Service Type",
                                    "table number": 4,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.8.1-2: Service Type statistics",
                                    "table number": 5,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.8.1-3: Service Type predictions",
                                    "table number": 6,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.8.2\tProcedures",
                            "text_content": "The figure depicts a procedure for Service Type analytics provided to an NF, illustrating the steps involved in analyzing service type data. The figure includes a flowchart with arrows indicating the sequence of actions, a table with columns for Service Type and the corresponding Service Type values, and a legend to clarify the meaning of the colors and symbols used in the flowchart. The figure is a visual representation of the process, making it easy to understand and follow.\nFigure 6.8.2-1: Procedure for Service Type analytics provided to an NF\n1.\tThe NF sends Nnwdaf_AnalyticsInfo_Request or Nnwdaf_AnalyticsSubscription_Subscribe (Analytics ID=\"Service Type\", Target of Analytics Reporting, Analytics Filter Information, Analytics Reporting Information = (\"Reporting Thresholds\" and Analytics target Period(s))) to the NWDAF.\n2.\tThe NWDAF collects service flow level data from UPF as listed in Table 6.8.1-1.\nNOTE:\tHow to collect the service flow level data from UPF is depend on the conclusion of FS_UPEAS.\n3.\tThe NWDAF collects service flow level data from AF as listed in Table 6.8.1-1.\n4.\tThe NWDAF derives the requested analytics.\n5.\tThe NWDAF sends Nnwdaf_AnalyticsInfo_Request response or Nnwdaf_AnalyticsSubscription_Notify (Service Type analytics).\n6-7.\tA change of user plane traffic information which is reported by UPF or AF, and is notified to NWDAF.\n8.\tThe NWDAF derives new analytics taking into account the most recent data collected.\n9.\tThe NWDAF provides a notification for the new analytics using Nnwdaf_AnalyticsSubscription_Notify service operation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.8.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF:\n-\tSupport for a new Analytics ID i.e. Service Type analytics.\n-\tSupport subscribing for service flow level data from UPF and/or from AF and providing Service Type analytics to NF.\nUPF/AF:\n-\tReport service flow level data to NWDAF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.9\tSolution #9: NWDAF-assisted application detection",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.9.1\tDescription",
                            "text_content": "This solution is proposed to address Key Issue #2: NWDAF-assisted application detection.\nTo differentiate an application traffic handling, the first step is to distinguish application traffic from other traffics. In 5G network, an application can be distinguished by a set of packet headers (SDFs) or application IDs. The most common approach to detect traffic is use a set of packet headers which usually contains source and destination address. The application ID can be used for referring to the UPF's specific application detection filter, and AF may provide PFDs according to clause 4.18 of TS 23.502 [3] to update application detection filter information associated with the application ID. A PFD contents could contain flow description (service-side 3-tuple), URL, and domain name/protocol information. When an AF delivers PFD to NEF (PFDF), it will be distributed to SMFs and UPFs to enable flow detection according to clause 5.8.2 of TS 23.501 [2]. The SMF use the procedure described in clause 4.18.3.1 of TS 23.502 [3] to provision or remove the PFDs associated to a specific application ID.\nHowever, as indicated by the KI description, the ASP may provide an initial PFD information but does not update it in time or does not update it anymore, then it is unknown how the UPF detect the application traffic. As it may happen when the ASP invokes the Nnef_PFDManagement_Create service to provide PFDs and then invokes the Nnef_PFDManagement_Delete service with a certain delay according to clause 4.18 of TS 23.502 [3].\nThe objective of this solution is to provide analytics on application traffic based on user consent. The proposed solution provides analytics including new PFD information or PFD information for known applications by extracting network traffic signature and inferring application id. The known application means an application for which the application ID is already known by the 5GC and can be referenced within PCC rules and for which PFD information (may not be the latest) is already available, which allows the 5GC to perform the \"application detection\" analytics in order to get the latest PFD information.\nTo realize this solution, one of the main features is 1) collect measurement of an application to extract statistical characteristics, 2) collect payload of packets to extract payload characteristics (such as domain name contained in the payload). The baseline usage of the generated analytics is to store the captured application characteristics as a PFD, and the PFD is used by SMF and UPF to detect a known application defined as TS 23.502 [3].\nThe NWDAF could collect the current PFD information in use (including Application ID, IP 3-tuple,URL, Domain name information) from the UDR via NEF (PFDF).\nBased on PFD information from NEF/UDR and traffic information from UPF, new PFD information (including Application ID, new IP 3-tuple, new URL, new Domain name information) for the existing Application ID could be derived by the NWDAF. The new PFD information provided by the NWDAF can be used by the NEF for provisioning SMF/UPF.\nThe SMF can requests the provision of the PFDs associated to an application ID, then it translates the PCC rules associated with the applications identifier to PDRs to install it on the UPF. So, for a full automatize process, the SMF needs to know the application identifier that contains the PFDs to assigns it to a PCC rule with the desired traffic policies. Also, the consumer of the analytic (e.g. NEF) may be interested only in a subset of the applications found by the NWDAF, so a new Analytics Filter is proposed in this solution to cover both needs:\n-\tFilter the applications that the NWDAF shall provision to the consumer.\n-\tProvide input information to the NWDAF to name the found applications.\nThe consumer informs the NWDAF about the target applications through the \"Applications Characteristics\". The \"Application Characteristics\" are specific well know KPIs between the traffic characteristics i.e. the relations that will identify each of the application.\nThe application characteristics are created from the traffic features provided by the UPF as input of the data collection: Data duration, QoS flow bit rate, packet transmission, size of packets, data volume, UL/DL Packet Delay, in combination with an application relation function: min(), application with the minimum value, max(), application with the maximum value.\nSeveral \"Application Characteristic\" can be used per filter using and/or operators as on Table 5.2.19.2.1-1 of TS 23.502 [3], e.g.:\nTable 5.2.19.2.1-1: Example of Event Filters for NWDAF exposure events\n\nThe name given to the \"Application Characteristics\" is used by the NWDAF to name the applications that match the characteristic.\nIn case the NWDAF receives \"Application Characteristics\" filters in the subscription/request of the analytic, the NWDAF only retrieve the applications matching the filters.\nThe below is the principles of the solution:\n-\tA consumer (e.g. NEF(PFDF)) requests to the NWDAF to provide PFDs for newly detected applications.\n-\t[Optionally] Use the filter \"Application Characteristics\".\n-\tThe NWDAF requests to provide information on SDF that does not match an installed PDR at the SMF/UPF.\n-\tThe NWDAF analyses the collected data to generate unique traffic patterns, and provides it to the consumer.\n-\tThe consumer i.e. NEF decides to create/update/delete PFD associated with an application ID to enable the detection of application traffic in the future (out of scope).\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.2.19.2.1-1: Example of Event Filters for NWDAF exposure events",
                                    "table number": 7,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.9.2\tInput Data",
                            "text_content": "NWDAF collects QoS flow related data from SMF for a specific S-NSSAI, DNN, and UE. The detailed data are described in Table 6.9.2-1.\nTable 6.9.2-1: Input data to detect known application from NFs\n\nNOTE 1:\tExtensive reporting of all traffic flows may conflict with requirement to avoid extra UPF load in the key issue. An NWDAF may subscribe only for reporting for some UEs to limit the load.\nNOTE 2:\tThe current Packet delay detection and reporting in R17at UPF is only supported for URLLC.\nNOTE 3:\tHow NWDAF collects the UL/DL Packet Delay from UPF (e.g. subscription via SMF) will be defined in FS_UPEAS.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.9.2-1: Input data to detect known application from NFs",
                                    "table number": 8,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.9.3\tOutput Analytics",
                            "text_content": "The output analytics of NWDAF is defined in Table 6.9.3-1.\nThe output analysis can be used to provision new PFDs for known applications.\nTable 6.9.3-1: Output for known application detection\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.9.3-1: Output for known application detection",
                                    "table number": 9,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.9.4\tProcedures",
                            "text_content": "The procedure depicted in 6.9.4-1 shows known application detection analytics.\nThe figure depicts a procedure to extract application characteristics, illustrating the steps involved in analyzing and extracting data from a telecommunication system.\nFigure 6.9.4-1: A procedure to extract application characteristics\n1.\tThe NEF(PFDF) as consumer NF subscribes to the NWDAF to request analytics for application detection (or via the NEF in untrusted domain). This subscription maybe is triggered by local configuration or OAM. The Analytics Filter Information may optionally include the UE ID, S-NSSAI and/or DNN, Application ID.\n2.\tNWDAF performs user consent check with UDM to determine if the analytics procedure is allowed or not.\n3.\tThe NWDAF fetches currently stored PFD information in use from UDR via NEF(PFDF).\n4.\tThe NWDAF collects session related information from the UPF about URL, Domain name part, and IP 3-tuples of packets corresponding to Application ID from the SDF not matching installed PDRs.\n5.\tThe NWDAF derives PFD analytics.\n6.\tThe NWDAF notifies the analytics consumer NF with observed PFD Information. Based on the observed PFD information provided by the NWDAF, the consumer determines to create/update/delete PFDs information and if needed send request to the NEF(PFDF) by invoking the Nnef_PFDManagement_Create/Update/Delete service containing Application Identifier and one or more sets of PFDs, and step 1-5 defined in clause 4.18.2 in TS 23.502 [3] are executed.\n7.\tThe NEF (PFDF) fetches the PFD information currently in use from UDR.\n8.\tThe NEF (PFDF) compares the PDF information from UDR with PFD information from the NWDAF to determine whether to create/update/delete PFD information corresponding to the application ID.\n9.\tThe NEF (PFDF) invokes the Nudr_DM_Create/Update/Delete (Application Identifier, one or more sets of PFDs) to the UDR to create/update/delete PFD information corresponding to the application ID, i.e. steps 3-5 defined in clause 4.18.2 of TS 23.502 [3] are executed.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.9.5\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF:\n-\tNeeds to provide a new analytic for application detection information.\n-\tNeeds to process user plane data for extracting traffic characteristics.\n-\tNeeds to be able to filter and name the applications detected based on the \"Application Characteristics\" filter.\nUPF:\n-\tNeeds to report URL, Domain name part, and IP 3-tuples of packets from unknown application to NWDAF.\n-\tNeeds to provide requested sessions statistics including data volume, data duration, QoS flow bit rate and packet transmission.\nNEF(PFDF):\n-\tSupports to consume new PFD information from NWDAF.\n-\tSupports to determine to create/update/delete PFD information and send request to UDR.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.10\tSolution #10: Support for Data and Analytics Exchange in Roaming Case",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.10.1\tDescription",
                            "text_content": "When two VPLMN and HPLMN expose data or analytics to each other, both PLMNs need the ability to control the amount of data exposed and to abstract or hide network-internal aspects based on user consent, operator policy, regulatory constraints and/or roaming agreements.\nThe solution following the following assumptions and principles:\n-\tThe hPLMN may impose constraints on the type or amount of data collected. The constraints may differ for different vPLMNs.\n-\tThe vPLMN may impose constraints on the type or amount of data collected. The constraints may differ for different hPLMNs.\n-\tThe data collection must honour user data consent for user related data collection.\nThe solution proposes a Gateway Exposure Function (GEF) in a PLMN, which is responsible for data/analytics exposure to other PLMNs. The GEF is provisioned with constraints on the type and amount of data exposed to each PLMN according to roaming agreement. The GEF is also responsible for enforcing obtaining the user consent for data collection where applicable.\nWhen a data/analytics consumer in PLMN A (vPLMN/hPLMN) needs to collect data/analytics from PLMN B (hPLMN/vPLMN), the consumer contacts the GEF in PLMN A, then GEF in PLMN A contacts GEF in PLMN B, or the consumer contacts the GEF in PLMN B directly. The GEF in PLMN B discovers the data/analytics producer in PLMN B and collects the data/analytics. GEF is also responsible for data/analytics manipulation before sending to the other PLMN according to the regulatory constraints and agreement.\nNOTE:\tWhether GEF is a standalone NF will be determined as part of the evaluation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.10.2\tProcedures",
                            "text_content": "The figure depicts a scenario where a consumer is in a Virtual Private LAN-N (vPLMN) and the data and analytics exposure is high. The GEF (Global Exposure Framework) is used to measure the exposure of the consumer to data and analytics services. The figure shows the data and analytics exposure through various layers, including the consumer's location, the vPLMN, and the network infrastructure. The GEF score is used to determine the level of exposure and the need for mitigation measures.\nFigure 6.10.2-1: Data and Analytics Exposure via GEF when data/analytcis consumer is in vPLMN\nFigure 6.10.2-1 shows the procedure when the data/analytics consumer is in the visiting PLMN (vPLMN), the NWDAF in the visiting PLMN (vNWDAF) needs to collect data/analytics from home PLMN (hPLMN) of the UE.\nNOTE:\tThe UE can be one single UE, group of UE or any UE roaming to the VPLMN from the HPLMN.\nIt is assumed that both vGEF and hGEF have been provisioned, by their respective operators, with the policies and constraints for exporting data to or from roaming/home networks.\n0.\tGEF is registered itself in the NRF. The GEF profile may include a type to indicate data collection or analytics exposure.\n1-2.\tThe analytics consumer in the vPLMN (e.g. an AMF) wants to subscribe an Analytics for an inbound roaming UE, the vNWDAF determines that it needs to collect data/analytics from hPLMN of the UE. For example, the data to be collected might be related to expected UE behaviour. The analytics consumer and vNWDAF obtain the hPLMN ID from the SUPI of the UE. In the analytics request in step 1, the analytics consumer may provide indication to the vNWDAF, that the analytics needs data from hPLMN of the UE, or the vNWDAF can determine that based on the Analytics ID.\nThere are 3 options to establish the connection between the vPLMN and HPLMN.\nOption A:\n3.\tvNWDAF discovers vGEF via vNRF. vNRF provides the ID of vGEF that is responsible for collecting data/analytics from that PLMN.\n4.\tvNWDAF sends data/analytics subscription request to the vGEF. Similar services as Data management and analytics exposure service of NWDAF (defined in clauses 7.2, 7.3 and 7.4 of TS 23.288 [5]) can be defined as the data and analytics subscription services provided by the GEF.\n5.\tvGEF discovers hGEF via vNRF and hNRF. vGEF provides HPLMN ID to vNRF. vNRF interacts with hNRF via N27 reference point as defined in TS 23.501 [2].\n6.\tvGEF send data/analytics subscription request to the hGEF which is got in step 5. hGEF checks roaming agreements, hPLMN policies and regulatory constraints between hPLMN and the origin vPLMN to determine if the request can be accepted or must be rejected.\nOption B:\n3.\tvNWDAF discovers vGEF via vNRF. vNRF provides the ID of vGEF that is responsible for collecting data/analytics from that PLMN.\n4.\tvNWDAF discovers hGEF via vNRF and hNRF taking into account the home PLMN ID and the request data or analytics exposure. The hNRF returns the ID of hGEF to the vNWDAF.\n5.\tvNWDAF sends data/analytics subscription request to the vGEF. The vNWDAF sends the ID of hGEF to the vGEF.\n6.\tvGEF send data/analytics subscription request to the hGEF. hGEF checks roaming agreements, hPLMN policies and regulatory constraints between hPLMN and the origin vPLMN to determine if the request can be accepted or must be rejected.\nOption C:\n3.\tvNWDAF discovers hGEF via vNRF and hNRF taking into account the home PLMN ID and the request data or analytics exposure. hNRF provides the ID of hGEF that is responsible for collecting data/analytics from that PLMN to vNWDAF via vNRF.\n4.\tvNWDAF sends data/analytics subscription request to the hGEF. hGEF checks roaming agreements, hPLMN policies and regulatory constraints between hPLMN and the origin vPLMN to determine if the request can be accepted or must be rejected.\nNOTE:\tWhich option(s) to be supported will be determined in the conclusion phase.\n7-8.\tIf the checks in step 6 is OK, hGEF enforces user consent (for UE-related data collection) and collects data/analytics from the data/analytics sources in the hPLMN.\n9.\thGEF manipulates the data/analytics according to the hPLMN policies and regulatory constraints and roaming agreements, e.g. remove some sensitive data, changes the granularity of the data, anonymization, formatting, etc.\n10-11.\thGEF sends the data/analytics to vGEF and vGEF forwards to vNWDAF. vGEF may also manipulate the data/analytics to the format that the vNWDAF can understand.\n12.\tAlternatively, hGEF can send the data/analytics notification directly to the vNWDAF, if vGEF provides notification endpoint information of the vNWDAF in step 6.\nWhen the analytics/data consumer is located in hPLMN, and the UE is roaming, the procedure shown in figure 6.10.2-2 applies instead. The difference from in figure 6.10.2-1 is step 3, which is now split into steps 3a and 3b. In step 3a the hNWDAF enforces the user consent with the hUDM. In step 3b the hNWDAF queries hUDM for retrieving the GUAMI of the AMF that is serving the user. This GUAMI contains the PLMN ID of the AMF, therefore, it can be used for determining whether the UE is roaming or not.\nThe figure depicts a scenario where a data and analytics consumer is located in a high-performance local network (hPLMN) and is exposed to GEF (Global Ethernet Forwarding). This exposure can lead to potential security risks, as the consumer may be exposed to data and analytics traffic that could be used for malicious purposes. To mitigate this risk, the consumer should implement appropriate security measures, such as using encryption and access controls, to ensure that only authorized users can access the data and analytics traffic.\nFigure 6.10.2-2: Data and Analytics Exposure via GEF when data/analytics consumer is in hPLMN\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.10.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tNew NF, i.e. GEF, needs to be specified.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.11\tSolution #11: PDU session management in roaming scenarios using network analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.11.1\tDescription",
                            "text_content": "This solution addresses key issue #3: \"Data and analytics exchange in roaming case\".\nPDU Session management in roaming scenarios can be improved using the data and analytics information exchange between HPLMN and VPLMN.\nAs specified in TS 23.502 [3], in the case of roaming, the AMF in the VPLMN determines if a PDU Session is to be established in LBO or Home Routing. For Home Routing, if the UE does not include an S-NSSAI in the PDU Session request, both a Serving PLMN S-NSSAI (in the Allowed NSSAI) and its corresponding HPLMN S-NSSAI values are selected by the AMF. Also, the AMF selects both an SMF in the Serving PLMN using the S-NSSAI of the Serving PLMN mapping to the S-NSSAIs of the HPLMN used for the PDU Session, and, additionally an SMF in the HPLMN using the S-NSSAI of the HPLMN used for the PDU Session. Here the selection of Network Slices (i.e. Serving PLMN S-NSSAI and its corresponding HPLMN S-NSSAI) and selection of SMFs (i.e. V-SMF and H-SMF) should take into account the status of Network Slices / NFs in both VPLMN and HPLMN. Therefore, analytics in HPLMN (i.e. Network Slice load level, NF load, etc.) can be sent to the VPLMN and used by the AMF in VPLMN for Network Slice and H-SMF selection for Home Routed PDU Session establishment.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.11.2\tProcedures",
                            "text_content": "Figure 6.11.2-1 shows the procedure that V-NWDAF requests the Network Slice load level analytics in HPLMN from H-NWDAF, upon receiving an analytics information/subscription request from the AMF.\nThe figure depicts a procedure for providing load level analytics to VPLMN, illustrating the steps involved in analyzing the load levels of HPLMN. The figure includes a flowchart with arrows indicating the sequence of actions, and labels for each step, such as \"Load Level Analysis,\" \"Data Collection,\" and \"Data Processing.\" The figure also includes a legend to clarify the meaning of the symbols used in the flowchart. Overall, the figure provides a clear and concise visual representation of the process, making it easy to understand and follow.\nFigure 6.11.2-1: Procedure for providing HPLMN load level analytics to VPLMN\n1.\tAMF sends an Analytics request/subscribe (Analytics ID = Load level information, Analytics Filter Information = (VPLMN S-NSSAI, HPLMN S-NSSAI, HPLMN ID)) to V-NWDAF by invoking a Nnwdaf_AnalyticsInfo_Request or a Nnwdaf_AnalyticsSubscription_Subscribe.\n2.\tV-NWDAF invokes Nnrf_NFDiscovery_Request (Expected Service Name = Nnwdaf_AnalyticsInfo (or Nnwdaf_AnalyticsSubscription), NF type of the expected NF = NWDAF, Analytics ID = Load level information, HPLMN ID, VPLMN ID, VPLMN S-NSSAI, HPLMN S-NSSAI, NF type of the NF service consumer = NWDAF) to an appropriate configured NRF in the VPLMN, and discovers the H-NWDAF using the procedure as described in clause 4.17.5 of TS 23.502 [3]. V-NWDAF sends an Analytics request/subscribe (Analytics ID = Load level information, Analytics Filter Information = HPLMN S-NSSAI) to H-NWDAF by invoking a Nnwdaf_AnalyticsInfo_Request or a Nnwdaf_AnalyticsSubscription_Subscribe, based on the Analytics request/subscribe received from the AMF.\n3-5.\tH-NWDAF collects data from the NF(s) and/or OAM in HPLMN and derives the requested Network Slice / Network Slice instance load analytics information for the Network Slice identified by HPLMN S-NSSAI, as specified in clause 6.3 of TS 23.288 [5].\n6.\tH-NWDAF sends the HPLMN Network Slice / Network Slice instance load analytics information to the V-NWDAF using either Nnwdaf_AnalyticsInfo_Request response or Nnwdaf_AnalyticsSubscription_Notify.\n7-9.\tV-NWDAF collects data from the NF(s) and/or OAM in VPLMN and derives the requested Network Slice / Network Slice instance load analytics information for the Network Slice identified by VPLMN S-NSSAI, as specified in clause 6.3 of TS 23.288 [5]. These steps can be executed in parallel with step 3-6.\n10.\tV-NWDAF sends the HPLMN analytics information received in step 6, together with the VPLMN analytics information derived in step 9, to the AMF using either Nnwdaf_AnalyticsInfo_Request response or Nnwdaf_AnalyticsSubscription_Notify.\nThe AMF can use the HPLMN and VPLMN analytics information for Home Routed PDU Session establishment, as follows:\n-\tbase on the HPLMN and VPLMN analytics information on Network Slice load, the AMF selects the Network Slices (i.e. VPLMN S-NSSAI and its mapped HPLMN S-NSSAI), and also the Network Slice instances in HPLMN and VPLMN if multiple VPLMN NSI IDs and/or HPLMN NSI IDs are available (e.g. received from the NSSF previously or configured) in the AMF for the selected Network Slices.\n-\tfurther, based on the HPLMN and VPLMN analytics information, e.g. the resource usage information in the Network Slice load analytics, or NF load analytics (using procedures similar to the above), the AMF selects an H-SMF in the selected Network Slice or Network Slice instance (if available) in the HPLMN, and a V-SMF in the selected Network Slice or Network Slice instance (if available) in the VPLMN, among the set of the SMF instance(s) returned by the NRF (as described in clause 4.3.2.2.3 of TS 23.502 [3]) or locally configured in the AMF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.11.3\tImpacts on existing nodes and functionality",
                            "text_content": "AMF: based on HPLMN and VPLMN analytics information, selects Network Slices and Network Slice instances (if available) in HPLMN and VPLMN, and selects the SMFs (i.e. V-SMF and H-SMF), for Home Routed PDU Session establishment in roaming scenarios.\nV-NWDAF: requests HPLMN analytics information from the H-NWDAF.\nH-NWDAF: provides HPLMN analytics information to the V-NWDAF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.12\tSolution #12: DCCF and MFAF Relocation",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.12.1\tDescription",
                            "text_content": "In scenarios where multiple DCCF and/or MFAF instances are deployed in the same network, there are some cases that the serving DCCF and/or MFAF may need to be changed, such as when a UE moves (e.g. due to idle mode mobility or a handover), the data or analytics source may change (e.g.: a new NWDAF, a new AMF, a new SMF). The new data source may not be in the area served by the current DCCF and/or the current MFAF. This solution proposes a way to change the DCCF and/or MFAF upon data source or analytics source change so the serving areas of the DCCF/MFAF and data source remain aligned.\nThe DCCF and MFAF relocation comprises the following steps:\n-\tWhen a DCCF coordinates data or analytics collection for a UE or a group of UEs, the DCCF subscribes to event notifications for UE mobility to outside of the serving area of the DCCF (for example area of interest as specified in clause 4.15.4.2 of TS 23.502 [3]). If an MFAF is used, the DCCF also subscribes to receive notifications of UE mobility to outside of the serving area of the selected MFAF.\n-\tWhen a DCCF coordinating data or analytics collection receives a mobility event notification:\n-\tIt determines if the UE is still within the current DCCF serving area. If not, it determines a new DCCF (e.g. by querying the NRF). It then interacts with the new DCCF to transfer the UE DCCF context for the UE.\n-\tIf an MFAF is used, the DCCF determines if the UE is within the current MFAF serving area. If not, it determines a new MFAF (e.g. by querying the NRF). The DCCF then interacts with the new MFAF to initiate a UE MFAF context transfer from the old MFAF or to establish a new UE MFAF context.\n-\tIf there is a new MFAF or if there is a new DCCF and an MFAF is not used, the DCCF updates the Data Source with the new Notification Endpoint address. Subsequently, the data source sends notifications to the new DCCF or new MFAF.\nMFAF UE Context information transferred or setup in the new MFAF may include information from on-going processing, such as buffered notifications and processed data, and configuration information such as Formatting Instructions, Processing Instructions, Data Consumer or Analytics Consumer information and MFAF notification information as described in clause 9.2.2 of TS 23.288 [5].\nDCCF UE Context information transferred to the new DCCF may include information from on-going processing, such as buffered notifications and processed data, and configuration information such as Service Operation, Analytics or Data Specification, Time Window, Formatting Instructions, Processing Instructions, Data Consumer or Analytics Consumer information and DCCF notification information as described in clause 8.2.2 of TS 23.288 [5].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.12.2\tProcedures",
                            "text_content": "Upon change of a source DCCF and/or MFAF instance, it is required to inform the related consumer of the event and possibly to update subscriptions between the DCCF and the consumer. The subscriptions can be renewed between the target DCCF instance and the consumer.\nThe figure depicts a context transfer context (DCCF) and/or multi-factor authentication (MFAF) context transfer (MFT) process, illustrating the steps involved in transferring context between two or more parties. The diagram shows the flow of information, with the sender (S) sending a message to the receiver (R), and the receiver (R) receiving the message and performing the necessary authentication. The figure is a visual representation of the complex process, highlighting the importance of context transfer in ensuring secure communication.\nFigure 6.12.2-1: DCCF and/or MFAF Context Transfer\nFigure 6.12.2-1 illustrates the procedure for DCCF and/or MFAF Context Transfer.\n0.\tA consumer NF subscribes to DCCF Data Management services. The consumer NFsets to \"False\" the \"No relocation\" indicator in the subscription request.\nNOTE:\tThe \"No relocation\" indicator is used by DCCF to determine whether to execute the relocation procedure (No Relocation set to \"False\") or not (No Relocation set to \"True\").\n1.\tAMF sends DCCF-1 a notification indicating that the UE is in a new area of interest.\n2.\tDCCF-1 determines that the UE is no longer in the area served by the DCCF-1 or in the area served by the MFAF-1.\n3.\tDCCF-1 may query the NRF to discover a DCCF and/or MFAF that can serve the UE in its new location. In the case of data subscriptions from multiple DCCFs, the DCCF-1 may preferably select a target DCCF that is already serving the consumer.\n4.\tIf DCCF-1 determined in step 2 that it is no longer in the serving area of the UE, it selects a new DCCF (DCCF-2) to serve the UE. If the DCCF determined in step 2 that MFAF-1 is no longer in the serving area of the UE, it selects a new MFAF (MFAF-2) to serve the UE.\n5.\tIf a new MFAF (MFAF-2) is selected, DCCF-1 sends a message to MFAF-2 requesting MFAF-2 to become the new MFAF and to retrieve the MFAF UE context from MFAF-1.\n6.\tIf MFAF-2 receives the message in step 5, it retrieves the UE context from MFAF-1.\n7.\tMFAF-1 forwards to MFAF-2, notifications related to the UE (where formatting and processing may be performed by MFAF-2).\n8.\tMFAF-2 indicates to DCCF-1 that MFAF UE context transfer/setup is complete and provides MFAF-2 Notification Endpoint information to the DCCF-1.\n9.\tIf a new DCCF (DCCF-2) is selected in step 4, DCCF-1 sends a message to DCCF-2 requesting DCCF-2 to become the new DCCF. If DCCF-2 accepts the transfer request:\na.\tDCCF-2 retrieves the UE Context from DCCF-1.\nb.\tIf an MFAF is used, DCCF-1 indicates to DCCF-2 the MFAF (MFAF-1 or MFAF-2).\nc.\tIf an MFAF is not used, DCCF-2 provides DCCF-2 Notification Endpoint information in the response to DCCF-1.\nd.\tDCCF-1 and DCCF-2 determine whether subscriptions to Data Sources need to be updated.\nNOTE 1:\tAs in clause 5A.2, each Data Source NF or Set of Data Source NF should be associated with only one DCCF instance or DCCF Set. Therefore based on the subscription information for the UE provided by DCCF-1, DCCF-2 should select a new Data Source NF and inform DCCF-1.\ne.\tDCCF-2 confirms the context transfer from the DCCF-1.\n10.\tIf a new DCCF (DCCF-2) is selected in step 4, DCCF-2 informs the MFAF (MFAF-1 or MFAF-2) that DCCF 2 is now the DCCF for the UE.\n11.\tIf the DCCF has not changed, DCCF-1 informs the Data Source of the MFAF (MFAF-2) notification endpoint information (either via update of a subscription to the existing data source or via a new subscription to a new data source if selected by DCCF-1). Notifications are subsequently sent from the Data Source to MFAF-2.\n12.\tIf the DCCF has changed, DCCF-2 updates/subscribes to the Data Source, providing MFAF-2 Notification Endpoint Information (if there is a new MFAF 2), or DCCF-2 Notification Endpoint Information (if MFAF is not used) and indicating that DCCF-2 is the new DCCF subscribing for data/analytics.\na.\tIf an MFAF is used, DCCF-2 indicates to Data source the MFAF (MFAF-1 or MFAF-2).\nb.\tIf an MFAF is not used, DCCF-2 provides DCCF-2 Notification Endpoint information to Data source.\n13.\tDCCF-1 unsubscribes with the data source(s) that are no longer needed for the remaining data subscriptions.\n14.\tThe consumer is informed by DCCF-1 that its subscription to DCCF-1 is now being handled by DCCF-2. In this message, the new Subscription Correlation ID, which was assigned by DCCF-2, is provided as the Subscription Correlation ID parameter and the old Subscription Correlation Id, which was allocated by DCCF-1, is provided as the Subscription Change Notification Correlation ID parameter.\nNOTE 2:\tFor this procedure, following constraint is assumed for data collection for group of UEs or any UE. The NF consumer will select a DCCF(s) that serves the area(s) where the group of UEs or any UE reside and the selected DCCF(s) will select MFAF(s) that serves the area(s) where the group of UEs or any UE reside.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.12.3\tImpacts on existing nodes and functionality",
                            "text_content": "DCCF/MFAF:\n-\tNew services and service operations for UE Context Transfer.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.13\tSolution #13: NWDAF MTLF and NWDAF AnLF interoperability support for registration and discovery in 5GC",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.13.1\tDescription",
                            "text_content": "This solution addresses KI#5: Enhance trained ML Model sharing.\nThe solution is based on the existing NWDAF discovery and selection as defined in TS 23.288 [5].\nTo discover an NWDAF containing MTLF via NRF by NWDAF containing AnLF belonging to a different vendor:\n-\tAn NWDAF containing MTLF shall include ML model file serialization format supported in the ML model filter information for the trained ML model per Analytics ID(s).\n-\tDuring the discovery of NWDAF containing MTLF a consumer (i.e. an NWDAF containing AnLF) may include in the request ML model file serialization format supported per Analytics ID(s). The NRF returns one or more candidate for instances of NWDAF containing MTLF with the ML model file serialization format supported for the trained ML model per Analytics ID (s) as indicated by the NF consumer.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.13.2\tProcedures",
                            "text_content": "The figure depicts a network-wide data forwarding architecture, specifically focusing on the use of Network Function Virtualization (NFV) and Network-to-Network (N2N) forwarding. It illustrates the process of discovering and selecting Multipath Lossy Forwarding (MLF) and Multilevel Forwarding (MLF) forwarding technologies, which are crucial for maintaining network reliability and performance. The figure also highlights the use of Network Radio Frequency (NRF) for data forwarding, which is a key component of the architecture.\nFigure 6.13.2-1: NWDAF containing MTLF discovery and selection via NRF by NWDAF containing AnLF belonging to different vendors\nNOTE:\tThe procedure described in this clause is based on the NWDAF discovery and selection as defined in TS 23.288 [5].\nEditor's note:\tHow ML model privacy is supported when NWDAF containing MTLF and NWDAF containing AnLF belong to different vendors is in scope of SA WG3.\nEditor's note:\tWhether any other parameters apart from ML model file serialization format needs to be considered to support interoperability between NWDAF containing AnLF and NWDAF containing MTLF belonging to different vendors is for FFS.\nAn NWDAF containing MTLF shall send Nnrf_NFManagement_NFRegister request which include ML model file serialization format supported in the ML model filter information for the trained ML model per Analytics ID(s). The ML model file serialization format(s) included in the ML model Filter information indicates the supported ML model file serialization format(s) for the trained ML model(s) available at the NWDAF containing MTLF for the service consumer.\nDuring the discovery of NWDAF containing MTLF a consumer (i.e. an NWDAF containing AnLF) may include in the request ML model file serialization format supported per Analytics ID(s) by the NWDAF containing AnLF.\nThe NRF returns one or more candidate for instances of NWDAF containing MTLF to the NF consumer and each candidate for instance of NWDAF with the ML model file serialization format supported for the trained ML model per Analytics ID (s) as indicated by the NWDAF containing AnLF.\nThe NWDAF containing AnLF subscribes to a (set of) trained ML Model(s) associated with a (set of) Analytics ID(s) by invoking the Nnwdaf_MLModelProvision_Subscribe service operation. The NWDAF service consumer includes the ML model file serialization format supported as input in Nnwdaf_MLModelProvision_Subscribe service operation.\nThe NWDAF containing MTLF notifies the NWDAF service consumer with the trained ML Model Information (containing (set of) file address of the trained ML model) by invoking Nnwdaf_MLModelProvision_Notify service operation. The content of trained ML Model Information that can be provided by the NWDAF containing MTLF is specified in clause 6.2A.2 of TS 23.288 [5].\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.14\tSolution #14: Enhance trained ML Model sharing via ML Model format",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.14.1\tDescription",
                            "text_content": "This is a solution for the Key Issue#5: Enhance trained ML Model sharing.\nAs shown in Figure1, ML model(s) is trained and inferred based on some specific AI framework (e.g. TensorFlow, Pytorch, Caffe, etc.) and it cannot be understood and used by other AI frameworks because the properties of each AI framework (e.g. Network topology, Execution flow, Data format, Supporting language) are different.\nThe figure depicts a problem of ML model(s) sharing between different AI frameworks, illustrating the challenges and potential solutions.\nFigure 6.14.1.1-1: Problem of ML model(s) sharing between different AI Frameworks\nAs shown in Figure 6.14.1.1-2, it is proposed to enhance ML model sharing between different AI Frameworks via ML model Format such as , which is an open format built to represent machine learning models. ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers, for example:\n1).\tFor a NWDAF (containing MTLF) with TensorFlow AI framework, it only needs to convert a TensorFlow specific ML Mode file to an open ONNX ML Model file, which can be consumed by any NWDAF(AnLF) who supports open ONNX ML Model.\n2).\tFor a NWDAF (containing AnLF) who supports open ONNX ML Model, it interacts with the NWDAF (containing MTLF) to retrieve the open ONNX ML Model file, which will be converted by NWDAF (containing AnLF) to Caffe specific ML Model file.\nEditor's note:\tONNX is just an example of format for ML model, and which open format for ML Model and the associated software support for the ML model is used is FFS.\nThe figure depicts an open ML model format that supports ML model sharing, illustrating the structure and components of an ML model. It includes a header section, a data section, and a header section, with the data section containing the model's parameters and the header section containing the model's metadata. The figure also includes a section for sharing the model, with a section for sharing the model's parameters and a section for sharing the model's metadata. The figure is designed to be easily understood and used by ML model developers and users.\nFigure 6.14.1.1-2: Open ML model Format to support ML model sharing\nNOTE:\tIn addition,  is studying how to use AI/ML model for video coding, where AI/ML model sharing between different companies has been conducted for video coding evaluation and crosscheck purposes:\n-\tObservations from JVET shows that conversion to/from ONNX can be done from various framework.\n-\tIt was agreed to use ONNX format for model description for companies' evaluation of model performance.\n-\tPlease refer to  for detailed information.\nThe figure depicts a registration and discovery process for NWDAF (MTLF) with an open ML model format. It illustrates the steps involved in establishing a connection between a network device and a machine learning model, using a standardized format for data exchange. The figure includes a registration process, where the network device sends a registration request to the ML model, followed by a discovery process, where the ML model sends back a response to the network device. The figure also includes a visual representation of the data exchange format, which is an open ML model format, allowing for easy integration and sharing of machine learning models across different networks.\nFigure 6.14.1.2-1: Registration and discovery for NWDAF(MTLF) with open ML model Format\n1-3.\tThe NWDAF (containing MTLF) registers its NF profile (Address of NWDAF (containing MTLF), Supported Analytics ID, Supported ML Model Format Information, Supported AI Framework Information) into NRF.\nThe Supported ML Model Format Information indicates which ML Model Format is supported. For example, the trained ML Mode by the NWDAF (containing MTLF) can be converted to an ONNX ML Model file.\nThe Supported AI Framework Information indicates which AI Framework (e.g. Tensor Flow, Pythorch, Caffe) is used to train the ML Model.\nEditor's note:\tIt is FFS how to protect the ML model privacy in the MTLF, if the AnLF and the MTLF belongs to different vendors and coordination with SA3 is needed.\nEditor's note:\tIt is FFS on what model metadata should be included in the model sharing procedure.\n4-6.\tThe NWDAF (containing AnLF) is to discover multiple NWDAFs (containing MTLF) via the NRF by invoking the Nnrf_NFDiscovery_Request (Analytics ID, ML Model Format Information, AI Framework Information) service operation.\nThe NRF notifies the NWDAF (containing AnLF) with one or more NWDAF (containing MTLF) instances.\n7.\tThe NWDAF (containing AnLF) selects a NWDAF (containing MTLF) and then subscribes to the chosen NWDAF (containing MTLF1) a trained ML Model by invoking the Nnwdaf_MLModelProvision (Analytics ID, ML Model Format Information, AI Framework Information) service operation.\n8.\tThe chosen NWDAF (containing MTLF1) notifies the NWDAF (containing AnLF) with the ML model information by invoking Nnwdaf_MLModelProvision_Notify service operation.\nThe ML model Information includes either an ML Model file (e.g. an open ONNX ML Model file) or a specific AI Framework ML Model file (e.g. a TensorFlow specific ML Model file), respectively.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.14.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF(MTLF):\n-\tregister \"Supported ML Model Format Information, Supported AI Framework Information\" in NF profile to NRF.\n-\tprovide ML Model Information per Supported ML Model Format Information/Supported AI Framework Information as indicated in Nnwdaf_MLModelProvision.\nNRF:\n-\tsupport NWDAF(MTLF) discovery procedure per Supported ML Model Format Information/Supported AI Framework Information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.15\tSolution #15: ML model sharing with different AnLF providers",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.15.1\tDescription",
                            "text_content": "In Rel-17, NWDAF decomposed into as described in TS 23.288 [5]:\n-\tAnalytics logical function (AnLF): An NWDAF containing the Analytics logical function can perform inference, derive analytics information and expose analytics.\n-\tModel Training logical function (MTLF): An NWDAF containing the Model Training logical function, trains ML models and exposes new training services.\nBut, even it has decomposed into two functions, the MTLF provides the ML model to the AnLF of same provider as MTLF i.e. ML model will be share to the same vendor AnLF, but not other vendor AnLF, see the below note from clause 5.1 of TS 23.288 [5].\nNOTE 3:\tIn this Release of the specification an NWDAF containing AnLF is locally configured with (a set of) IDs of NWDAFs containing MTLF and the Analytics ID(s) supported by each NWDAF containing MTLF to retrieve trained ML models. An NWDAF containing AnLF uses NWDAF discovery for NWDAF containing MTLF within the set of configured IDs of NWDAFs containing MTLF, if necessary. ML Model provisioning/sharing between multiple MTLFs is not supported in this Release of the specification.\nTherefore, based on the KI#5, in this solution, it is assumed that based on the business logic of the MTLF, the MTLF will determine whether to expose the certain ML models to another provider's AnLF or not. For example, assume that MTLF have two set of certain models, model#1 is developed based on publicly available model and model#2 is develop based on business needs with high accuracy level. In this case, MTLF provider is only ready to share the model#1, but not model#2.\nBased on the above assumption, this solution proposed that MTLF includes the support of interoperable indicator in the NF profile for the NRF registration, and the consumer (AnLF) discovers and selects the MTLF that is interoperable for an analytic ID. Such Interoperable Indicator encodes the 3GPP-specific Vendor Id (which is similar to the ViD as described in clause 23.3.2.3.1 of TS 23.003 [10]). Based on the interoperable indicator, the MTLF determine and select the model, and then MTLF sends the model details to the AnLF. Based on the local policy, if a MTLF does not support the model or does not want to share it, the MTLF will send a rejection message, e.g. reject message with that sharing the model is not possible for the analysis ID.\nThereby, two objectives are achieved:\na)\tAnLF when discovering MTLFs the returned list of MTLF instances can be limited to those that allow sharing ML models to the AnLF instance.\nb)\tMTLF when receiving a MLModelProvision request, can verify that the requesting AnLF instance is allowed to retrieve the ML model. Otherwise, it can reject the request.\nFurthermore, this solution also proposed that MTLF provide the accuracy level and resource efficiency of the ML model to the AnLF. Similar to preferred level of accuracy of the analytics, the MTLF determine the accuracy for the trained model and required resource efficiency (e.g. required resource to run the model).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.15.2\tProcedures",
                            "text_content": "The figure depicts a procedure for sharing a machine learning model, with a step-by-step guide on how to share the model with others. The model is represented as a series of steps, each labeled with a number, and a description of the process is provided for each step. The steps include selecting the model, preparing the data, training the model, and sharing the model. The figure is a visual representation of the process, making it easy to understand and follow.\nFigure 6.15.2-1: Procedure for sharing of ML model\n0.\tThe MTLF registers its NF profile in the NRF as described in clause 5.2.7.2.2 of TS 23.502 [3]. Each MTFL NF profile therefore has included the Interoperable Support Indicator, which indicates that the MTLF supports the interoperable models and what are the corresponding interoperability conditions, one of the conditions being a list of AnLF providers (vendors) that are allowed to retrieve ML models from the MTLF.\n1.\tThe AnLF discovers and selects the MTLF by local information or via from NRF. During the discovery of MTLF via NRF, the NRF provides MTLF profiles to the AnLF, the AnLF selects the MTLF that support the interoperability.\nNOTE 1:\tIt is possible that AnLF can explicitly query the NRF supporting the interoperable MTLF by providing an Interoperable Support Indicator in the discovery request. At a minimum, the NRF discovery allows to query only those MTLFs where the requesting AnLF provider (vendor) is allowed to retrieve ML models from.\n2.\tThe AnLF sends the Nnwdaf_MLModelInfo_Request or Nnwdaf_MLModelProvision_Request to the MTLF with an analytic ID and ML model filter information.\nNOTE 2:\tIt is up to stage 3 and/or SA3 to define how to ensure that MTLF receives information (e.g. vendor ID) to determine whether the ML model can be provided to the requesting AnLF. For example, using the Vendor ID data type as defined in TS 29.510 [11] or completely new format.\nNOTE 3:\tHow MTLF verifies that vendor information of AnLF as provided by AnLF in the Nnwdaf_MLModelInfo_Request or Nnwdaf_MLModelProvision_Request service requests is correct, i.e. matching the actual AnLF vendor, is for SA WG3 to solve.\n3.\tMTLF determine the AnLF service provider and determine whether to expose the model or not. If yes, the MTLF selects the ML Model. If not, MTLF will reject the request and return a corresponding error message.\n4.\tThe MTLF sends the ML models details to the AnLF in the Nnwdaf_MLModelInfo_Request or Nnwdaf_MLModelProvision_Request response. In the response, the MTLF includes the ML model accuracy level and resource efficiency level to the AnLF.\nNOTE 4:\tIt could be that AnLF can explicitly ask preferred level of ML model accuracy and resource efficiency in step 2. The accuracy and resource efficiency level can be \"low\", \"medium\" and \"high\".\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.15.3\tImpacts on existing nodes and functionality",
                            "text_content": "AnLF able to select the MTLF which support the interoperability, i.e. can provide a ML model to the AnLF. Furthermore, AnLF includes access information (encoding the 3GPP-specific Vendor Id) in the Nnwdaf_MLModelInfo_Request and Nwdaf_MLModelProvision_Request.\nMTLF registers the support of interoperability with the NRF such as Interoperable Support Indicator in the NF profile (e.g. NFProfile in NRF is extended to include a list of AnLF providers (vendors) that can access the MLModelProvision service).\nMTLF when receiving a Nwdaf_MLModelProvision or Nnwdaf_MLModelInfo request will determine the AnLF vendor information from the request message to determine if the ML model can be shared with the AnLF.\nFurthermore, MTLF can provide the ML model accuracy and resource efficiency levels. Based on internal policy, the MTLF select the model and provide it to the AnLF.\nNRF stores and filter MTLFs that support interoperability and, as a response to the Nnrf_NFDiscovery_Request provide the filtered list of MTLF instances to the AnLF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.16\tSolution #16: NWDAF assisted URSP determination",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.16.1\tDescription",
                            "text_content": "This solution is proposed to address Key Issue #6: NWDAF-assisted URSP.\nA URSP rule consists of traffic descriptor and route selection descriptor. Traffic descriptor is determined e.g. by application guidance from AF and is relatively fixed, which may not need analytics from NWDAF. This solution mainly proposes the existing analytics and enhanced analytics from NWDAF to assist to adjust the route selection descriptor and the related components of route selection descriptors can be reflected by Analytics ID(s). And the mapping between RSD components and output from Analytics IDs are showed in Table 6.16.1-1.\nTable 6.16.1-1: NWDAF assisted URSP determination\n\nThe PCF generates a URSP Rule based on the Service Parameters provided by the AF, or alternatively locally configured in the PCF or both, then the PCF checks that the RSC of the URSP Rule complies with the UE context Policy control subscription information for a SUPI. Then, the PCF checks if Analytics are needed for further refinement of the candidate values.\nIn this solution, the PCF is configured, depending on operator policies, to subscribe to those Analytics ID(s) listed in the Table 6.16.1-1, then output of these Analytics are used to:\n-\tdetermine if traffic of the application is to be offloaded outside the PDU Session.\n-\tprioritize (or remove some of) the list of candidate values for the Network Slice Selection component or for the DNN Selection component.\n-\tallocate the SSC Mode value, and the PDU Session Type.\n-\tselect the preferred Access Type.\n-\tdetermine if PDU Session Pair ID and/or RSN needs to be provided.\nThese are some examples of how the PCF assigns the values of the different Route Selection Components:\nNetwork Slice Selection: PCF can request or subscribe to:\n-\tAnalytics ID \"Service Experience\" for a particular application that is part of the traffic descriptor, via the candidate network slices by setting filter information. The PCF may select or prioritize the network slice that provides the best service experience for the application.\n-\tAnalytics ID \"Load Level Information\" for the candidate network slices and select the one with lowest load.\n-\tAnalytics ID \"Dispersion Analytics\" to get, e.g. Data volume dispersion Analytics type. The PCF may calculate the average data rate in the network slice by subscribing to notifications of network analytics related to Data Volume Dispersion in the network slice for a duration of interest when it sets the Target of Analytics Reporting as \"any UE\". The PCF may update URSP on slice selection policy for the associated UEs based on the data volume dispersion analytics results provided by the NWDAF for data volume dispersion statistics at a given slice and/or data volume dispersion predictions at a given slice.\n-\tAnalytics ID \"Session Management Congestion Control Experience\" for the PDU Session associated with the candidate S-NSSAI indicated by Analytics Filter Information, targeting the SUPI as Target of Analytics Reporting. The PCF may select or prioritize the S-NSSAI that provides the lowest experience level of Session Management Congestion Control for the SUPI.\n-\tBoth, first the list of candidate slices and the service experience it provides for the application is provided and then the load level for those slices are checked.\n-\tOr just subscribe to Analytics ID \"Service Experience\" for a particular application, for slices that are not heavy loaded.\n-\tOr just to subscribe to Analytics ID \"Dispersion Analytics\" as explained above for certain slice(s).\nDNN Selection: Similar to the first bullet, The PCF may subscribe to Analytics ID on \"Service Experience\" for a particular application that is part of the traffic descriptor, via the candidate DNNs. The PCF may select or prioritize some of the DNN that provides the best service experience for the application.\nThe PCF may also subscribe to notifications of network analytics related to \"UE Communication\". The PCF may update the URSP on DNN selection policy for the associated SUPI, group of UEs or UEs associated with the Application Identifier based on this notification from NWDAF (e.g. considering DNN in Traffic characterization and associated Traffic Volume, Spatial validity and inactivity time) . The PCF may subscribe to Analytics ID \"Session Management Congestion Control Experience\" for the PDU Session associated with the candidate DNN indicated by Analytics Filter Information, targeting the SUPI as Target of Analytics Reporting. The PCF may select or prioritize the DNN that provides the lowest experience level of Session Management Congestion Control for the SUPI.\nNon-Seamless Offload indication: PCF can request or subscribe \"UE Communication\" to get information on the location where UE will use the application and then get the information about the WLAN performance of this location by requesting or subscribing the Analytics ID \"WLAN performance\". If the WLAN performance is good enough, PCF may choose to configure this indication for the application in that area to reduce the load of 3GPP access. PCF may subscribe to notifications of network analytics related to \"Network Performance\". The PCF may update this indication within URSP of the associated UEs within the area of interest based on this notification from NWDAF (e.g. on gNB status and gnB resource usage information). PCF may subscribe to notifications of network analytics related to \"User Data Congestion\". The PCF may update this indication within URSP of the associated SUPI based on this notification from NWDAF (e.g. Network Status Indication).\nSSC Mode Selection, PDU Session Type and Access Type preference: the PCF may subscribe to Analytics ID on \"Service Experience\" for a particular application that is part of the traffic descriptor, via the candidate SSC mode, PDU Session Type and Access Type preference. The PCF may select the SSC mode, PDU Session Type and Access Type preference that provides the best service experience for the application. these factors should also be captured by \"Service Experience\" Analytics. This solution enhanced the \"Service Experience\" Analytics in clauses 6.16.1.1 and 6.16.1.2. SSC Mode Selection: the PCF may subscribe to Analytics ID on \"Expected UE behaviour\" for this SUPI. The PCF may select the SSC mode depending on the mobility pattern (e.g. If no mobility then the SSC mode is not relevant and can be omitted).\nPDU Session Pair ID and RSN: PCF can request or subscribe to Analytics ID \"Redundant Transmission Experience\" to be notified if PDU Session Pair ID and/or RSN needs to be provided. If the output of the Analytics says \"redundant transmission shall be performed\", the PCF may provide appropriate PDU Session Pair ID and/or RSN with the help of local configuration in the corresponding SMF. Details on how the SMF determines PDU Session Pair ID and/or RSN can be found in clause 5.33.2.1 of TS 23.501 [2].\nTime Window and Location Criteria: The Time Window in the RSD Validation Criteria can be set based on the time validity period and spatial validity in the Analytics ID(s) used as input in the RSD generation. The PCF may need to select the validity period and spatial validity out of those provided in the output of each Analytics ID(s).\nThe PCF can also subscribe or request analytics of combination of several RSCs in one RSD in Analytic ID = Service Experience. This design enhances the input parameters of the \"observed service experience\" analytics, including PDU session type, SSC mode and etc.\nThe PCF can adjust the RSD precedence according to the analytic from NWDAF, and also the PCF can receive the analytic of the whole RSD (if the combination of RSCs are all of RSCs included in one RSD) or different arbitrary combination of RSCs in URSP rule.\nNOTE:\tFor example, the combination of S-NSSAI + DNN or the combination of PDU session type + SSC mode and etc. from NWDAF. The NWDAF should support to provide the analytic of combination of several RSCs to PCF in Analytics ID = Service Experience.\nBased on input data of Observed Service Experience related network data Analytics as described in clause 6.4.2 of TS 23.288 [5], table 6.16.1.1-1 provides enhanced input data by adding PDU Session related information and table 6.16.1.1-2 provides enhanced input data access type.\nTable 6.16.1.1-1: QoS flow level Network Data from 5GC NF related to the QoS profile assigned for a particular service (identified by an Application Id or IP filter information)\n\nTable 6.16.1.1-2: UE level Network Data from 5G NF related to the Service Experience\n\nBased on output analytics of Observed Service Experience related network data Analytics for applications as described in clause 6.4.3 of TS 23.288 [5], table 6.16.1.2-1 provides enhanced output analytics by adding PDU Session related information and access type.\nTable 6.16.1.2-1: Service Experience Statistics\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.16.1-1: NWDAF assisted URSP determination",
                                    "table number": 10,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.16.1.1-1: QoS flow level Network Data from 5GC NF related to the QoS profile assigned for a particular service (identified by an Application Id or IP filter information)",
                                    "table number": 11,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.16.1.1-2: UE level Network Data from 5G NF related to the Service Experience",
                                    "table number": 12,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.16.1.2-1: Service Experience Statistics",
                                    "table number": 13,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.16.2\tProcedures",
                            "text_content": "The same as procedures of related Analytics ID in TS 23.288 [5] and also clause 4.15.6.10 of TS 23.502 [3] with additional subscription (or request) to the NWDAF to determine the guidance for URSP.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.16.3\tImpacts on existing nodes and functionality",
                            "text_content": "PCF:\n-\tSubscribes or requests Analytics ID (s) on Table 6.16.1-1 for URSP determination.\nAF:\n-\tSubscribes or requests Analytics ID (s) on Table 6.16.1-1 to provide the guidance for URSP determination as described in clause 4.15.6.10 of TS 23.502 [3].\nNWDAF:\n-\tsupports enhanced Analytics ID \"Service Experience\" to provide the analytic of whole RSD or arbitrary combination of RSCs.\nSMF:\n-\tNsmf_EventExposure, PDU Session Establishment and/or PDU Session Release is extended to include the SSC mode per PDU Session.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.17\tSolution #17: NSSP in roaming scenarios using network analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.17.1\tDescription",
                            "text_content": "This solution addresses key issue #3 \"Data and analytics exchange in roaming case\" and key issue #6 \"NWDAF-assisted URSP\".\nWhen the UE is roaming, the PCF in the HPLMN may update the NSSP as part of the URSP rules in the UE. To decide the NSSP in roaming scenarios, the H-PCF may take into account of the Network Slice status in VPLMN. Therefore, analytics in VPLMN (i.e. Service Experience for an application and/or Network Slice, Network Slice load level, etc.) can be sent to the HPLMN and used by the H-PCF for decision of NSSP to be provisioned to the UE, so that the UE can be instructed to transmit the application data over the PDU Session(s) in the indicated VPLMN and/or HPLMN Network Slice(s) in roaming scenarios.\nNOTE:\tFS_UEPO, key issue 1, aims to enable the provisioning of URSP rules in the VPLMN and may thus remove the need for the H-PCF to determine NSSP.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.17.2\tProcedures",
                            "text_content": "Figure 6.17.2-1 shows the procedure that H-NWDAF requests the Observed Service Experience analytics in VPLMN from V-NWDAF, upon receiving an analytics information/subscription request from the H-PCF.\nThe figure depicts a procedure for providing VPLMN Service Experience analytics to HPLMN, illustrating the steps involved in analyzing and providing insights into the service experience of a network.\nFigure 6.17.2-1: Procedure for providing VPLMN Service Experience analytics to HPLMN\n1.\tH-PCF sends an Analytics request/subscribe (Analytics ID = Service Experience, Target of Analytics Reporting = a UE or a group of UEs or any UE, Analytics Filter Information = (Application ID, HPLMN S-NSSAI, VPLMN S-NSSAI, VPLMN ID)) to H-NWDAF by invoking a Nnwdaf_AnalyticsInfo_Request or a Nnwdaf_AnalyticsSubscription_Subscribe.\nNOTE:\tHere the VPLMN S-NSSAI is used as an indication of request/subscription to analytics information of the mapped Network Slice in the VPLMN, and its value can be set to zero by the H-PCF.\n2.\tThe H-NWDAF determines the VPLMN S-NSSAI, which is mapped to the HPLMN S-NSSAI, and discovers the V-NWDAF. The H-NWDAF invokes the Nnssf_NSSelection_Get service operation to the hNSSF with the HPLMN S-NSSAI and VPLMN ID received in step 1, and receives the VPLMN S-NSSAI and the information of appropriate vNRF to be used to select NFs/services within VPLMN, which may be obtained by the hNSSF from the vNSSF, in the Nnssf_NSSelection_Get response. The H-NWDAF further invokes the Nnrf_NFDiscovery_Request (Expected Service Name = Nnwdaf_AnalyticsInfo (or Nnwdaf_AnalyticsSubscription), NF type of the expected NF = NWDAF, Analytics ID = Service Experience, HPLMN ID, VPLMN ID, VPLMN S-NSSAI, HPLMN S-NSSAI, NF type of the NF service consumer = NWDAF) to the hNRF, and discovers the V-NWDAF using the procedure as described in clause 4.17.5 of TS 23.502 [3].\nH-NWDAF sends an Analytics request/subscribe (Analytics ID = Service Experience, Analytics Filter Information = (Application ID, VPLMN S-NSSAI)) to V-NWDAF by invoking a Nnwdaf_AnalyticsInfo_Request or a Nnwdaf_AnalyticsSubscription_Subscribe, based on the Analytics request/subscribe received from the H-PCF.\n3-5.\tV-NWDAF collects data from the NF(s) and/or OAM in VPLMN and derives the requested Service Experience analytics information, as specified in clause 6.4 of TS 23.288 [5].\n6.\tV-NWDAF sends the VPLMN Service Experience analytics information to the H-NWDAF using either Nnwdaf_AnalyticsInfo_Request response or Nnwdaf_AnalyticsSubscription_Notify.\n7-9.\tH-NWDAF collects data from the NF(s) and/or OAM in HPLMN and derives the requested Service Experience analytics information, as specified in clause 6.4 of TS 23.288 [5]. These steps can be executed in parallel with step 3-6.\n10.\tH-NWDAF sends the VPLMN analytics information received in step 6, together with the HPLMN analytics information derived in step 9, to the H-PCF using either Nnwdaf_AnalyticsInfo_Request response or Nnwdaf_AnalyticsSubscription_Notify.\nWhen the UE is roaming, the PCF in the HPLMN may take into account of the VPLMN Service Experience analytics information to update the NSSP (as part of the URSP rules) in the UE, i.e. including the VPLMN S-NSSAI and/or HPLMN S-NSSAI of the Network Slice(s) with better Service Experience for the application, which instructs the UE to use the PDU Session in the Network Slice(s) for transmission of the application.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.17.3\tImpacts on existing nodes and functionality",
                            "text_content": "PCF: based on HPLMN and VPLMN analytics information, updates the NSSP (as part of the URSP rules) to the UE for the UE using the PDU Session in the indicated Network Slice(s) to transmit the application in roaming scenarios.\nH-NWDAF: requests VPLMN analytics information from the V-NWDAF.\nV-NWDAF: provides VPLMN analytics information to the H-NWDAF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.18\tSolution #18: Integrity KPI for QoS Sustainability Analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.18.1\tKey Issue mapping",
                            "text_content": "This key issue addresses Key Issue#7 i.e. enhancements on QoS sustainability analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.18.2\tDescription",
                            "text_content": "In general, this solution proposes to use QoS sustainability analytics solution which is defined in clause 6.9 of TS 23.288 [5] as baseline and add new input and output parameters to meet 5GAA requirement. It is assumed to reuse the same Analytics ID as defined Rel-17.\nThe consumer of QoS Sustainability analytics may request the NWDAF analytics information regarding the QoS change statistics for an Analytics target period in the past in a certain area or the likelihood of a QoS change for an analytics target period in the future in a certain area with finer granularity i.e. below cell level.\nThe consumer can request either to subscribe to notifications (i.e. a Subscribe-Notify model) or to a single notification (i.e. a Request-Response model).\nThe service consumer may be a NF (e.g. AF).\nThe request includes the following parameters:\n-\tAnalytics ID = \"QoS Sustainability \";\n-\tTarget of Analytics Reporting: any UE;\n-\tAnalytics Filter Information:\n-\tQoS requirements (mandatory):\n-\t5QI (standardized or pre-configured), and applicable additional QoS parameters and the corresponding values (conditional, i.e. it is needed for GBR 5QIs to know the GFBR); or\n-\tthe QoS Characteristics attributes including Resource Type, PDB, PER and their values;\n-\tLocation information (mandatory): an area or a path of interest. The location information could reflect a list of waypoints;\nNOTE:\tIn this Release, the consumer of the \"QoS Sustainability\" Analytics ID will provide location information in the area of interest format (TAIs or Cell IDs) and also location information below cell level which are understandable by NWDAF.\n-\tS-NSSAI (optional);\n-\tOptional maximum number of objects;\n-\tAnalytics target period: relative time interval, either in the past or in the future, that indicates the time period for which the QoS Sustainability analytics is requested;\n-\tReporting Threshold(s), which apply only for subscriptions and indicate conditions on the level to be reached for the reporting of the analytics, i.e. to discretize the output analytics and to trigger the notification when the threshold(s) provided in the analytics subscription are crossed by the expected QoS KPIs.\n-\tA matching direction may be provided such as crossed (default value), below, or above.\n-\tAn acceptable deviation from the threshold level in the non-critical direction (i.e. in which the QoS is improving) may be set to limit the amount of signalling.\nThe level(s) relate to value(s) of the QoS KPIs defined in TS 28.554 [9], for the relevant 5QI:\n-\tfor a 5QI of GBR resource type, the Reporting Threshold(s) refer to the QoS flow Retainability KPI;\n-\tfor a 5QI of non-GBR resource type, the Reporting Threshold(s) refer to the RAN UE Throughput KPI.\n-\tfor any 5QI, the Reporting Threshold(s) refer to the Integrity KPI which contains latency and delay of 5G networks as defined in TS 28.554 [9].\n-\tIn a subscription, the Notification Correlation Id and the Notification Target Address.\nThe NWDAF collects the corresponding statistics information on the QoS and Integrity KPI for the relevant 5QI of interests from the OAM, i.e. the QoS flow retainability or the RAN UE Throughput as defined in TS 28.554 [9].\nIf the Analytics target period refers to the past:\n-\tThe NWDAF verifies whether the triggering conditions for the notification of QoS change statistics are met and if so, generates for the consumer one or more notifications.\n-\tThe analytics feedback contains the information on the location and the time for the QoS change statistics and the Reporting Threshold(s) that were crossed.\nIf the Analytics target period is in the future:\n-\tThe NWDAF detects the need for notification about a potential QoS change based on comparing the expected values for the KPI of the target 5QI against the Reporting Threshold(s) provided by the consumer in any cell in the requested area for the requested Analytics target period. The expected KPI values are derived from the statistics for the 5QI obtained from OAM. OAM information may also include planned or unplanned outages detection and other information that is not in scope for 3GPP to discuss in detail.\n-\tThe analytics feedback contains the information on the location and the time when a potential QoS change may occur and what Reporting Threshold(s) may be crossed.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.18.3\tProcedures",
                            "text_content": "Figure 6.18.3-1 depicts a procedure for QoS Sustainability analytics provided by NWDAF.\nThe figure depicts a QoS sustainability analytics dashboard, showcasing key metrics such as packet loss, jitter, and delay, which are crucial for network performance. The dashboard is designed to provide real-time insights into network health, enabling network operators to make informed decisions and optimize their network resources.\nFigure 6.18.3-1: QoS Sustainability analytics provided by NWDAF\n1.\tThe consumer requests or subscribes to analytics information on \"QoS Sustainability\" provided by NWDAF. The parameters included in the request are described in clause 6.9.1 of TS 23.288 [5].\nThe consumer may include multiple sets of parameters in order to provide different combinations of \"Location information\" and \"Analytics target period\" when requesting QoS Sustainability analytics.\n2.\tThe NWDAF collects the data specified in clause 6.9.2 of TS 23.288 [5] from the OAM, following the procedure captured in clause 6.2.3.2 of TS 23.288 [5].\n3.\tThe NWDAF verifies whether the triggering conditions are met and derives the requested analytics. The NWDAF can detect the need for notification based on comparing the requested analytics of the target 5QI against the Reporting Threshold(s) provided by consumer in any cell over the requested Analytics target period.\n4.\tThe NWDAF provides response or notification on \"QoS Sustainability\" to the consumer.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.18.4\tImpacts on services, entities and interfaces",
                            "text_content": "Table 6.18.4.1-1: Data collection for \"QoS Sustainability\" analytics\n\nNOTE 1:\tThe timeslot is the time interval split according to the time unit of the OAM statistics defined by operator.\nNOTE 2:\tHow to collect the finer granularity about location is not elaborated in this solution but use other solutions e.g. based on output of KI#9.\nThe NWDAF outputs the QoS Sustainability analytics. Depending on the Analytics target period, the output consists of statistics or predictions. The detailed information provided by the NWDAF is defined in Table 6.9.3-1 for statistics and Table 6.9.3-2 for predictions.\nTable 6.9.3-1: \"QoS Sustainability\" statistics, TS 23.288 [5]\n\nTable 6.9.3-2: \"QoS Sustainability\" predictions, TS 23.288 [5]\n\nNOTE 1:\tThe meaning of Confidence is based on the SLA, i.e. the consumer has to understand the meaning of the different values of Confidence.\nNOTE 2:\tThe Analytics can contain multiple sets of the above information if the location information reflected a list of waypoints.\nThe number of QoS sustainability analytics entries is limited by the maximum number of objects provided as part of Analytics Reporting Information.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.18.4.1-1: Data collection for \"QoS Sustainability\" analytics",
                                    "table number": 14,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.9.3-1: \"QoS Sustainability\" statistics, TS 23.288 [5]",
                                    "table number": 15,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.9.3-2: \"QoS Sustainability\" predictions, TS 23.288 [5]",
                                    "table number": 16,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "6.19\tSolution #19: Enhanced QoS Sustainability Analytics in the finer granularity area",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.19.1\tDescription",
                            "text_content": "QoS Sustainability analytics is an important analytics service, especially for V2X-related or safety related applications, since it helps to handle the impact of a sudden change of the QoS and thus avoid a harsh application adjustment, which could affect safety and efficiency. However, there is the need to enhance the granularity and the accuracy of the QoS Sustainability analytics as well as to extend the QoS parameters that the QoS Sustainability notification can be provided. The latter will help to increase the usefulness of the specific analytics ID as well as to support the requirements of various use cases (e.g. V2X related).\nMore accurate QoS Sustainability outputs needs QoS and input parameters to be associated with more accurate location and speed information, when input information is monitored at RAN. Also, the list of input features of the QoS Sustainability analytics ID should be extended by adding information on radio resource utilization and performance measurements for transfer over the UP to improve the correctness and accuracy of QoS sustainability output. Finally, NWDAF should also be able to collect - optionally - additional information on the context that is related to those performance measurements when such information is available, such as PEI, Subscriber category, Operating system information, information on the serving UPF node. Different UPF nodes serving the UE may be responsible for very different QoS, depending on the location of the UPF node such as in edge deployments. PEI may also be used to retrieve from services such as the GSMA database, additional information such as device model, device manufacturer, IMEI or IMEISV or TAC range, supported frequency bands, equipment type. Such additional information may be used by NWDAF to add more information to the collected measurements and filter those measurements that are applicable to the UE and subscription context for which analytics are requested by the service consumer.\nIn order to produce more accurate analytics, the service consumer may provide additional analytics filter information in the request of subscription, in order to request analytics which better fit the conditions of selected UEs instead of analytics that generically apply to a large number of UEs with different context (e.g. type of construction, speed, etc.) . Such additional analytics filter information may include one or more of the following: device speed or speed range, serving UPF node information, Subscriber category (as in clause 6.2.1.3 of TS 23.503 [4]), device model, device manufacturer, IMEI or IMEISV or TAC range, supported frequency bands, equipment type.\nAdditional QoS parameters (delay, packet loss rate) should be considered by the QoS Sustainability analytics and additional inputs for these QoS parameters are needed as inputs to the QoS Sustainability analytics. Finally, in the case that an area of interest is provided in the QoS Sustainability request message by an analytics consumer then the necessary granularity of the area of interest should be indicated.\nThe outputs of the QoS Sustainability analytics (statistics and predictions), should be provided for more granular location, according to the request with an area or a path of interest.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.19.2\tProcedures",
                            "text_content": "According to the description in clause 6.9 in TS 23.288 [5] the consumer of QoS Sustainability analytics may request the NWDAF analytics information regarding the QoS change statistics for an Analytics target period in the past in a certain area or the likelihood of a QoS change for an Analytics target period in the future in a certain area or path of interest, which is smaller than a cell.\nNOTE 1:\tIn this Release of the specification, to derive the QoS Sustainability analytics in a finer granularity AoI smaller than cell, the AF is required to provide the requested AoI or requested path of interest, which is smaller than cell.\nThe area is described in the request message (either of a Subscribe-Notify model or of a Request-Response model) via Location information (mandatory):\n-\ta path of interest: The location information could reflect a list of waypoints;\n-\tan area: The location information could reflect expected granularity levels of the requested area.\nIn order to achieve the intended objectives, this solution proposes two alternative solutions:\n-\tAlt#1 updates the table with input data of the QoS Sustainability analytics (TS 23.288 [5]) by adding information on radio resource utilization and input related to other QoS parameters (e.g. delay, packet error rate).\n-\tAlt#2 in addition to the updates of the table with input data additional input are considered as explained below.\nTable 6.19.2.2-1: Data collection for \"QoS Sustainability\" analytics (TS 23.288 [5])\n\nNOTE 1:\tThe timeslot is the time interval split according to the time unit of the OAM statistics defined by operator.\nNOTE 2:\tWhether the information listed in Table 6.19.2.2-1 can be collected in requested Area or path of Interest from AF should be dependent on RAN WG3/SA WG5.\nIn Alt#1, with the OAM data per finer granularity area in Table 6.19.2.2-1, the NWDAF derives the \"QoS Sustainability\" statistics on the finer granularity area.\nIn Alt#2, in addition to the information listed in Table 6.19.2.2-1 collected from the OAM in requested Area or path of Interest, additional input data per UE within the finer granularity area for the QoS Sustainability analytics is shown in Table 6.19.2.2-2.\nNote that the NWDAF should firstly determine the Cell list or TA list where requested area or path of Interest is included before the data collection from LMF, AMF, SMF and PCF.\nFor a finer granularity area smaller than a cell, the NWDAF can determine the Cell ID for the cell based on the local configuration of the mapping between the geo area and the network area. Alternatively, during the QoS sustainability analytics subscription by the AF via NEF, the NEF can also determine the Cell ID for the cell based on its local configuration and send the Cell ID to NWDAF.\nTo get a UE ID list located in the finer granularity area, the NWDAF can request the UE location information for all the UEs located in the cell then determine the UE ID list by itself. Alternatively, the NWDAF can also request LMF to provide the UE ID list located in the finer granularity area. In this, the NWDAF should include both the Cell ID and the finer granularity area information into the request service operation to the LMF.\nTable 6.19.2.2-2: Additional data collection for \"QoS Sustainability\" analytics\n\nNOTE 3:\tThe new input about QoS profile from SMF/PCF corresponding to the QNC or AQP will not trigger new RAN measurement.\nNOTE 4:\tIn order to reduce the amount of information collected per measurement point, the new input about UPF information, VelocityEstimate, Subscription Information, PEI, UE Information shall be collected only when a notification is received for the event =\"GFBR can no longer be guaranteed\".\nNOTE 5:\tNWDAF may decide to ignore some of the filters if collected measurements are not sufficient to derive meaningful analytics. In such scenario, a warning message is provided in the response or notification to the NF consumer.\nNote that based on the current QNC/AQP notification mechanism, the SMF/PCF cannot know which parameter of the PER, PDB or GFBR cannot be fulfilled from the QNC/AQP=\"GFBR can no longer be guaranteed\" event. On one hand, because the V2X Application based on the QoS sustainability analytics is quite safety sensitive, when QNC/AQP=\"GFBR can no longer be guaranteed\", the NWDAF can default assume that all the GFBR/PDB/PER are not fulfilled in RAN and send the analytics to V2X AF to help application adjustment. Alternatively, the NWDAF can try to figure the reason out on its own by comparing the RAN notification (i.e. a new reference for the newly fulfilled QoS profile) with the previously fulfilled QoS profile, i.e. if only one of the values has changed the reason is that parameter (if two or three have changed, the NWDAF does not know which parameter(s) caused the problem).\nThis solution does not provide any enhancement on the current QNC/QAP triggering mechanism i.e. NWDAF can only collect the current QNC/AQP events triggered by the AF. It means that the signalling pressure is not too high since signalling is not collected for every QoS Sustainability request, Notification control is enabled when the QoS Notification Control parameter is set in the PCC rule (received from the PCF) that is bound to the QoS Flow.\nNWDAF subscribes to the network data from AMF in the Table 6.19.2.2-2 by invoking Namf_EventExposure_Subscribe (Event IDs = Location Changes, Area of Interest=Cell list or TA list).\nEditor's note:\tHow to collect the UE location and speed from LMF is FFS and the cooperation with FS_eLCS_Ph3 is needed.\nNWDAF subscribes the network data from SMF/PCF in the Table 6.19.2.2-2 by using the services provided by SMF/PCF together with the Cell list or TA list.\nThe correlation information in clause 6.2.4 of TS 23.288 [5] are re-used to correlate the data from LMF, AMF and SMF/PCF.\nWith the CN data per UE in the finer granularity area in Table 6.19.2.2-2, the NWDAF derives the \"QoS Sustainability\" statistics on the finer granularity area. For example, the NWDAF can derives the analytics as follows:\n-\thow many percent of the UE's bit rate/packet delay/packet error rate which can be or cannot be guaranteed on the finer granularity area (below cell level); or\n-\taverage bit rate/packet delay/packet error rate can be or cannot be guaranteed on the finer granularity area (below cell level).\nThe NWDAF outputs the QoS Sustainability analytics, which should be provided according to the analytics request area of path of interest granularity. The provided granularity depends also on collected monitoring data (e.g. that the model has been trained).\nAlso, the Crossed Reporting Threshold(s) should be indicated for QoS parameter: Throughput, Delay, Packet loss.\nTable 6.19.2.3-1: \"QoS Sustainability\" statistics\n\nTable 6.19.2.3-2: \"QoS Sustainability\" predictions\n\nThe procedure in Figure 6.9.4-1 of TS 23.288 [5] is re-used with additional data collection step from LMF, AMF, UDM, etc.\nEditor's note:\tThe procedure will be added when the service operation for LMF data collection is defined.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.19.2.2-1: Data collection for \"QoS Sustainability\" analytics (TS 23.288 [5])",
                                    "table number": 17,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.19.2.2-2: Additional data collection for \"QoS Sustainability\" analytics",
                                    "table number": 18,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.19.2.3-1: \"QoS Sustainability\" statistics",
                                    "table number": 19,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.19.2.3-2: \"QoS Sustainability\" predictions",
                                    "table number": 20,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.19.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF:\n-\tMonitor more information by OAM including radio resource utilization and input related to other QoS parameters or collects QNC/AQP events from SMF/PCF, UE Location and UE speed from LMF or AMF.\n-\tThe outputs of the QoS Sustainability analytics (statistics and predictions), should be provide:\n-\tCrossed Reporting Threshold(s) for QoS parameter: Throughput, Delay, Packet loss.\n-\tmore granular location, according to the request with an area or a path of interest.\n-\textensions of the NWDAF to support UDM query and optionally GSMA database.\nConsumer NFs:\n-\tIn the case that an area of interest is provided in the QoS Sustainability request message by an analytics consumer then the necessary granularity of the area of interest should be indicated.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.20\tSolution #20: GTP metrics for QoS Sustainability analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.20.1\tDescription",
                            "text_content": "This solution addresses the Key Issue #7: Enhancements on QoS Sustainability analytics.\nIn Rel-17, the NWDAF supporting QoS Sustainability analytics collects UE QoS flow Retainability KPI and RAN UE Throughput KPI from OAM (see clause 6.9.2 of TS 23.288 [5]).\nThis solution proposes that the NWDAF additionally collects the following input (see Table 6.20.2-1) according to existing measurements defined in clause 5.33.3 of TS 23.501 [2] (QoS Monitoring to Assist URLLC Service).\nIn order to extend to Network Performance measurements following IP-layer section capacity and IP-layer available section capacity definition from ITU-T Y.1540 [8], the NWDAF should also collect capacity metrics based on GTP path (see Table 6.20.2-2) between UPF, NG-RAN and UE.\nNOTE:\tHow OAM can perform capacity measurements is to be determined by SA WG5.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.20.2\tInput data",
                            "text_content": "Table 6.20.2-1: Packet drop and/or packet delay measurement at GTP level\n\nThe following new data collection proposes to extend the measurements related to QoS Monitoring and defined in TS 23.501 [2] and TS 28.552 [7] to include the IP-layer section capacity and IP-layer available section capacity between UE, NG-RAN and UPF at GTP level.\nTable 6.20.2-2: New Data collection for QoS Sustainability analytics\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.20.2-1: Packet drop and/or packet delay measurement at GTP level",
                                    "table number": 21,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.20.2-2: New Data collection for QoS Sustainability analytics",
                                    "table number": 22,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.20.3\tProcedures",
                            "text_content": "The procedure for \"QoS Sustainability\" analytics provided by NWDAF specified in clause 6.9.4 of TS 23.288 [5] is enhanced by adding data collection from SMF or UPF in step 2.\nNOTE:\tDirect data collection from UPF depends on the outcome of FS_UPEAS.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.20.3\tImpacts on services, existing nodes and functionality",
                            "text_content": "NWDAF:\n-\tConsume UL/DL packet delay.\n-\tConsume UL/DL new capacity metrics between UPF and UE and between UPF and NG-RAN.\n-\tConsume UL/DL new available capacity metrics between UPF and UE and between UPF and NG-RAN.\nUPF:\n-\tPerform the measurements described in clause 6.20.2.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.21\tSolution #21: Federated Learning procedure between different NWDAFs",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.21.1\tDescription",
                            "text_content": "This solution is proposed for KI#8 to support the Federated Learning procedure between different NWDAFs containing MTLF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.21.2\tProcedures",
                            "text_content": "During the NWDAF containing MTLF registration in NRF procedure:\n-\tThe NWDAF containing MTLF shall include the \"FL capability\" registered in its NF Profile registered in the NRF.\n-\tThe \"FL capability\" indicates to support \"FLaggregation\" and / or \"FL participant\" for the corresponding Analytics ID.\n-\t\"FLaggregation\" capability means the MTLF is able to manage the FL operation, select FLparticipants, aggregate the ML models from different ML clients and send back the trained ML model information to the FL participants.\n-\t\"FL participant\" capability means the MTLF is able to perform the ML model training for the ML model that requested by the \"FL aggregation\" by using the available local database and report the trained ML model information to the \"FL aggregation\". The local database can be the data that is allowed to collect by the MTLF from other 5GS or ADRF.\n\"FL Consumer\" NWDAF is either an NWDAF containing AnLF, or an NWDAF containing MTLF that does not support the \"FL aggregation\" capability for the specific Analytics ID, but it is able to enable FL for his/her ML model by requesting FL to \"FL Server\" NWDAF.\n\"FL Server\" NWDAF is the NWDAF containing MTLF that supports the \"FL aggregation\" capability for the specific Analytics ID and selected as the FL Server.\n\"FL Client\" NWDAF is the NWDAF containing MTLF that supports the \"FL participant\" capability for the specific Analytics ID and selected by the \"FL Server\" NWDAF as the FL Client.\nThe \"FL Server\" NWDAF may be selected based on operator's local configuration or by the NWDAF containing AnLF for the analytics ID.\nWhen the \"FL Consumer\" NWDAF is an NWDAF containing AnLF and it discovers an MTLF for a trained ML model as described in clause 5.2 of TS 23.288 [5]. If there is no trained ML model for the Analytics ID supported, the NRF will select the NWDAF containing MTLFs that supports the Analytics ID and the Area Of Interest to train the ML model. The NRF may take priority to select the NWDAF(s) containing MTLF that support \"FL aggregation\" capability if multiple NWDAF containing MTLF profiles registered in the NRF can support the requested ML model training, NRF returns the candidate for instances of NWDAF containing MTLF sent to consumer. The NWDAF containing AnLF selects one NWDAF containing MTLF from the list that received from NRF and initiates the ML Model Provisioning procedure as described in clause 6.2A of TS 23.288 [5]. If the NWDAF containing MTLF selected by NWDAF containing AnLF supports the \"FL aggregation\" capability for the Analytics ID, the NWDAF containing MTLF will further decide if FL procedure is initiated. If the NWDAF containing MTLF selected by NWDAF containing AnLF does not support the \"FL aggregation\" capability, the NWDAF containing MTLF may either performs the ML model training and provision as defined in clause 6.2A in TS 23.288 [5] or discovers a NWDAF containing MTLF that supports \"FL aggregation\" capability to trigger FL operation. When \"FL Consumer\" NWDAF is an NWDAF containing MTLF and it determines to trigger FL by internal logic (e.g. lack of data to train, heavy overhead from the existing ML training, etc.), \"FL Consumer\" NWDAF discovers an NWDAF which supports \"FL aggregation\" capability via NRF and initiates FL by invoking a Nnwdaf_MLModelTraining_Subscribe operation with the indication of enabling FL and initial ML model file address to the selected NWDAF (i.e. \"FL Sever\" NWDAF).\nThe \"FL Server\" NWDAF selects the \"FL Client\" NWDAF from NRF as described in clause 5.2 of TS 23.288 [5]. The \"FL Server\" NWDAF further includes the \"FL Client\" capability as \"FL participant\" capability and the number of reported NWDAFs for the Analytics ID in the discovery request message. The NRF returns the candidates for instances of NWDAF containing MTLF and each candidate for instance of NWDAF containing MTLF includes the Analytics ID, the ML Model Filter Information and support of \"FL participant\" for the Analytics ID.\nThe FL operation procedure between NWDAFs containing MTLF is described in Figure 6.21.2.3-1.\nThe figure depicts the FL operation procedure between NWDAFs, illustrating the steps involved in managing the network's flow of data. The diagram shows the network's topology, including the NWDAFs, and the flow of data between them. The FL operation procedure is a crucial aspect of network management, ensuring efficient data transmission and minimizing network congestion.\nFigure 6.21.2.3-1: FL operation procedure between NWDAFs\n0a.\tWhen \"FL Consumer\" NWDAF is an NWDAF containing MTLF without \"FL aggregation\" capability and it determines to trigger FL from the internal logic, the \"FL Consumer\" NWDAF discovers and selects \"FL Server\" NWDAF via NRF, and subscribes Nnwdaf_MLModelTraining_Subscribe service to the \"FL Sever\" NWDAF with indication of \"Enabling FL\" and the file address of ML model to train.\n0b.\tWhen \"FL Consumer\" NWDAF is an NWDAF containing AnLF, the \"FL Consumer\" NWDAF discovers and selects \"FL\" Server NWDAF via NRF, and subscribes Nnwdaf_MLModelProvsion_Subscribe service to the \"FL Server\" as described in clause 6.2A of TS 23.288 [5].\n0c.\tThe FL operation maybe triggered by local configuration in the \"FL Server\" NWDAF itself or request from \"FL Consumer\" by either step 0a or step 0b. If the Nnwdaf_MLModelProvision_Subscribe operation is triggered at step 0b, the \"FL Server\" NWDAF will consider whether FL operation is needed or not by taking into account the Area Of Interest, the ML model Reporting Information, Expiry time and local operator configuration.\nThe \"FL Server\" NWDAF is configured the Initial FL parameters corresponding to the Analytics ID:\n-\tNumber of FL rounds,\n-\tTotal number of FL clients used in the process.\n-\tThe area of interesting for the analytics ID, the area of interesting can be a PLMN or a registration area list.\nFor Initial ML model training, the pre-configured Initial FL parameters will be used.\nThe ML model maybe re-trained to improve correctness of NWDAF analytics as discussed in KI#1, the FL parameters used for re-training maybe different to the pre-configured Initial FL parameters.\nNOTE 1:\tThe initiation of ML model re-training and the details of FL parameter should be aligned with the conclusion of KI#1.\n1.\t\"FL Server\" NWDAF selects the \"FL Client\" NWDAFs for the specific Analytics ID within the area of interesting for the FL as described in clause 6.21.2.2. \"FL Server\" NWDAF sends Nnwdaf_MLModelTraining_Subscribe to the \"FL Client\" NWDAFs with additional parameters:\n-\tIndication for \"Enabling Local Training\".\n-\tthe FL ID: For each ML model FL operation, the \"FL Server\" NWDAF will allocate different FL IDs for different \"FL Client\" NWDAFs. The \"FL Server\" NWDAF will identify the received the interim ML models from different \"FL Client\" via Analytics ID + FL ID. The FL ID will not updated during the FL operation procedure.\n-\tML model information (containing a (set of) file address of the trained ML model) to request the ML model operation.\nNOTE 2:\tThe selection of FL Clients and the detail parameters to share the ML model should be aligned with the conclusion of KI #5.\n2.\tFor each \"FL Client\" NWDAF, if the ML model information is received from consumer, the \"FL Client\" NWDAF downloads the ML model according to the ML model information received from step 1.\n3.\tUser consent will be performed by each \"FL Client\" NWDAF if UE related parameters are required for ML training.\n4.\tEach \"FL Client\" NWDAF may collect data from other available 5GS (e.g. AMF, SMF) or DCCF for local ML model training.\n5.\tData source sends data to \"FL Client\" NWDAF.\n6.\tEach \"FL Client\" NWDAF performs local ML model training and sends the trained interim ML model via Nnwdaf_MLModelTraining_Notify to the \"FL Server\" NWDAF. The Analytics ID, FL ID, File address of learning results and ML Model Filter Information for the trained interim ML model by \"FL Client\" NWDAF are included in the notify message.\n7.\t\"FL Server\" NWDAF downloads interim trained ML models Identified by Analytics ID and FL ID trained by each \"FL Client\" NWDAF according to the ML model information received in step 6.\n8.\t\"FL Server\" NWDAF performs aggregation for the ML models for the same analytics ID.\nStep 2 to step 8 in box A may repeated to support iterative learning based on the FL parameters configured for the Analytics ID expect step 3. For example, after the step 8 for the first round of learning, the \"FL Server\" NWDAF will initiate step 1 for the second round of learning.\nUse consent check is only performed for in the first round of iterative learning.\n9-10.\tThe \"FL Client\" NWDAF may subscribe the trained ML model for the Analytics ID from \"FL Server\" NWDAF as described in clause 6.2A.1 of TS 23.288 [5].\n11a.\t\"FL Sever\" provides the trained ML models by FL to the \"FL Consumer\" NWDAF at step 0a by invoking \"Nnwdaf_MLModelTraining_Notify\" service operation.\n11b.\t\"FL Sever\" provides the trained ML models by FL to the \"FL Consumer\" NWDAF at step 0b by invoking \"Nnwdaf_MLModelProvision_Notify\" service operation.\nNOTE 2:\tThe ML model provision between \"FL Server\" NWDAF and \"FL Client\" NWDAF in this solution should align with the conclusion in KI#5.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.21.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF containing MTLF:\n-\tregister the \"FL capability\" in NF profile to NRF.\nFor \"FL Server\" NWDAF:\n-\tsupport \"FL Client\" NWDAF discovery procedure.\n-\tsupport to send FL request to \"FL Client\" NWDAF.\n-\tsupport to aggregate the interim learning results from \"FL Clients\" NWDAF.\n-\tsupport a new service \"Nnwdaf_MLModelTraining\".\nFor \"FL Client\" NWDAF:\n-\tsupport local ML training based on \"FL Server\" NWDAF request.\n-\tsupport to report the trained interim ML model to \"FL Server\" NWDAF.\n-\tsupport a new service \"Nnwdaf_MLModelTraining\".\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.22\tSolution #22: Federated learning group creation",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.22.1\tDescription",
                            "text_content": "The solution addresses Key Issue #8: Supporting Federated Learning in 5GC with proposing a procedure to create Federated Learning group of NWDAFs for a given analytics request from any NF.\nTo enable Federated Learning among NWDAFs, it is required to support creation of a Federated Learning group for a given analytics request. In this regard, this solution focuses on how to discover proper participant NWDAFs supporting Federated Learning, create the Federation Learning group, and provision information required to coordinate the operation among the participant NWDAFs.\nThis solution is based on the following assumption:\n-\tA Federated Learning group consists of one central NWDAF and multiple local NWDAFs. The local NWDAF performs local ML model training and provide local ML model to the central NWDAF. The central NWDAF aggregates the local ML model trained by local NWDAFs in the Federated Learning group, calculate and distribute a global ML model to the local NWDAFs.\n-\tFor a given Federated Learning group, the same ML model is used by all the participant NWDAF analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.22.2\tProcedures",
                            "text_content": "The figure depicts a simplified procedure for creating a federated learning group in a distributed learning system. It illustrates the steps involved in creating a group, including selecting a leader, assigning roles, and setting up communication channels. The figure is a simplified representation, and the actual procedure may vary depending on the specific system and requirements.\nFigure 6.22.2-1: Federated learning group creation procedure\n0.\tNWDAF(s) respectively invokes an Nnrf_NFManagement_NFRegister Request service providing their own NF profile that includes supported Analytics ID, ML Model Filter Information (e.g. S-NSSAI(s), Area(s) of Interest) and ML model sharing capability, which is required to send locally trained model to the Central NWDAF during federation learning operations as local NWDAF, when becoming operative for the first time.\nEditor's note:\tThe aspects of model sharing between Central NWDAF and Local NWDAF should be aligned with in key issue #5 (e.g. including details on ML model information).\n1.\tThe NF sends Nnwdaf_AnalyticsInfo_Request to the NWDAF. The request message includes Analytics ID, Target of Analytics Reporting, Analytics Filter Information and Analytics Reporting Information.\n2.\tThe NWDAF 1 determines to perform federated learning for the received Analytics request if it is locally configured to perform federated learning for the requested Analytics ID (e.g. based on the operator policy). The NWDAF 1 also determines to act as Central NWDAF for federation learning for the requested analytics in step 1 if it has Federated Learning Model Aggregation capability (i.e. capability of aggregating local training models and calculating the global model from then).\nNOTE 1:\tThe Central NWDAF in this solution is assumed to host both MTLF and AnLF logical functions. If NWDAF 1 contains only AnLF, it performs the discovery of Central NWDAF, which contains MTLF and has Federated Learning Model Aggregation capability via NRF, and delegates the model training.\nNOTE 2:\tThe Central NWDAF decides to initiate FL for the received Analytics request based on the local configuration.\n3.\tThe NWDAF invokes the Nnrf_NFDiscovery_Request service operation from the NRF to find other NWDAFs that are able to perform federated learning as local NWDAFs for the Analytics request in step 1. The Nnrf_NFDiscovery_Request message includes Analytics ID in step 1, ML Model Filter Information according to the Analytics Filter Information received in step 1 and ML model sharing capability that is required to perform Federation Learning.\n4.\tThe NRF returns multiple local NWDAF candidates matching the requested capabilities and Analytics ID.\n5.\tThe central NWDAF requests the local NWDAF candidates to join the federated learning group for the Analytics ID received in step 1. The request message includes Central NWDAF information (e.g. NWDAF ID and address), S-NSSAI, Analytics ID and ML Model Filter Information for the federated learning operation, etc.\n6.\tThe local NWDAF candidates reply to the NWDAF with the indication on whether to accept the federation learning group participation request or not.\n7.\tUpon receiving the responses from local NWDAF candidates in step 6, the central NWDAF determines a federated learning group consisting of NWDAFs that indicate to accept to the federation learning group participation request in step 6. The central NWDAF creates federated learning group information that includes Analytics ID, list of local NWDAF information (identifiers and addresses of NWDAFs), ML Model Filter Information, ML model information (e.g. the ML model file address, ML model identifier, etc), Central NWDAF address as target address where local training model is sent, transmission expiration time information, and local learning processing rule information.\nNOTE 3:\tThe details on ML model information will be aligned with the conclusion of key issue #5 with respect to the aspects of model sharing.\nThe local learning processing rule information includes either local processing rule ID or local ML model training rule e.g. how many iterations for local model training should be performed for one epoch before providing the local model to the Central NWDAF.\nNOTE 4:\tThe local processing rule ID refers to a pre-agreed operation rule for local ML model training in federated learning operation among NWDAFs.\nThe transmission expiration time information indicates a deadline before which the local ML model should be transmitted to the Central NWDAF to generate global ML model for an epoch. For example, the deadline can be represented by timestamp and timer value respectively indicating start time of federated learning operation and expiry time period.\n8.\tThe central NWDAF provides the local NWDAFs (i.e. federated learning group member local NWDAFs) with federated learning operation information that includes Analytics ID, ML model information, Central NWDAF address as target address where local training model is sent, transmission expiration time information, and local learning processing rule information.\n9.\tLocal NWDAFs acknowledge to the central NWDAF to indicate if the local NWDAF is able to perform federate learning according to the federated learning operation information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.22.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF:\n-\tSupport creation of federated learning group with acting as NRF service consumer to discover and select NWDAFs having required capability to perform federated learning.\n-\tSupport to share ML model with other NWDAFs and, especially for Central NWDAF, aggregate ML models provided by other NWDAFs.\nNRF:\n-\tSupport new parameters in NF profile provided by NWDAF.\n-\tSupport new discovery parameters related to federated learning group creation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.23\tSolution #23: Support of federated learning for model training",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.23.1\tDescription",
                            "text_content": "Model training using Federated learning is useful in scenarios where data may not be easily collected from Data Producer NF. For example, there may be data privacy/data security requirements where data collection from data producer NFs is not feasible or there can be high signalling load if data is collected from Data Producer NFs that have limited resources available (e.g. NFs supporting a local edge network).\nFederated learning solves this problem by locally training an ML model using data that are locally available and distributing local model parameters to a central model training function that aggregates the model parameters and generates a central ML model.\nThe following architecture is proposed to support model training using federated learning.\nThe figure depicts a network architecture supporting model training using federated learning. It illustrates a multi-layered architecture with a central server, multiple edge servers, and a distributed training model. The architecture supports model training by utilizing federated learning, which allows for the training of a model on a large dataset without sharing the data with all participating devices. This approach ensures privacy and security while enabling the training of complex models.\nFigure 6.23.1-1: Architecture supporting model training using federated learning\nThe main functions of the federated learning architecture is as follows:\n-\tA central MTLF (that supports FL aggregation) that configures one or more local MTLF(s) (that supports FL participation) with the data that are required to be collected from one or more (local) Data Producer NFs and generates an aggregated ML model based on ML model parameters received from an ML model trained locally from each local MTLF.\n-\tOne or more local MTLF(s) that support ML model training by collecting data from one or more Data Producer NFs available locally.\n-\tA central Analytics Logical Function (AnLF) that discovers the Central MTLF supporting federated learning for model training since not all MTLFs will support Model Training using federated learning. The AnLF can discover the central MTLF on per Analytic ID/Analytic Filter information basis. The NRF includes information in the NF profile whether an MTLF support FL aggregation or FL participation.\nOnce the AnLF discovers the Central MTLF that supports FL aggregation, the AnLF will request an ML model for an Analytic ID including ML model filter information that can include an S-NSSAI, area of interest, DNAI and other information. The Central MTLF based on the Analytic ID requested and the ML model filter information determines that the requested ML model requires federated learning and discovers one or more local MTLFs for each data (i.e Event ID) that cannot be collected directly from a Data Producer NF. The central MTLF discovers the local MTLF(s) from the NRF and configures the local MTLF to train a local ML model indicating the data required to be collected by one or more Data Producer NF(s). The central MTLF then retrieves local ML model parameters from each local MTLF and aggregates gradients/loss factors generating a central ML model that is sent to the AnLF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.23.2\tProcedures",
                            "text_content": "A detailed procedure is provided below:\nThe figure depicts a schematic representation of a federated learning model, illustrating the support of model training using federated learning. The figure includes various components such as the central server, edge servers, and clients, which collaborate to train the model. The central server serves as the hub for communication and coordination, while the edge servers provide local processing and storage. The clients, represented by circles, are the end-users who contribute data to the model training process. The figure highlights the importance of communication and collaboration in federated learning, emphasizing the need for efficient communication protocols and secure data sharing.\nFigure 6.23.2-1: Support of model training using federated learning\n0.\tAn AnLF NWDAF receives a request from a consumer NF. The request includes an Analytics ID and analytic filter information as described in TS 23.288 [5].\n1.\t[conditional]The AnLF determines the central MTLF. The AnLF may determine that a Central MTLF supporting federated learning is required.\n2.\t[conditional]The AnLF discovers the central MTLF from the NRF by invoking an Nnrf_NFDiscovery_Request including the Analytic ID, service area, MTLF that supports FL aggregation capability.\nNOTE 1:\tThe service area may be needed in case in a network deployment a specific service area, the MTLF is configured to support model training using federated learning.\n3.\t[conditional]The AnLF receives from the NRF the NF ID of the central MTLF.\n4.\t[conditional]The AnLF sends a subscription request to the central MTLF including Analytic ID and ML model filter information as described in TS 23.288 [5].\n5.\tThe central MTLF determines that federated learning is required. The MTLF may determine such information if:\n-\tData (corresponding to an Event ID) cannot be collected directly from an NF (based on local configuration)\n-\tThe request for analytics information is for a DNAI where federated learning is required.\n-\tThe request for analytics information is for a service area where federated learning is required.\n6.\tThe central MTLF discovers the local MTLF for federated learning. The determination is based on the training data (i.e. Event ID) required by the local MTLF to train the local ML Model.\n7.\tThe central MTLF discovers the local MTLF from the NRF by invoking an Nnrf_NFDiscovery_Request including the Analytic ID, service area and an indication that the MTLF supporting FL participation for ML model training.\n8.\tThe AnLF receives from the NRF the NF ID of the local MTLF(s).\n9a.-9b.\tThe central MTLF configures the local MTLF(s) to train a local ML model using data from one or more data producer NFs corresponding to the Event ID(s) required. The central MTLF includes in the request to the local MTLF the Analytic ID of the ML model required. The procedure for local configuration is shown in Figure 6.23.2-2.\n10a.10b.\tEach local MTLF collects data and locally trains an ML model\n11a-11b.\tThe central MTLF and local MTLF(s) exchange ML model parameters that allows aggregation of gradients and loss factors from each local ML model. Steps 11a and 11b are ML model specific and out of scope of 3GPP.\nNOTE 2:\tSteps 10a through 11b are iterative and continue until the central MTLF determines that the generated ML model can be used by the AnLF (e.g. reached the required confidence level).\n12.\tThe MTLF updates its central trained model using the aggregated model parameters\n13.\tThe MTLF indicates to the AnLF that a trained model is available.\nThe figure depicts a support structure for fiber-optic lines (FL) between central and local Multi-Technology Line (MTLF) facilities. The support structure is designed to provide redundancy and failover reliability, ensuring the continuity of communication services.\nFigure 6.23.2-2: Support of FL between central and local MTLFs\n1.\tThe central MTLF determines if horizontal or vertical FL takes place based on the analytic ID. The Central MTLF determines the local MTLF(s) for federated learning as described in steps 6-8 of Figure 6.23.2-1. The central MTLF determines if horizontal or vertical FL takes place based on the analytic ID.\n2.\tThe Central MTLF sends a request for federated learning to MTLF 1 where the request includes, an Analytic ID of the model required, one or more of the following Event ID(s) needed, service area.\n3.\tThe MTLF aggregator repeats step 2 for MTLF 2.\n5.\tMTLF 1 performs data collection and provides model parameters to the Central MTLF aggregator.\n6.\tMTLF 2 performs data collection and provides model parameters to the Central MTLF.\n7.\tThe Central MTLF calculates aggregated model parameters.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.23.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tDiscovery and selection of local MTLF for model training using federated learning.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.24\tSolution #24: Horizontal Federated Learning among Multiple NWDAFs",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.24.1\tDescription",
                            "text_content": "This solution is proposed to address Key Issue #8: Supporting Federated Learning in 5GC.\nCurrent enablers for network automation architecture by NWDAF still faces some major challenges as follows:\n-\tUser data privacy and security (protected by e.g. GDPR) has become a worldwide issue, it is also difficult for NWDAF to collect UE level network data.\n-\tWith the introduction of MTLF in Rel-17, various data from wide area is needed to train an ML model for NWDAF containing MTLF. However, it is difficult for NWDAF containing MTLF to collect all the raw data from distributed data source in different areas, because heavy signalling load may exist if it centralized all the data into the NWDAF containing MTLF.\nIn order to address the challenges, Federated Learning (also called Federated Machine Learning) technique in NWDAF containing MTLF could be adopted to train an ML model, in which there is no need for raw data transferring (e.g. centralized into one NWDAF) but only need for cooperation among multiple NWDAFs (MTLF) distributed in different areas i.e. sharing of ML model and of the learning results among multiple NWDAFs (MTLF).\nDuring the FL training process, the Server NWDAF can inform the training status to the consumer based on the consumer's request. The consumer could modify subscription to NWDAF for new model requirement. The Server NWDAF will update or terminate the FL training process accordingly.\nThis solution is mainly focusing on horizontal Federated Learning among Multiple NWDAFs, whose procedures are illustrated in the following clauses.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.24.2\tProcedures",
                            "text_content": "The figure depicts a general procedure for Federated Learning among multiple NWDAF instances, illustrating the steps involved in training a machine learning model on a distributed dataset. The figure includes a flowchart, a matrix, and a legend to clearly represent the process.\nFigure 6.24.2.1-1: General procedure for Federated Learning among Multiple NWDAF Instances\n1-3.\tClient NWDAF registers its NF profile (Client NWDAF Type (see clause 5.2.7.2.2 of TS 23.502 [3]), Address of Client NWDAF, Support of Federated Learning capability information, Analytics ID(s) , Service Area) into NRF.\n4-6.\tServer NWDAF discovers one or multiple Client NWDAF instances which could be used for Federated Learning via the NRF to get IP addresses of Client NWDAF instances by invoking the Nnrf_NFDiscovery_Request (Analytics ID, Support of Federated Learning capability information, Service Area) service operation.\nIt is assumed an Analytics Id is preconfigured for a type of Federated Learning. Thus, the NRF can realize the Server NWDAF is requesting to perform federated learning based on the pre-configuration. And the NRF responds to the central NWDAF the IP address of multiple NWDAF instances which support the Analytics Id.\nNOTE:\tThe analytic ID(s) supporting Federated Learning can be configured by operator.\nBased on the response from NRF, Server NWDAF selects which NWDAF clients will participate.\n7.\tServer NWDAF sends a request to the selected Client NWDAFs that participate in the Federated learning including some parameters (such as initial ML model, data type list, maximum response time window, etc.) to help the local model training for Federated Learning.\nNOTE:\tThis step should be aligned with the outcome of KI#5.\n8.\tEach Client NWDAF collects its local data by using the current mechanism in clause 6.2 of TS 23.288 [5].\n9.\tDuring Federated Learning training procedure, each Client NWDAF further trains the retrieved ML model from the server NWDAF based on its own data, and reports the results of ML model training to the Server NWDAF, e.g. the gradient.\nThe trained models/parameters are shared/exchanged among the multiple NWDAF instances during the FL training process by using the Nnwdaf_MLAggregation service or the extended Nnwdaf_MLModelProvision service as defined in clause 6.24.3. Note that only one of the options should be chosen for the normative phase.\n10.\tThe Server NWDAF aggregates all the local ML model training results retrieved at step 9 such as the gradient to update the global ML model.\n11a.\tBased on the consumer request, the Server NWDAF updates the training status (an accuracy level) to the consumer using Nnwdaf_MLModelProvision_Notify service periodically (one or multiple rounds of training or every 10 min, etc.) or dynamically when some pre-determined status (e.g. some accuracy level) is achieved.\n11b.\t[Optional] Consumer decides whether the current model can fulfil the requirement e.g. accuracy and time. The consumer modifies subscription if the current model can fulfil the requirement.\n11c.\tAccording to the request from the consumer, the Server NWDAF updates or terminates the current FL training process by invoking an Nnwdaf_MLAggregation_Modify or an Nnwdaf_MLAggregation_Terminate service operation.\n12.\t[If the FL procedure continues] The Server NWDAF sends the aggregated ML model information (updated ML model) to each Client NWDAF for next ground model training by invoking an Nnwdaf_MLAggregration_Notify/Nnwdaf_MLModelProvision_Notify service operation.\n13.\tEach Client NWDAF updates its own ML model based on the aggregated model information (updated ML model) distributed by the Server NWDAF at step 12.\nNOTE:\tThe steps 8-13 should be repeated until the training termination condition (e.g. maximum number of iterations, or the result of loss function is lower than a threshold) is reached.\nAfter the training procedure is finished, the globally optimal ML model or ML model parameters could be distributed to the Client NWDAFs for the inference.\nThe figure depicts a procedure for the usage of Federated Learning in abnormal behavior, illustrating the steps involved in training a machine learning model on a large dataset. The figure includes a flowchart, a list of steps, and a legend to help understand the process.\nFigure 6.24.2.2-1: Procedure for usage of Federated Learning in Abnormal Behaviour\n1.\tA Server NWDAF determines to train an Abnormal Classifier using the input data defined in Table 6.7.5.2-1 of TS 23.288 [5]). The Server NWDAF discovers two Client NWDAFs i.e. Client NWDAF 1 in Area A, Client NWDAF 2 in Area B will participate as defined in figure 6.24.2.1-1.\n2.\tClient NWDAF 1 and Client NWDAF 2 collect raw data from SMF and AMF, respectively. The data collection procedures from AMF and SMF are defined in step 2-3, clause 6.7.5.4 of TS 23.288 [5].\n3-4.\tClient NWDAF 1 and Client NWDAF 2 collect Exception information from AF, respectively. The Exception information is defined in clause 6.7.5.2 of TS 23.288 [5].\nRepeat from step 5-8 until the training termination condition (e.g. maximum number of iterations) is fulfilled:\n5.\tDuring Federated Learning training procedure, based on the local raw data, Client NWDAF 1 and Client NWDAF 2 further train the retrieved Abnormal Classifier from the Server NWDAF, respectively.\n6.\tClient NWDAF 1 and Client NWDAF 2 respectively report the information of local training results for Abnormal Classifier (e.g. volume of the local dataset, parameters for update of the Abnormal Classifier) to the Server NWDAF.\n7.\tServer NWDAF aggregates all the local training results for Abnormal Classifier to derive the aggregated Abnormal Classifier information.\n8.\tServer NWDAF sends the aggregated Abnormal Classifier information to Client NWDAF 1 and Client NWDAF 2, and then, Client NWDAF 1 and Client NWDAF 2 update the its own Abnormal Classifier based on the aggregated Abnormal Classifier information distributed by the Server NWDAF.\nAfter the training procedure is finished, the globally optimal Abnormal Classifier or Abnormal Classifier parameters could be distributed to the Client NWDAF 1 and Client NWDAF 2 as well as the new Client NWDAFs, if requested, for the inference.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.24.3\tNnwdaf services used for model sharing/parameter exchanging",
                            "text_content": "This service enables model sharing/parameter exchanging in the execution phase of a ML training process among multiple NWDAF instances.\nFigure 6.24.3.1-1 illustrates the use of service operations of the Nnwdaf_MLAggregation service for e.g. trained model sharing/parameter exchanging among the Server and Client NWDAFs in a ML training process.\nThe figure depicts a service operations diagram for the Nnwdaf_MLAggregation service, illustrating the various stages and components involved in its operation.\nFigure 6.24.3.1-1: Service Operations of the Nnwdaf_MLAggregation Service\nFigure 6.24.3.1-1 shows the use of service operations of the Nnwdaf_MLAggregation service, e.g. for trained parameters exchanging/models sharing in the ML training process. In the very beginning, i.e. the 0th round, Server NWDAF distributes a container either containing initial model parameters or a reference to it or to a model (e.g. URL) to the selected Client NWDAF(s) together with the FL correlation ID, and identity of the current iteration round (e.g. IR ID=0).\nIn the 1st round, the Client NWDAF(s) subscribe to the Server NWDAF for global model/parameter updating, e.g. by invoking an Nnwdaf_MLAggregation_Subscribe service operation together with the current round trained local models/parameters, FL correlation ID, and identity of the current iteration round (e.g. IR ID=1, 2, …). Server NWDAF sends a container either containing the parameters of the aggregated global model or a reference to it or to the aggregated global model (e.g. URL) to the Client NWDAF(s) by invoking an Nnwdaf_MLAggregation_Notify service operation with FL correlation ID, and identity of the current iteration round (e.g. IR ID=1, 2, …).\nIn the ith round (i>1), the Client NWDAF(s) update its subscription to the Server NWDAF for global model/parameter updating, e.g. by invoking an Nnwdaf_MLAggregation_Subscribe/Nnwdaf_MLAggregation_Update service operation to update the current subscription together with the subscription ID, a container either containing the local model parameters or a reference to it or to the local model (e.g. URL), FL correlation ID, and identity of the current iteration round (e.g. IR ID=2, 3, …). Server NWDAF sends a container either containing the parameters of the aggregated global model or a reference to it or to the aggregated global model (e.g. URL) to the Client NWDAF(s) by invoking an Nnwdaf_MLAggregation_Notify service operation with FL correlation ID, and identity of the current iteration round (e.g. IR ID=2, 3, …).\nNOTE:\tThe content of the container is out of scope of 3GPP.\nIf terminate or update of the ML process is needed, the Server NWDAF terminate or update the current ML process by invoking an Nnwdaf_MLAggregation_Terminate or an Nnwdaf_MLAggregation_Modify service operation with FL correlation ID and IR ID to terminate/update the training at the Client NWDAF(s).\nThis extended service enables the model sharing/parameter exchanging in the execution phase of a ML training process among multiple NWDAF instances.\nFigure 6.24.3.1-1 illustrates the use of service operations of the extended Nnwdaf_MLModelProvision service for e.g. trained model sharing/parameter exchanging among the Server and Client NWDAFs in a ML training process.\nThe figure depicts a service operations diagram for the Extended Nwdaf_MLModelProvision service, illustrating the various steps and components involved in its provisioning process.\nFigure 6.24.3.2-1: Service Operations of the Extended Nnwdaf_MLModelProvision Service\nDepending on whether the provision is for trained model sharing or parameter exchange the wanted output is set accordingly. Beside the existing inputs and outputs, the new inputs and outputs of the Nnwdaf_MLModelProvision_Subscribe request include:\n-\tIdentity of the current ML process, e.g. FL correlation ID.\n-\tIdentity of the current iteration round, e.g. IR ID = 0, 1, 2, ...\nBeside the exist inputs and outputs, the new inputs and outputs of the Nnwdaf_MLModelProvision_Notify include\n-\tIdentity of the current ML process, e.g. FL correlation ID.\n-\tIdentity of the current iteration round, e.g. IR ID = 1, 2, 3, ...\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.24.4\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF:\n-\tRegistration into NRF;\n-\tNew Nnwdaf service Nnwdaf_MLAggregation/Extended service Nnwdaf_MLModelProvision;\n-\tNew Data Analytics (i.e. new Analytics ID) for Federated Learning, which can be configured by operator:\n-\tAs a server NWDAF:\n-\tDiscover request to NRF with the analytics id corresponding to a federated learning\n-\tClient NWDAF instances discovery;\n-\tInitial Federated Learning parameters determination and distribution;\n-\tCollection of local ML model information from the Client NWDAF instances;\n-\tAggregates local model information to update ML model, e.g. for gradient calculation, reporting to the Server NWDAF.\n-\tUpdate the training status to Consumer (AF/NF/OAM) periodically or dynamically.\n-\tAs a Client NWDAF,\n-\tReceive aggregated model information (updated ML model) from Server NWDAF and perform local ML model update.\nNRF:\n-\tServer NWDAF and Client NWDAF registration and discovery.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.25\tSolution #25: Outdoors Advertisement use case with finer granularity location information",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.25.1\tDescription",
                            "text_content": "This solution addresses Key issue #9: Enhancement of NWDAF with finer granularity of location information.\nIn the LCS architecture, the LCS can provide LCS client location information including geographic location, speed, heading, accuracy, timestamp, and so on. Such information precisely represents the location status of a single UE or a group of UE, which can help NWDAF to conduct some valuable statistics and prediction analyses. Therefore, under the permission of users' consent and privacy checking, it is desirable to obtain location information from LCS architecture in line with consumer requirements to help NWDAF make better analyses and predictions.\nOutdoors advertisements statistics business is a potential scenario combining NWDAF and LCS architectures. In this scenario, the positioning information of an uncertain group of UE within a certain area needs to be counted. These amount of UEs is changing.\nIn this scenario, the NWDAF consumers can provide clear statistical requirements including the location of a specific billboard, the period to be calculated, the counting distance range, the accuracy information, and so on. Then NWDAF provides billboard location information, statistical period, number of UE passing by, the proportion of valid viewers, average staying time of viewers, proportion of UE staying longer than the specified time, etc. Thus, a new analytic ID needs to be designed.\nTwo categories of outdoor advertisements will be studied, expressways advertisements and street advertisements.\nFor large outdoor advertisements, e.g. roadside advertisements on expressways, advertising information on the billboard can be seen far away. In this way, the granularity of UE location information required by NWDAF may be coarser, such as around 400m near billboards. Therefore, NWDAF only counts the number of users driving towards a correct and fixed direction. Furtherly, the users whose staying time reach a threshold are counted as valid viewers of the advertisement.\nFor small outdoor advertisements, e.g. street or neighbour advertisements, people can see the contents shown on ads when they are close to the billboard. In this way, the UE location information required by NWDAF will be finer granular, such as around 5m near the billboard. At first, NWDAF conducts preliminary screening on the speed and heading information with ignoring users who move at a fast speed. Then, NWDAF determines the duration of the users and counts the number of people passing by and valid viewers in this certain area.\nIn order to solve the aforementioned issue, this solution proposes a scheme for providing statistics/prediction service under the measuring outdoors advertisements viewers scenario.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.25.2\tInput Data",
                            "text_content": "The input data for the analytics is described in Table 6.25.2-1.\nTable 6.25.2-1: Input data for measuring the number of outdoors advertisements viewers usage\n\nNOTE:\tFrom which network function to acquire the location information will have some coordination with the FS_eLCS_Ph3 study.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.25.2-1: Input data for measuring the number of outdoors advertisements viewers usage",
                                    "table number": 23,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.25.3\tOutput Analytics",
                            "text_content": "The output analytics of NWDAF is defined in Table 6.25.3-1 and Table 6.25.3-2.\nTable 6.25.3-1: Measuring the number of outdoors advertisements viewers usage statistics\n\nTable 6.25.3-2: Measuring the number of outdoors advertisements viewers usage prediction\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.25.3-1: Measuring the number of outdoors advertisements viewers usage statistics",
                                    "table number": 24,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.25.3-2: Measuring the number of outdoors advertisements viewers usage prediction",
                                    "table number": 25,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.25.4\tProcedures",
                            "text_content": "Figure 6.25.4-1 depicts a procedure for the Outdoor Advertisement use case analytics provided by NWDAF.\nThe figure depicts outdoor advertisement use case analytics provided by NWDAF, illustrating the effectiveness of their solutions in enhancing the visibility and reach of advertisements in outdoor environments.\nFigure 6.25.4-1: Outdoors Advertisement use case analytics provided by NWDAF\n1.\tThe consumer requests or subscribes to analytics information on the Outdoors Advertisement use case provided by NWDAF. The parameters are carried in the request including the location of a specific billboard, category of advertisement, the period to be counted, the counting distance range, the preferred granularity of the counting distance range, and so on.\n-\tan Analytics subscription or request (New Analytics ID, Analytics Filter information = AOI, Analytics Reporting information = Analytics target period 1 or prediction target period 2) to the NWDAF by Nnwdaf_AnalyticsSubscription_Subscribe or Nnwdaf_AnalyticsInfo_Request.\nThe consumer may include multiple sets of parameters in order to provide different combinations of \"Location information\" and \"Analytics target period\" when requesting Outdoors Advertisement analytics.\n2.\tThe NWDAF collects the UE location information data from the LCS architecture.\nNOTE:\tUE location information collection principles will be coordinated with FS_eLCS_Ph3 study.\n3.\tThe NWDAF conducts preliminary screening based on the category of advertisement and then classifies statistics through time stamps and other information. The UE can be counted only when it enters the counting distance range and its location information meets the requirements by the rules of the category of advertisement and NWDAF consumer.\nThe number of users passing by and the valid viewers can be counted:\n-\tFor the expressway advertisements, users whose geographical location is in a large range of the requested counting distance can be counted as users passing by. The users whose speed and heading meet the requirements are counted as valid viewers of the advertisement. The duration between valid viewers entering and leaving the range requested in NWDAF consumers will be regarded as staying time.\n-\tFor the street advertisements, users whose geographical location is in a smaller range of the requested counting distance can be counted as users passing by. The users who have a limited speed are counted as valid viewers of the advertisement. The duration between valid viewers entering and leaving the range requested in NWDAF consumers will be regarded as staying time.\nThe NWDAF verifies whether the triggering conditions are met and derives the requested analytics. The NWDAF can detect the need for notification based on comparing the requested analytics of the preferred granularity of counting distance range provided by the consumer over the requested Analytics target period.\n4.\tThe NWDAF provides a response or notification on the Outdoors Advertisement use case to the consumer. The details for UE mobility analytics provided by the NWDAF are defined in the output analytics information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.25.5\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF:\n-\tThe NWDAF collects data from LCS architecture and analyses measuring the number of outdoor advertisements viewers.\n-\tThe new Analytic ID supporting the Outdoors Advertisement use case needs to be supported.\nEditor's note:\tThe name of new analytic ID is FFS.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.26\tSolution #26: Finer granularity of location information based on cell sequence",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.26.1\tDescription",
                            "text_content": "Location information with cell/TA granularity is not enough for some vehicle use cases. For example, while sending warning messages to vehicles running on the road of traffic jam or traffic accident, we need further location information of direction to determine whether the vehicles are running on the up lane or down lane of the same road.\nTo decide the direction information, we can use the information of cell sequence that the vehicle has went through. Unlike traditional UEs (e.g. mobile phones carried by people) moving irregularly, vehicles can only run forward (cannot run back and forth) along the road so vehicles driving in the same direction of the road tend to go through the same sequence of cells.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.26.2\tProcedures",
                            "text_content": "Firstly, a UE Location order indicator should be added in the Analytics Filter information when consumer NF would like to request or subscribe the UE Mobility analytics. The UE Location order indicator indicates the NWDAF should derives the UE Mobility analytics in a UE Location order.\nUE mobility analytics is specified in clause 6.7.2 of TS 23.288 [5]. The following table is the output analytics of UE mobility statistics. Multiple UE locations can be provided in the indicated time slot. However, there is no clear indication about the order of those locations (cells). To determine the direction of location information using cell sequence, we need to add a new NOTE 4 as follows to make the multiple locations are in the right order. Other procedures such as how to subscribe/notify this location information are the same as clause 6.7.2 of TS 23.288 [5].\nTable 6.7.2.3-1: UE mobility statistics\n\nNOTE 1:\tWhen target of analytics reporting is an individual UE, one UE ID (i.e. SUPI) will be included, the NWDAF will provide the analytics mobility result (i.e. list of (predicted) time slots) to NF service consumer(s) for the UE.\nNOTE 2:\tIf Visited AOI(s) was provided in the analytics request/subscription, the UE location provides information on the observed location(s) that the UE or group of UEs had been residing during the Analytics Target Period.\nNOTE 3:\tWhen possible and applicable to the access type, UE location is provided according to the preferred granularity of location information.\nNOTE 4:\tIf target of analytics reporting is an individual UE or multiple UE locations are provided, UE locations will be in the order of which the UE passes through.\nTo implement the order of the UE locations in the UE Mobility analytics, this solution proposes two alternative solutions:\n-\tAlt#1, update the UE Mobility analytics i.e. add a list of timestamps for each UE location in the \"> UE location (1..max)\" during the current \"duration\" parameter.\n-\tAlt#2, does not update the UE Mobility analytics but proposes that NWDAF does not aggregate the UE locations in a long duration but provides the UE locations one by one in their own time period, i.e. the \"UE location (1..max)\" in the UE Mobility analytics has only one UE location which indicates the UE is located in this UE location in the duration from the time slot start.\nEditor's note:\tIt is FFS which alternative will be selected for the normative standards.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.7.2.3-1: UE mobility statistics",
                                    "table number": 26,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.26.3\tImpacts on existing nodes and functionality",
                            "text_content": "Consumer NF (e.g. AMF):\n-\tShould include a UE Location order indicator into the Analytics Filter when it would like to request/subscribe the UE Mobility Analytics in a UE Location order.\nNWDAF:\n-\tWhen NWDAF receives a UE location order indicator in the Analytics Filter to request/subscribe the UE Mobility Analytics:\n-\tAlt#1, the NWDAF adds a list of timestamps or orders for each UE location in the \"> UE location (1..max)\" during the current \"duration\" parameter.\n-\tAlt#2, NWDAF does not aggregate the UE locations in a long duration but provides the UE location one by one in their own time period, i.e. the \"UE location (1..max)\" in the UE Mobility analytics has only one UE location which indicates the UE is located in this UE location in the duration from the time slot start.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.27\tSolution #27: Relative Proximity Analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.27.1\tDescription",
                            "text_content": "In Rel-17, NWDAF location analytics are only available with the coarse resolution of Tracking Area (TA) level or cell level, so KI#9 description in clause 5.9 requests solutions for location analytics with finer granularity. Furthermore, location information is mainly related to the absolute positioning of a UE and relative proximity of a UE versus other UEs is currently lacking in input data acquired by the NWDAF or the output data provisioned by the NWDAF. Relative proximity information can thus be leveraged by NWDAF to provide location information with finer granularity than TA/cell. In this solution, we propose a set of possible procedures for the NWDAF to assist a consumer NF to more accurately localize a cluster (or a set) of UEs via provisioning statistics or prediction information related to their relative proximity. For example, this analytics type may help the consumer improve the location estimation accuracy of a UE by using proximity information from nearby UEs, or it may help the consumer identify UEs in the vicinity of another UE.\nIn addition, information on the relative proximity of two or more UEs can be leveraged by different vertical use cases such as V2X and smart factories to enhance performance and safety requirements in scenarios with moving physical objects such as cars, Vulnerable Road Users (VRUs) or factory robots equipped with UE connectivity. This solution proposes the introduction of time to collision (TTC) information as part of relative proximity analytics, indicating statistics and predictions of the time it would take for the UE(s) acting as target of analytics reporting to collide with another UE. Similar to other analytics described in TS 23.288 [5], this solution describes input data (see Tables 6.27.1-1 and 6.27.1-2), output analytics in the form of statistics and predictions (see Tables 6.27.1-3 and 6.27.1-4), and procedures (see clause 6.27.2) to support relative proximity analytics.\nInput Data to the NWDAF from different sources\nTable 6.27.1-1: Information collected from OAM\n\nNOTE 1:\tOAM reporting relies on MDT, which uses RRC and reports UE measurements up to every 16 ms, as described in TS 37.320 [20] and TS 38.331 [21], which suffices to derive relative proximity and TTC information.\nTable 6.27.1-2: Proximity related input data collected via DCAF/ NEF\n\nNOTE 2:\tThe list of UE IDs that fulfil a proximity criterion can be determined by DCAF based on the input information collected from the UE application. The UE does not need to determine or provide proximity information related to other UEs.\nTable 6.27.1-3: Information collected from 5GC/AF\n\nOutput analytics from the NWDAF to the consumer NF\nTable 6.27.1-4: Relative proximity statistics\n\nTable 6.27.1-5: Relative proximity predictions\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.27.1-1: Information collected from OAM",
                                    "table number": 27,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.27.1-2: Proximity related input data collected via DCAF/ NEF",
                                    "table number": 28,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.27.1-3: Information collected from 5GC/AF",
                                    "table number": 29,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.27.1-4: Relative proximity statistics",
                                    "table number": 30,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.27.1-5: Relative proximity predictions",
                                    "table number": 31,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.27.2\tProcedures",
                            "text_content": "The figure depicts a procedure for relative proximity analytics, which involves analyzing the spatial proximity of two objects or entities. The figure shows a step-by-step process for determining the relative proximity of two objects, with arrows indicating the direction of the analysis. The figure is labeled with the figure number and the corresponding figure number, which helps in identifying the specific figure being referred to.\nFigure 6.27.2-1: Procedure for delivery of relative proximity analytics\n1.\tThe Consumer NF or AF sends a request to the NWDAF for analytics related to relative proximity, using either the Nnwdaf_AnalyticsInfo or Nnwdaf_AnalyticsSubscription service.\nThe Analytics ID is set to \"Relative Proximity\". The target for analytics reporting can be a single UE, group of UEs (e.g. UE1 and UE2 in Figure 6.27.2-1) or any UE. Analytic filters are set to indicate the proximity range or other criteria to be considered for relative proximity. This can be in the form of an area of interest, specific directions of interest, a ranging distance, a predefined geographic area, or other forms of indication. Other analytics filters can also be set to indicate a minimum or maximum number of UEs to be accounted for relative positioning. Other attributes can be also indicated as part of analytics filters, e.g. defining certain velocity, average speed, orientation or mobility trajectory to be accounted for relative positioning. Furthermore, analytics filters can be set to indicate S-NSSAI, DNN, analytics target period or preferred level of accuracy of the analytics.\nThe Consumer NF can request statistics or predictions or both for a given time window.\n2-5.\tIf the request is authorized, and in order to provide the requested analytics, the NWDAF may subscribe to OAM services to retrieve relevant information to proximity analytics. The NWDAF may collect MDT input data per individual UE from OAM. An example set of information to be provided to the NWDAF is defined in Table 6.27.1-1.\n6-7.\tFor relative proximity information, if the request is authorized, and in order to provide the requested analytics, NWDAF may follow the UE Input Data Collection Procedure via the DCAF. DCAF may collect proximity related input data directly from the UE Application, and determine a list of UEs fulfilling certain proximity criterion.\nNOTE 1:\tThe UE data collection procedure should be based on clause 6.2.8 of TS 23.288 [5].\nNOTE 2:\tDifferent Application IDs of the same DCAF or different DCAFs may be selected for different UEs, since each DCAF can only determine the proximity information for the UEs that have PDU session between UE and DCAF.\nThe NWDAF subscribes to the AF services as above invoking either Nnef_EventExposure_Subscribe for untrusted DCAF or Naf_EventExposure_Subscribe service for trusted DCAF with (Event ID = Relative Proximity, Event Filter information, Target of Event Reporting). The target of event reporting and / or Event Filter information is set according to the target of analytics reporting and / or analytics filters set during the step 1 of the procedure.\nEvent filters can be defined for relative proximity to indicate to DCAF on how to process the data from individual UEs to determine the set of UEs to be accounted for relative proximity.\nIn the case of a trusted DCAF, the NWDAF may provide the Area of Interest, proximity range, predefined geographical area, or other criteria to the DCAF on the resolution of TAIs or any other finer resolution recognizable by the 5GC. In the case of an untrusted DCAF, NEF translates the requested criteria provided as event filter by the NWDAF into geographic zone identifier(s) or other geographic range identifier(s) or geographic direction identifier(s) that act as event filter(s) for the DCAF.\nThe DCAF may process (e.g. anonymize, aggregate and normalize) the data from individual UEs based on Event Filters indicated by the NWDAF to determine the set of UEs to be accounted for relative proximity before notifying that directly (trusted DCAF) or via NEF (for untrusted DCAF) to the NWDAF. An example set of information to be provided to the NWDAF is defined in Table 6.27.1-2.\nNOTE 3:\tIt needs to be confirmed with SA WG4 the feasibility of whether DCAF can collect the proximity related input data in Table 6.27.1-2 and apply the required processing described in steps 6-7 for input data delivery to NWDAF.\n8.\tThe NWDAF collects input data from AMF as defined in Table 6.27.1-3 via the AMF event exposure service.\nNOTE 4:\tStep 8 could be performed before step 6 if DCAF cannot determine the set of UEs fulfilling a proximity criterion.\n9.\tThe NWDAF collects input data from the LCS system as defined in Table 6.27.1-3.\n10.\tThe NWDAF collects input data from AF as defined in Table 6.27.1-3 via the SMF event exposure service.\n11.\tThe NWDAF derives requested analytics.\n12.\tThe NWDAF provide requested relative proximity and TTC information to the consumer NF or AF along with the corresponding Validity Period or any Validity Area, Validity Direction of interest or ranging distance, using either the Nnwdaf_AnalyticsInfo_Request response or Nnwdaf_AnalyticsSubscription_Subscribe response, depending on the service used in step 1. An example set of information to be provided to the consumer NF or AF from the NWDAF is defined in Table 6.27.1-3 and Table 6.27.1-4.\n13-15.\tIf at step 1 the consumer NF or AF has subscribed to receive continuous reporting of relative proximity information, the NWDAF may generate new analytics and, when relevant according to the Analytics target period and Reporting Threshold, provide them along with the corresponding Validity Period (or any Validity Area, Validity Direction of interest or ranging distance) to the consumer NF or AF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.27.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF:\n-\tAn analytics ID for relative proximity and time to collision information:\n-\tA set of input data from other 5GC NFs (e.g. DCAF) or OAM.\n-\tA set of output data to other 5GC NFs.\n-\tA set of analytics filters.\nAF:\n-\tA set of event exposures and event filters for proximity and time to collision information.\nDCAF:\n-\tSupport to determine proximity information between different UEs.\nOAM:\n-\tInput data related to proximity information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.28\tSolution #28: Detect and Improve correctness of NWDAF analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.28.1\tDescription",
                            "text_content": "The quality of an NWDAF machine-learning model may affect the NF performance or status, according to the usage of an NWDAF analytics and the decisions they make with them. A not reliable (or not well-trained) analytics ID may not help a NF to make a precise or correct decision, which may has impact on aspects of network performance. Hence, it is important to identify when an analytics ID requires improvement. This allows a network the NWDAF inference to keep providing an analytics ID output to one or more NWDAF consumers, which leads to a stable network status. In addition, this enables supporting an NWDAF training to become aware of problems in the configuration and/or generation of an analytics ID, which could lead to an unstable network status.\nNWDAF derives statistics and/or predictions, based on requests by analytics consumers. The statistics outputs can be considered more accurate than prediction outputs. Hence, correctness improvement analysis can focus on the prediction outputs of NWDAF analytics.\nFor the detection of a need for correctness of an analytics ID it is needed to introduce Analytics ID performance information, which could be derived by:\na)\tComparing the predicted outputs of an Analytic ID with the real value (i.e. ground truth) of that analytic ID. For instance, the Mean Absolute Error of the predicted analytics ID could be used as an example Analytics ID performance information, and/or\nb)\tMeasuring the impact of the decision of a NF that uses predicted outputs of an Analytic ID. The impact can be calculated according to the change of relevant KPIs of the NF, after the enforcement of a decision that was made, based on a predicted output of an Analytic ID. For example, the Analytics ID performance information can be defined per Analytics ID from the NF who measures the impact of the decision of a NF that uses predicted outputs of the Analytic ID\nSome examples as the following:\n-\tAnalytics ID=\"Service Experience\" used by PCF to adjust the QoS parameters for an application or NSSF/AMF to control the number of UEs or PDU Sessions in a network slice: Increased or Decreased service experience value per UE per Application ID from AF;\n-\tAnalytics ID=\"UE Mobility\" used by AMF to adjust the paging strategy: Increased or Decreased number of paging signalling per UE from AMF;\n-\tAnalytics ID=\"Network Performance\" used by PCF to determine the BDT policy: Increased or Decreased Radio Resource Utilization per RAN from OAM.\nNOTE 1:\tIn addition to the Analytics ID performance information feedback by others NF, the NWDAF itself may also evaluate the Analytics ID performance based on the continuous input data from the data sources e.g. the continuous service data as defined in Table 6.4.2-1 for the Analytics ID = \"Service Experience\".\nThe above-mentioned Analytics ID performance information is to indicate the execution result of a decided action based on the effect of the analytics ID. It can be calculated at NWDAF by using the analytics IDs statistics outputs. For instance, the predictions of an Analytics ID will be become the statistics of the respective analytics ID in a future point of time. If the relevant KPIs of the NF are in the statistics outputs of another analytics ID which reflects the effects of the action taken by the NF based on the prediction, the NF making decisions may provide the NWDAF the relationship between the above-mentioned Analytics ID performance information and the statistics outputs of the analytics ID (i.e. another analytics ID mentioned above). In this case, the NWDAF calculates the Analytics ID performance information according to the statistics outputs of the analytics ID specified by the NF making decisions based on the prediction.\nAlternatively or in conjunction with the NWDAF, the above-mentioned Analytics ID performance information can also be provided by a NF that makes decisions and/or applies decided actions via a feedback, based on the prediction of the analytics ID. The feedback can indicate the execution result of a decided action based on the effect of the predicted analytics ID. For instance, Analytics ID which reflects the effects of the action taken by the NF based on the prediction, the NF making decisions may compare the result with the decision made based on the statistics outputs of the analytics ID and indicates \"good/hit\" or \"not good/hit\" to the NWDAF.\nIn detail, the monitoring of network analytics correctness needs to identify the sources of data collection for the KPIs and/or metrics related to the Analytics ID performance information. And then to start the data collection from these data sources. The monitoring functionality in Consumer NF or NWDAF itself can provide following Analytics ID performance information of each Analytics ID to the NWDAF with a tracing function:\n-\tAnalytic ID.\n-\tList of Output analytics (Optional): identification of the analytics output information for the analytics ID that were consumed in the interval of time for the following grade information calculation.\n-\tAnalytics ID Grade Information: information resulting from the calculation of a grade related to the effect of an analytics on the changes in network status after the consumption of analytics. For example, it can be a real number between 1 and -1, where:\n-\t0 indicates that the consumption of the analytics ID had no significant effect on the expected network status pattern.\n-\t1 indicates \"hit\", i.e. the consumption of the analytics ID had significant positive effect in the expected network status pattern (e.g. improved the pattern of the KPIs) or a stable/good network performance. Hence, there is no need for further improvement/optimisation of the respective Analytics ID.\n-\t1 indicates \"not hit\" i.e. the consumption of the analytics ID had significant negative effect in the expected network status pattern (e.g. degraded the pattern of the KPIs) or not good network performance. In that case the improvement of the respective Analytics ID may be checked.\n-\tUnstable Analytics ID Information: information resulting from the calculation of a grade related to the effect of an analytics on the changes in network status after the consumption of analytics and identifying that this grade as crossing, deviating from thresholds (e.g. thresholds configured by operator) that denote an analytics has been identified as leading to unstable network status.\nNOTE 2:\tEither Analytics ID Grade Information or Unstable Analytics ID Information is included in the Analytics ID performance information.\nThe NWDAF with a tracing function can associate information of the quality of usage of the analytics ID (i.e. Analytics ID performance information), and the internal configuration (e.g. amount of the collected data to train, the configuration of machine learning model and so on) for an analytics ID in a period. The NWADF can keep information about last known Analytics ID performance information states, which is stable at a given point in time when using a given analytics with the most appropriated configuration.\nThe activation of the tracing and the monitoring of an analytics ID can happen:\n-\twith the subscription request of the analytics ID by the analytics consumer that is provided to the NWDAF. The request can include information to indicate that the tracing of an analytics ID needs to be started, optionally together with information about the criteria of the correctness of the analytics ID by the analytics consumer. The criteria of correctness includes the acceptable threshold of Analytics ID performance information and the corresponding correctness evaluation. Based on the criteria, the NWDAF can calculate the Analytics ID Grade Information of the corresponding analytics ID.\n-\tor by the NWDAF itself.\nAccording to the outputs of tracing and monitoring of an analytics ID, e.g. if the analytics ID is unstable (i.e. low performance), the NWDAF needs to refresh the output of the analytic ID and can decide and provide notifications for actions at the Inference and/or the Training functions. The quality of the NWDAF analytics is affected by various factors e.g. the quality and amount of the collected data to train, the configuration of machine learning model etc. Example actions at the Inference Function (AnLF) include:\n-\tChanging an inference configuration of an analytics ID.\n-\tSelecting a new analytics model of an analytics ID.\n-\tDeactivate an analytics model of an analytics ID.\nExample actions at the Training Function (MTLF) include:\n-\tChanging a training configuration of an analytics ID.\n-\tPerform retraining or reselection of an analytics model of an analytics ID.\n-\tDeactivate an analytics model of an analytics ID.\nThe NWDAF can use stored information during tracing of an analytics ID (e.g. on successful configurations of MTLF or AnLF) that have led to a stable or good network status for an analytics consumer, in case that an improvement decision of an analytics ID has been initiated. This information can help the NWDAF in its improvement decision and select improvement action.\nThe Inference Engine (AnLF) can provide Notifications to the analytics consumers, when it is identified that an analytics ID is unstable or needs improvement or is stable again:\n-\tA notification for the analytics ID that is unstable (i.e. low performance).\n-\tA status notification that an analytics ID that is stable (i.e. high performance) and the refreshed output of the Analytic ID.\n-\tA cooling duration indicates NWDAF needs more time to refresh the output of the Analytic ID. The consumer NF can re-request the same Analytic ID after the cooling duration.\nThis notification can help the NFs to decide whether they can continue consuming the specific analytics ID (that requires improvement).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.28.2\tProcedures",
                            "text_content": "The figure depicts a procedure to monitor and improve the correctness of NWDAF (Non-Widely Available Data Analytics) analytics, which is a crucial component of network performance monitoring. The figure illustrates the steps involved in the process, including data collection, data analysis, and data visualization. The NWDAF analytics are used to identify and address issues in network performance, such as latency, packet loss, and throughput, which can lead to poor user experience and potential service disruptions. The figure provides a visual representation of the process, making it easier to understand and follow.\nFigure 6.28.2-1: Procedure to monitor and improve the correctness of NWDAF analytics\n1.\tThe analytics consumer subscribes to the NWDAF service by invoking the Nnwdaf_AnalyticsSubscription_Subscribe or Nnwdaf_AnalyticsInfo_Request service operation and provides an indication that the tracing of an analytics ID needs to be started, optionally together with information about the criteria of the correctness of the analytics ID consumed by the analytics consumer. The NWDAF may indicate the analytics consumer or Decision Enforcement NF (via the analytics consumer) to provide feedback to the NWDAF (AnLF) about the performance information of the corresponding analytics ID in the response message.\n2.\tThe NWDAF (AnLF), generates the analytics output, according to the requested analytics ID and provides the notifications to analytics consumer, by invoking Nnwdaf_AnalyticsSubscription_Notify or Nnwdaf_AnalyticsSubscription_Notify service operation (as presented in clause 6.1, TS 23.288 [5])\n3.\tThe analytics consumer (NF) may use the received analytics outputs to make decisions that can be applied (or executed) either directly by the same NF (i.e. the analytics consumer) or the analytics consumer (NF) may use the received analytics outputs to make decisions that can be applied by another NF (i.e. Decision Enforcement NF) e.g. when the analytics consumer is PCF.\n4.\tIn the case that the monitoring of the correctness of an analytics ID has been initiated then performance information of the corresponding analytics ID are calculated within the NWDAF and/or with the support of involved NFs.\n4a.\tThe NWDAF can calculate performance information of the analytics ID by deriving statistics of same (i.e. predicted) analytics ID and/or statistics of (one or more other) analytics ID that reflect the effects of the action taken by the NF based on the predicted outputs according to the criteria of the correctness of the analytics ID. The NWDAF collects data from the analytics consumer (NF) and/or the Decision Enforcement NF to generate the output of the tracing Analytics ID.\n4b.\tThe analytics consumer (NF) can provide the feedback to the NWDAF (AnLF) about the performance information of the corresponding analytics ID, optionally by receiving information by a Decision Enforcement NF (if involved). The analytics consumer NF or the Decision Enforcement NF, can provide feedback of the execution result (e.g. based on changes of relevant KPIs of the NF) of a decided action based on the effect of the predicted analytics ID.\n5.\tThe NWDAF (AnLF) detects whether there is need for improvement of an Analytics ID, which is leading to unstable network status. By comparing monitored analytics ID performance information with the criteria of the correctness of an analytics ID (i.e. that have been provided by the analytics consumer or set in the NWDAF), the NWDAF calculate the Analytics ID grade information. The NWDAF will decide whether the correction is needed according to the Analytics ID grade information. The unstable Analytics ID information already known are also taken into account.\nThe NWDAF (AnLF) can also associate  the Analytics ID performance information, and the internal configuration for an analytics ID, via a tracing function included in the NWDAF (AnLF). The NWDAF (AnLF) can keep information about last known stable the Analytics ID performance information, which isstable at a given point in time when using a given analytics with the most appropriated configuration. The above can facilitate the decision making of the improvement process.\n6.\tIn the case that the need for correctness of analytics ID has been detected then an improvement process should be initiated. The decision for improvement of the unstable analytics ID at the NWDAF can be made using analytics ID performance information. The specific improvement action that will be triggered is an internal decision of the NWDAF and can involve the AnLF and/or the MTLF.\n-\tExample actions at the Inference Function (AnLF) could be: change an inference configuration of an analytics ID, selecting a new analytics model of an analytics ID, Deactivate an analytics model of an analytics ID.\n-\tExample actions at the Training Function (MTLF) could be: changing a training configuration of an analytics ID, perform retraining or reselection of an analytics model of an analytics ID, deactivate an analytics model of an analytics ID.\nThe NWDAF can use stored information during tracing of an analytics ID (e.g. on successful configurations of MTLF or AnLF) that have led to a stable or good network status for an analytics consumer to support an improvement decision for an analytics ID.\n7.\tA notification to the consumer of the NWDAF analytics ID is provided, when it is identified that an analytics ID is unstable or needs improvement. The notification message can include:\n-\ta notification for the analytics ID that is unstable (i.e. low performance);\n-\ta status notification that an analytics ID that is stable (i.e. high performance) and the refreshed output of the Analytic ID;\n-\ta cooling duration indicates NWDAF needs more time to refresh the output of the Analytic ID. The consumer NF can re-request the same Analytic ID after the cooling duration.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.28.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF:\n-\tMonitor the correctness of an analytics ID, calculating performance information of an analytics ID.\n-\tTracing correctness of an analytics ID and detect whether there is need for improvement of an Analytics ID.\n-\tDecide and apply appropriate action for the improvement of an Analytics ID.\n-\tProvide notification to the consumer of an analytics ID, when it is identified that an analytics ID is unstable or needs improvement.\nConsumer NFs:\n-\tIndicate that the tracing of an analytics ID needs to be started, providing (optionally) information about the criteria of the correctness of the analytics ID.\n-\tProvide feedback to the NWDAF about the performance information of an analytics ID on the execution result (e.g. based on changes of relevant KPIs of the NF) of a decided action based on the effect of the predicted analytics ID.\nDecision Enforcement NFs:\n-\tProvide feedback to the NWDAF or to the Consumer NF about the performance information of an analytics ID and the execution result (e.g. based on changes of relevant KPIs of the NF) of a decided action based on the effect of the predicted analytics ID.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.29\tSolution #29: Detection of ML Model degradation and actions",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.29.1\tDescription",
                            "text_content": "This is a solution for KI#1, on how to improve correctness of NWDAF analytics and addresses the following item in this KI:\n-\tHow and which information is needed to enhance the ML model provisioning to improve the correctness of NWDAF Analytics.\n-\tStudy mechanisms to detect that degradation on an ML model has happened and whether and which actions should be triggered.\nIn current ML model provisioning procedure defined in TS 23.288 [5], an NWDAF containing MTLF provides a trained ML model to an NWDAF containing AnLF which invokes the Nnwdaf_MLModelProvision_Subscribe towards the NWDAF containing MTLF.\nHowever, the accuracy of the trained ML model when used for analytics, e.g. accuracy level or confidence of the predictions using the trained ML model, may not meet the analytics requirement(s) of the NWDAF containing AnLF according to the analytics request(s)/subscription(s) from analytics consumer NF(s). Also the accuracy of the trained ML model may diminish, due to e.g. changes of network status and changes of UE communication patterns, etc.\nThis solution considers two aspects of the ML Model degradation problem:\n-\tDetection of the degradation of an ML model.\n-\tTriggering of a proper action in case any degradation in an ML model is observed.\nThe trained ML model needs to be updated by the NWDAF containing MTLF in order to guarantee or improve the correctness of analytics by the NWDAF containing AnLF. Hence, a solution of enhancing existing ML model provisioning procedure is proposed, so that the NWDAF containing MTLF can detect the degradation of an ML model, update the ML model towards the NWDAF containing AnLF accordingly and thus improve the correctness of NWDAF analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.29.2\tProcedures",
                            "text_content": "The proposed solution consists of two main parts:\n-\tHow to detect whether an ML model has been degraded.\n-\tTrigger proper action in case ML model degradation has been observed.\nEach part is discussed in the following (sub)clauses.\nFigure 6.29.2.2-1 illustrates an NWDAF containing AnLF registering to an NWDAF containing MTLF its monitoring capability for the determining the accuracy of the ML model. Then, the NWDAF containing MTLF subscribes to the NWDAF containing AnLF for the monitoring of an ML model. If the accuracy of an ML model is not sufficient, or if degradation in the ML model is detected, the NWDAF containing AnLF generates a notification to the NWDAF containing MTLF.\nIn this solution, the NWDAF containing AnLF may start the accuracy monitoring process when it starts making use of an ML model, and it registers with the MTLF that is responsible for training/updating this ML model. The NWDAF containing MTLF, due to the registration of accuracy monitoring from NWDAF containing AnLF or due to local policies, subscribes to the NWDAF containing AnLF for receiving notifications of the detection of degradation of the ML Model.\nWhen the subscription request is received, the NWDAF containing AnLF is assumed to be in possession of possible ML model's associated information, included in the ML model file, that can be used to support the AnLF performing the accuracy monitoring of the ML model. The NWDAF containing AnLF may start the accuracy monitoring process when it starts making use of the ML model. NWDAF containing AnLF monitors the accuracy of the ML model and notifies NWDAF containing MTLF if any degradation is detected.\nThe figure depicts a monitoring system for an ML model, showing the process of monitoring the model's performance and detecting any degradation. The system includes a visual representation of the model's performance, a report, and a degradation indicator.\nFigure 6.29.2.2-1: Monitoring an ML model and report degradation if detected\nIn the case of detecting low accuracy of an ML model which has been monitored, an NWDAF containing AnLF notifies the subscribed NWDAF containing MTLF. The NWDAF containing MTLF may not declare an ML model as \"degraded\" until enough degradation detection notifications have been received. When the NWDAF containing MTLF determines that an ML model is \"degraded\", it marks it with an indication in the ML model information (see TS 23.288 [5] clause 6.2A.2 for existing contents).\nIt is then up to the NWDAF containing MTLF to determine the actual actions to be taken. These actions include, e.g.:\n-\tTrigger a re-training process with an extended data set, including that the NWDAF containing MTLF may need to collect new data (e.g. statistics) from, e.g. ADRF.\n-\tIn case of existing more than one ML model for an Analytics ID, based on the records of ML model accuracy metrics, another ML model might be chosen without re-training any of the existing ML models.\nFigure 6.29.2.4-1 illustrates the procedure by which an NWDAF containing AnLF registers with an NWDAF containing MTLF that it is starting to monitor the accuracy of an ML model. A new Nnwdaf_MLModelMonitor_Register service operation is used for that purpose.\nThe figure depicts a procedure for monitoring and registering machine learning models in a telecommunication network. It illustrates the steps involved in the process, including data collection, model evaluation, and model registration. The figure is crucial for ensuring the accuracy and reliability of machine learning models in telecommunication networks.\nFigure 6.29.2.4-1: Procedure for ML model monitoring registration\n1.\tAn NWDAF containing AnLF starts monitoring the accuracy of an ML model, due to start using the ML model for producing analytics.\n2-3.\tThe NWDAF containing AnLF sends an Nnwdaf_MLModelMonitor_Register request to an NWDAF containing MTLF (NWDAF containing AnLF NF ID, unique identifier of the ML model, optionally subscription endpoint of the ML Monitoring service operation). The NWDAF containing MTFL is now aware of the NF ID of the NWDAF containing AnLF that are monitoring the accuracy of that ML model.\nWhen the NWDAF containing AnLF does no longer monitor the accuracy of the ML model, it sends an Nnwdaf_MLModelMontior_Unregister service operation. The NWDAF containing MTLF deletes the associated data.\nFigure 6.29.2.5-1 illustrates the procedure for the detection of ML model degradation. A new Nnwdaf_MLModelMonitor_Subscribe and Nnwdaf_MLModelMonitor_Notify service operations are used for that purpose. An NWDAF service consumer, i.e. an NWDAF containing MTLF, subscribes at another NWDAF, i.e. an NWDAF containing AnLF, to be notified when the accuracy of the previously provisioned trained MT model is not sufficient.\nThe figure depicts a procedure for detecting degradation in machine learning models, illustrating the steps involved in identifying and rectifying issues in predictive models.\nFigure 6.29.2.5-1: Procedure for ML model degradation detection\n0.\tAn NWDAF containing MTLF receives a trigger for subscribing to the ML model monitor at an NWDAF containing an AnLF. This trigger could be the reception of an Nnwdaf_MLModelMonitor_Register request, an administrative action, or determined by local policy. The NWDAF containing MTLF reads the information registered by the AnLF, such as the NF ID, unique identifier of the ML model, MLModelMonitor subscription endpoint, etc.\n1.\tThe NWDAF containing MTLF sends an Nnwdaf_MLModelMonitor_Subscribe request (Analytics ID, unique identifier of the ML model to be monitored, optionally Reporting Threshold(s)) to an NWDAF containing AnLF subscription endpoint.\n2.\tThe NWDAF containing AnLF sends a response to the NWDAF containing MTLF.\n3.\tNWDAF containing AnLF starts an internal process for monitoring the accuracy of the ML model.\nNOTE:\tNWDAF containing AnLF can monitor the accuracy in many ways: e.g. get ground truth value of the predictions, subscribe to NF events that related to the analytics ID, or following the instructions embedded in the model from the MTLF, etc.\n4,5\tUpon detection of an insufficient accuracy of the ML model, and if deviation (i.e. deviation of the output analytics using the trained ML model from the actual network running data) is greater than the Reporting Threshold(s) if received in the Subscribe, the NWDAF containing AnLF sends an Nnwdaf_MLModelMonitor_Notify request to the notification endpoint (e.g. the NWDAF containing MTLF). The Notify request should include a Deviation value.\n6.\tThe NWDAF containing MTLF sends a response indicating that it has received ML model monitor notification from respective instance of NWDAF containing AnLF.\n7.\tThe NWDAF containing MTLF adds an indication to the ML Model Information as \"degraded\".\n8.\tThe NWDAF containing MTLF takes an appropriate action. This can be, e.g. re-training the ML model with additional data.\nModel provisioning is affected by the proposed solution in a way that provisioning can be postponed if an action might be required, in case of detection of an ML model degradation.\nWhen NWDAF containing MTLF receives a subscription request from a NWDAF's service consumer for ML model provision, upon accepting the subscription, the NWDAF containing MTLF generates a regular notification request including the required ML model information including an indication of the \"degraded\" status.\nFigure 6.29.2.6-1 shows an enhanced procedure for signalling whether a model is degraded.\nThe figure depicts a step-by-step procedure for enhancing machine learning model provisioning, with a focus on the use of AI and ML techniques. It includes a detailed explanation of the steps involved, such as data preparation, model selection, and model training, as well as the use of AI and ML tools like TensorFlow, Keras, and PyTorch. The figure also highlights the importance of data privacy and security, as well as the potential benefits of using AI and ML in various industries, such as healthcare, finance, and transportation.\nFigure 6.29.2.6-1: Procedure for enhanced ML model provisioning\n1.\tAn ML Model Provisioning service consumer (i.e. an NWDAF containing AnLF) sends an Nnwdaf_MLModelProvisioning_Subscribe request for subscribing to a (set of) ML models associated to a (set of) Analytics ID.\n2.\tThe NWDAF containing MTLF sends a response.\n3,4.\tPrior to sending a notification, the NWDAF containing MTLF determines whether the model is marked as \"degraded\". Then the NWDAF containing MTLF sends an Nnwdaf_MLModelProvisioning_Notify request (ML model Information, including the file address of the trained ML model and its \"degradation\" indication status).\n5,6.\tThe NWDAF containing AnLF sends a response and determines, based on the \"degraded\" indication in the ML Model information, whether it still wants to download the ML model or not.\n7.\tLater, the NWDAF containing MTLF finishes the re-training and a new ML model becomes available. The MTLF clears the \"degraded\" indication of the ML Model Information.\n8.\tThe NWDAF containing MTLF sends an Nnwdaf_MLModelProvisioning_Notify request (ML Model Information, addresses of the file address of the trained ML model).\n9.\tThe service consumer acknowledges NWDAF containing MTLF by sending back Nnwdaf_MLModelProvision_Notify response.\nThe ML Model Information (including the new \"degraded\" indication) is also available through the Nnwdaf_MLModelInfo_Request service operation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.29.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF containing AnLF:\n-\tNew functionality for monitoring the accuracy of an ML model and registering/unregistering the monitoring of the accuracy of an ML model using the Nnwdaf_MLModelMonitor_Register service operation.\n-\tNew functionality for receiving subscription requests for monitoring the accuracy of an ML model (Nwdaf_MLModelMonitor_Subscribe/Unsubscribe) and generating their corresponding notifications (Nnwdaf_MLModelMonitor_Notify).\n-\tUpon requesting the provisioning of an ML model, new functionality for receiving a notification with the ML model information containing the \"degraded\" indication in Nnwdaf_MLModelProvisioning_Notify request and response to Nnwdaf_MLModelInfo_Request.\nNWDAF containing MTLF:\n-\tNew functionality for registering/unregistering and storing NF ID of NFs which are monitoring the accuracy of an ML model by receiving the Nnwdaf_MLModelMonitor_Register service operation.\n-\tNew functionality for subscribing to notifications of the accuracy of an ML model (Nnwdaf_MLModelMontior_Subscribe/Unsubscribe and Nnwdaf_MLModelMonitor_Notify).\n-\tNew functionality for triggering an NWDAF containing MTLF action upon receiving information of the insufficient accuracy of an ML model. Such actions may include, starting a procedure for re-training the degraded ML model.\n-\tNew functionality for including a \"degraded\" indication in the ML model information, Nnwdaf_MLModelProvisioning_Notify request and response to Nnwdaf_MLModelInfo_Request.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.30\tSolution #30: Improve correctness of NWDAF analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.30.1\tDescription",
                            "text_content": "This is a solution for Key Issue #1: \"How to improve correctness of NWDAF analytics\".\nAfter MTLF providing one or multiple ML models related to an analytics ID to the AnLF, based on some specific monitoring mechanism, the analytics correctness for the one model or multiple models can be evaluated by the AnLF or MTLF. The analytics correctness evaluation result (e.g. Accuracy in Use or MAE in Use, etc.) will be obtained or reported to the MTLF meanwhile with the model usage scope for each model, which indicates the target scope (area, DNN, S-NSSSAI and target UE(s)) the model is used in the real network.\nBy updating the model repeatedly, or choosing from the multiple models, the MTLF will get a model with good enough performance e.g. according to analytics correctness evaluation result (e.g. Accuracy in Use or MAE in Use, etc.). The MTLF stores the model information with and its corresponding model usage scope.\nWhen the same AnLF (e.g. due to abnormal loss of model information) or some other AnLF subscribes a trained ML model to the MTLF, if the requested analytics ID and model filter information matches with the model information, then the MTLF provides it to the requested AnLF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.30.2\tProcedures",
                            "text_content": "The figure depicts a set of procedures for improving model performance based on analytics correctness evaluation of one candidate model. The figure includes a flowchart with steps for data collection, model selection, model training, model evaluation, and model improvement. The steps are labeled and numbered, making it easy to follow the process. The figure also includes a legend to clarify the different stages of the process. Overall, the figure provides a clear and concise guide for improving model performance based on analytics correctness evaluation.\nFigure 6.30.2-1: procedures for improving model performance based on analytics correctness evaluation of one candidate model\n1.\tThe NWDAF containing AnLF1 subscribes to a trained ML model associated with an Analytics ID and model filter information by invoking Nnwdaf_MLModelProvision_Subscribe or Nnwdaf_MLModelProvision_Request service operation as defined in TS 23.288 [5].\nThe NWDAF containing MTLF provides a matched ML model information by invoking Nnwdaf_MLModelProvision_Notify or Nnwdaf_MLModelProvision_Response service operation.\n2.\tThe NWDAF containing AnLF1 retrieves analytics based on the obtained ML model and provides the analytics result to the analytics NF consumer, which is described in TS 23.288 [5].\nDuring the analytics inference procedure and analytics usage procedure in the real network, the analytics correctness can be evaluated by the AnLF1 or MTLF, e.g. based on monitoring mechanism defined in the solution 1, 3, 4, 5, 6 or others. The analytics correctness evaluation result (e.g. Accuracy in Use or MAE in Use, etc.) will be obtained or reported to the MTLF as well with the model usage scope, which indicates the target scope (area, DNN, S-NSSSAI and target UE(s)) the model is used in the real network.\nNOTE:\thow does the AnLF and MTLF evaluate analytics correctness should depend on the conclusion of KI#1.\n3.\tIf the analytics correctness is low and doesn't achieves the configured goal, then the MTLF will reselect a new ML model or retrain the provided ML model for the corresponding model usage scope.\n4.\tThe NWDAF containing MTLF provides a new model or the updated model to the NWDAF containing AnLF1, with a corresponding model ID, which uniquely identifies a model instance.\n5.\tSimilar as the step 2, the analytics correctness for the new model or the updated model can be re-evaluated. And then steps 3-5 will be repeated until the analytics correctness is well enough as described in step 6.\n6.\tIf the analytics correctness is good enough e.g. based on configuration in MTLF, then the NWDAF containing MTLF stores the model information and its corresponding model usage scope.\n7.\tThe NWDAF containing AnLF1(e.g. due to abnormal loss of model information) or NWDAF containing AnLF2 subscribes to a trained ML model associated with an Analytics ID and model filter information, which is similar as step 1.\n8.\tIf NWDAF containing MTLF determines the requested analytics ID and model filter information matches with model filter information and the model usage scope, then it will perform step 9 to provide the model information to the AnLF.\n9.\tThe NWDAF containing MTLF provides the matched ML model information determined in step 8 by invoking Nnwdaf_MLModelProvision_Notify or Nnwdaf_MLModelProvision_Response service operation.\nThe figure depicts a series of procedures for improving model performance based on analytics correctness evaluation of multiple candidate models. The figure includes a flowchart, a matrix, and a legend, illustrating the steps involved in the evaluation process. The matrix shows the comparison of the performance of different models, with the legend indicating the significance of each column. The flowchart guides the user through the evaluation process, starting with the initial model and progressing to the final model with the highest accuracy. The figure is essential for understanding the methodology and ensuring the accuracy of the evaluation process.\nFigure 6.30.2-2: procedures for improving model performance based on analytics correctness evaluation of multiple candidate models\n1.\tThe NWDAF containing AnLF1 subscribes to a trained ML model associated with an Analytics ID and model filter information by invoking Nnwdaf_MLModelProvision_Subscribe or Nnwdaf_MLModelProvision_Request service operation as defined in TS 23.288 [5].\nIf there are multiple candidate models matching with the model request in the NWDAF containing MTLF, and optionally NWDAF containing AnLF indicates its support for multiple ML models, then NWDAF containing MTLF provides multiple matched ML models IDs and corresponding model information by invoking Nnwdaf_MLModelProvision_Notify or Nnwdaf_MLModelProvision_Response service operation.\n2.\tFor the multiple obtained ML models, the analytics correctness for each model can be evaluated by the AnLF1 or MTLF, e.g. based on monitoring mechanism defined in the solution 1, 3, 4, 5, 6 or others. The analytics correctness evaluation result for each model (e.g. Accuracy in Use or MAE in Use, etc.) will be obtained or reported to the MTLF as well with the model usage scope, which indicates the target scope (area, DNN, S-NSSSAI and target UE(s)) the model is used in the real network.\n3.\tBased on the received analytics correctness evaluation result for the multiple candidate ML models, the NWDAF containing MTLF chooses the one(s) whose analytics correctness is good enough e.g. based on configuration in MTLF, and stores the model information and the corresponding model usage scope.\n4.\tThe NWDAF containing AnLF1(e.g. due to abnormal loss of model information) or NWDAF containing AnLF2 subscribes to a trained ML model associated with an Analytics ID and model filter information, which is similar as step 1.\n5.\tIf NWDAF containing MTLF determines the requested analytics ID and model filter information matches with model filter information and the model usage scope, then it will perform step 6 to provide the model information to the AnLF.\n6.\tThe NWDAF containing MTLF provides the matched ML model information determined in step 8 by invoking Nnwdaf_MLModelProvision_Notify or Nnwdaf_MLModelProvision_Response service operation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.30.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF containing MTLF:\n-\tObtains by itself or from the AnLF the analytics correctness evaluation result for each model (e.g. Accuracy in Use or MAE in Use, etc.) and the corresponding model usage scope.\n-\tStores the model information with the good enough performance and its corresponding model usage scope.\n-\tProvides the model information with good enough performance to the AnLF, based on the analytics ID, model filter information and model usage scope.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.31\tSolution #31: Multiple Analytics outputs based NF action decision",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.31.1\tDescription",
                            "text_content": "This is a solution for Key Issue #1: \"How to improve correctness of NWDAF analytics\".\nWhen the consumer NF requests analytics for the prediction and willing to decide the action based on the prediction, there exists a certain risk on incorrect prediction by NWDAF. Specifically, the NWDAF provides a single prediction output for a specific analytics target object as specified in current TS 23.288 [5], the consumer NF only can determine the action based on the single prediction, even if the single prediction has low probability to true (e.g. 0.51) but high probability to fail (e.g. 0.49).\nIn order to minimize the effect of incorrect analytics on NF action, this solution proposes that NWDAF provides multiple prediction outputs with the certain probability for the same analytics target object to the consumer NF, and then, the consumer NF takes an action which considers all the possible ground truth from multiple analytics outputs.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.31.2\tProcedures",
                            "text_content": "Figure 6.31.2-1 depicts the procedures for providing multiple analytics to consumer NF.\nThe figure depicts a series of procedures for providing multiple analytics outputs, illustrating the step-by-step process of data analysis and visualization.\nFigure 6.31.2-1: Procedures for providing multiple Analytics outputs\n0.\tThe NWDAF containing AnLF registers the capability to supports multiple analytics output for the same target object to NRF.\n1a-1b.\tThe analytics consumer NF discovers the NWDAF containing AnLF via NRF by invoking Nnrf_NFDiscovery Request with the indication of multiple analytics outputs for the same target object, and selects the serving NWDAF from the candidate NWDAFs.\n2a-2b.\tThe analytic consumer NF requests analytics to the NWDAF by invoking Nnwdaf_AnalyticsInfo_reqeust/Nnwdaf_AnalyticsSubscription_Subscribe service operation with the indication of multiple analytics outputs for the same target object which includes either \"the number of required analytics outputs\" or \"the lowest probability of analytics\", and then, the NWDAF provides the multiple outputs (i.e. prediction results) for the same target object with the probability (i.e. confidence in output parameter) as indicated by \"the number of required analytics outputs\" or the outputs which has larger probability than \"the lowest probability of analytics\" for an Analytics to the analytics consumer NF.\nNOTE:\tThe sum of the probability (i.e. confidence in output parameter) for all the outputs should be less than or equal to 100.\n3.\tThe analytics consumer NF decides an action which considers all the possible ground truth from multiple analytics outputs.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.31.3\tImpacts on existing nodes and functionality",
                            "text_content": "NWDAF:\n-\tNWDAF registers the capability to provide multiple analytics output for the same target object to NRF.\n-\tIn case prediction, NWDAF provides multiple analytics outputs for the same target object with each probability in confidence field.\nNF:\n-\tAnalytics consumer NF decides an action based on multiple NWDAF analytics outputs for the same target object.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.32\tSolution #32: Enhanced ML model provisioning",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.32.1\tDescription",
                            "text_content": "This solution addresses key issue #1 \"How to improve correctness of NWDAF analytics\".\nIn current ML model provisioning procedure defined in TS 23.288 [5], an NWDAF containing MTLF provides a trained ML model to an NWDAF containing AnLF which invokes the Nnwdaf_MLModelProvision_Subscribe towards the NWDAF containing MTLF.\nHowever, the performance of the trained ML model when used for analytics, e.g. accuracy level or confidence of the predictions using the trained ML model, may not meet the analytics requirement(s) of the NWDAF containing AnLF according to the analytics request(s)/subscription(s) from analytics consumer NF(s). Also the performance of the trained ML model may degrade, due to e.g. change of network status / collected network data.\nIn those cases, the trained ML model needs to be updated by the NWDAF containing MTLF in order to guarantee or improve the correctness of analytics by the NWDAF containing AnLF.\nHence, a solution of enhancing existing ML model provisioning procedure is proposed, so that the NWDAF containing MTLF can detect the performance requirements or degradation of an ML model, update the ML model towards the NWDAF containing AnLF accordingly and thus improve the correctness of NWDAF analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.32.2\tProcedures",
                            "text_content": "The procedure in Figure 6.32.2-1 is used by an NWDAF service consumer, i.e. an NWDAF containing MTLF, to subscribe at another NWDAF, i.e. an NWDAF containing AnLF, to be notified when the performance of the previously provisioned trained MT model does not meet the analytics requirements or degrade.\nNOTE 1:\tThe service names in the procedure are descriptive and may be updated where applicable during the normative phase.\nThe figure depicts a procedure for enhancing machine learning model provisioning, with a focus on the steps involved in the model creation, validation, and deployment process. The figure includes a flowchart that outlines the steps, with arrows indicating the sequence of actions. The figure also includes a legend to clarify the different colors and symbols used in the flowchart. The figure is labeled \"Figure 6\" and is presented in a 32x2 format, with the first column representing the steps and the second column representing the steps in reverse order. The figure is a visual representation of the process, making it easy to understand and follow.\nFigure 6.32.2-1: Procedure of enhanced ML model provisioning\n1.\tNWDAF1 containing MTLF provisions the same ML model to NWDAF2 containing AnLF, NWDAF3 containing AnLF and NWDAF4 containing AnLF based on the Nnwdaf_MLModelProvision_Subscribe service operations from those NWDAFs, using the procedure described in clause 6.2A.1 of TS 23.288 [5]. The NWDAF2 containing AnLF, as well as NWDAF3 containing AnLF, indicated its capability of providing ML model performance feedback information in the Nnwdaf_MLModelProvision_Subscribe service operation.\n2a-2b.\tNWDAF1 containing MTLF decides to subscribe to notifications on the trained ML model performance. Based on the indicated capability of providing ML model performance feedback information in the Nnwdaf_MLModelProvision_Subscribe service operation, NWDAF1 containing MTLF invokes the Nnwdaf_MLModelPerformance_Subscribe service operation towards NWDAF2 containing AnLF and NWDAF3 containing AnLF respectively. The Nnwdaf_MLModelPerformance_Subscribe contains the Analytics ID(s) associated with the trained ML Model(s) and optionally Reporting Threshold(s) for trained ML model performance. Here the Reporting Threshold(s) refers to the average and/or variance of the deviation of the predictions (i.e. predicted data) using the trained ML model from the actual network data, in terms of e.g. Mean Absolute Error or Accuracy.\n3a-3b.\tNWDAF2 containing AnLF (/NWDAF3 containing AnLF) determines whether/when to send notifications on the performance of trained ML model to the NWDAF containing MTLF. When NWDAF2 containing AnLF (/NWDAF3 containing AnLF) detects that the analytics deviation (i.e. deviation of the predictions using the trained ML model from the actual network data) is greater than the Reporting Threshold(s) if received in the Nnwdaf_MLModelPerformance_Subscribe in Step 2, or greater than the Reporting Threshold(s) which is set according to local policy, NWDAF2 containing AnLF (/NWDAF3 containing AnLF) invokes an Nnwdaf_MLModelPerformance_Notify service operation towards NWDAF1 containing MTLF. The Nnwdaf_MLModelPerformance_Notify indicates the analytics deviation which is greater than the Reporting Threshold(s), and optionally the data set for the detected deviation when the deviation occurs. The ML model accuracy (i.e. level of accuracy of the analytics using the trained ML model) may also be included in the Nnwdaf_MLModelPerformance_Notify. The information contained in the Nnwdaf_MLModelPerformance_Notify is shown in Table 6.32.2-1.\nTable 6.32.2-1: ML model performance data from the NWDAF containing AnLF\n\nNOTE 2:\tThe address (e.g. URL) of the data set for the detected deviation can be included in the ML model performance data, instead of including the data set, to reduce the size of the notification.\n4.\tNWDAF1 containing MTLF decides whether update of the trained ML model is needed, based on the notifications received in step 3a-3b. NWDAF1 containing MTLF may, if supports, use the ML model performance data in the notifications as input data to perform analytics on the trained ML model performance, and decide whether or not to update the trained ML model based on the statistics and/or predictions of the ML model performance. The information in ML model performance statistics and predictions is shown in Table 6.32.2-2 and Table 6.32.2-3.\nTable 6.32.2-2: ML model performance statistics\n\nTable 6.32.2-3: ML model performance predictions\n\nNOTE 3:\tHere it is assumed that the NWDAF1 containing MTLF is capable of performing analytics (statistics and/or predictions) on ML model performance, based on the ML model performance data in the notifications from the NWDAF(s) containing AnLF, though the NWDAF1 containing MTLF does not support network analytics as described in TS 23.288 [5].\nIf update of the trained ML model is needed, NWDAF1 containing MTLF retrains the ML model using the data set (if provided) in the Nnwdaf_MLModelPerformance_Notify, or using the data collected from 5GC NF(s), OAM and/or UE application(s).\n5a-5c.\tNWDAF1 containing MTLF notifies NWDAF2 containing AnLF, NWDAF3 containing AnLF and NWDAF4 containing AnLF with the updated trained ML Model information by invoking Nnwdaf_MLModelProvision_Notify service operation, as described in clause 6.2A.1 of TS 23.288 [5].\nNOTE 4:\tHere without step 2 and step 3 performed towards/by NWDAF4 containing AnLF, NWDAF1 containing MTLF also updates the trained ML model towards NWDAF4 containing AnLF based on the subscriptions in step 1.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.32.2-1: ML model performance data from the NWDAF containing AnLF",
                                    "table number": 32,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.32.2-2: ML model performance statistics",
                                    "table number": 33,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.32.2-3: ML model performance predictions",
                                    "table number": 34,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.32.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF containing MTLF:\n-\tSubscribes to notifications of the trained ML model performance feedback information.\n-\tUses the ML model performance data in the notifications as input data to perform analytics on the trained ML model performance, and decide whether or not to update the trained ML model based on the statistics and/or predictions of the ML model performance.\nNWDAF containing AnLF:\n-\tProvides notifications of the trained ML model performance feedback information to the NWDAF containing MTLF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.33\tSolution #33: Improving correctness of NWDAF analytics by providing correction information",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.33.1\tDescription",
                            "text_content": "This solution is proposed to address Key Issue #1: how to improve correctness of NWDAF analytics.\nAnalytics consumer may not use the analytics as soon as it receives analytics from NWDAF, while it may use the analytics only when it needs to make a decision, or the analytics consumer may use the analytics for a period of time and make several decisions during this time. In this case, there is a time period between the analytics received and the analytics actually used by the analytics consumer. Meanwhile, the NWDAF may improve the accuracy of the analytics or find the provided analytics is incorrect due to various factors (e.g. update of ML model, reselection of ML model, parameter adjustment, more data input, etc.) and the improved analytics may have positive impact to consumer's decision. Therefore, it is useful that NWDAF can provide correction information for provided analytics to the consumer (e.g. information to update provided analytics, notification of stopping using provided analytics, incorrect content of provided analytics, etc.).\nAs described in TS 23.288 [5], analytics consumer may provide preferred level of accuracy and output strategy, which means accuracy variation within a certain range may not influence some consumers, therefore, different analytics consumer should determine whether it receives the correction information and the time period during which the correction information can be provided. To reduce signalling load, the frequency and condition of providing correction information should also be designated by analytics consumer, for example, the consumer can give a correction threshold, requiring NWDAF to provide correction information when NWDAF finds the accuracy improved over the threshold.\nThis solution proposes that consumers may provide requirement on correction information in subscription, and NWDAF maintains provided analytics and provides correction information for the latest provided analytics to the consumer.\nIn this solution, the following functionalities are proposed to take into consideration:\n-\tAnalytics consumer provides following information in subscription if it requires to receive correction information:\n-\tCorrection time period: defines the time interval during which the correction information can be accepted by the consumer. It is a relative time interval as the gap with respect to analytics is provided.\n-\tCondition of providing correction information: defines the condition when the correction information can be provided to the consumer, e.g. correction threshold (when NWDAF finds the accuracy difference between new analytics and provided analytics exceeding the specified threshold).\n-\tPreferred correction information form: defines the information form in which the consumer requires to receive. It can be set as following values:\n-\tan incorrectness notification: used to notify the consumer provided analytics is incorrect;\n-\tan updated analytics: the NWDAF can provide an updated analytics to replace provided analytics;\n-\tan error value: NWDAF can provide a delta compared to the provided analytics.\n-\tNWDAF maintains provided analytics during correction time period.\n-\tNWDAF provides correction information for the latest provided analytics to consumer according to the preferred correction information form in subscription.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.33.2\tProcedures",
                            "text_content": "Figure 6.33.2-1 illustrates the procedure for NWDAF providing correction information.\nThe figure depicts a flowchart illustrating the steps for improving the correctness of NWDAF (Non-Widely Applicable Data Analytics) analytics. It includes a series of steps, such as collecting data, validating the data, and applying corrections, to ensure the accuracy of the analytics. The figure is a visual representation of the process, making it easy to understand and follow.\nFigure 6.33.2-1: Procedures for improving correctness of NWDAF analytics by providing correction information\n1.\tThe NF (analytics consumer) sends Nnwdaf_AnalyticsSubscription_Subscribe/ Nnwdaf_AnalyticsInfo_Request. This service operation is enhanced with providing more parameters which include correction time period, condition of providing correction information (e.g. correction threshold), preferred correction information form (e.g. incorrectness notification, updated analytics, etc.), if the NF requires the correction information for provided analytics.\n2.\tThe NWDAF collects input data and performs analytics as the procedures in TS 23.288 [5].\n3.\tThe NWDAF sends the analytics output to NF as the procedures in TS 23.288 [5].\n4.\tThe maintenance of provided analytics will be triggered depending on various factors (e.g. model updated, reselection of ML model, parameter adjustment, more input data, etc.).\n5.\tIf step 4 occurs within correction time period, NWDAF maintains provided analytics.\nIf condition of providing correction information is met, the NWDAF generates the correction information in preferred correction information form as the consumer required.\n6.\tThe NWDAF sends the correction information for the latest provided analytics to NF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.33.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF:\n-\tSupport on maintaining provided analytics.\n-\tSupport on generating correction information for the latest provided analytics.\nAnalytics consumer:\n-\tSupport on providing requirement related to correction information in subscription information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.34\tSolution #34: Enhancing the accuracy of NWDAF Analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.34.1\tDescription",
                            "text_content": "This solution addresses aspects of key issue #1 on how to improve correctness of NWDAF analytics.\nWhen NWDAF predicts something for the future, it does not monitor/collect information about the occurrence of the actual event, so it cannot compare the true observed event with its corresponding previous predictions.\nSimilarly, consumers requesting an analytics of type \"prediction\" from an NWDAF, are provided only analytics output/prediction with a confidence estimated by NWDAF implementation logic. An analytics consumer does not retrieve an accuracy report related to the prediction or related to earlier predictions done for the same analytics type and model used (i.e. an accuracy indication derived from comparing the actual outcome with a previous predicted value).\nTo compute the accuracy of analytics, it is necessary to monitor the performance of the ML model and in case trigger re-training. Depending on the use case, such operations may require high computational power and large storage space, and AnLF might not fulfil such requirements. In particular, it is proposed to let MLTF to execute the ML model monitoring, leveraging the ADRF to store the necessary analytics and data, that MTLF uses to compute the accuracy.\nAlso, this solution proposes to enable the NWDAF containing MTLF to determine the actual outcome of a prediction, so that it can either:\n-\tReport in an accuracy report, the outcome to the consumer so the consumer can compare the outcome with the previously provided prediction; or\n-\tCompare the outcome with the previous prediction to generate an accuracy report which the NWDAF containing MTLF provides to the consumer via AnLF.\nThis solution proposes to re-use existing services to execute the monitoring in 2 variants:\n-\tIn variant 1 the monitoring is triggered by AnLF, e.g. after receiving an analytics request from an Analytics consumer that requires also an accuracy report. In this variant, AnLF instruments the ADRF to collect analytics and data after a prediction has been made. AnLT indicate to MTLF to retrieve the stored data, so that it can learn about actual outcomes, compare them with the predicted data, and generate an accuracy report. The accuracy report comprises the accuracy for a given analytics subscription or for a given Analytics ID (e.g. average over all subscriptions for that Analytics ID). The accuracy report may provide the actual outcomes, or information on how the outcomes deviate from the predicted values. When aggregated accuracy is provided (e.g. for all subscriptions to an analytics ID), the accuracy reports may be provided as a function of the prediction confidence level (i.e. probability assertion). If an NWDAF makes a prediction with low confidence, one should expect lower accuracy compared to when the NWDAF makes a prediction with high confidence. This is reflected in the accuracy reports.\n-\tIn variant 2 the monitoring is triggered by the MTLF itself, and no coordination with AnLF is needed.\nNOTE:\tThe format of the accuracy report depends on the use case and analytics ID. In general, an accuracy value in given range, e.g. 1 to 10 may be defined.\n-\tNWDAF Analytics services are enhanced to enable an analytics consumer to collect a detailed accuracy report from NWDAF (e.g. how well the NWDAF performed for a specific Analytics ID, using a specific model, for a specific area/slice(group of)UE, in a given time window).\n-\tNWDAF registers its measured accuracy (per Analytics ID) in its NF profile in NRF/UDM, so that analytics consumers can use this information when selecting the NWDAF instance/set.\n-\tNWDAF containing MTLF uses the accuracy information to further fine-tune the model it is using (e.g. trigger model re-training, adjust data sources for the model training and the analytics generation).\n-\tThe analytics consumer uses the accuracy report provided by NWDAF to manage the subscription (e.g. if accuracy is low the analytics consumer may terminate the subscription, adjust subscription parameters, or change the NWDAF, etc.) and/or to take the actual accuracy into account into local decision making (e.g. adjust the weight of the analytics reports in the decision making compared to other inputs).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.34.2\tProcedures",
                            "text_content": "Figure 6.34.2.1-1 illustrates the procedure for measuring and reporting accuracy of NWDAF analytics initiated by AnLF.\nThe figure depicts a procedure for measuring and reporting the accuracy of NWDAF analytics initiated by AnLF. It illustrates the steps involved in collecting data, analyzing the results, and reporting the results to the relevant stakeholders. The figure includes a flowchart, a list of steps, and a table that outlines the data collection, analysis, and reporting process.\nFigure 6.34.2.1-1: Procedure for measuring and reporting accuracy of NWDAF analytics initiated by AnLF\n1.\tThe (consumer) NF sends Nnwdaf_AnalyticsSubscription_Subscribe request to an NWDAF containing AnLF with a flag indicating that it is interested in receiving an accuracy report along with the analytics (prediction) report. The NFc also provides a callback URI to receive the accuracy report. The NFc may also send separate processing and filtering instructions for the accuracy report(s) (e.g. to club or filter the accuracy reports). The NFc may also send instructions to NWDAF on how to handle the subscription after having generating accuracy report. For example, the instructions may specify that if three consecutive predictions are wrong, the NWDAF subscription must be terminated, and a termination notification will be sent to the NFc.\n2.\tThe NWDAF containing AnLF requests an ML model from the appropriate NWDAF containing MTLF, including the MonitoringCorrelationID parameter, needed by MTLF to execute the accuracy monitoring operations.\n3.\tThe NWDAF containing MLTF provides the ML model to the AnLF as per current specifications.\n4.\tThe NWDAF containing AnLF requests ADRF to subscribe for the collection of the analytics and data that correspond to the analytics requested by the NFc in step 1. AnLF uses the procedures defined in Clause 6.2B.3 of TS 23.288, including the MonitoringCorrelationID.\n5.\tThe ADRF executes the operations defined in Clause 6.2B.3 of TS 23.288 [5] to subscribe to the analytics and data that correspond to the analytics requested by the NFc in step 1. ADRF stores the notifications and tags the received data using the MonitoringCorrelationID.\n6.\tThe NWDAF containing MLTF subscribes to ADRF to retrieve all data tagged with the MonitoringCorrelationID received from the AnLF\n7.\tThe NWDAF containing MLTF receives the data from the ADRF.\n8a-b.\t(can be executed after step 3). The NWDAF AnLF generates the predictions and provides them to the NFc.\n9.\tBased on the collected analytics and data, the MLTF computes the accuracy using the predictions and the actual measured data observed at the time for which the prediction had been made.\n10.\tAn accuracy report is sent to the AnLF after the events have occurred that were needed for the verification of the predictions. The accuracy report is sent in an MLModelProvision notification from MTLF.\n11-11a.\tThe accuracy report is sent to the consumer. The accuracy report may be sent in a separate notification from AnLF to NFc or it can be clubbed with the next analytics notification sending predictions of future events. The frequency of the accuracy notification may be controlled via the filtering/reporting instruction(s) given in the subscribe request in step 1. (optional) If, in step 1, an instruction was received on how to handle the subscription after having terminated the accuracy report, the NWDAF executes such instruction. For example, NWDAF terminates the subscription if three consecutive accuracy reports are below a given threshold (e.g. \"no match\") by sending a termination request.\n12.\tBased on the computed accuracy, MLTF may decide to re-train the ML model.\n13.\tWhen the newly generated ML model is ready, the MTLF notifies the AnLF about the new ML model instance.\nFigure 6.34.2.2-1 illustrates the procedure for measuring and reporting accuracy of NWDAF analytics initiated by AnLF.\nThe figure depicts a procedure for measuring and reporting the accuracy of NWDAF analytics initiated by MTLF. It illustrates the steps involved in collecting data, analyzing the results, and reporting the results to the MTLF. The figure includes a flowchart and a list of steps, ensuring a clear and concise representation of the process.\nFigure 6.34.2.2-1: Procedure for measuring and reporting accuracy of NWDAF analytics initiated by MTLF\n1.\tThe NWDAF containing AnLF requests an ML model from the appropriate NWDAF containing MTLF.\n2.\tThe NWDAF containing MLTF provides the ML model to the AnLF as per current specifications.\n3.\tThe NWDAF containing MTLF requests ADRF to subscribe for the collection of the analytics and data that correspond to the analytics generated by the ML model provisioned in step 2. MTLF uses the procedures defined in clause 6.2B.3 of TS 23.288 [5].\n4.\tThe ADRF executes the operations defined in clause 6.2B.3 of TS 23.288 [5] to subscribe to the analytics and data as requested by MTLF. ADRF stores the notifications.\n5.\tThe NWDAF containing MLTF subscribes to ADRF to retrieve the analytics and data that correspond to the analytics generated by the ML model provisioned in step 2.\n6.\tThe NWDAF containing MLTF receives the analytics and data from the ADRF.\n7.\tBased on the collected analytics and data, the MLTF computes the accuracy using the predictions and the actual measured data observed at the time for which the prediction had been made.\n8.\tAn accuracy report is sent to the AnLF after the events have occurred that were needed for the verification of the predictions. The accuracy report is sent in an MLModelProvision notification from MTLF.\n9.\tBased on the computed accuracy, MLTF may decide to re-train the ML model.\n10.\tWhen the newly generated ML model is ready, the MTLF notifies the AnLF about the new ML model instance.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.34.3\tImpacts on services, entities and interfaces",
                            "text_content": "The solution has the following impacts:\nNWDAF containing MTLF:\n-\tgenerates accuracy reports to be sent to AnLF and analytics consumers, upon their request;\n-\tNWDAF registers its measured accuracy (per Analytics ID) in its NF profile in NRF/UDM.\n-\tNnwdaf_AnalyticsSubscription service:\n-\t_subscribe service operation includes an Accuracy Report Required flag and additional filter information related.\n-\t_notify service operation includes the Accuracy Report.\n-\tNnwdaf_MLModelProvision service:\n-\t_subscribe service operation includes the optional parameter MonitoringCorrelationID.\n-\t_notify service operation includes the Accuracy Report.\nADRF:\n-\tTags stored data using the MonitoringCorrelationID attribute.\n-\tNadrf_DataManagement_StorageSubscriptionRequest service includes the MonitoringCorrelationID optional parameter.\n-\tNadrf_DataManagement_RetrievalRequest service includes the MonitoringCorrelationID optional parameter.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.35\tSolution #35: Improve model training and provisioning exploiting sub-areas with similar statistical properties",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.35.1\tDescription",
                            "text_content": "This solution addresses aspects of key issue #1 on how to improve correctness of NWDAF analytics.\nKnowing the statistical properties of a data set used in AI/ML is important to understand the behaviour of an ML model. ML models trained on a specific training data set can be employed on data with similar statistics without experiencing performance degradation. Different network areas may exhibit similar context, (e.g. geographical circumstances, network deployment, etc.), which leads to similar data statistics (data statistics refer to data distribution, i.e. the information on values - or intervals - of the data such as network load, interference, how frequent some data values occur, etc.). So, an AI/ML model trained using data from one network area could be utilized in a different network area that exhibits similar data statistics.\nFurthermore, if multiple AI/ML models are employed in one area, even employed for different analytics and/or used by different analytics functions, information on changes in that area can be used by all analytics functions to, e.g. update their models given that change in the analytics context.\nThis solution is based on the ability to divide and characterize the network into sub-areas based on the environment statistical properties instead of a purely geographical sub-division. This statistical characterization of network sub-areas is then used to improve the quality of ML model training which should in turn improve the correctness of the corresponding NWDAF Analytics.\nThis solution proposes the introduction of the \"Area monitoring analytics service\", which provides AOI partitioning based on environment statistical properties and takes as parameters in the service request (see Table 6.35.1-1) the area of interest (AOI) to be analyzed, the area granularity attribute and other analytics parameters (e.g. reporting_threshold indicating the threshold for receiving the reporting, anomaly_description indicating the desired reporting content). Environment statistical properties aim at representing how an area is used, and can include density of UEs per area, UE behaviour in the area such as UE mobility model and UE communication model, etc.\nThe resulting AOI partitioning into sub-areas with associated sub-area types detected (i.e. dividing the AOI in multiple sub-area types and associating to each of them the respective network elements) along with the description of their statistical properties are stored in the Analytics Area Type Properties Function (AATPF), that allows the tracking of the discovered sub-area types and supports their management. The Sub-Area type ID is an identifier to be assigned to a sub-area and its properties description (area size specified by area granularity attribute or according to the data distribution) based on its data statistics.\nNOTE:\tThe AATPF can be a standalone function or co-located with NWDAF.\nThe Area monitoring service can be consumed by OAM. Furthermore, an NWDAF containing AnLF can be a consumer too, to know the sub-area types in order for it to re-use and select appropriate ML models.\nTable 6.35.1-1 lists the parameters to be included in the service request of Area monitoring analytics.\nTable 6.35.1-1: Parameters in the service request of Area monitoring analytics.\n\nTable 6.35.1-2 lists the input data and the associated source of Area monitoring analytics.\nTable 6.35.1-2: Input data and the associated source of Area monitoring analytics.\n\nTable 6.35.1-3 lists the output data of Area monitoring analytics.\nTable 6.35.1-3: Output data of Area monitoring analytics.\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.35.1-1: Parameters in the service request of Area monitoring analytics.",
                                    "table number": 35,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.35.1-2: Input data and the associated source of Area monitoring analytics.",
                                    "table number": 36,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.35.1-3: Output data of Area monitoring analytics.",
                                    "table number": 37,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.35.2\tProcedures",
                            "text_content": "In this procedure the NWDAF service consumer subscribes to the Analytics ID \"area monitoring\". The NWDAF analyzes the expected environment properties for a set of sub-areas within the AOI(s) provided in the analytics request/subscription.\nThe figure depicts a procedure for detecting and managing sub-areas using the Area Monitoring analytics service. It illustrates the steps involved in identifying and categorizing sub-areas, as well as the process of monitoring and managing these areas. The figure includes a flowchart and a list of steps, providing a clear and concise visual representation of the procedure.\nFigure 6.35.2.1-1: Procedure for detecting and managing sub-areas using the Area Monitoring analytics service\nPre-condition: The Analytics Area Type Properties Function (AATPF) stores the mapping of AOI in sub-areas along with their Sub-Area type IDs assigned and properties descriptions.\n1.\tNWDAF service consumer (NF or OAM) subscribes to analytics information. It sets, among others input parameters (as detailed in TS 23.288 [5], clause 6.1), the Analytics ID to the \"Area Monitoring\" analytics service ID, the (list of) AOI(s) and, optionally, the area granularity attribute. In addition, the service consumer may provide a reporting threshold indicating for which level of environmental properties changes a notification shall be returned and an anomaly description indicating if it is interested to receive the \"full\" description of the environment properties or the \"delta\" or \"none\".\n2-3.\tNWDAF subscribes to the AATPF to receive the AOI partitioning, Sub-Area type IDs and their properties description using the Naatpf_AreaTypeInfo_Subscription service and receiving as response the Naatpf_AreaTypeInfo_Notify service operation.\n4-5.\tNWDAF subscribes to the data sources required for the analytics services.\n6.\tIf \"area granularity\" is provided (see table 6.35.1-1), the classification of each sub-area of the AOI is performed by the NWDAF and their properties descriptions are generated. Otherwise, if \"area granularity\" is not provided, the NWDAF determines the sub-areas based on the data statistics. NWDAF classifies the sub-areas periodically and/or sporadically (e.g. based on internal/external triggers) based on new data collected.\n7-9.\t(conditional) Whenever new environment properties are discovered, NWDAF sends to the AATPF, using the Naatpf_RegisterAreaType_Register service, the AOI partitioning, and the sub-areas properties descriptions generated at step 6. The AATPF assigns new Sub-Area type IDs to the new environment properties discovered and stores the updated AOI partitioning along with the properties' description. In step 9, the AATPF informs the NWDAF that the operation has been concluded and provides the Sub-Area type IDs associated with the sub-areas detected. The AATPF may store the \"Expected environment properties\" for the monitored AOI(s) in some other entity, e.g. the ADRF. Such copy may, e.g. be used by another NWDAF instance also providing the \"Area Monitoring\" service for the same/overlapping AOI(s), to recover the information from the ADRF in case the NWDAF instance is (re-) started, and/or to allow the NWDAF to compare the current properties with an older version of the \"expected environment properties\".\n10.\tNWDAF periodically and/or based on internal/external triggers, keeps analysing the AOI. If a change in the environment properties is detected (e.g. the delta of the current environment properties is above a threshold compared to the earlier properties description), the following steps 11 to 19 are executed. The NWDAF may also utilize earlier versions of the \"expected environment properties\" available locally or in the ADRF to determine whether abnormal environment properties are observed, or, e.g. whether such environment properties have already been observed in the past (e.g. periodically every week).\n11.\tThe NWDAF notifies the consumer that an anomaly in a sub-area has been detected. The NWDAF sets the flag temporary to True to inform the service consumer that the sub-area could come back to expected environment properties.\n12.\tThe NWDAF monitors the sub-area(s) where the abnormal environment properties have been detected.\n13.\t(optional) If the anomaly is still present, the NWDAF periodically informs the analytics consumer. The notification may include an indication about the type of the change, e.g.:\n-\t\"trend\": indicates that with respect to previous properties the delta might be small (e.g. might be below the reporting threshold), but comparing with older data a trend can be observed (e.g. the area is getting more busy).\n-\t\"pattern\": indicates a repeating change of the environment properties (e.g. observed difference between working days, Saturdays and Sundays/holidays).\n-\t\"abnormal/exception\": change above reporting threshold that is not a \"trend\" or \"pattern\".\nThe notification may further include the time value since when this change has been observed, as well as additional information about the change, e.g. the expected duration, periodicity, estimated future increase for certain values, etc. Furthermore, the notification includes the impacted sub-areas, their Sub-Area Type IDs, and the anomaly description if requested.\n14.\tThe NWDAF utilizing the Naatpf_RegisterAreaType_Update service, sends to the AATRF the abnormal properties descriptions generated with the flag temporary set to True.\n15.\tThe AATPF acknowledges to the NWDAF that the request has been received.\n16.\t(conditional) If environment properties return back to the expected properties or timer T expires, the NWDAF sends an area type update to the AATPF setting the temporary flag to False.\n17.\t(conditional) If the AOI environment properties still differ from the expected ones, the AATPF updates the Sub-Area type IDs and their properties description.\n18.\tThe AATPF informs the NWDAF about the new Sub-Area Type ID assigned to the sub-area.\n19.\tThe NWDAF notifies the analytics service consumer about a permanent deviation from the previous \"expected environment properties\", i.e. the temporary flag is set to False. The notification may include an indication about the type of the change, see step 13. Alternatively, if the environment properties are back to the earlier state, the NWDAF notifies the service consumer about the end of the abnormal situation.\nThe figure depicts a procedure for usage of sub-areas to improve ML model provisioning. It illustrates the steps involved in selecting, configuring, and deploying sub-areas within a larger ML model provisioning process. The sub-areas are crucial for ensuring the accuracy and efficiency of the model, and the figure provides a visual representation of the process, making it easier to understand and follow.\nFigure 6.35.2.2-1: Procedure for usage of sub-areas to improve ML model provisioning\nPrecondition: NWDAFs update their profiles stored at the NRF to include the Area types managed. AATPF stores the mapping <AOI, Area type ID> and respective properties description. AATPF is the function deputed to assign Area type IDs to sub-areas based on their data properties description. It avoids the usage of multiple Area type IDs for sub-areas with similar data properties descriptions as well as the usage of the same Area type ID for different data properties descriptions. NWDAF (MTLF) registers for each AI/ML model the Area type for which it has been trained.\n1.\tNWDAF service consumers send a discovery request for NWDAF to NRF specifying the AOIs and the Analytics ID. If the NWDAF service consumer is aware about the Area type for which it is interested, it can specify the Area type in the discovery request.\n2.\tThe NRF returns the list of NWDAFs matching the parameters specified in the discovery request. Furthermore, the NRF also returns the Area types supported by each discovered NWDAF.\n3.\tNWDAF service consumers subscribe to selected NWDAF(s) serving the AOIs specifying the Area type if known. In case the Area type is not provided (e.g. not known), the analytics service is requested for all the Area types included in the AOI.\n4.\tNWDAFs request to the NWDAF (MTLF) a trained AI/ML model specifying among others the novel Area type attribute. In this way, AI/ML models trained for the same area type, but different geographical location, can be used to produce analytics in the specified AOI.\n5.\tNWDAF (MTLF) provides to different NWDAFs (managing different AOIs) the required trained AI/ML models. For NWDAFs requesting a model for the same Analytics ID in sub-areas assigned to the same Area type ID, NWDAF (MTLF) deploys the same AI/ML model trained for that Analytics ID for the specific Area type ID. This allows to use an existing AI/ML model from another AOI but trained for the same Area type ID even when there is no specific AI/ML model trained for that AOI. In the case that there is no availability of the AI/ML model trained for requested Area type ID, the NWDAF (MTLF) may perform the model training for missing Area type ID by collecting the data from multiple AOI with the same Area type or with similar data properties in order to have a richer training dataset.\n6.\tThe NWDAF(s) run the AI/ML models to produce the requested analytics.\n7.\tNWDAF(s) notify the NWDAF Service Consumer(s) with the analytics reports requested.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.35.3\tImpacts on services, entities and interfaces",
                            "text_content": "The solution has the following impacts:\n-\tIntroduction of the \"Area monitoring analytics service\" exposed by the Analytics Area Type Properties Function (AATPF.\nNWDAF:\n-\tSupport for additional parameters in the Nnwdaf_AnalyticsSubscription_Notify service operation.\nNRF:\n-\tSupport for additional parameters in the Nnrf_discovery service operations.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.36\tSolution #36: Enhanced provisioning of ML model based on information about how inference will be executed",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.36.1\tDescription",
                            "text_content": "This solution addresses aspects of key issue #1 on how to improve correctness of NWDAF analytics.\nWhen an NWDAF acting as service consumer invokes the Nnwdaf_MLModelProvision_Subscribe service of an NWDAF containing an MTLF, the MTLF may perform one of the following:\na)\tSelect an existing trained ML Model to be provisioned.\nb)\tTrigger further training of an existing trained ML model before it is provisioned.\nc)\tGenerate a new ML model to be trained and provisioned.\nIn cases b) and c), the NWDAF containing MTLF may initiate data collection from NFs, AF, DCCF, or OAM, required for the training of the ML model. Therefore, the decision of the MTLF among options a, b, and c can:\ni.\tlead to very different levels of computational load for the NWDAF containing MTLF.\nii.\tincrease the networking load on the NWDAF containing MTLF as well as on other Network Functions (NFs), while this increase might highly vary depending on how many data sources are used.\nThe decision of the MTLF among options a, b, and c is currently (i.e. according to Rel.17 specifications) taken by the MTLF based on local, unspecified logic. Based on the information currently provided in the Nnwdaf_MLModelProvision_Subscribe request, even if the \"required accuracy\" is provided as well, the MTLF may decide in favour of an option that leads to high computational and networking overhead without any real benefit (i.e. not really increasing the achieved accuracy during the inference phase at the NWDAF containing AnLF) compared to another option, which would put less load on the system.\nMore concretely, if an NWDAF service consumer subscribes to an NWDAF containing MTLF for an ML model for a specific type of analytics, the MTLF may decide that the best option is to perform further training of an existing model (i.e. option b) or create a new model because it is expected to lead to higher accuracy (i.e. option c). However, it can happen that the accuracy achieved when the ML model is later used by the NWDAF containing AnLF is not higher than the accuracy that would be achieved by an already trained (i.e. option a). Further, based on how the NWDAF containing AnLF is using the ML model, the same accuracy might be achieved by a more lightweight version of the ML model.\nAccording to clause 6.2.1 of TS 23.288 [5], an NWDAF containing AnLF, may:\n-\tuse only a subset of the parameters and/or data sources specified as allowed input parameter for the analytics ID.\n-\tuse only data from a reduced extend (e.g. duration, scope) of the data collection.\n-\trequest different sampling ratios and/or partitioning criteria to the data source.\nFor example, an NWDAF containing AnLF, might determine to only use UE mobility information collected from AMF, but not use UE location information provided by OAM. Then, the NWDAF containing AnLF could use a potentially more lightweight ML model that was trained only on AMF data, resulting in the same accuracy of the analytics as when using an ML model that was trained on data collected from both AMF and OAM.\nThis solution proposes to exchange and use information related to how inference will actually take place at the NWDAF analytics consumer once the ML model has been received. The solution also proposes enhancing and optimizing the ML model selection and provisioning (i.e. selection of trained model, trigger further training of an existing ML model, or generate a new model to be trained) performed by NWDAF containing MTLF.\nIn this solution, the ML model provisioning request includes inputs about the data used for inference, such as the actual data sources that will be used for inference, the granularity of input data that will be used for inference, and the target environment capacity requirements. Similarly, to assist the AnLF in selecting the appropriate ML model for inference, the ML model provisioning response includes information about the data (parameters and data sources) that have been actually used for the training of the ML model. The new parameters are described in table 6.36.1-1.\nTable 6.36.1-1: Description of new parameters proposed in this solution\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.36.1-1: Description of new parameters proposed in this solution",
                                    "table number": 38,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.36.2\tProcedures",
                            "text_content": "Figure 6.36.2-1 illustrates the procedure for enhancing the provisioning of an ML model based on information about how inference will be executed. The procedure includes the request of analytics data from an NF service consumer, which may be the trigger for the provisioning of an ML model from the NWDAF containing MTLF to the NWDAF that acts as an NF service consumer for ML model provisioning (i.e. NWDAF containing AnLF).\nThe figure depicts a procedure for enhancing the provisioning of machine learning models based on information about how inference will be executed. It illustrates the steps involved in the process, including data collection, model training, and model deployment. The figure is a visual representation of the process, making it easier to understand and follow.\nFigure 6.36.2-1: Procedure for enhanced provisioning of ML model based on information about how inference will be executed.\n1.\tThe NF consumer subscribes an Analytics ID to an NWDAF containing AnLF, using the Nnwdaf_AnalyticsSubscription_Subscribe service operation.\n2.\tThe NWDAF containing AnLF requests an NWDAF containing MTLF an ML model that can be used to support the Analytics ID requested in step 1, either because it has no ML model for this purpose or because the ML model(s) it has may not perform sufficiently well. Step 2 may be triggered by step 1, but it may also have been triggered by a different trigger before the execution of step 1. The request for the ML model is performed by sending an Nnwdaf_MLModelProvision_Subscribe request to the NWDAF containing MTLF with the addition of the parameters \"data used for inference\", the \"input data granularity\", the \"target environment capacity requirements\" and the \"requested accuracy\".\n3.\tThe NWDAF containing MTLF selects an existing trained ML model or creates a new ML model to be provisioned and determines the level of further training of the ML model, based on the \"data used for inference\", the \"input data granularity\", the \"target environment capacity requirements\" and the \"requested accuracy\" provided in step 2.\n4.\tThe NWDAF containing MTLF determines the training data and data sources required for (re-)training the ML model determined in step 3 and collects the data from the determined data source(s). The NWDAF (re-)trains the ML model using the collected data.\n5.\tThe NWDAF containing MTLF provides to the NWDAF containing AnLF the ML model using the Nnwdaf_MLModelProvision_Subscribe response, with the additional parameter \"data used for training\" indicating the data and data sources including the \"input data granularity\" used for the ML model training.\n6.\tThe NWDAF containing AnLF uses the information received in step 5 to determine the ML model to use in order to compute the analytics that were requested in step 1. Then it executes the inference, e.g. based on the received ML model.\n7.\tThe NWDAF containing AnLF sends to the NF consumer notifications with the computed analytics for the requested Analytics ID, adding information about which data and data sources have been used for inference. This information can be useful in order to determine the level of trust that the analytics consumer can have in the results received.\n8.\tThe NWDAF containing AnLF determines that a data source to fulfill the Analytics subscription received in Step 1 has changed.\n9.\tThe NWDAF containing AnLF determines that it no longer needs to receive notifications about availability of ML models associated to the previous input data sources.\n10.\t[Conditional to step 9.] The NWDAF containing AnLF uses the Nnwdaf_AnalyticsSubscription_Unsubscribe service operation to quit the subscription to ML models.\nIf a new ML model is required, the procedure restarts from step 2.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.36.3\tImpacts on services, entities, and interfaces",
                            "text_content": "The solution has the following impacts:\n-\tAdditional parameters (\"data used for inference\", \"input data granularity\", \"target environment capacity requirements\" and \"requested accuracy\") in the Nnwdaf_MLModelProvision_Subscribe and Nnwdaf_MLModelProvision_Notify service operations.\n-\tAdditional parameters (data and data sources used for inference) in the Nnwdaf_AnalyticsSubscription_Notify service operation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.37\tSolution #37: Analytics Exchange in Home routed roaming case",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.37.1\tDescription",
                            "text_content": "This solution is for the Key Issue#3: Data and analytics exchange in roaming case.\nSome principles for the data and analytics exchange in roaming case are proposed as follows:\n-\tNo raw data exchange is allowed between the H-PLMN and V-PLMN considering series of factors e.g. data privacy and security, signalling pressure on the SEPP.\n-\tAnalytics exchange may be allowed between the H-PLMN and V-PLMN:\n-\tWhat direction of the analytics exchange and between the H-PLMN and V-PLMN and which Analytics ID can be exchanged should be dependent on specific use cases. For example, this solution proposes that the V-NWDAF provides the service experience analytics to H-PCF to help determine the QoS parameters for an application; in Solution#11, the H-NWDAF can provide the slice Load level information to V-NWDAF to help V-AMF for network slice selection.\n-\tUser consent should be checked before the analytics exchange.\nNOTE 1:\tBefore conclusion for this solution, the cooperation with SA3 is needed on how the user consent is checked in roaming scenario and whether the V-PLMN is aware of user consent or not.\nEditor's note:\tIt Is FFS to which extent the VPLMN can provide meaningful analytics for a new inbound roamer without historical data about the roaming user and with only limited access to input data sources in the HPLMN. Depending on the results, allowing collection of raw data from VPLMN may be indispensable.\nEditor's note:\tIt Is FFS whether raw data aggregation can be an alternative to analytics to reduce signalling load.\nNOTE 2:\tBefore conclusion for this solution, the cooperation with SA3 is needed on whether data privacy and security issues exist or not when raw data or analytics is exchanged between the H-PLMN and V-PLMN, and how to solve potential issues.\nBecause this solution assumes that no raw data exchange is allowed, so the H-NWDAF and the V-NWDAF will respectively take the responsibility for data analytics in their own network and then further exchange the (sub-)analytics with each other.\nTo prevent the access of the raw data, this solution proposes that only the Nnwdaf_Analytics services are allowed between the H-NWDAF and the V-NWDAF.\nTake the use case i.e. \"PCF uses service experience as input to calculate and update the authorized QoS for an application\" as defined in clause 6.1.1.3 of TS 23.503 [4] as an example, this solution proposes that the H-PCF can adjust QoS parameters for the application in home routed roaming case based on the service experience analytics.\nIn details, for an Application ID, the V-NWDAF and the H-NWDAF firstly derive the service experience analytics in visited network and the service experience analytics in home network, respectively. Based on the H-PCF's service experience analytics subscription, the H-NWDAF further subscribes the service experience analytics in visited network for the application to V-NWDAF, then the H-NWDAF derives the (E2E) service experience analytics based on the service experience analytics in visited network and the service experience analytics in home network and provides it to H-PCF. Finally, H-PCF may use the E2E service experience as input to calculate and update the authorized QoS for the application in HR roaming case.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.37.2\tProcedures",
                            "text_content": "The figure depicts a step-by-step process for accessing the service experience analytics subscription from H-NWDAF to V-NWDAF, illustrating the various steps involved in the subscription process.\nFigure 6.37.2.1-1: Procedure for the service experience analytics subscription from H-NWDAF to V-NWDAF\n1.\tPCF firstly determines one or more UEs for an application are in home routed roaming case, then the PCF in home network subscribes service experience analytics of an application for these UEs to the H-NWDAF by triggering the Nnwdaf_AnalyticsSubscription_Subscribe service operation. The parameters included in the service operation are defined in clause 6.4.1 of TS 23.288 [5]. In addition, optionally, a HR roaming indicator and the V-PLMN ID should be also included in the service operation to help H-NWDAF know that the UEs are in HR roaming case. Alternatively, the H-NWDAF can also query the UDM to know that the UEs are in HR roaming case.\n2.\tH-NWDAF discovers the V-NWDAF by using the V-PLMN ID via NRF and then subscribes the service experience analytics in the visited network to the V-NWDAF by triggering the Nnwdaf_AnalyticsSubscription_Subscribe service operation. Before subscribing analytics to the V-NWDAF, the H-NWDAF may check VPLMN specific user consent information from the HPLMN UDM which indicates whether the user authorizes HPLMN to consume data collected or analytics generated in the specific VPLMN. If the VPLMN specific user consent information is not granted, then the H-NWDAF does not perform the step 2 to obtain data or analytics from VPLMN.\n3.\tV-NWDAF collects data in the visited network for the UE by using the procedures as defined in clause 6.2.2 of TS 23.288 [5].\n4.\tV-NWDAF derives the service experience analytics in the visited network based on the collected data in visited network.\n5.\tV-NWDAF provides the service experience analytics in the visited network to H-NWDAF by triggering the Nnwdaf_AnalyticsSubscription_Notify service operation.\n6.\tH-NWDAF collects data in the home network for the UE by using the procedures as defined in clause 6.2.2 of TS 23.288 [5]. In the home routed remaining case, the AF is located in the home network, so it is the H-NWDAF's responsibility to collect the service data from AF.\n7.\tH-NWDAF derives the service experience analytics in the home network based on the collected data in home network.\n8.\tH-NWDAF derives the E2E service experience analytics based on the service experience analytics in the visited network and the service experience analytics in the home network.\n9.\tH-NWDAF provides the service experience analytics for these UEs to the PCF in home network.\n10.\tThe PCF may adjust the QoS parameters for the application based on the E2E service experience analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.37.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "H-NWDAF:\n-\tSupports to accept the service experience analytics subscription request for UE in home routed roaming case from H-PCF.\n-\tSupports to subscribe service experience analytics in the visited network from V-NWDAF.\n-\tSupport to derive the E2E service experience analytics based on the service experience analytics in the visited network and the service experience analytics in the home network.\n-\tSupport to check VPLMN specific user consent information for data or analytics collection in VPLMN from the HPLMN UDM before subscribing analytics to the V-NWDAF.\nV-NWDAF:\n-\tSupports to accept the service experience analytics in the visited network subscription from H-NWDAF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.38\tSolution #38: Interactions between VPLMN and HPLMN for restricted data collection and analytics retrieval",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.38.1\tDescription",
                            "text_content": "Data or analytics exposed to a peer PLMN need to be restricted based on operator policies, regulatory requirements, roaming agreements, and user consent.\nIt is suggested that the NWDAF serves as central entry point for related requests and authorizes requests and restricts exposed data and analytical information. New services at the NWDAF allow to invoke those special authorization and restriction functionality.\nThe access to other services of the NWDAF, to DCCF services and to exposure services at other NFs from peer PLMNs can be restricted based on operator's policy by the NRF: The NRF will not providing related access tokens.\nThe NWDAF is well suited to handle analytics and data collection requests as it already performs comparable operations. The NWDAF also has existing capabilities for user consent checking. Using the NWDAF for data collection also enables usage of the DCCF.\nA UE from HPLMN roams in a VPLMN network. NWDAF of HPLMN collects data from VPLMN NFs. This enables the NWDAF to collect more complete statistics about a UE or group of UEs by taking into account also data collected while the UE or group of UEs is roaming in some VPLMN. Data may for instance relate to locality, mobility and communication of the UEs while roaming in the VPLMN. Collected data may also enable the HPLMN to provide statistics taking into consideration the behaviour of UEs subscribed at the HPLMN while roaming, which in turn enables a VPLMN to optimize the provided service for an inbound roaming UE.\nThe H-NWDAF from the HPLMN contacts the V-NWDAF of the VPLMN and asks it to retrieve data. The V-NWDAF checks if the HPLMN is authorized to request the data based on operator polices, interacts with different NFs in the VPLMN to retrieve the requested data, anonymizing the data if mandated by operator policies and/or user consent, and returns the requested information to the H-NWDAF. The V-NWDAF may also store the exposed data for subsequent audits and/or future use.\nBased on operator's policy/Oauth2.0 security, NFs from HPLMN are only allowed to access a specific NWDAF_DataRetrieval service at V-NWDAF (service level protection is available). Other services (e.g. NF exposure services, DCCF data collection service) are restricted and the NRF in the VPLMN rejects related inquiries from the HPLMN and may redirect to the Nnwdaf_DataRetrieval service.\nWhen UE1 enters a VPLMN network (i.e. it is roaming), the network does not have any historical data related to UE1 that it can use to create analytics (statistics and/or predictions). It can only start to collect data after the UE1 has entered the VLPMN, so the initial accuracy of the analytics reports would be rather low. However, HPLMN may have such data available for UE1 and can provide to the VPLMN NWDAF information related to UE1 that can help the VPLMN to optimize the service for the UE.\nThe HPLMN therefore creates an analytics profile of a UE subscribed at the HPLMN and may share it with VPLMNs restricting the contents considering regulatory requirements and operator policies. The access may be restricted to specific VPLMNs based on operator policy or user consent restricted specific VPLMNs, and parts of the UE analytics profile contents may only be accessible from specific VPLMNs, for instance to satisfy operator or regulatory policies or user consent restrictions.\nThe \"VPLMN specific user consent and operator policy for analytics exposure \" contains information on whether and which information about the UE in the HPLMN may be shared with a VPLMN, whereby different filter information may be provided per VPLMN.\nThe \"UE analytics profile\" is generated by the NWDAF of the HPLMN (H-NWDAF) and stored in the ADRF of the HPLMN (H-ADRF).\nThe NWDAF of the VPLMN (V-NWDAF) can retrieve the UE analytics profile from the H-NWDAF for an inbound roaming UE and use it for determining analytics related to that UE for consumers NFs in the VPLMN. It may store the profile in the ADRF of the VPLMN (V-ADRF).\nThe UE analytics profile may contain:\n-\tUE Mobility patterns.\n-\tUE Location patterns.\n-\tExpected UE behavioural parameters.\n-\tUE QoS / Congestion Experience patterns.\n-\tUE Data usage patterns (e.g. indicating where a UE disperses most of its data volume and session transactions).\n-\tData related to the UE that the V-NWDAF can use to generate its own analytics about the UE.\nBased on operator's policy/Oauth2.0 security, NFs from VPLMN are only allowed to access a specific NWDAF_DataRetrieval service at H-NWDAF (service level protection is available). Other services (e.g. NF exposure services, DCCF data collection service) are restricted and the NRF in the HPLMN rejects related inquiries from the VPLMN and may redirect to the Nnwdaf_DataRetrieval service.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.38.2\tProcedures",
                            "text_content": "The figure depicts a network setup where HPLMN (High-Performance Local Area Networks) collects data from VPLMN (Virtual Private LAN Service) using a HPLMN-VPLMN link. The figure illustrates the network architecture, highlighting the use of HPLMN and VPLMN technologies to facilitate data transmission and communication between different network segments.\nFigure 6.38.2.1-1: HPLMN collecting data from VPLMN\n1.\tH-NWDAF of HPLMN discovers V-NWDAF of VPLMN. Based on operator's policy/Oauth2.0 security, H NWDAF is allowed to access only a specific NWDAF_DataRetrieval service at V-NWDAF (service level protection is available). Other services (e.g. NF exposure services, DCCF data collection service) are restricted and the NRF in the VPLMN rejects related inquiries from the HPLMN and may redirect to the Nnwdaf_DataRetrieval service.\nH-NWDAF requests data collection via V-NWDAF data retrieval service. It indicates as reporting target one or several UE(s), a UE group or range, or all visiting UEs from the HPLMN, and the desired data types or events, and possibly target NF types from which to collect the data or at which to subscribe for the events.\n2.\tV-NWDAF checks if the HPLMN is authorised to request the data based on VPLMN operator polices (that may depend on the HPLMN and may indicate permissible or restricted NF types, data types, or events).\n3.\tV-NWDAF collects the data from different NFs/DCCF and aggregates the collected data.\n4.\tV-NWDAF anonymizes or restricts the data based on VPLMN operator polices (that may depend on the HPLMN).\n5.\tV-NWDAF sends the processed data to H-NWDAF.\n6.\tV-NWDAF may store the sent data for subsequent auditing or future use.\nTo achieve the above-defined behaviour, a new Data retrieval service is provided by the NWDAF that enables both one-time enquires (Nnwdaf_DataRetrieval_GET) based on the request/response model and event subscriptions (Nnwdaf_DataRetrieval_Subscribe) based on the Subscribe/Notify model.\nThe figure depicts a VPLMN (Virtual Private LAN) consuming an analytics profile generated by an HPLMN (Hybrid Public-Private Network). The VPLMN is a private network that is connected to the HPLMN, allowing for secure and private communication. The analytics profile generated by the HPLMN provides insights into the network usage, traffic patterns, and performance metrics. This information can be used to optimize network performance and improve overall network efficiency.\nFigure 6.38.2.2-1: VPLMN consuming analytics profile generated by HPLMN\n1.\tUDM stores the VPLMN specific user consent, operator or regulatory filters.\n2.\tH-NWDAF generates UE1 analytics or predictions and based on them creates or updates the \"UE analytics profile\" for UE1 and stores it in the H-ADRF. The H-NWDAF may send an update whenever it has new data or analytics that impacts the UE analytics profile.\n3-5.\tWhen UE1 attaches to the VPLMN, the V-NWDAF contacts H-NWDAF to retrieve the \"UE analytics profile\" for UE1. The V-NWDAF may retrieve the profile when the V-NWDAF determines to generate analytics for UE1 (e.g. because of a request from a VPLMN analytics consumer). The NWDAF in the VPLMN may also subscribe to notifications about updates of the UE analytics profile at the H-NWDAF. The NWDAF offers a special roaming analytics exposure service for this purpose. The H-NWDAF checks if the VPLMN is authorized to request the analytics profile based on HPLMN operator polices (that may depend on the VPLMN).\n6.\tH-NWDAF retrieves \"UE analytics profile\" of UE1 from H-ADRF.\n7.\tH-NWDAF retrieves VPLMN specific user consent, operator or regulatory filters from UDM and applies them to the retrieved \"UE analytics profile\" of UE1 to generate a \"VPLMN UE analytics profile\" with information on the UE1 that can be exposed to the VPLMN.\n8.\tH-NWDAF provides the \"VPLMN UE analytics profile\" of UE1 to the V-NWDAF.\n9.\tV-NWDAF uses the obtained \"VPLMN UE analytics profile\" of UE1 to extract information related to the UE1. V-NWDAF uses this information, as well as data obtained in the VPLMN related to the UE1, to generate analytics related to the UE1 and provide analytics reports to its consumers.\n10.\t(optional) V-NWDAF may store the \"VPLMN UE analytics profile\" of UE1 in the V-ADRF for future use, e.g. when UE is again served by the VPLMN. The \"VPLMN UE analytics profile\" stored in the V-ADRF may be an updated version of the profile obtained from H-ADRF, with updates based on the data the V-NWDAF VPLMN has collected related to the UE1, while UE1 is residing in the VPLMN.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.38.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "V-NWDAF:\n-\tOffer new data retrieval services that enable data retrieval by NFs from another PLMN:\n-\tNnwdaf_DataRetrieval_GET enabling one-time enquires based on the request/response model.\n-\tNnwdaf_DataRetrieval_Subscribe enabling based on the Subscribe/Notify model.\n-\tRetrieve analytics profile for UE from H-NWDAF and extract and provide analytics based on it.\nH-NWDAF:\n-\tOffer new analytics retrieval services that enable analytics profiule retrieval by NFs from another PLMN:\n-\tNnwdaf_AnalyticsRetrieval_GET enabling one-time enquires based on the request/response model.\n-\tNnwdaf_AnalyticsRetrieval_Subscribe enabling based on the Subscribe/Notify model,\n-\tGenerate an \"UE analytics profile\" for each UE subscribed at HPLMN and store it in ADRF.\n-\tProvide \"UE analytics profiles\" to the V-NWDAF after having filtered the UE analytics profile based on operator or regulatory policies and the \" VPLMN specific user consent\" restrictions for the UE.\n-\tRetrieve data about roaming UEs from V-NWDAF.\nNRF:\n-\tRestrict access to other event exposure services and analytics services from outside the own PLMN and redirect to NWDAF data retrieval service at analytics retrieval service\nADRF:\n-\tStore \"UE analytics profiles\" and provide them to the V-NWDAF after having filtered the UE analytics profile based on operator or regulatory policies and the \"VPLMN user consent\" restrictions for the UE.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.39\tSolution #39: Architecture enhancements to support Data and analytics exchange in roaming case",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.39.1\tDescription",
                            "text_content": "This is a solution for the Key Issue#3: Data and analytics exchange in roaming case, which focuses on possible architecture enhancements.\nNOTE:\tThe solution only addresses how home PLMN retrieve data analytics or data for roaming users in the VPLMN.\nThe proposed architecture enhancements solution is composed of the following two aspects:\n-\tNWDAF in Home PLMN collects data from Visited PLMN to derives analytics for roaming UE(s).\n-\tNWDAF consumer in Home PLMN obtains analytics from the NWDAF in Visited PLMN for roaming UE(s).\nThe consumer (NWDAF or NWDAF consumer) in HPLMN requests data or analytics from Visited PLMN via interworking DCCF in home PLMN and visited PLMN, respectively.\nThe figure depicts a simplified roaming architecture enhancement for data and analytics exchange in roaming, illustrating the local breakout scenario. It highlights the use of a local network (LON) to support data and analytics exchange, while also considering the need for roaming. The figure illustrates the use of a local network (LON) to support data and analytics exchange, while also considering the need for roaming.\nFigure 6.39.1.1-1: Roaming architectures enhancement to support Data and analytics exchange in roaming (local breakout scenario)\nThe figure depicts a simplified architecture for enhancing roaming architectures to support data and analytics exchange in roaming scenarios. It highlights the use of home-roaming networks, which are designed to provide high-speed connectivity to users' homes. The architecture includes a combination of wired and wireless technologies, with the home-roaming network acting as the primary data exchange point. The figure also includes a simplified representation of the roaming network, highlighting the use of home-roaming networks and the integration of data and analytics services.\nFigure 6.39.1.1-2: Roaming architectures enhancement to support Data and analytics exchange in roaming (home routed scenario)\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.39.2\tProcedure",
                            "text_content": "The figure depicts a procedure for NWDAF (Network Wide Data Aggregation) in HPLMN (Hybrid Packet-Level Network) to collect data from VPLMN (Virtual Packet Line Network). The NWDAF is a key component of the HPLMN architecture, enabling efficient data collection and management. The figure illustrates the steps involved in the NWDAF process, including the selection of VPLMNs, the establishment of data collection points, and the transmission of collected data to the central HPLMN.\nFigure 6.39.2.1-1: Procedure for NWDAF in HPLMN to collect data from VPLMN\n1.\tThe NWDAF service consumer subscribes to analytics information by invoking the Nnwdaf_AnalyticsSubscription_Subscribe service operation. The parameters that can be provided by the NWDAF service consumer are listed in clause 6.1.3 of TS 23.288 [5].\n2.\tIf the Target of Analytics Reporting is one UE, or a group of UE or any UE, that is roaming from the HPLMN to the visited PLMN, and the NWDAF in HPLMN needs the data related to the roaming UE(s) in the visited PLMN to derive the analytics for the analytics ID, then the NWDAF requests data collection to the DCCF in VPLMN by invoking Ndccf_DataManagement_Subscribe, including roaming indication, VPLMN ID, target area in VPLMN, event ID(s), Target of Event Reporting (UE ID, UE list, or any UE).\nEditor's note:\tHow to determine the VPLMN ID by HPLMN NWDAF is FFS.\n3.\t(Optional)According to data collection request from the HPLMN NWDAF, the DCCF in HPLMN discovers the DCCF in visited PLMN from NRF based on VPLMN ID.\n4.\tHPLMN DCCF requests data collection to the VPLMN DCCF by invoking Ndccf_DataManagement_Subscribe, including roaming indication, HPLMN ID, VPLMN ID, target area in VPLMN, event ID(s), Target of Event Reporting (UE ID, UE list, or any UE). Before subscribing data to the VPLMN DCCF, the HPLMN DCCF may check VPLMN specific user consent information from the HPLMN UDM which indicates whether the user authorizes HPLMN to consume its data collected or analytics generated in the specific VPLMN. If the VPLMN specific user consent information is not granted, then the HPLMN DCCF should not perform the step 4 to collect data from the VPLMN.\n5.\tVPLMN DCCF determines if the requested data is available at itself. If the data is available, then the VPLMN DCCF performs step 10 to sends the data to the HPLMN by invoking Ndccf_DataManagement_Notify. If not, then the VPLMN DCCF performs step 6.\nBefore the step 5, by enhancing the existing Ndccf_DataManagement service, the VPLMN DCCF checks if the consumer from HPLMN is authorized to obtain data from the VPLMN, taking the VPLMN ID, HPLMN ID, target area in VPLMN, Event ID(s) into account based on the roaming agreements, VPLMN policies and regulatory constraints between hPLMN and vPLMN, etc. If not, then VPLMN DCCF rejects HPLMN DCCF's data request by invoking Ndccf_DataManagement_Notify indicating no authority to obtain roaming data in VPLMN.\nNOTE:\tThe merits of enhancing the existing Ndccf_DataManagement service instead of defining a new service to trigger the special checking by the VPLMN DCCF needs to be discussed in the evaluation phase.\n6.\t(Optional) Based on the target AOI in the VPLMN and the requested event ID(s), the VPLMN DCCF discovers the target data provider(s) in the VPLMN via NRF.\n7.\tThe VPLMN DCCF subscribes to the data provider(s) the requested data by invoking, e.g. Nnf_EventExposure_Subscibe, indicating the Target of Event Reporting is a certain UE or a group of UE or any UE roaming from the HPLMN.\n8.\tThe data providers collect data for the roaming UE(s) from the HPLMN.\n9.\tThe data providers send the collected data to the VPLMN DCCF by invoking, e.g. Nnf_EventExposure_Notify.\n10.\tThe VPLMN DCCF send the collected data to the HPLMN DCCF by invoking Ndccf_DataManagement_Notify.\n11.\tThe HPLMN DCCF send the collected data to the HPLMN NWDAF by invoking Ndccf_DataManagement_Notify.\n12.\tBased on the collected data from the VPLMN for the roaming UE(s), the HPLMN NWDAF derives the requested analytics for the roaming UE(s).\n13.\tThe HPLMN NWDAF sends the generated analytics to the NWDAF consumer.\nThe figure depicts a procedure for a consumer in a HPLMN (Home Premises Local Network) to obtain analytics from a VPLMN (Virtual Private LAN Service) NWDAF (Network Wide Data Aggregation Service). The figure illustrates the steps involved in obtaining analytics from the NWDAF, including obtaining the necessary permissions, configuring the consumer device, and connecting to the NWDAF. The figure also includes a diagram of the network topology, showing the connections between the consumer device, the NWDAF, and the VPLMN.\nFigure 6.39.2.2-1: Procedure for NWDAF consumer in HPLMN to obtain analytics from VPLMN NWDAF\n1.\tIf the Target of Analytics Reporting is one UE, or a group of UE or any UE, that is roaming from the HPLMN to the visited PLMN, the HPLMN NWDAF service consumer subscribes to analytics information by invoking the Ndccf_DataManagement_Subscribe service operation to the HPLMN DCCF, including roaming indication, VPLMN ID, target area in VPLMN, analytics ID(s), Target of Analytics Reporting (UE ID, UE list, or any UE).\n2.\t(Optional)According to analytics request from the HPLMN NWDAF consumer, the DCCF in HPLMN discovers the DCCF in visited PLMN from the NRF based on the VPLMN ID.\n3.\tHPLMN DCCF requests the analytics to the VPLMN DCCF by invoking Ndccf_DataManagement_Subscribe including roaming indication, VPLMN ID, target area in VPLMN, analytics ID(s), Target of Analytics Reporting (UE ID, UE list, or any UE). Before subscribing analytics to the VPLMN DCCF, the HPLMN DCCF may check VPLMN specific user consent information from the HPLMN UDM which indicates whether the user authorizes HPLMN to consume its data collected or analytics generated in the specific VPLMN. If the VPLMN specific user consent information is not granted, then the HPLMN DCCF should not perform the step 3 to obtain analytics from the VPLMN.\n4.\tVPLMN DCCF determines if the requested analytics is available at itself. If the analytics is available, then the VPLMN DCCF performs step 9 to sends the analytics to the HPLMN by invoking Ndccf_DataManagement_Notify. If not, then the VPLMN DCCF performs step 5.\nBefore the step 4, by enhancing the existing Ndccf_DataManagement service, the VPLMN DCCF checks if the consumer from HPLMN is authorized to obtain analytics from the VPLMN, taking the VPLMN ID, HPLMN ID, target area in VPLMN, analytics ID(s) into account based on the roaming agreements, VPLMN policies and regulatory constraints between hPLMN and vPLMN and etc. If not, then VPLMN DCCF rejects HPLMN DCCF's data request by invoking Ndccf_DataManagement_Notify indicating no authority to obtain roaming data in VPLMN.\n5.\t(Optional) Based on the target AOI in the VPLMN and the requested analytics ID(s), the VPLMN DCCF discovers the target NWDAF in the VPLMN via NRF.\n6.\tThe VPLMN DCCF subscribes to the VPLMN NWDAF the requested analytics by invoking, Nnwdaf_AnalyticsSubscription_Subscribe, including roaming indication, VPLMN ID, target area in VPLMN, analytics ID(s), Target of Analytics Reporting (UE ID, UE list, or any UE).\n7.\tThe VPLMN NWDAF collects data and derives the requested analytics for the roaming UE(s) from the HPLMN.\n8.\tThe VPLMN NWDAF sends the analytics result to the VPLMN DCCF by invoking, e.g. Nnwdaf_AnalyticsSubscription_Notify.\n9.\tThe VPLMN DCCF send the analytics result to the HPLMN DCCF by invoking Ndccf_DataManagement_Notify.\n10.\tThe HPLMN DCCF send the analytics result to the HPLMN NWDAF consumer by invoking Ndccf_DataManagement_Notify.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.39.3\tImpacts on existing nodes and functionality",
                            "text_content": "Consumer in HPLMN (e.g. HPLMN NWDAF or HPLMN NF consumer):\n-\tFor UE(s) roaming from the HPLMN to the visited PLMN, subscribes data/analytics information to the HPLMN DCCF, indicating roaming indication, VPLMN ID, target area in VPLMN, analytics ID(s), Target of Analytics Reporting (UE ID, UE list, or any UE).\nH-DCCF:\n-\tDiscovers the DCCF in visited PLMN from NRF based on VPLMN ID.\n-\tRequests data collection to the VPLMN DCCF, indicating roaming indication, HPLMN ID, VPLMN ID, target area in VPLMN, event ID(s), Target of Event Reporting (UE ID, UE list, or any UE).\n-\tChecks VPLMN specific user consent information from the HPLMN UDM before subscribing data or analytics to the VPLMN DCCF.\nV-DCCF:\n-\tChecks if the consumer from HPLMN is authorized to obtain data/analytics from the VPLMN taking the VPLMN ID, HPLMN ID, target area in VPLMN, Event ID(s) into account.\n-\tCollects data/ analytics from data provider(s) for the roaming UE(s) from the HPLMN.\n-\tSends the collected data/analytics to the VPLMN DCCF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.40\tSolution #40: Data and analytics exchange for roaming UEs",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.40.1\tDescription",
                            "text_content": "In roaming scenario, the HPLMN/VPLMN may cooperate to collect data or to produce analytics for a particular UE. The level of detailed data to be collected from the other PLMN or analytics to be exposed by the other PLMN can be limited based on the user consent, operator policy, regulatory constraints and/or roaming agreements. For example, an NWDAF in the HPLMN may request input data for observed service experience of a UE to NFs or NWDAF in the VPLMN to produce more accurate analytics for a home-routed traffic.\nIn the solution, the NWDAF in HPLMN/VPLMN accesses the NWDAF in the other PLMN via NEF for data collection or analytics subscription and behaves as an untrusted AF for the other PLMN. It is assumed in the solution that the address of the NEF in the other PLMN is preconfigured at the NWDAF in HPLMN/VPLMN as part of roaming agreement or can be discovered through the NRF in HPLMN/VPLMN depending on the operator policy, regulatory constraints and/or roaming agreements.\nEditor's note:\tIt is FFS whether data or analytics collection from the HPLMN by the VPLMN needs to be supported.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.40.2\tProcedures",
                            "text_content": "The procedure for data collection from NFs and/or NWDAFs in VPLMN is depicted in Figure 6.40.2-1.\nThe figure depicts a procedure for data collection from a Virtual Private LAN/WAN (VPLMN) network, illustrating the steps involved in collecting network data.\nFigure 6.40.2-1: Procedure for data collection from VPLMN\n1.\tA Consumer NF in HPLMN request/subscribe analytics to the NWDAF in HPLMN. The message includes Target of Analytics Reporting that is set to specific UEs, a group of UE(s) or any UE. In case that a group of UE(s) or any UE is used as Target of Analytics Reporting, the message also includes an indication for roaming UE and the PLMN ID of VPLMN.\n2.\tThe NWDAF in HPLMN decides to collect data and/or analytics from the NF(s) and/or NWDAF(s) in VPLMN, based on the information received from the Consumer NF. The NWDAF in HPLMN verifies VPLMN specific user consent by referring to the UDR in HPLMN which indicates whether the user authorizes HPLMN to consume its data collected or analytics generated in the specific VPLMN. If the VPLMN specific user consent is granted that to obtain UE related data and/or analytics in VPLMN, then NWDAF in HPLMN performs step 4.\n3-4.\tThe NWDAF in HPLMN subscribes to NF(s) in VPLMN via NEF in VPLMN for data collection. The NEF in VPLMN verifies operator policy, regulatory constraints and/or roaming agreements for access from NWDAF in HPLMN by referring to the UDR in the VPLMN, and, if the NWDAF in HPLMN is authorized to request the data form VPLMN, it forwards the subscription request to the relevant NF(s). The NEF can refer to the NSSF or AMF if the subscription request from the NWDAF in HPLMN includes HPLMN S-NSSAI(s), and translate HPLMN S-NSSAI(s) to corresponding VPLMN S-NSSAI(s) before forwarding subscription request to the NF(s).\n5-6.\tThe NWDAF in HPLMN subscribes to NWDAF(s) in VPLMN via NEF in VPLMN for analytics. The NEF in VPLMN verifies, operator policy, regulatory constraints and/or roaming agreements for access from NWDAF in HPLMN by referring to the UDR in the VPLMN, and, if the NWDAF in HPLMN is authorized to request the analytics form VPLMN, it forwards the subscription request to the relevant NWDAF(s). The NEF can refer to the NSSF or AMF if the subscription request from the NWDAF in HPLMN includes HPLMN S-NSSAI(s), and translate HPLMN S-NSSAI(s) to corresponding VPLMN S-NSSAI(s) before forwarding subscription request to the NF(s).\n7.\tThe NWDAF in HPLMN receives input data from NF(s) in VPLMN via NEF.\n8.\tThe NWDAF in HPLMN receives analytics form the NWDAF(s) in VPLMN via NEF.\n9.\tThe NWDAF in HPLMN generates the analytics output requested by the consumer NF.\n10.\tThe NWDAF provides the analytics output to the consumer NF.\nThe procedure for analytics data collection from NWDAFs in HPLMN by an NWDAF in VPLMN is depicted in Figure 6.40.2-2.\nThe figure depicts a procedure for data collection from HPLMN, illustrating the steps involved in collecting data from a high-performance local network (HPLMN). The figure includes a flowchart with arrows indicating the sequence of actions, such as data collection, data processing, and data transmission. The use of color-coded arrows and labels helps to visually represent the flow of data and the steps involved in the process. The figure is a valuable tool for understanding the data collection process and ensuring that the data is collected accurately and efficiently.\nFigure 6.40.2-2: Procedure for data collection from HPLMN\n1.\tA Consumer NF in VPLMN request/subscribe analytics to the NWDAF in VPLMN. The message includes Target of Analytics Reporting that is set to specific UEs, a group of UE(s) or any UE. The message also includes an indication for roaming UE and the PLMN ID of HPLMN.\n2.\tThe NWDAF in VPLMN decides to collect analytics from the NWDAF(s) in HPLMN, based on the information received from the Consumer NF. The NWDAF in VPLMN can refer to the NSSF or AMF if the subscription request from the Consumer NF includes VPLMN S-NSSAI(s), and translate VPLMN S-NSSAI(s) to corresponding HPLMN S-NSSAI(s) before sending subscription request to the NEF in HPLMN.\n3-4.\tThe NWDAF in VPLMN subscribes to NWDAF(s) in HPLMN via NEF in HPLMN for analytics. The NEF in HPLMN verifies VPLMN specific user consent, operator policy, regulatory constraints and/or roaming agreements for access from NWDAF in VPLMN by referring to the UDR in the HPLMN, and, if the NWDAF in VPLMN is authorized to request the analytics form VPLMN, it forwards the subscription request to the relevant NWDAF(s).\n5.\tThe NWDAF in VPLMN receives analytics form the NWDAF(s) in HPLMN via NEF.\n6.\tThe NWDAF in VPLMN generates the analytics output requested by the consumer NF.\n7.\tThe NWDAF provides the analytics output to the consumer NF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.40.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "Consumer NF:\n-\tSupport to include indication for roaming UE and the PLMN ID.\nNWDAF:\n-\tSupport translation of S-NSSAI(s).\nNWF:\n-\tSupport translation of S-NSSAI(s).\n-\tSupport to check user consent, operator policy, regulatory constraints and/or roaming agreements.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.41\tSolution #41: Sending data that is about to be purged",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.41.1\tDescription",
                            "text_content": "This solution is solving the problem with a data producing NF or NWDAF having heavy load or performance (e.g. due to shortage of memory) to store data or that it will soon purge data for any other reason. An NF may have light load or performance (e.g. due to reserved certain amount of memory or low on memory) for data to be stored for each subscription of data that has been muted.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.41.2\tProcedures",
                            "text_content": "This solution re-use existing procedures.\nThe figure depicts a detailed procedure for the solution, illustrating the steps involved in the solution process.\nFigure 6.41.2-1: Procedures of the solution\n1.\tThe data producer (any NF storing data - subject to mute or similar) determines to soon purge data subscribed to by data consumer NF (NWDAF or DCCF).\n2.\tThe data producer does the following:\n-\tIn the case of a data producer NF being subscribed to with mute (Deactivate notification flag is set) it performs an Nnf_EventExposure_Notify service operation including the data collected and the cause code why sending the data.\nNOTE:\tIn the case of NWDAF, DCCF being subscribed for Data and formatting and pre-processing instructions is instructed it performs an Nnwdaf_DataManagement_Notify service operation including fetch instruction, according as described in TS 23.288 [5].\n3.\tThe data producer purges data.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.41.3\tImpacts on services, entities and interfaces",
                            "text_content": "Data producer:\n-\tAdding a cause (e.g. heavy NF load or performance) in the exposure explaining why data is sent even when Deactivate notification flag is set.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.42\tSolution #42: Storage and retrieval of trained ML models to/from ADRF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.42.1\tDescription",
                            "text_content": "This solution addresses KI#4: How to Enhance Data collection and Storage.\nIn addition to ADRF functionalities defined in Rel-17, the ADRF supports the following functionalities:\n-\tTrained ML model(s) file and ML model file serialization format stored by NF consumer i.e. NWDAF containing MTLF.\n-\tTrained ML model(s) file retrieval by NF consumer i.e. NWDAF containing AnLF.\nThe solution specifies how trained ML model(s) are stored by NWDAF containing MTLF and retrieved by NWDAF containing AnLF as described in clause 6.42.2.1 and clause 6.42.2.2 respectively.\nEditor's note:\tThe aspects of trained ML model(s) storage/retrieval to/from ADRF by NWDAF should be aligned with Key Issue #5.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.42.2\tProcedures",
                            "text_content": "The procedure in Figure 6.42.2.1-1 illustrate the mechanisms to store ML model(s) in the ADRF by the NF consumer i.e. NWDAF containing MTLF.\nThe figure depicts a procedure for storing trained machine learning (ML) models in an object-oriented data repository (ADRF) for efficient data management and retrieval. The figure illustrates the steps involved in creating, storing, and retrieving the models, emphasizing the importance of data organization and accessibility.\nFigure 6.42.2.1-1: Procedure for trained ML model(s) storage in ADRF\nEditor's note:\tHow ML model privacy is supported by ADRF to consumers belonging to different vendors is in scope of SA WG3.\nEditor's note:\tML model storage in ADRF triggered by NWDAF AnLF is for FFS.\nIf trained ML model(s) storage in ADRF is triggered by NWDAF containing AnLF then steps 1 and 2 are performed.\n1.\tThe NWDAF containing AnLF sends Nnwdaf_MLModelInfo_Request with the following input parameters Analytics ID(s), ML model file specific information (ML model file serialization format), Notification end point address (ADRF) to the NWDAF containing MTLF.\n2.\tThe NWDAF containing MTLF sends Nadrf_MLModelManagement_StorageRequest with input parameters Analytics ID(s), Trained ML model file(s), ML model file specific information (ML model file serialization format).\n3.\tThe ADRF may subscribe to ML model training update with the NWDAF containing MTLF. It sends Nnwdaf_MLModelProvision_Subscribe with input parameters Analytics ID(s), ML model file specific Information (ML model file serialization format).\n4.\tWhen the ML model for which the ADRF has subscribed for ML model training update has been updated, the NWDAF containing MTLF sends Nnwdaf_MLModelProvision_Notify with following parameters Analytics ID, Trained ML model file, Notification Correlation ID.\n5.\tThe NWDAF containing MTLF sends Nnwdaf_MLModelInfo_Response with the following parameters Analytics ID(s), Trained ML model file address, ADRF storage status which indicates if the ML model storage requested in step 1 was successful or failed.\nIf trained ML model(s) storage in ADRF is initiated by ADRF then steps 6 and 7are performed. The trigger to initiate storage of trained ML model(s) from NWDAF MTLF is followed by steps 6 and 7.\n6.\tThe ADRF sends Nnwdaf_MLModelProvision_Subscribe with the following input parameters ML model file specific information (ML model file serialization format).\n7.\tThe NWDAF containing MTLF sends Nnwdaf_MLModelProvision_Notify with the following input parameters Analytics ID, Trained ML model file, Notification Correlation ID.\nThe procedure in Figure 6.42.2.2-1 illustrate the mechanisms to retrieve ML model(s) from the ADRF by the NF consumer i.e. NWDAF containing AnLF.\nThe figure depicts a procedure for retrieving trained machine learning (ML) models from an Artificial Neural Network (ADRF) database. The figure shows a step-by-step process for selecting the appropriate model from the ADRF, including the selection of the appropriate algorithm, the selection of the appropriate dataset, and the selection of the appropriate model architecture. The figure also includes a visual representation of the ADRF database, which is a database of machine learning models that have been trained and are available for use. The figure is important for understanding the process of selecting the appropriate model from the ADRF database and for ensuring that the models are used effectively in the context of the given telecommunication figure.\nFigure 6.42.2.2-1: Procedure for trained ML model(s) retrieval from ADRF\n1.\tNWDAF containing AnLF sends Nadrf_MLModelManagement_RetrievalRequest which includes Analytics ID(s), ML Model Filter Info (ML model file specific information), optionally Target NF (NWDAF containing MTLF) to subscribe for notifications. The ML model file specific information includes the ML model file serialization format requested by the NWDAF containing AnLF.\n2.\tThe ADRF determines if the ML model file for the Analytics ID(s) requested is already stored. If the ML model file for the Analytics ID(s) requested in not stored in ADRF then step 3, 4, 5, 6 are performed, before these steps, the ADRF discovers the target MTLF from the NRF optionally if it isn't informed by the AnLF in the step 1. If the ML model file for the Analytics ID(s) requested in stored in ADRF the steps 3, 4, 5, 6 are skipped.\n3.\tADRF sends Nnwdaf_MLModelProvision_Request with the input parameters defined in TS 23.288 [5] and additional input parameters ML model file specific information (ML model file serialization format).\n4.\tThe NWDAF containing MTLF sends a Nnwdaf_MLModelProvision_Response with following parameters Analytics ID(s), Trained ML model file(s).\n5.\tADRF sends Nnwdaf_MLModelTrainingUpdate_Subscribe with the input parameters Analytics ID(s), ML model file specific information (ML model file serialization format).\n6.\tWhen the ML model for which the ADRF has subscribed for ML model training update has been updated, the NWDAF containing MTLF sends Nnwdaf_MLModelTrainingUpdate_Notify with the following parameters Analytics ID, Trained ML model(s) file, Notification Correlation ID.\n7.\tThe ADRF sends a response back to NWDAF containing AnLF using Nadrf_MLModelManagement_Retrieval Response with the following parameters ML Model File Information (Trained ML model(s) file, ML model file serialization format, Trained ML Model ID per Analytics ID).\n8.\tThe NWDAF containing AnLF subscribes to ADRF using Nadrf_MLModelManagement_RetrievalTrainingUpdate_Subscribe service operation containing input parameters Trained ML Model ID per Analytics ID.\n9.\tThe ADRF sends a notification to NWDAF containing AnLF using Nadrf_MLModelManagement_RetrievalTrainingUpdate_Notify service operation containing following parameters ML Model File Information (Trained ML model(s) file, ML model file serialization format, Trained ML Model ID per Analytics ID).\n10.\tNWDAF containing AnLF determines that the ML model training update is no longer required.\n11.\tThe NWDAF containing AnLF sends Nadrf_MLModelManagement_RetrievalTrainingUpdate_Unsubscribe with Subscription Correlation ID as input parameters.\n12.\tADRF determines if any of the NF consumer(s) have subscription for ML Model training update per Analytics ID. If none of the NF consumer(s) have subscription for ML model training update per Analytics ID, the ADRF removes the ML model file and ML model file specific information and proceed to step 9.\n13.\tADRF sends Nnwdaf_MLModelTrainingUpdate_Unsubscribe to ADRF with the Subscription Correlation ID as input parameter.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.43\tSolution #43: ML model storage in ADRF and ML model provision from ADRF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.43.1\tDescription",
                            "text_content": "This solution addresses Key Issue #4 \"How to Enhance Data collection and Storage\" and Key Issue #5 \"Enhance trained ML Model sharing\".\nAn NWDAF containing MTLF may be consumed by multiple ML model consumers at the same time, resulting in repeated consumption signalling and data traffic of ML models with the same Analytics ID.\nThus, the NWDAF containing MTLF can store trained ML models into ADRF directly. Or, When the DCCF/MFAF is deployed in the network, the NWDAF containing MTLF can store trained ML models into ADRF via DCCF/MFAF.\nMeanwhile, the NWDAF containing MTLF can register the trained ML model of the Analytics ID it supports into NRF or DCCF, the registered ML profile may include the ID of NWDAF containing MTLF, Analytics ID(s), ML model information.\nThe ML model consumers (e.g. NWDAF containing AnLF) can subscribe/request the needed ML model from ADRF directly or via DCCF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.43.2\tProcedures",
                            "text_content": "The figure depicts the storage and provision of machine learning models in an Autonomic Data Repository and Fabric (ADRF) system. It illustrates the process of ML model storage in ADRF and ML model provision from ADRF. The figure shows the storage of models in ADRF, which is a key component of the ADRF system, and the provision of these models from ADRF. This process is crucial for maintaining the reliability and efficiency of the ADRF system.\nFigure 6.43.2-1: Procedure of ML model storage in ADRF and ML model provision from ADRF\n1.\tAn NWDAF containing MTLF instance has the trained ML Model(s).\n2.\tThe NWDAF containing MTLF requests to store the ML Model to the ADRF by invoking the Nadrf_MLModelManagement_StorageRequest (containing the trained ML model(s) and/or ML model(s) information) service operation or the NWDAF containing MTLF stores the trained ML Model to the ADRF via DCCF.\n3.\tThe ADRF stores the trained ML model(s) and/or the ML model(s) information sent by the NWDAF containing MTLF. The ADRF may be based on implementation, determines whether the same trained ML Model is already stored by the NWDAF containing MTLF. If the trained ML Model is already stored, the ADRF decides to store again to update the trained ML Model sent by the NWDAF containing MTLF.\n4.\tThe ADRF sends Nadrf_MLModelManagement_StorageRequest Response message to the NWDAF containing MTLF indicating that the trained ML Model is stored, including when the ADRF may have determined at step 3 that the trained ML Model is already stored.\n5.\tThe NWDAF containing MTLF and/or the ADRF requests to register ML Model profile to DCCF by invoking the Ndccf_MLModelManagement_Register. Or the NWDAF containing MTLF and/or the ADRF registers its ML Model profile to the NRF by invoking the Nnrf_NFManagement_NFRegister.\nThe ML Model profile may include one of the following parameters: NWDAF ID, ADRF ID, Analytics ID(s), model framework, model platform,model type, model algorithm, model compilation language, model Spatial validity, model validity period, model accuracy, model space effectiveness, etc.\n6.\tThe DCCF responds to the NWDAF containing MTLF and/or the ADRF with a Ndccf_MLModelManagement_Register Response. Or The NRF responds to the NWDAF containing MTLF and/or the ADRF with a Nnrf_NFManagement_NFRegister Response.\n7.\tThe ML model consumer (i.e. an NWDAF containing AnLF) subscribes or requests a (set of) trained ML Model(s) associated with a (set of) Analytics ID(s) to DCCF or ADRF.\nNOTE:\tThe procedure of NWDAF discovery and selection for trained ML models via NRF is defined in TS 23.288 [5].\n8.\tThe ADRF or DCCF notifies the ML model consumer with the trained ML Model Information (containing a (set of) file address of the trained ML model).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.43.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF containing MTLF:\n-\tSupports sending the trained ML model to ADRF.\n-\tSupports registering the ML Model profile to DCCF.\nADRF:\n-\tSupports Nadrf_MLModelManagement service to store the ML models.\n-\tSupports Nadrf_MLModelProvision or Nadrf_MLModelInfo_Request service to send the ML models.\nDCCF:\n-\tSupports Ndccf_MLModelManagement service to register the ML models.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.44\tSolution #44: DCCF Reselection when multiple instances of DCCF exist in a network",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.44.1\tDescription",
                            "text_content": "The proposed solution is based on the following principles:\n-\tMultiple instances of DCCF are operating in one PLMN where each instance can be configured to collect data from any combination of Serving Area Information, or NF types/set ID of data sources.\n-\tThe network is configured in a way that service consumers will interact with data sources through DCCF.\n-\tReselection is initiated by service consumers to unsubscribe from source DCCF and subscribe to target DCCF.\n-\tA data source NF is bounded to a specific DCCF instance or set as defined in Rel-17.\n-\tSource DCCF notifies the service consumer if it cannot serve a UE anymore.\n-\tService consumer unsubscribes from the data collection to source DCCF. The service consumer is capable of receiving such notification and includes an indication that such capability is supported in the service request to DCCF.\nEach instance of DCCF can be identified using a discovery mechanism through NRF which is specified in TS 23.501 [2]. Moreover, a service consumer NF e.g. another DCCF, can use information about the Serving Area to query a DCCF.\nWhen a service consumer NF receives notification from the source DCCF about not being able to serve the UE, it unsubscribes from the source DCCF. Then the source DCCF will unsubscribe from data sources and ensure all collected data is sent to the service consumer NF.\nNOTE 1:\tAll serving areas are logical areas within one PLMN. Each serving area will have its own instance of DCCF and optionally other NFs e.g. data providers, etc.\nNOTE 2:\tAt UE mobility, DCCF takes no action for subscriptions on group of UEs or Any UEs.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.44.2\tProcedures",
                            "text_content": "The procedure in Figure 6.44.2-1 is used when a service consumer NF determines to use a DCCF, known as target DCCF. The procedure is triggered e.g. when a UE location no longer lies within the serving area of the source DCCF, so that the source DCCF will notify the service consumer that it cannot serve the UE anymore, and includes all pending data to be notified. Other internal triggers that may result in DCCF reselection are handled within NF sets as specified in TS 23.501 [2] and TS 23.502 [3].\nThe figure depicts a DCCF reselection initiated by a target DCCF selected by a service consumer, illustrating the process of selecting a DCCF for reselection in a dynamic network environment.\nFigure 6.44.2-1: DCCF reselection initiated by target DCCF selected by service consumer\n0.\tA consumer NF sends a subscription request to the DCCF using Ndccf_DataManagement_Subscribe request, including the \"No relocation\" indicator set to \"True\". The indicator enables the DCCF to notify the service consumer that it can no longer serve the UE.\n1.\tSource DCCF notifies the service consumer that, e.g. location of UE falls outside the serving area of the DCCF, so it cannot serve the UE anymore. A cause code is also added with the notification (e.g. UE moved outside DCCF serving area, if data source is added in subscription - UE moved outside data source serving area).\n2.\tService consumer for the source DCCF determines to select a new instance of DCCF and discovers and selects the target DCCF.\n3.\tThe service consumer sends a subscription request to the target DCCF using Ndccf_DataManagement_Subscribe request.\n4.\t[OPTIONAL] The service consumer unsubscribes from the source DCCF since it will be served by the target DCCF from now on.\n5.\t[OPTIONAL] Target DCCF may subscribe to relevant data source(s), if not yet subscribed.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.44.3\tImpacts on Services, Entities, and Interfaces",
                            "text_content": "DCCF:\n-\tNotify service consumer that it cannot serve the UE, including a cause code. If there is any pending data, it is also delivered to the service consumer NF.\nService consumer NF:\n-\tIndicates support to receiving notifications when DCCF cannot serve the UE anymore.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.45\tSolution #45: Managing Impact of Muting on NF Producer",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.45.1\tDescription",
                            "text_content": "Clause 6.2.7 of TS 23.288 [5] specifies a muting mechanism whereby a data source (e.g. AMF, SMF) stores events until the event consumer requests the data using an \"activate notification\" flag. Variability in the number of event notifications generated per subscription, the number of subscriptions requesting muting and the duration of muting among other factors can use up the limited capacity of data sources to buffer notifications. The only control currently provided to manage storage space for buffered event notifications is that the number of stored events may be limited based on NF configuration. When this number is reached, the NF continues to store new events and deletes the oldest events (see clause 6.2.7.2 of TS 23.288 [5]), which means the old events are lost from the perspective of the Event Consumer NF. This solution proposes enhancements to manage the storing of notifications by data sources and provides additional recourse to a data source that is approaching its capacity limit.\nIn this solution, when an Event Consumer NF (e.g. NWDAF, DCCF) requests notification muting from an Event Producer NF as described in clause 6.2.7.2 of TS 23.288 [5], the Event Consumer can in addition specify an instruction that indicates to the Event Producer NF the desired behaviour when an exception occurs at the Event Producer NF (e.g. full buffer). The instruction contains information about:\n-\tAction on buffered notifications (e.g. 'Send All', 'Discard All', 'Drop Old').\n-\tAction on subscription (e.g. 'close', 'continue with muting', 'continue without muting').\nAccording to clause 6.2.7.2 of TS 23.288 [5], the only option now available is \"drop old\" and \"continue with muting\", in which case the dropped notifications are lost to the Event Consumer NF.\nThe Event Producer NF evaluates the request from the Event Consumer NF and responds to the Event Consumer NF. For example, depending on what the Event Producer NF supports, the Event Producer NF may accept or reject (with reason code) the request.\nThe response from the Event Producer NF may also indicate:\n-\tThe maximum number of notifications that the Event Producer NF will store.\n-\tAn estimate of the duration for which notifications can be buffered (e.g. it can provide buffering for up to 2 days).\nThe above may be based on local policy configuration at the Event Producer NF, and/or an evaluation by the Event Producer NF of its available storage resources. It can be performed on a per subscription basis or for a group of subscriptions (all or subset of subscriptions created by an Event Consumer NF at the Event Producer NF).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.45.2\tProcedures",
                            "text_content": "The figure depicts a modified version of the procedure for muting event notification, with the addition of a new step to ensure the notification is not sent to the user.\nFigure 6.45.2-1: Modifications to Procedure for muting event notification\nFigure 6.45.2-1 summarizes the changes to the procedure for muting event notification specified in TS 23.288 [5] clause 6.2.7.2-1.\n0.\tLocal policies may be configured specifying default actions and handling of requests from Event Consumers for buffered notifications.\n1.\tThe Event Consumer NF sends a EventExposure_Subscription_Request to the Event Producer NF, including the deactivation notification flag and optionally an exception instruction request.\n2.\tThe Event Producer NF may apply local polices to the requested exception instructions and may evaluates the resources available for buffering of notifications.\n3.\tThe Event Producer NF sends a subscription response to the Event Consumer NF indicating the result of the Exception Request. The Event Producer NF accepts the instructions, or rejects the instructions indicating a reason (e.g. request for \"continue with muting\" is not allowed). The Event Producer NF may also provide the Event Consumer NF with an estimate of the number of notifications it can buffer and the duration for which notifications can be buffered.\n4.\tAn exception occurs (e.g. Producer NF no longer has sufficient storage space available for buffering of Notifications, or otherwise determines it is approaching a resource limitation).\n5.\tEvent Producer NF executes exception instructions and notifies the Event Consumer NF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.45.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tEvent Consumer NFs (DCCF, NWDAF):\n-\tSupport sending exception instructions.\n-\tEvent Producer NFs (AMF, SMF, etc.):\n-\tSupport local configuration of policy for buffered notification exception handing.\n-\tSupport reception and processing of exception instructions.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.46\tSolution #46: ADRF / NWDAF Data Storage Management",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.46.1\tDescription",
                            "text_content": "Clause 6.2.6 of TS 23.288 [5] specifies that data may be stored in an ADRF/NWDAF based on a request to the DCCF or NWDAF from an NWDAF or DCCF service consumer. The request may specify \"ADRF Information\" indicating whether the data are to be stored in an ADRF, and optionally an ADRF ID. Alternatively, data may be stored in the ADRF/NWDAF based on local configuration on the DCCF or NWDAF. Once data or analytics is stored in the ADRF/NWDAF, it remains there permanently unless some action is taken to remove it when the data or analytics is no longer needed. Over time, this may result in the ADRF/NWDAF becoming a wasteland containing a huge volume of data or analytics that serves no purpose and is no longer needed.\nThis solution enhances storage management through policies that consider both operator's/local configuration and instructions from consumers that request data storage.\nIn this solution, consumer requests for data or analytics are enhanced so they may optionally include storage handling information that indicate how the consumer would like stored data or analytics to be maintained in the ADRF/NWDAF. The storage handling information provided by a consumer is used according to a Storage Policy provisioned (e.g. by an operator) on the DCCF, NWDAF or ADRF. Specifically:\n-\tA Storage Policy is provisioned on the DCCF, NWDAF or ADRF. The policy specifies operator rules for storing data. This may include whether Storage Handling Information from a consumer is allowed, default rules that apply in the absence of a consumer request containing Storage Handling Information or when the requested Storage Handling is disallowed, and allowed values or range for Storage Handing Information. For example, the Storage Policy may specify that the default duration for storing data gathered from AMFs is 4 months, Storage Handling Information requests from consumers is allowed and the allowed values for Storage Handing Information sent by a consumer is 1 month to 12 months.\n-\tStorage Handling Information is sent by data or analytics consumers. It specifies storage instructions for data or analytics requested by a Consumer. This information is added to existing service operations used by consumers to request data and storage (Ndccf_DataManagement_Subscribe and Nnwdaf_DataManagement_Subscribe).\nThe Storage Policy and Storage Handling Information may indicate:\n1.\tHow long data/analytics are to be stored,\n2.\tWhat subset of data/analytics are to be stored.\n3.\tA priority indication of the data so that more important data can be retained and less important data can be removed when necessary.\n4.\tSpecification for sending (or not sending) an alert to the consumer when data removal is imminent.\nA consumer request containing Storage Handing Information is evaluated in the context of Storage Policy rules that apply for the requested data/analytics. Different Storage Policy rules may apply for different data/analytics (e.g. AMF data may be stored for a longer or shorter duration than SMF data).\nOne or both of a Storage Policy and Storage Handling Information may be available for particular data/analytics, for a set of data/analytics or for all data/analytics to be stored. Storage Policy rules and Storage Handling Information are considered in determining the Storage Approach to be applied for requested data. The Storage Approach consists in enforcing the storage based on the Storage Policy and/or the Storage Handling Information. A precedence may be specified as part of the Storage Policy to determine whether a Storage Policy rule supersedes a Storage Handling Request.\n-\tIf only a Storage Policy is specified (e.g. provisioned by the operator), then a Storage Policy rule applicable to the data to be stored is applied as the Storage Approach (e.g. store all AMF data for 4 months).\n-\tIf only Storage Handling Information is specified (by a consumer), then the request is either accepted or rejected as the Storage Approach according to configuration (e.g. by the operator) for honouring consumer requests in the absence of a policy (e.g. consumer asks to store requested AMF data for 7 months, and request is accepted or rejected).\n-\tIf both a Storage Policy and a Storage Handling Information is specified, then the request for Storage Handling is allowed within the scope of Storage Policy rules and precedence configured by the operator. For example, if a Storage Policy rule is to store all AMF data for a maximum of 4 months but a consumer that sent a Storage Handling Request asks that the data be stored for 7 months, then data storage for 4 months or for 7 months is authorized and applied as the Storage Approach according to operator configuration of Storage Policy vs Storage Handling Request precedence.\nIn response to a consumer request containing Storage Handling Information, the ADRF/NWDAF/DCCF provides the result of the request indicating the Storage Approach.\nTo execute a Storage Approach:\n-\tWhen a DCCF is used, the DCCF may keep track of the Storage Approach and the DCCF executes tasks to update the NWDAF or ADRF storage accordingly. For example, after the 4 months storing AMF data has elapsed, the DCCF sends an Nadrf_DataManagement_Delete to remove the data that is no longer needed.\n-\tWhen a DCCF is not used, the ADRF or NWDAF keeps track of the Storage Approach and executes tasks to update the NWDAF/ADRF storage.\n-\tWhen data is to be removed from the ADRF or NWDAF, the DCCF, ADRF or NWDAF may send a notification to the Consumer that the data is about to be deleted. The consumer may acknowledge the notification or send a further request to extend the data storage period.\nIn addition, the NWDAF/ADRF/DCCF may provide the consumer with a \"Storage Transaction Identifier so that the data can be easily fetched by the consumer. For example, if a consumer has asked to store AMF notifications for 5 months, the DCCF, ADRF or NWDAF may provide a Storage Transaction Identifier that can be used by the consumer to retrieve the stored data. This saves the effort at the DCCF, ADRF or NWDAF to filter out data when a request is received per URI.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.46.2\tProcedures",
                            "text_content": "The procedure from TS 23.288 [5] clause 6.2B.3 which is used by consumers (NWDAF, DCCF) to store received notifications in the ADRF is replicated below. Changes to support storage management provided by this solution are indicted in the figure in red and are described in the steps below. Note the step numbering from the current procedure has been maintained but may be updated in the normative phase.\nThe figure depicts a historical data and analytics storage system, with storage management notifications, illustrating the system's architecture and functionality.\nFigure 6.46.2-1: Historical Data and Analytics Storage (with storage management) via Notifications\n0a-c.\tThe operator configures Storage Policy on the DCCF, NWDAF or ADRF according to operator preference.\n1a-b.\tThe Data or Analytics Consumer may provide Storage Handling Information in its request for Data/Analytics to the NWDAF or DCCF.\n2a-b.\tIf Storage Policy is not configured on the NWDAF or DCCF, the NWDAF or DCCF sends the Storage Handling Request to the ADRF in the Nadrf_DataManagement_StorageSubscription request.\n3a-c.\tThe NWDAF, DCCF or ADRF determines the Storage Approach based on the received Storage Handing Information and the Storage Policy.\n7a-c.\tThe NWDAF, DCCF or the ADRF determines that stored data/analytics can be removed from the ADRF. The determination may be made according to a Storage Approach from step 3.\n7a-1-7c-1.\tAs determined by the Storage Approach, the DCCF, ADRF or NWDAF may send a notification to the Consumer that stored data/analytics are about to be deleted. The consumer may acknowledge the notification, or send a further request to extend the data/analytics storage period.\n10a-10b.\tThe DCCF or NWDAF may send an Nadrf_DataManagement_Delete request to remove the stored data/analytics.\n11.\tADRF deletes the stored data/analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.46.3\tImpacts on services, entities and interfaces",
                            "text_content": "NWDAF:\n-\tInclude Storage Handling Information in service operations that request data.\n-\tSupport Storage Policy and execution of Storage Approach.\n-\tSupport notification to consumer of impending data/analytics deletion and response from consumer.\nDCCF/MFAF:\n-\tInclude Storage Handling Information in service operations that request data.\n-\tSupport Storage Policy and execution of Storage Approach.\n-\tSupport notification to consumer of impending data/analytics deletion and response from consumer.\nADRF:\n-\tSupport Storage Policy and execution of Storage Approach.\n-\tSupport notification to consumer of impending data/analytics deletion and response from consumer.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.47\tSolution #47: Sharing models between NWDAFs",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.47.1\tDescription",
                            "text_content": "A pre-condition to share models between NWDAFs is that business aspects are in place and interoperability tests are done. When these are done, an Interoperable Token is known by both NWDAF containing MTLF and NWDAF containing AnLF. The NWDAF containing MTLF can register into NRF the Interoperable Token. This Interoperable Token is then used when another NWDAF as ML model consumer discovers an appropriate NWDAF containing MTLF to subscribe ML Models from. The Interoperability token implicitly maps to an interoperable model information, e.g. file format, platform, etc. The encoding or format of the Interoperability token is up to vendors' implementation.\nModels are software running in the NWDAF's model execution environment. A commonly used such environment is a container-based environment. This solution builds on such environment but can easily be extended to include any environment running inside an NWDAF.\nNOTE:\tThe definition of an ML model may differ between different NWDAFs. The Interoperable Token indicates whether an NWDAF can use the model exposed by another NWDAF.\nThe MLModelProvision service operation is updated to be able to handle different formats, according to model serving environments in the NWDAF containing AnLF. This is done by adding the possibility for the NWDAF containing AnLF to share what environment it is running and what services it is using for communicating externally to other NFs (such as data collection), and what output format it expects.\nThe model file, which is referred to in the URL the NWDAF containing MTLF includes in the response to the MLModelProvision service subscription, includes the model software and optionally a manifest.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.47.2\tProcedures",
                            "text_content": "This solution re-use existing procedures.\nThe figure depicts existing procedures for ML Model Provisioning, illustrating the steps involved in setting up and managing machine learning models in a system. The figure includes a flowchart, a matrix, and a list of steps, providing a clear and concise visual representation of the process.\nFigure 6.47.2-1: Existing procedures for ML Model Provisioning\nOnly subscription is shown above, but the same can apply for request as well.\n1.\tThe NWDAF service consumer subscribes to ML Model (s) according to existing procedure in TS 23.288 [5].\nInformation that is added by the NWDAF service consumer:\n-\tInteroperable Token.\nNOTE 1:\tFormat of the token is up to the stage 3 discussion.\n-\tRepresentative Ratio: percentage of the related UEs whose data is used in the Analytics computation, when the Target of ML Model Reporting is a group of UE(s) or any UE.\nNOTE 2:\tRepresentative ratio is used when NWDAF trains a Model for a group of UEs or any UE, where it can only use the data of the related UEs who grant the User consent. The representative ratio can help the consumer to know if the model can represent the group of UEs or any UE, thus whether the model is useful or not.\n-\tA container for information to the NWDAF containing MTLF may include for example:\n-\tWanted Output format from NWDAF containing MTLF (In this solution an OCI image).\n-\tThe environment the AnLF is running on (e.g. K8s version).\n-\tWhat APIs the model shall have and make use of. Example of such APIs are API for requesting Analytics from model.\nNOTE 3:\tThe parameters listed for the container are only for information and will not require any 3GPP work. The content of the container is not to be specified by 3GPP.\n2.\tNWDAF containing MTLF notifies service consumer according to existing procedure in TS 23.288 [5].\nThe ML Model File includes the wanted output (in this solution an OCI image) and may be a manifest on how to unpack into a runtime and what APIs are available.\nNOTE 4:\tThe content of the manifest is not to be specified by 3GPP. The manifest e.g. may contain helm chart and API description, when the wanted output is an OCI image.\nNo further information is needed from the NWDAF containing MTLF.\nEditor's note:\tHow ML model privacy is supported when NWDAF containing MTLF and NWDAF containing AnLF belong to different vendors is in scope of SA WG3.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.47.3\tImpacts on services, entities and interfaces",
                            "text_content": "NWDAF containing MTLF:\n-\tRegistration of one or more Interoperable Tokens into NRF per Analytics ID.\nNRF:\n-\tInteroperable Token (May be multiple tokens per Analytics ID).\nNWDAF service consumer:\n-\tAdding Interoperable Token in the subscription for model.\n-\tAdding Representative Ratio in the subscription for model.\n-\tAdding a container for information to the NWDAF containing MTLF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.48\tSolution #48: PCF/UE re-evaluates the URSP rules according to NWDAF's analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.48.1\tImpacts of NWDAF analytics towards URSP rules",
                            "text_content": "In URSP rules, the UE maps the application traffic to a PDU sessions according to Traffic Descriptor and RSD. In a specific Traffic Descriptor, for example the IP descriptor or DNN and etc. which of the RSDs will be selected depends on the RSD precedence and UE implementation.\nBut now, how to generate or re-evaluate the URSP rules for UE depends on the PCF internal mechanisms. Also, even if UE receives the URSP rules from PCF, the real enforcement of URSP rules is unknown to 5GC.\nThe analytic from NWDAF has influence on URSP rules, as described in following:\n-\tThe DNN selection. For Analytic ID = DN performance, the NWDAF provides DN Performance Analytics which provides analytics for user plane performance (i.e. average/maximum traffic rate, average/maximum packet delay, average packet loss rate) in the form of statistics or predictions to a service consumer. And for a specific Traffic Descriptor (for example, the Application server IP address), the PCF can determine a better DNN.\n-\tThe slice selection. For Analytics ID = \"Load level information\", the NWDAF provides slice load level information to a consumer NF on a Network Slice level or a Network Slice instance level or both. For a specific Traffic Descriptor, the PCF can determine a better slice based on the slice load level analytics provided by the NWDAF.\n-\tThe access type selection. For Analytics ID = \"WLAN performance\" and \"Service Experience\", the NWDAF provides Observed Service Experience that including the 3GPP Access performance and the WLAN performance. According to these analytics, the PCF can decide the better access technology and provide the better access type in RSD for a specific Traffic Descriptor.\n-\tHigh frequency used RSDs. For a specific Traffic Descriptor, the NWDAF can provide the statistic and prediction of high frequency used of RSDs. Also, the NWDAF can provide the high frequency used of DNN, S-NSSAI, Access type and etc.\n-\tModification of Route Selection Validation Criteria in RSD. If some of the RSD has worse performance under certain UE location or time range, the Route Selection Validation Criteria should be modified.\nWith the help of analytic or prediction from NWDAF, the PCF can update the URSP rules to UE, for example, the access type, DNN selection or slice selection.\nAlso, the NWDAF can provide the URSP rules experience to PCF. For example, the PCF distributes the URSP rules (TD = FQDN = 'ABC.com', RSD 1 = SSC mode 3, DNN2) to several of UEs. But the PCF needs to check the RSD enforcement frequency and application service experience after using the RSD. The NWDAF can provide the RSD frequency and the application performance after using the RSD. This may guide the PCF to re-evaluate the URSP rules, for example, some of the low precedence URSP rules are frequently used and has high performance.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.48.2\tPCF updates or generates URSP rules according to NWDAF's analytics",
                            "text_content": "According to the analytics from NWDAF, the PCF updates or generates the URSP rules. The update or generation of URSP rules will take the action are defined below into account:\n-\tUpdates the RSD precedence in Traffic Descriptor, for example, the Non-3GPP Access in RSD 2 has better performance than 3GPP Access in RSD 1, so the RSD 2 should have a higher precedence.\n-\tUpdates the elements in RSDs, for example changes the access type, DNN selection and slice selection. The PCF can also add more elements in RSDs, or remove the existing parameters in RSDs.\n-\tDelivery new URSP rules to UE according to NWDAF's analytics.\n-\tChanges the Route Selection Validation Criteria. For example, according to the analytic, some of the RSD can't be used at certain UE location or time range, because the performance of DN and S-NSSAI are worse.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.48.3\tExtensions of Analytic ID = \"Service Experience\"",
                            "text_content": "In the RSD of URSP rules, both the 3GPP access, non-3GPP access and multi-Access are available for access type of PDU session. There is no performance of Access type of PDU session in Observed Service Experience. So, it is reasonable to extend the Analytic ID = \"Service Experience\" to add more analytics to help to re-evaluate the URSP rules.\nIn Table 6.48.3-1 and Table 6.48.3-2, extended analytics are listed to extend the Analytic ID = \"Service Experience\".\nThe Observed Service Experience are extended to add an Access Type of PDU session to list the service experience in different access type of PDU session when UE's PDU session is 3GPP access, non-3GPP accessor multi-Access.\nWhen PCF subscribes the extended Analytic ID = \"Service Experience\", it can receive the performance in 3GPP access, non-3GPP access type and multi-Access type, and PCF can re-evaluate the access type of PDU session in URSP rules for UE.\nTable 6.48.3-1: Enhanced Service Experience statistics\n\nTable 6.48.3-2: Enhanced Service Experience predictions\n\nThe NWDAF provides the statistic or prediction of service experience information for each Application under different access type of PDU session, for example, the 3GPP Access, non-3GPP Access or multi-Access.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.48.3-1: Enhanced Service Experience statistics",
                                    "table number": 39,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.48.3-2: Enhanced Service Experience predictions",
                                    "table number": 40,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.48.4\tNewly introduce Analytic ID = \"URSP rules experience\"",
                            "text_content": "This clause specifies how NWDAF can provide URSP rules experience (i.e. in a certain Traffic descriptor the frequency of the RSD enforcement, the application performance after using the RSD, or the performance of each route selection component related) analytics, in the form of statistics or predictions, to a service consumer (for example, the PCF).\nThe NWDAF collects the QoS related data from SMF, for example, the S-NSSAI, DNN, SSC mode and etc. These parameters are referred to the RSC in URSP rules under certain Traffic descriptor.\nThe URSP rules experience analytics may provide one or more of the following outputs:\n-\tRSD enforcement frequency in a certain Traffic Descriptor, URSP rules.\n-\tApplication service experience when using certain RSDs in the Traffic Descriptor.\n-\tPerformance of the route selection component in certain Traffic Descriptor, URSP rules.\nThe service consumer may be PCF.\nThe consumer of these analytics shall indicate in the request or subscription:\n-\tAnalytics ID = \"URSP rules experience\".\n-\tTarget of Analytics Reporting: one or more SUPI(s) or Internal Group Identifier(s), or \"any UE\".\n-\tAnalytics Filter Information, including the details of Traffic descriptor, for example, the Application descriptors or Domain descriptors.\n-\toptionally, maximum number of objects and maximum number of SUPIs.\n-\toptionally, preferred level of accuracy of the analytics;\n-\toptionally, a list of analytics subsets that are requested (see clause 6.48.4-2)\n-\toptionally, preferred level of accuracy per analytics subset;\n-\tAn Analytics target period that indicates the time window for which the statistics or predictions are requested;\n-\tIn a subscription, the Notification Correlation Id and the Notification Target Address;\nNWDAF collects the network data from AF (directly or via NEF) and from other 5GC NF(s) in order to calculate and provide statistics and predictions on the application service experience when using certain Traffic descriptor and RSD. Also, NWDAF collects the results of URSP rules enforcement from PCF.\nThe service data and performance data collected from the AF (including the service data collected from the UE through the AF), the network data from other 5GC NFs.\nTable 6.48.4.2-1: Input related to the URSP rules experience\n\nNOTE:\tThe Table 6.48.4.2-1 lists the main Input related to the URSP rules experience. Some other input from AF or other 5GC elements can be referred to the Observed Service Experience defined in TS 23.288 [5], from Table 6.4.2-1 to Table 6.4.2-2, to collect information.\nThe NWDAF services as defined in the clause 7.2 and 7.3 of TS 23.288 [5] are used to expose the analytics.\n-\tURSP rules experience statistics information is defined in Table 6.48.4.3-1.\n-\tURSP rules experience predictions information is defined in Table 6.48.4.3-2.\nThe output of Analytic ID = \"URSP rules experience\" are listed below:\nTable 6.48.4.3-1: URSP rules experience statistics\n\nTable 6.48.4.3-2: URSP rules experience Prediction\n\nThe analytic of URSP rules experience provides the combined performance, for example, the application service experience, of certain RSDs in a Traffic descriptor. Also, the NWDAF provides the performance under single Route Selection Component, for example, the DNN performance or Slice performance.\nThe performance of certain Route Selection Descriptor in URSP rules experience statistic/prediction, can also be the performance of multiple combination of RSCs for a Traffic Descriptor.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.48.4.2-1: Input related to the URSP rules experience",
                                    "table number": 41,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.48.4.3-1: URSP rules experience statistics",
                                    "table number": 42,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.48.4.3-2: URSP rules experience Prediction",
                                    "table number": 43,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.48.5\tProcedures for URSP rules re-evaluation in PCF and UE",
                            "text_content": "The figure depicts a network-wide re-evaluation of the URSP rule for PCF according to NWDAF's analytics, illustrating the process of re-evaluating the rule based on network data.\nFigure 6.48.5-1: URSP rule re-evaluation for PCF according to NWDAF's analytics\n1.\tThe PCF sends an Analytics request/subscribe (Analytics ID, Target of Analytics Reporting = single UE, group of UEs or any UE, Analytics Reporting Information=Analytics target period) to NWDAF by invoking a Nnwdaf_AnalyticsInfo_Request or a Nnwdaf_AnalyticsSubscription_Subscribe. The analytics can be requested with the filter information.\nThe PCF subscribes the following Analytics ID for URSP rules re-evaluating:\n-\tSubscribes Analytics ID = \"Service Experience\" to receive the both 3GPP access and non-3GPP access performance. Compare the performance in each access type and determine the access type in URSP rules. Also, by setting analytics filter as Traffic Descriptor (for example, the DNN, FQDN, IP descriptor and etc), the PCF subscribes the Analytics ID = \"Service Experience\" to receive the statistic or prediction of RSD under this TD, for example, the frequency of used RSD, or RSD performance.\n-\tSubscribes Analytic ID = DN performance to receive the DN Performance Analytics to decide the DNN selection in URSP rules.\n-\tSubscribes Analytics ID = \"Load level information\" to receive the slice load level information to determine the network slice selection in URSP rules.\n-\tSubscribes Analytics ID = \"WLAN performance\" to receive the WLAN performance to determine the access type in URSP rules.\n-\tSubscribes Analytics ID = \"URSP rules experience\" to receive RSD enforcement frequency in a certain Traffic Descriptor, URSP rules; Or to receive the application service experience when using certain RSDs in the Traffic Descriptor; Or to receive the performance of the route selection component in certain Traffic Descriptor, URSP rules.\n2.\tThe NWDAF collects the performance data as Table 6.48.4.2-1 indicated from SMF or AF via Nsmf_EventExposure_Subscribe/ Nnef_EventExposure_Subscribe. And the SMF or AF notifies the performance data of PDU session that the application traffic matched to the NWDAF via Nsmf_EventExposure_Notify/Nnef_EventExposure_Notify.\n3.\tThe NWDAF derives the analytic.\n4.\tThe NWDAF provides the data analytics, i.e. the observed Service Experience analytics to the consumer NF (including PCF and UE) by means of either Nnwdaf_AnalyticsInfo_Request response or Nnwdaf_AnalyticsSubscription_Notify, depending on the service used in step 1, indicating the results below:\n-\tSlice performance analytics: the NWDAF provides slice load level information to a consumer NF on a Network Slice level or a Network Slice instance level or both, see clause 6.3.3A of TS 23.288 [5] for detailed outputs. For a specific Traffic Descriptor, the NWDAF can provide a better slice which has lower slice load in RSD of this Traffic Descriptor.\n-\tDN performance analytics: the NWDAF provides DN Performance Analytics which provides analytics for user plane performance (i.e. average/maximum traffic rate, average/maximum packet delay, average packet loss rate) in the form of statistics or predictions to a service consumer, see clause 6.14.3 of TS 23.288 [5] for detailed outputs. And for a specific Application server IP address (can be the Traffic Descriptor), the PCF can decide a better DNN with better performance.\n-\tWLAN performance analytics: the NWDAF provides WLAN performance analytics to PCF, including the RSSI, RTT, UL/DL data rate of specific SSID. The PCF can decide the access type by comparing the performance between RAT access and WLAN.\n-\tEnhanced Observed Service Experience analytics: the NWDAF provides enhanced Observed Service Experience that including the 3GPP Access performance, the non-3GPP performance and the multi-Access performance, see clause 6.48.3 of this paper for detailed outputs. According to these analytics, the PCF can decide the better access type (3GPP access or non-3GPP access) in RSD of PDU session for a specific Traffic Descriptor.\n-\tURSP rules experience: For a specific Traffic descriptor, the NWDAF also provides the statistic or prediction of RSD or RSD parameters. For a certain Traffic descriptor, the NWDAF provides the URSP rules enforcement frequency and the application service experience corresponding to the RSD. The PCF can decide to generate or update the URSP rules.\n5.\tThe PCF generates or updates the URSP rules for single UE, a group of UEs or several UEs. According to the performance and URSP rules enforcement information provided by NWDAF, the action of URSP rules re-evaluation are listed below:\n-\tUpdates the RSD precedence in Traffic Descriptor, for example, the Non-3GPP Access in RSD 2 has better performance than 3GPP Access in RSD 1, so the RSD 2 should have a higher precedence.\n-\tUpdates the elements in RSDs, for example changes the access type, DNN selection and slice selection. The PCF can also add more elements in RSDs, or remove the existing parameters in RSDs.\n-\tDelivery new URSP rules to UE according to NWDAF's analytics.\n-\tChanges the Route Selection Validation Criteria. For example, according to the analytic, some of the RSD can't be used at certain UE location or time range, because the performance of DN and S-NSSAI are worse.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.48.6\tImpacts on services, entities and interfaces",
                            "text_content": "NWDAF:\n-\tUpdate Extensions of Analytic ID = \"Service Experience\" by adding access type of PDU session.\n-\tIntroduce new Analytic ID that to provide URSP rules enforcement statistic or prediction under a specific Traffic Descriptor in Analytic ID = \"URSP rules experience\".\nPCF:\n-\tPCF re-evaluates URSP rules according to NWDAF's analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.49\tSolution #49: NWDAF assisted URSP decision for redundant transmission",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.49.1\tDescription",
                            "text_content": "The solution addresses the key issue #6 \"NWDAF-assisted URSP\".\nApart from redundant transmission at transport layer, two redundant mechanisms are defined to provide redundant transmission for URLLC services since Rel-16: a) Dual Connectivity based end to end Redundant User Plane Paths; b) Redundant Transmission on N3/N9 interface. URSP can be applied to support the end to end Redundant transmission, i.e. the network can provide URSP rules for applications requiring redundant transmission to the UE, with different combination of DNN and S-NSSAI. The URSP is further enhanced to include RSN and PDU Session Pair ID for the redundant transmission in Rel-17. While the Redundant Transmission on N3/N9 can be initiated by the SMF based the authorized 5QI, gNB capability and local policies.\nAs defined in the TS 23.288 [5], Redundant Transmission Experience related analytics can assist the SMF for decision on Redundant Transmission on N3/N9 interface, by providing the UL/DL packet delay, packet drop rate to the SMF. However, how the end to end Redundant transmission can benefit from the Redundant Transmission Experience related analytics is undefined yet.\nTo achieve this goal, this paper proposes that the NWDAF exposes the Redundant Transmission Experience analytics to the PCF for the UE, then the PCF for the UE can determine whether to provision the corresponding URSP rules for redundant transmission to the UE. Thus, the UE can initiate redundant transmission for URLLC services. Based on this solution, the redundant E2E user plane can be triggered as needed, subjected to the network quality.\nThe Redundant Transmission Experience analytics as defined in TS 23.288 [5] is to be enhanced:\n-\tPDU Session ID is involved as new Analytics Filtering Information.\n-\tThe NWDAF is required to collect more input data from UPF or OAM or SMF for Redundant Transmission Experience Analytics, as described in the following table, in addition to what is specified in the Table 6.13.2-1 of TS 23.288 [5].\nTable 6.49.1-1: Packet drop and/or packet delay measurement per QFI or GTP level\n\nThe Observed Redundant Transmission Experience as defined in Table 6.13.3-1 and Table 6.13.3-2 of TS 23.288 [5] needs to be enhanced respectively, as below:\nTable 6.49.1-2: Redundant Transmission Experience statistics\n\nTable 6.49.1-3: Redundant Transmission Experience predictions\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.49.1-1: Packet drop and/or packet delay measurement per QFI or GTP level",
                                    "table number": 44,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.49.1-2: Redundant Transmission Experience statistics",
                                    "table number": 45,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.49.1-3: Redundant Transmission Experience predictions",
                                    "table number": 46,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.49.2\tProcedures",
                            "text_content": "NOTE 1:\tThe procedure is just for information to show how the PCF requests the NWDAF to provide analytics to help PCF make decision on URSP regarding E2E redundant transmission.\nFigure 6.49.2-1 shows the procedure how the NWDAF can be triggered to provide the Redundant Transmission analytics to the PCF for the UE and how the Redundant Transmission analytics can be utilized by the PCF to trigger the establishment of Redundant end to end user plane paths.\nThe figure depicts a procedure for triggering end-to-end user plane path redundancy transmission, which is crucial for ensuring reliable communication in a 5G network. The figure illustrates the steps involved in initiating a redundant transmission, including the selection of a redundant path, the transmission of the redundant path, and the retransmission of the original path. This process is essential for maintaining the integrity of the network and ensuring that users can continue to communicate even in the event of a failure.\nFigure 6.49.2-1: Procedure for triggering end to end user plane path Redundant Transmission\n1.\tThe PCF for the UE receives dynamic redundant transmission request from the AF, either via the Service specific information provisioning procedure as defined in step 0 to step 5 in figure 4.15.6.7-1 of TS 23.502 [3]. The request message includes the target AF-Service-Identifier, target UE(s) identified by the user identity or External Group ID or any UE, dynamic redundant transmission request indication, and optionally SLA requirements for the application service.\n2.\tThe PCF for the UE sends a request to the NWDAF for analytics on the target UE, using either the Nnwdaf_AnalyticsInfo or Nnwdaf_AnalyticsSubscription_Subscribe service. The type of analytics is set to Redundant Transmission Experience. Analytics Filter Information optionally contains DNN, S-NSSAI, PDU Session ID, Area of Interest, etc. The DNN, S-NSSAI and PDU Session ID can be determined by the PCF based on local configuration or URSP rules.\n3.\tIf the request is authorized, the NWDAF, in order to provide the requested analytics, may collect the service data information from OAM, SMF/UPF, following the procedure captured in clause 6.2.3.2 of TS 23.288 [5].\nThis step may be skipped when e.g. the NWDAF already has the requested analytics available.\n4.\tThe NWDAF derives requested analytics.\n5.\tThe NWDAF provides requested Redundant Transmission Experience analytics to the PCF for the UE, using either the Nnwdaf_AnalyticsInfo_Request response or Nnwdaf_AnalyticsSubscription_Notify, depending on the service used in step 1.\n6.\tBased on the received analytics result, the PCF for the UE may decide to update the URSP rules of the UE to activate E2E Redundant Transmission.\n7.\tThe PCF for the UE provides the updated URSP rules to the UE via UE Configuration Update procedure as specified in clause 4.2.4.3 of TS 23.502 [3].\n8.\tOptionally, the PCF for the UE notifies the AF that the E2E Redundant Transmission can be initiated by sending E2E Redundant Transmission Availability indication via Npcf_EventExposure_Notify service operation.\nNOTE 2:\tThe AF can further instruct the UE to trigger redundant transmission for the application, via user plane message or Application Triggering procedure as defined in clause 4.13.2.2 of TS 23.502 [3].\n9.\tThe application on the UE initiates redundant transmission based on UE's re-evaluation of the updated URSP rules.\n10.\tThe UE initiates Redundant PDU Session Establishment/Modification procedure to establish E2E Redundant user plane paths for URLLC services:\n-\tIf the PDU Session parameters (e.g. DNN, S-NSSAI, SSC mode) of the existing PDU Session for URLLC service are not updated and the corresponding URSP rule contains RSN and/or PDU Session Pair ID, the UE initiates PDU Session Modification procedure by indicating the RSN/PDU Session Pair ID to the SMF, and initiates another Redundant PDU Session Establishment procedure by indicating the corresponding RSN/PDU Session Pair ID to the SMF.\n-\tIf PDU Session parameters of the existing PDU Session for URLLC service are updated, the UE initiates the PDU Session Establishment procedure for both Redundant user plane, and may provide the corresponding RSN/PDU Session Pair ID, if available in the URSP, to the SMF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.49.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF:\n-\tSupport the enhanced analytics on Redundant Transmission Experience Analytics.\nAF:\n-\tSupport to request for dynamic Redundant Transmission user plane path.\nPCF:\n-\tSupport to subscribe or request Redundant Transmission Experience Analytics from the NWDAF.\n-\tSupport to update URSP rules based on the Redundant Transmission Experience Analytics.\nUE:\n-\tSupport Redundant PDU Session Establishment/Modification based on the re-evaluation of URSP rules.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.50\tSolution #50: Enhancements on QoS Sustainability analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.50.1\tDescription",
                            "text_content": "This solution is proposed to address Key Issue #7: Enhancements on QoS Sustainability analytics.\nThe consumer of QoS Sustainability analytics may request the NWDAF analytics information regarding the QoS change statistics for an analytics target period in the past in a certain area or the likelihood of a QoS change for an Analytics target period in the future in a certain area. While in the existing solution, the certain area can only be TA/cell, a cell level QoS prediction is not precise enough for any UE within the cell, since in specific parts of a cell the experienced QoS will be less or higher than the current cell-level QoS prediction.\nThus, besides TA/cell information, a finer granularity area (e.g. below Cell level) is also introduced for NWDAF to provide with more accuracy analytics.\nThe procedure for below cell analytics is illustrated in clause 6.50.2.\nThe NWDAF collects location, bit rate and delay for the UE from the sources listed in Table 6.50.1.1-1.\nTable 6.50.1.1-1: UE related Network Data from 5GC NF\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.50.1.1-1: UE related Network Data from 5GC NF",
                                    "table number": 47,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.50.2\tProcedures",
                            "text_content": "The figure depicts a procedure for \"QoS Sustainability\" analytics in a finer granularity, illustrating the steps involved in analyzing the quality of service (QoS) of a communication system. The figure includes a flowchart with arrows indicating the sequence of actions, such as data collection, data analysis, and decision-making. The use of color-coded boxes and labels helps to visually represent the different stages of the process, making it easier to understand the steps involved. The figure also includes a legend to explain the different colors and labels used in the flowchart. Overall, the figure provides a clear and concise visual representation of the QoS sustainability process, making it easier to understand and follow.\nFigure 6.50.2-1: Procedure for \"QoS Sustainability\" analytics in a finer granularity\n1.\tThe NF consumer requests or subscribes to analytics information on \"QoS Sustainability\" provided by the NWDAF. The parameters included in the request are defined in clause 6.9.1 of TS 23.288 [5]. The NF can request statistics or predictions or both.\nThe consumer provides the TAIs or Cell IDs, and/or finer granularity area (e.g. below cell via longitude/latitude range etc.) in \"Location information\" when requesting QoS Sustainability analytics. If the AF doesn't provide TAIs or Cell IDs, the NWDAF as an 5GC internal NF is expected to obtain such information, i.e. to determine which cells are related to the finer granularity area.\nThe consumer may optionally provide UE Context or Subscription information such as one or more of the following: device speed or speed range, serving UPF node information, Subscriber category (as in TS 23.503 [4] clause 6.2.1.3), device model, device manufacturer, IMEI or IMEISV or TAC range, supported frequency bands, equipment type.\n2a.\tIf the request is authorized, and in order to provide the requested analytics, the NWDAF decides the AMF(s) based on the TAIs/Cell IDs, and obtains the UE list in the TAs/Cells from AMF by invoking Namf_EventExposure_Subscribe service operation using event ID \"Number of UEs present in a geographical area\" as described in TS 23.502 [3].\n2b.\tThe NWDAF invokes Namf_EventExposure_Subscribe service operation to get the update of the UE list using event ID \"UE moving in or out of Area of Interest\" as described in TS 23.502 [3].\n3.\tThe NWDAF initiates the LCS Service Request to the GMLC/LMF to get the location and optionally the speed of UEs from UE list provided by the AMF in step 2.\n4.\tThe GMLC/LMF initiates the UE location service procedure and gets the location of the UEs.\n5.\tThe GMLC/LMF provides location information for each UE in the UE list to the NWDAF.\n6.\tFrom the list of UE locations returned by the GMLC/LMF, the NWDAF identifies the UEs located in finer granularity area by comparing the UEs' locations to the finer granularity area, provided in step 1.\n7.\tThe NWDAF invokes Namf_EventExposure_Subscribe service operation to get the serving SMF for the UE.\n8.\tBased on the serving SMF in step 7, the NWDAF invokes Nsmf_EventExposure_Subscribe service operation to get the UPF information for the UE.\n9.\tThe NWDAF may collect QoS information either from the UPF directly, or subscribe to the UPF via the SMF. The QoS information may include the bandwidth, packet delay for the UE and the information on the serving UPF node id.\n10.\tOptionally, the NWDAF may collect additional information for the UE Context or UE Subscription from the UDM such as Subscriber category, PEI (if available). PEI may be used to retrieve, from GSMA database, additional information such as device model, device manufacturer, IMEI or IMEISV or TAC range, supported frequency bands, equipment type. Such additional information may be used by NWDAF to add more information to the collected measurements and filter those measurements that are applicable to the UE and subscription context for which analytics are requested by the service consumer.\n11.\tThe NWDAF verifies whether the triggering conditions are met and derives the requested analytics. The NWDAF can detect the need for notification based on comparing the requested analytics of the target 5QI against the Reporting Threshold(s) provided by the consumer in any cell over the requested Analytics target period.\n12.\tThe NWDAF provides the response or notification on \"QoS Sustainability\" to the NF consumer.\nNOTE 1:\tNWDAF may decide to ignore some of the filters if collected measurements are not sufficient to derive meaningful analytics. In such scenario, a warning message is provided in the response or notification to the NF consumer.\nNOTE 2:\tIn order to reduce the amount of information collected per measurement point, the additional information from UDM may only be collected for the events of GBR unfulfillment. In this way the additional analytics filter information may only be supported for 5QI of resource type GBR and for events of GBR unfulfillment.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.50.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF:\n-\tExtensions of the NWDAF function to support a finer granularity area (e.g. below Cell level) analytics of with the NF consumers.\n-\tExtensions of the NWDAF subscription services to support location and speed request from the GMLC/LMF.\n-\tExtensions of the NWDAF to support UDM query and optionally GSMA database for more accurate analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.51\tSolution #51: Selection, Monitoring, and Maintenance of NWDAF(s) for Federated Learning in 5GC",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.51.1\tDescription",
                            "text_content": "This solution is proposed to address Key Issue #8: Supporting Federated Learning in 5GC. The study bullets of this Key Issues include:\n-\tStudy how to coordinate multiple NWDAFs including selection of participant NWDAF instances in the Federated Learning group, e.g. assistance information (if any) to perform the selection, and decision of role for the participant NWDAF.\n-\tStudy whether and how to perform performance (e.g. network performance and model performance) monitoring of the NWDAF Federated Learning operation.\nTo address the challenges in the above bullets for supporting Federated Learning in 5GC, this solution focus on the NWDAF(s) selection in Federated Learning preparation phase, NWDAF(s) monitoring and maintenance in Federated Learning execution phase.\nA lot of factors influence Client NWDAF(s) selection in Federated Learning preparation phase. For example, the capability of NWDAF(s), the interoperability and availability of Client NWDAF(s) to join in Federated Learning.\nIn Federated Learning execution phase, due to dynamic changes of federation network, current Client NWDAF(s) may leave or join, the dynamic joining and leaving of Client NWDAF(s) to a Federated Learning multi-round learning/training process in 5GC should be considered. In addition, methods may be applied for Server NWDAF to monitoring the status changes (e.g. changes of capabilities and availability) of Client NWDAF(s).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.51.2\tProcedures",
                            "text_content": "In Federated Learning preparation phase, Server and (potential) Client NWDAFs are discovered via NRF, and Client NWDAF(s) are selected by the method for handshake pattern. The Client NWDAF(s) selection is based on the availability, capability, etc.\nThe figure depicts a procedure for selecting Client NWDAF(s) in the Federated Learning preparation phase, illustrating the steps involved in selecting the appropriate client nodes for the federated learning model. The figure includes a flowchart with arrows indicating the sequence of actions, and a legend to clarify the different types of client nodes. The figure is essential for understanding the process of selecting the clients that will participate in the federated learning model, ensuring that the model is trained on a representative set of data.\nFigure 6.51.2.1-1: Procedure for Client NWDAF(s) selection in Federated Learning preparation phase\nFigure 6.51.2.1-1 illustrates the procedures of Client NWDAF(s) selection in Federated Learning preparation phase.\nThe procedure for NWDAFs selection is as follows:\n0.\tNWDAFs register into NRF with Federated Learning capability. Server NWDAF discovers Client NWDAFs based on e.g. Federated Learning capability, Analytics ID, etc.\n1.\tServer NWDAF sends Federated Learning preparation request to the Client NWDAF(s) by invoking an Nnwdaf_MLPreparation_Request service operation with Interoperability information. In the preparation request, indication of the role for the NWDAF(s), i.e. act as Client NWDAF(s), may be contained.\nNOTE 1:\tThe Interoperability information indicates what abilities (e.g. able to run certain models) are needed for the client NWDAF to support this FL procedure, e.g. if the server NWDAF and the client NWDAF can share model and how to share model. The Interoperability information is determined among different vendors and its content is not to be specified by 3GPP.\n2.\tClient NWDAF(s) decides whether to join the Federated Learning process based on its availability, capability and Interoperability information.\n3.\tClient NWDAF(s) send the response to server NWDAF indicating if it wants to join the FL procedure.\n4.\tThe Server NWDAF may send test tasks to the Client NWDAF(s) that want to join the FL procedure. The Client NWDAF(s) run the test tasks and send the results to the Server NWDAF.\nNOTE 2:\tThe test tasks may be micro computation or training tasks, the requirement for completing the micro tasks is the same as or is similar to the main tasks. The test task could be a small task to let the client NWDAF collect local data and sends the local model weights back to the server; or some test to make sure that the server and client NWDAF can communicate if they use the same FL framework or library. How to retrieve and run the test tasks is out of scope of 3GPP.\n5.\tServer NWDAF selects the Client NWDAF(s), the result of the test tasks may be taken into account by the Server NWDAF for the selection of Client NWDAF(s).\nIn Federated Learning execution phase, Server NWDAF monitors the status changes of Client NWDAF(s). Client NWDAF(s) may be re-selected based on the updated status, availability, and/or capability, etc. of the Client NWDAF(s) for the FL tasks.\nThe figure depicts a procedure for NWDAFs monitoring and re-selection in Federated Learning execution phase, illustrating the steps involved in ensuring the accuracy and reliability of the learning process.\nFigure 6.51.2.2-1: Procedure for NWDAFs monitoring and re-selection in Federated Learning execution phase\nFigure 6.51.2.2-1 illustrates the procedure of monitoring and re-selection of Client NWDAF(s) in Federated Learning execution phase.\nThe procedure for monitoring and re-selection of Client NWDAF(s) is as follows:\n1.\tServer NWDAF monitoring the status of Client NWDAF(s) during the Federated Learning execution process, receives the updated status of the Client NWDAF(s).\nServer NWDAF may perform monitoring and obtain the updated status of Client NWDAF(s) directly and/or via NRF.\nNOTE 1:\tThe status of client NWDAF could be the NF load, NF availability, its capability changes, e.g. it does not support FL anymore.\n2.\tServer NWDAF checks Client NWDAF(s) status based on the received information, judges whether re-selection of Client NWDAF(s) for the next round(s) of Federated Learning is needed. The judgement is based on the updated status of the Client NWDAF(s), including the availability, capability, etc.\n3.\t[If re-selection is needed as judged in step 2.] Server NWDAF re-select Client NWDAF(s) as steps 1-5 in Figure 6.51.2.1-1.\nThe procedure for discovery of new Client NWDAF(s) in Federated Learning execution phase is given in clause 6.51.2.3.\n4.\tClient NWDAF(s) terminates operations for the Federated Learning if it receives termination request from the Server NWDAF.\nThere are two possible cases for Server NWDAF to get the information of the new Client NWDAF(s), i.e. from the new Client NWDAF(s) directly or via NRF.\nThe figure depicts a procedure for dynamic discovery of new Network Wide Adversarial Frequencies (NWDAFs) in Federated Learning execution phase when the information about the Server NWDAF is known at the new Client NWDAF(s). The procedure involves identifying the new Client NWDAF(s) and their corresponding Server NWDAF(s) through a process of dynamic discovery. This ensures that the learning process is fair and unbiased, as the new Client NWDAF(s) are not influenced by the Server NWDAF(s) that are known to them.\nFigure 6.51.2.3.1-1: Procedure for dynamic discovery of new NWDAFs in Federated Learning execution phase when the information about the Server NWDAF is known at the new Client NWDAF(s)\nClient NWDAFs 1 to N are selected by Server NWDAF for participating the current round of Federated Learning. Client NWDAFs N+1 to N+X, which are the new ones, have the capability to join in the next rounds of training processes.\nNew Client NWDAF(s), which are available and/or have the capability to join in the Federated Learning processes, know the information about the Server NWDAF and inform Server NWDAF directly. The procedure is the following:\n0.\tServer NWDAF registers into NRF about the Federated Learning procedure with the following parameters:\n-\tFederated Learning (FL) Correlation ID.\n-\tAnalytics ID.\nNOTE:\tFL Correlation ID is used to identify a specific FL procedure. For example, an Server NWDAF or a Client NWDAF can join different FL procedures at the same time, then when they receive messages or data from other NWDAF, they have to know the message or data is for which FL procedure.\nWhen a server NWDAF starts a FL procedure, it registers the FL procedure in the NRF with FL Correlation ID, Analytics ID. When later a client NWDAF wants to join a FL dynamically, e.g. it wants to update its local model using global information, it will query NRF if there is an ongoing FL for the analytics ID. Then NRF will provide the server NWDAF ID and FL Correlation ID to the client NWDAF, then the client NWDAF can contact the server NWDAF to join the FL procedure. With the FL correlation ID, the server NWDAF knows which FL procedure the client NWDAF wants to join and which model it should provide to the client.\n1.\tIf the information about the Server NWDAF and the corresponding FL procedure is known via NRF, new Client NWDAF(s) inform Server NWDAF to the Client NWDAF(s) by invoking an Nnwdaf_MLPreparation_Request service operation their interoperability and availability.\n2.\tBefore starting next round of training, Server NWDAF selects Client NWDAF(s) from NWDAFs 1 to N+X based on the updated information of the Client NWDAF(s). The procedure is the same as steps 1-5 in figure 6.51.2.1-1.\nThe figure depicts a procedure for dynamic discovery of new Network Wide Adversarial Frequencies (NWDAFs) in Federated Learning execution phase when the information about the Server NWDAF is unknown at the new Client NWDAF(s). The procedure involves the use of a dynamic discovery algorithm that identifies new NWDAFs based on the information available at the new Client NWDAF. This ensures that the learning process is fair and unbiased, as the new Client NWDAF is not aware of the Server NWDAF's information.\nFigure 6.51.2.3.2-1: Procedure for dynamic discovery of new NWDAFs in Federated Learning execution phase when the information about the Server NWDAF is unknown at the new Client NWDAF(s)\nClient NWDAFs 1 to N are selected by Server NWDAF for participating the current round of Federated Learning. Client NWDAFs N+1 to N+X, which are the new ones, have the capability to join in the next rounds of training processes.\nServer NWDAF gets the information of the new Client NWDAF(s) dynamically via NRF by either subscribing to the event that a new Client NWDAF registers or discovering NRF when it needs to reselect Client NWDAFs.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.51.3\tImpacts on services, entities and interfaces",
                            "text_content": "NWDAF:\n-\tRegister FL procedure information into NRF dynamically during the Federated Learning processes.\n-\tSelection of Client NWDAF(s).\n-\tMonitoring Client NWDAF status updates.\n-\tDynamic discovery of new Client NWDAF(s).\n-\tNew Nnwdaf services Nnwdaf_MLPreparation and Nnwdaf_MLJoin. The service Nnwdaf_MLPreparation is for information/parameter sending in the preparation phase of a ML training process. The service Nnwdaf_MLJoin is for dynamic joining of new NWDAF(s) in the execution phase.\nNRF:\n-\tServer NWDAF and Client NWDAF(s) registration for the Federated Learning procedure.\n-\tRegisters FL procedure information dynamically during the Federated Learning processes.\n-\tReceive and notify information about Client NWDAF(s) updates to Server NWDAF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.52\tSolution #52: FL training update to NWDAF containing AnLF from NWDAF containing MTLF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.52.1\tDescription",
                            "text_content": "This solution is proposed for KI#8 to support the Federated Learning procedure between different NWDAFs containing MTLF and provide Federated Learning training updates from NWDAF containing MTLF (with FL aggregation capability/ in the role of FL server) to NWDAF containing AnLF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.52.2\tProcedures",
                            "text_content": "Procedure for Federated Learning training updates from NWDAF containing MTLF to NWDAF containing AnLF is described in Figure 6.52.2-1.\nThe figure depicts a procedure for FL training update to NWDAF containing AnLF from NWDAF containing MTLF. The NWDAF contains MTLF, which is a method for training the FL model. The AnLF is a new method for training the FL model. The update involves updating the NWDAF with the new AnLF and MTLF methods.\nFigure 6.52.2-1: Procedure for FL training update to NWDAF containing AnLF from NWDAF containing MTLF\nEditor's note:\tThe aspects related to trained ML model(s) sharing should be aligned with Key Issue #5.\n0.\tNWDAF containing AnLF discovers one or more instances of NWDAF containing MTLF via the NRF as illustrated in steps 0a, 0b, 0c.\n1.\tFL training between NWDAF containing MTLF (with Federated aggregation capability) and NWDAF containing MTLF (with Federated participation capability) is performed as described in Solution 21 Figure 6.21.2.3-1 or Solution 23 Figure 6.23.2-1. In addition, the NWDAF containing MTLF (with Federated participation capability) send their local training accuracy metrics via Nnwdaf_MLModelTraining_Notify in Figure 6.21.2.3-1 or exchange ML model parameters procedure (step 11) in Figure 6.23.2-1.\n2.\tThe NWDAF containing MTLF sends Nnwdaf_MLmodelProvision_Notify message with Analytics ID(s), ML model ID(s), ML model file address, ML model serialization format, Training Accuracy metric per ML model ID. The training accuracy metrics indicates the ML model accuracy when the NWDAF containing MTLF performs training using training dataset. The training accuracy metric is calculated by the NWDAF containing MTLF (with Federated aggregation capability) aggregating the received local training accuracy metrics in step 1.\n3.\t[conditional] NWDAF containing AnLF sends Nnwdaf_MLModelTrainingUpdate_Subscribe message to the NWDAF containing MTLF with Analytics ID(s), ML model ID(s), Base Accuracy metric, Notification Correlation ID. The same ML model ID(s) as provided in step 2 are included. The Base Accuracy metric is an accuracy metric determined by the NWDAF containing AnLF using the dataset from live network. The Base Accuracy metric is provided by the NWDAF containing AnLF to notify the NWDAF containing MTLF, when the same ML model as in step 2 or a new ML model (for a given Analytics ID) is available with training accuracy higher than Base Accuracy metric.\nNOTE:\tThe Accuracy metric used depends on the conclusion of KI#1, which is similar to accuracy or MAE.\n4.\t[conditional] NWDAF containing MTLF sends Nnwdaf_MLModelTrainingUpdate_Notify message with Analytics ID(s), ML model ID(s), Training Accuracy metric. The ML model ID(s) included in the message may be the same re-trained ML model as provided in step 2 with new training accuracy higher than the Base Accuracy metric provided in step 3 or the ML model ID(s) may be a new trained ML model available for the Analytics ID(s) provided in step 3 with training accuracy level higher than the Base Accuracy metric.\n5.\t[conditional] NWDAF containing AnLF decides if it wants to use the ML model ID provided in step 4.\n6.\t[conditional] NWDAF containing AnLF sends Nnwdaf_MLModelProvision_Request with Analytics ID(s), ML model ID(s) provided in step 4.\n7.\t[conditional] NWDAF containing MTLF sends Nnwdaf_MLModelProvision_Response with Analytics ID(s), ML model ID(s), ML model file address, Training Accuracy metric.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.53\tSolution #53: Horizontal Federated Learning with Multiple NWDAF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.53.1\tDescription",
                            "text_content": "This is a solution for the Key Issue#8: Supporting Federated Learning in 5GC.\nAs shown in Figure 6.53.1-1, there are several NWDAF (containing MTLF) distributed in an operator, where each NWDAF (containing MTLF) is responsible for AI model training based on collected data per certain area.\nIt looks necessary that various data from wide area is needed to train a better ML model for operator however it is difficult for NWDAF (containing MTLF) to collect all the raw data from distributed data source in different areas. For example, as in shown in figure 1 below, the raw data per serving area is stored in each local NWDAF (containing MTLF).\nThe figure depicts a network-wide distributed network-wide distributed antenna farm (NWDAF) deployment in a point-to-multipoint (PLMN) network. The NWDAF comprises multiple distributed antenna elements (DAEs) and is designed to provide high-quality signal coverage across the entire network. The deployment is shown in Figure 6.53.1-1, illustrating the various components and their interconnections.\nFigure 6.53.1-1: Distributed NWDAF(containing MTLF) deployment in a PLMN\nIt is proposed to utilize Horizontal Federal ML learning to train a ML model by retrieving the useful information from the raw data from distributed data source over wide area but not require to collect/store all the raw data from distributed data source over the wide area.\nThe main idea of Horizontal Federated Learning is to build machine-learning models based on data sets that are distributed in different network functions. As shown in Figure 6.53.1-1, NWDAF (containing MTLF1) is chosen as coordinator and the other NWDAF (containing MTLF) are chosen as client.\nA client NWDAF (containing MTLF) locally trains the local ML model with its own data and shares it to the coordinator NWDAF (containing MTLF). With local ML models from different Client NWDAF (containing MTLF):\n1)\tIf the coordinator NWDAF (containing MTLF) is with the capability of FL server, it aggregates the local ML models into a global or optimal ML model or ML model parameters and send them back to client NWDAF(containing MTLF).\n2)\tIf the coordinator NWDAF (containing MTLF) is only with the capability of FL client, it will find out a NWDAF(containing MTLF) support FL server, who will be responsible to aggregate the local ML models into a global or optimal ML model or ML model parameters and send them back to client NWDAF(containing MTLF).\nThe proposed solution is composed the following aspects:\n-\tRegistration and discovery of multiple NWDAF (containing MTLF) with capability of Horizontal Federated Learning.\n-\tHorizontal Federated Learning training procedure.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.53.2\tProcedures",
                            "text_content": "The figure depicts a registration and discovery process for Horizontal Federated Learning, a collaborative learning model that enables multiple devices to learn from each other's data without sharing their own. The process involves the use of registration and discovery protocols, which are essential for ensuring data privacy and security. The figure illustrates the steps involved in the registration process, which involves identifying the devices and their respective data, and the discovery process, which involves sharing the data with the other devices. The figure also includes a visual representation of the data flow, showing how the data is transferred between the devices and the central server. Overall, the figure provides a clear and concise overview of the Horizontal Federated Learning process, making it easier for users to understand and implement the model.\nFigure 6.53.2.1-1: Registration and discovery for Horizontal Federated Learning\n1-3.\tThe MTLF with FL capability registers its NF profile (Address of MTLF, Supported Analytics ID(s), Horizontal Federated Learning Indication(FL client, FL server), Serving Area, preferred Time Period for FL) into NRF.\nThe Serving Area indicates the area where MTLF is to collect the raw data.\nPreferred Time Period for FL indicates when the MTLF prefers to participate in Horizontal Federated Learning, e.g. based on local configuration.\nThe figure depicts a horizontal Federated Learning Training triggered by MTLF with FL Server capability, illustrating the process of training machine learning models in a federated learning setting. The figure includes various components such as the FL Server, MTLF, and the FL Training process, which are essential for achieving federated learning.\nFigure 6.53.2.2-1: Horizontal Federated Learning Training triggered by MTLF with FL Server capability\n1.\tThe AnLF subscribes to a trained ML Model associated with a Analytics ID by invoking the Nnwdaf_MLModelProvision(Analytics ID, ML model Filter(S-NSSAI, Area of Interest)) service operation.\nThe parameter Area of Interest provided by ANLF (as listed in clause 6.2A.2, TS 23.288 [5]) requests the MTLF1 with FL server to train the ML model associated with the Analytics ID based on the collected data over the Area of Interest.\nAs the MTLF1 with FL server lacks of data over the Area of Interest requested by the AnLF, it determines that training based on Horizontal Federated Learning is needed and is to discover multiple MTLF with FL client which have the data of the area of interest and could be used for Horizontal Federated Learning via the NRF.\n2-5.\tThe MTLF1 with FL server acting as coordinator is to discover multiple MTLF with FL client which could be used for Horizontal Federated Learning clients via the NRF by invoking the Nnrf_NFDiscovery_Request (an Analytics ID, Horizontal Federated Learning Indication, Serving Area, Time Period of Interest) service operation.\nThe NRF notifies the MTLF1 with FL server with the information of multiple MTLF with FL client, which is used to kick off Horizontal Federated Learning procedure as defined in 6.53.5 in details.\n6.\tThe MTLF1 with FL server notifies the AnLF with the trained ML model information (a file address of the trained ML model) by invoking Nnwdaf_MLModelProvision_Notify service operation.\nThe figure depicts a horizontal federated learning training scenario with a focus on horizontal federated learning (HFL) with a FL client capability. It illustrates the training process triggered by a MTLF, where the FL client is responsible for training the model. The figure includes a horizontal federated learning training scenario with a FL client capability, highlighting the training process triggered by a MTLF.\nFigure 6.53.2.3-1: Horizontal Federated Learning Training triggered by MTLF only with FL Client capability\n1.\tThe AnLF subscribes to a trained ML Model associated with a Analytics ID by invoking the Nnwdaf_MLModelProvision(Analytics ID, ML model Filter(S-NSSAI, Area of Interest)) service operation.\nThe parameter Area of Interest provided by ANLF (as listed in clause 6.2A.2, TS 23.288 [5]) requests the MTLF0 with FL Client to train the ML model associated with the Analytics ID based on the collected data over the Area of Interest.\nAs the MTLF0 with FL Client lack of data over the Area of Interest requested by the AnLF, it determines that training based on Horizontal Federated Learning is needed.\nIn addition, as the MTLF0 with FL Client cannot act as FL server and consequently query NRF to find out the MTLF1 with FL server, who is requested by the MTLF0 with FL Client to kick off Horizontal Federated Learning procedure.\nStep 2-5 are same with step2-5 as defined in clause 6.53.3.\n6.\tThe the MTLF1 with FL server notifies the MTLF0 with FL Client with the trained ML model information (a file address of the trained ML model).\nThe MTLF0 with FL Client notifies the AnLF with the trained ML model information (a file address of the trained ML model) by invoking Nnwdaf_MLModelProvision_Notify service operation.\nThe figure depicts a horizontal federated learning training procedure, illustrating the steps involved in training a machine learning model. It includes a step-by-step guide on how to perform federated learning, which involves training a model on a distributed dataset and then sharing the weights of the model across multiple participants. The figure provides a visual representation of the process, making it easier to understand and follow.\nFigure 6.53.2.4-1: Horizontal Federated Learning training procedure\n1.\tBased on the response from NRF as specified in step 7, clause 6.53.1.2, the MTLF1 with FL server acting as coordinator selects multiple MTLF with FL client to kick off Horizontal Federated Learning procedure by sending a request to the selected MTLF with FL client including parameters such as analytics ID, model instance ID for the FL trained model, initial ML model, data type list, maximum response time window, model filter information for each MTLF with FL clients to retrieve local ML model, the number of iterations for each MTLF with FL client per training round, etc.\n2.\tEach selected each MTLF with FL client collects its local raw data with the mechanism defined in clause 6.2, TS 23.288 [5].\n3.\tDuring Federated Learning training procedure, the selected MTLF with FL client trains the retrieved ML model with its local raw data over the its own serving area and reports the results of ML model training to the MTLF1 with FL server acting as coordinator.\n4.\tThe MTLF1 with FL server acting as coordinator aggregates all the local ML model training results retrieved at step 3 to update the ML model.\n5-6.\tThe MTLF1 with FL server acting as coordinator sends the aggregated ML model information (updated ML model) to the selected MTLF with FL client, which is used by each selected MTLF with FL client to update the local own ML model in itself).\nNOTE 1:\tThe steps 3-6 should be repeated until the training termination condition is reached e.g. based on maximum number of iterations configured by the MTLF1 with FL server acting as coordinator.\nNOTE 2:\tThe aspects of model sharing between MTLF with FL server and MTLF with FL client should be aligned with key issue #5.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.53.3\tImpacts on existing nodes and functionality",
                            "text_content": "MTLF with FL client:\n-\tregister the \"FL capability, Serving Area, Supported Time Period for FL\" in NF profile to NRF.\n-\tsupport local ML training based on instruction from the MTLF acting as coordinator.\n-\tsupport to report the trained interim ML model to NWDAF(MTLF) acting as coordinator.\n-\tsupport MTLF with FL Server discovery procedure.\nMTLF with FL server acting as coordinator:\n-\tregister the \"FL capability, Serving Area, Supported Time Period for FL\" in NF profile to NRF.\n-\tsupport MTLF with FL client discovery procedure.\n-\tsupport to send FL request to MTLF with FL client.\n-\tsupport to aggregate the interim ML model from MTLF with FL client.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.54\tSolution #54: Finer granular location information based on LCS input data",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.54.1\tDescription",
                            "text_content": "As described in the TS 23.288 [5], currently the preferred granularity of location information is either on TA level or cell level, however, below use case demands more precious location information.\n-\tMeasuring the number of viewers who see outdoor advertisements: In order to measure the users who see the advertisement in a specific location, statistical information of a specific location is required to estimate the viewers of an advertisement.\n-\tInference of taste and recommendation based on visited places: It is important to consider the location information before sending the recommendation. The exact location is crucial for deriving the analysis for location-based services (for example, mydaiz service provided by NTT DOCOMO).\nNOTE:\tThe use cases based on the finer granularity location information is reflecting the common characteristics of plenty of users under the user consent monitoring. However, in some particular cases (i.e. only one user in the scope of the statistics), the user's privacy information is not allowed to be exposed directly unless the permission of the user.\nIn this solution, it is defined location granularity and location accuracy granularity as:\n-\tLocation granularity:\n-\tTA level;\n-\tCell level;\n-\tGeographic Location and Dispatchable Location as described in clause 4.2 of TS 22.071 [6].\n-\tLocation accuracy granularity:\n-\tHorizontal Accuracy, Vertical Accuracy and Dispatchable Location accuracy as described in clause 4.3 of TS 22.071 [6].\nThe location information can be UE specific or group of UEs in specific location, in order for NWDAF to provide analytic, therefore, we propose that NWDAF will act as an LCS client and extract the location from LCS system (GMLC). Based on the input data from LCS, the NWDAF determine the finer granular location statistical or prediction information and provides to the consumer (such as AF or 5GC NF(s)).\nEditor's note:\tMore information about input and output data for the finer granular location statistical or prediction information is required.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.54.2\tProcedures",
                            "text_content": "The figure depicts a procedure for collecting precious location data from a LCS (Local Computer System) system. It illustrates the steps involved in collecting data from various sources, such as cameras, sensors, and other devices, to ensure accurate and reliable location information. The figure includes a flowchart and a list of steps, providing a clear and concise visual representation of the process.\nFigure 6.54.2-1: Procedure for a precious location collection from LCS system.\n1.\tThe NF consumer sends the Nnwdaf_AnalyticsInfo to the NWDAF. The Analytics ID is set to either existing UE location analytic ID (e.g. UE Communication Analytics) or a new precious location analytic, the Target of Analytics Reporting is set according to clause 6.5.1 of TS 23.288 [5] and Analytics Filter Information include Location granularity and Location accuracy granularity. The NF can request statistics or predictions or both and can provide a time window.\n2-3.\tNWDAF selects the LCS NF (GMLC) with UE location information as described in clause 5 of TS 23.273 [13] and collects the UE location information from LCS system as described in clause 6.1 of TS 23.273 [13].\n4.\tBased on the collected data, the NWDAF determine the UE location statistics and/or predictions and provides to the consumers.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.54.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "The NWDAF need to expose the new analytic ID with new filter information, or enhancements are needed to the existing analytic ID with new filter information such as Location granularity and Location accuracy granularity. Furthermore, NWDAF needs to collect the input data from the LCS system e.g. NWDAF will act as a LCS client and gets the input data.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.55\tSolution #55: location information with finer granularity in horizontal and vertical directions",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.55.1\tDescription",
                            "text_content": "The UE location information provided to NWDAF is only TA/cell granularity. However, NWDAF needs horizontal accuracy and the vertical accuracy with finer granularity than TA or cell level. For example, in a large interchange bridge, the horizontal accuracy and the vertical accuracy with TA/cell granularity of the UE location information is not enough to produce an accurate analytics or advice.\nFor accurate analytics or advice, the granularity of location information provided to NWDAF should be finer than TA/cell level. This solution proposes a procedure to enhance the NWDAF with finer granularity of location information and add extra input data to complete itself.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.55.2\tInput Data",
                            "text_content": "This solution helps the consumer NF to obtain UE location analytics also the NWDAF to obtain location information with finer granularity than TA/cell. Considering scenarios like high-rise buildings and large interchange bridges, it is beneficial to distinguish the UE velocity, granularity choice and UE location in horizontal and vertical directions.\nThe location related data are defined in Table 6.55.2-1.\nTable 6.55.2-1: Input data for location information with finer granularity in horizontal and vertical directions\n\nNOTE 1:\tAfter adding location information with finer granularity than TA/cell, there are 3 different data granularities can be chosen: TA level, cell level or finer granularity than TA/cell level. Besides, location information in horizontal and vertical directions can have different granularities.\nNOTE 2:\tIf granularity choice is TA/cell level, the source of UE location related data is AMF; If granularity choice is finer granularity than TA/cell level, the source of UE location related data is LCS architecture.\nNOTE 3:\tBecause there can be different granularities in different directions, UE location in 2 directions also can have different granularities. If granularity choices in horizontal and vertical directions are both TA/cell level, UE locations in horizontal and vertical directions are the same TA/cell. Otherwise, UE locations in horizontal and vertical directions are different, for example, UE location in horizontal direction is TA/cell and UE location in vertical direction is with finer granularity than TA/cell.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.55.2-1: Input data for location information with finer granularity in horizontal and vertical directions",
                                    "table number": 48,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.55.3\tOutput Data",
                            "text_content": "The output are defined in Table 6.55.3-1 and Table 6.55.3-2.\nTable 6.55.3-1: Location information with finer granularity in horizontal and vertical directions statistics\n\nTable 6.55.3-2: Location information with finer granularity in horizontal and vertical directions predictions\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.55.3-1: Location information with finer granularity in horizontal and vertical directions statistics",
                                    "table number": 49,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.55.3-2: Location information with finer granularity in horizontal and vertical directions predictions",
                                    "table number": 50,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.55.4\tProcedures",
                            "text_content": "Figure 6.55.4-1 illustrates the procedure for location information with finer granularity in horizontal and vertical directions.\nThe figure depicts a procedure for location information with finer granularity in horizontal and vertical directions, illustrating the use of a 3D grid to represent the location of objects. The grid is divided into 10x10x10 cells, each representing a 10x10x10m area. The figure shows the grid lines, the 10x10x10m grid cells, and the 10x10x10m grid cells within the 10x10x10m area. The figure is used to represent the location of objects in a 3D space, allowing for more detailed and precise location information.\nFigure 6.55.4-1: Procedure for location information with finer granularity in horizontal and vertical directions\n1.\tThe consumer NF sends a request (Analytics ID = finer granularity in 2 directions, Target of Analytics Reporting = UE id, Analytics Filter Information = AOI) to the NWDAF for analytics information using either the Nnwdaf_AnalyticsInfo or Nnwdaf_AnalyticsSubscription service. The request carries what kind of granularities the consumer asks for in horizontal and vertical directions and two directions can have different granularity demand.\n2a.\tIf the granularity of UE location in horizontal or vertical direction is finer than TA/cell, NWDAF collects input data related to UE location from the LCS.\n2b.\tIf the granularity of UE location in horizontal or vertical direction is TA/cell level, the UE location data is collected from the AMF.\n3.\tThe NWDAF derives requested analytics.\n4.\tThe NWDAF provides requested finer granularity in 2 directions analytics to the NF, using either the Nnwdaf_AnalyticsInfo_Request response or Nnwdaf_AnalyticsSubscription_Notify, depending on the service used in step 1. The details for the analytics provided by NWDAF are defined in output analytics.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.55.5\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF:\n-\tThe NWDAF can collect input data related to UE location with finer granularity than TA/cell level from the LCS.\n-\tThe NWDAF can support the analytics ID for finer granularity in 2 directions.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.56\tSolution #56: PSAP resolution with finer granularity of location information",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.56.1\tDescription",
                            "text_content": "This solution addresses Key issue #9: Enhancement of NWDAF with finer granularity of location information. This solution proposes a use case about PSAP (Public Safety Answering Point) resolution for emergency services with finer granularity of location information.\nEditor's note:\tIt is FFS if this use case requires analytics about UE location or only the UE location when emergency communication was initiated from that UE. Is it realistic that a UE can start emergency communication, but the UE location cannot be determined?\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.56.2\tFunctional description",
                            "text_content": "At a high level, the functional description of this solution is as follows:\n-\tUE initiates an emergency session request with including emergency URI and Cell Global Identification (CGI) with existing procedure.\n-\tIf required, IMS network access to the NWDAF to retrieve the PSAP destination with the estimated UE's location with finer granularity than Cell/TA level\n-\tThe IMS network uses the routing information returned by the NWDAF to route the emergency session request towards the appropriate PSAP.\nInput data (example):\n-\tUE ID\n-\tCell Global Identification (CGI)\n-\tUE location info (if available)\nOutput data (example):\n-\tPSAP destination\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.56.3\tProcedures",
                            "text_content": "The figure depicts the emergency session establishment procedure using NWDAF (Network Wide Data Access Facility), which is a protocol used in 5G networks to enable seamless data access across the network. The figure illustrates the steps involved in establishing an emergency session, including the use of NWDAF to ensure data transmission is not disrupted in case of network failures.\nFigure 6.56.3-1: Emergency Session Establishment procedure with using NWDAF\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.56.4\tImpacts on services, entities and interfaces",
                            "text_content": "Existing Emergency service procedure will be updated to acquire the PSAP destination with the finer granularity of location info than Cell ID/TA level.\nNWDAF:\n-\tThe NWDAF collects and analysis data from LCS and the other NFs to determine UE location and routing information.\n-\tThe new Analytic ID supporting the PSAP resolution use case needs to be supported.\nEditor's note:\tThe name of new analytic ID is FFS.\nEditor's note:\tThe existing analytic ID e.g. UE mobility, can be used to address the PSAP resolution use case.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.57\tSolution #57: NWDAF determines granularity when the consumer requests finer granularity location information",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.57.1\tDescription",
                            "text_content": "This solution mainly addresses Key issue #9: Enhancement of NWDAF with finer granularity of location information.\nIn the current eNA specification, the NWDAF consumer delivers its requirement for data collection, analytics, prediction, and so on. On the one hand, many existing analytics IDs, such as Service Experience, UE Mobility, and Dispersion Analytics, support NWDAF consumers by providing the preferred granularity of location information. Some potentially new analytics IDs may also need to provide preferred granularity of location information.\nOn the other hand, the consumers can also request a parameter like LCS QoS to express a more specific requirement when collecting UE location information. The NWDAF can in return to reflect QoS level to the consumers, helping consumers judge the situation of the current interaction link between NWDAF and LCS architecture.\nThis solution will introduce more granularity options and LCS QoS and by taking analytics ID = UE mobility as an example, which can also be applicable for the analytic ID where the consumer includes the preferred granularity of location information in the request message.\nThe consumer of these analytics may indicate in the request:\n-\tAnalytics ID = \"UE Mobility\";\n-\tTarget of Analytics Reporting: a single UE (SUPI) or a group of UEs (an Internal Group ID);\n-\tAnalytics Filter Information optionally containing:\n-\tArea of Interest (AOI): restricts the scope of the UE mobility analytics to the provided area;\n-\tVisited Area(s) of Interest (visited AOI(s)): additional filter to only consider UEs that are currently (i.e. now) in the \"AOI\" and had previously (i.e. in the \"Analytics target period\") been in at least one of the Visited AOI(s). If this parameter is provided, the Analytics target period shall be in the past (i.e. supported for statistics only);\nNOTE:\tIf finer granularity location information is needed, the detail of the exact target area (i.e. AOI), which is defined with finer granularity, may be determined and provided by NWDAF consumers and then delivered by NWDAF to the LCS architecture, including the shape of the target area and the coordinates of latitude and longitude and other information related to the target area. In addition, the NWDAF consumers may provide the coordinates of latitude and longitude associated with area accuracy to allow the LCS architecture to report the UE location within the tolerant granularity.\n-\tAn Analytics target period indicates the time period over which the statistics or predictions are requested;\n-\tOptionally, maximum number of objects;\n-\tPreferred level of accuracy of the analytics;\n-\tPreferred order of results for the time slot entries: ascending or descending time slot start;\n-\tOptionally, preferred granularity of location information: TA level, cell level, or different granularity options. The different granularity may be mapped into different accuracy requirements in the LCS;\n-\tOptionally, preferred LCS QoS: This information is included when the preferred granularity of location information is finer than TA/cell level; and\n-\tIn a subscription, the Notification Correlation Id and the Notification Target Address are included.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.57.2\tInput Data",
                            "text_content": "If the finer granularity location information is required, the NWDAF retrieves location information from LCS architecture. The preferred granularity can be mapped into the accuracy of the location operation and the preferred LCS QoS can be mapped into LCS QoS.\nThe detailed information collected by the NWDAF could be MDT data from OAM, network data from 5GC and/or service data from AFs:\n-\tUE mobility information from OAM is UE location carried in MDT data.\n-\tNetwork data related to UE mobility from 5GC is UE location information, UE location trends or UE access behaviour trends, as defined in the Table 6.57.2-1.\nTable 6.57.2-1: UE Mobility information collected from 5GC\n\n-\tService data related to UE mobility provided by AFs is defined in the Table 6.57.2-2.\nTable 6.57.2-2: Service Data from AF related to UE mobility\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.57.2-1: UE Mobility information collected from 5GC",
                                    "table number": 51,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.57.2-2: Service Data from AF related to UE mobility",
                                    "table number": 52,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.57.3\tOutput Analytics",
                            "text_content": "The NWDAF provides UE mobility analytics to consumers under the preferred granularity and preferred LCS QoS and so on. The analytics results provided by the NWDAF could be UE mobility statistics as defined in Table 6.57.3-1, UE mobility predictions as defined in Table 6.57.3-2:\nTable 6.57.3-1: UE mobility statistics\n\nTable 6.57.3-2: UE mobility predictions\n\nHere are two options to enable the NWDAF only collect or count the valid UE location data wherein the UE location exactly locates the target area:\nOption A: LCS scheme. The LCS architecture takes the responsibility to provide valid UE location data. The LCS architecture only triggers the area event reporting to the NWDAF when the UE locates in the exact target area defined by NWDAF or the NWDAF consumer;\nNOTE 1:\tThis option will have some coordinates work with the eLCS_Ph3. A solution addressing this scheme is proposed in eLCS_Ph3(Sol#35).\nOption B: NWDAF scheme. The NWDAF makes the judgment whether the UE location is in the exact target area or not. In this scheme, the LCS architecture still reports the UE location based on the current mechanism to the NWDAF (e.g. the UE location may not be in the target area.). Then the NWDAF makes the judgment based on the UE location and the target area. The judgment means the NWDAF only counts the valid UE location data and discards the other invalid UE location data. This scheme requires the NWDAF to take one more step of responsibility to count the valid UE location data.\nNOTE 2:\tThis requirement, enabling the NWDAF only collect or count the valid UE location data wherein the UE location exactly locates the target area, can also be applicable for the analytic IDs where the consumer includes the AOI defined with finer granularity in the request message.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.57.3-1: UE mobility statistics",
                                    "table number": 53,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.57.3-2: UE mobility predictions",
                                    "table number": 54,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.57.4\tProcedures",
                            "text_content": "Figure 6.57.4-1 depicts a procedure for finer location information analytics service provided by NWDAF.\nThe figure depicts a set of parameters enhancement options for a fine location request in a telecommunication network. The options include \"Fine location\" and \"Fine location with additional information.\" The fine location enhancement is indicated by a red dot, while the fine location with additional information is indicated by a green dot. The figure illustrates the process of selecting the appropriate enhancement option based on the user's needs.\nFigure 6.58.4-1: Parameters enhancement when the finer location information is requested\n1.\tThe consumer requests finer location information statistics or predictions. The parameters like preferred granularity, preferred LCS QoS, and other parameters are carried in the request message. The preferred LCS QoS is included only when the preferred granularity is finer than TA/cell level.\n2.\tThe NWDAF collects mobility information from LCS architecture. The LCS architecture returns the UE location information and achieved LCS QoS to the NWDAF.\n3.\tThe NWDAF initiates location information analysis under the preferred granularity and preferred LCS QoS.\n4.\tThe NWDAF provides the statistics or the prediction to the consumers in the output analytics. The NWDAF can also predict the achieved LCS QoS in the future time.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.57.5\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF:\n-\tThe NWDAF supports more granularities in the preferred granularity of location information and preferred LCS QoS when the consumers request finer location information.\nLCS:\n-\tThe LCS architecture supports providing LCS QoS and finer location information to NWDAF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.58\tSolution #58: Supporting UE mobility analytics with finer granularity than TA/cell",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.58.1\tDescription",
                            "text_content": "If the NWDAF requires to provide UE mobility analytics with finer granularity than TA/cell then the NWDAF can interface with the GMLC/AMF to obtain location information using the LCS procedures. In such scenario the NWDAF interface with a GMLC to obtain location information for a UE. Another approach is that the NWDAF acts as a GMLC client and obtain location information directly from the AMF.\nIn the LCS procedures as specified in TS 23.273 [13], a consumer may request a deferred location request requesting to be notified of a location of a UE when specific events associated to a target UE take place. The following types of events are defined:\na)\tUE availability: Any event in which the 5GCN has established a contact with the UE. This event is considered to be applicable when the UE is temporarily unavailable due to inaction by the user, or for temporarily loss of radio connectivity or IMSI detach and so on.\nb)\tArea: An event where the UE enters, leaves or remains within a pre-defined geographical area.\nc)\tPeriodic Location: An event where a defined periodic timer expires in the UE and activates a location report.\nd)\tMotion: An event where the UE moves by more than some predefined straight line distance from a previous location. The motion event may be reported one time only, or multiple times.\nThe existing UE mobility analytics provided by the NWDAF can be additionally enhanced to collect location information for one or more UEs (or any UE) using the deferred location events supported by the eLCS architecture. Such scenario is useful if the consumer requires to be aware of the UE mobility trends in a target area. For example, a consumer may require to be aware of mobility analytics of UEs that are in motion in a target area.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.58.2\tProcedures",
                            "text_content": "If a consumer requires UE mobility analytics with finer granularity than TA/cell then the following apply.\nThe figure depicts a network architecture supporting UE mobility analytics, taking into account mobility trends. It includes key components such as base stations (BTS), mobile edge computing (MEC), and cloud-based analytics. The architecture is designed to support real-time analysis of UE mobility, enabling efficient network management and optimization.\nFigure 6.58.2-1: Supporting UE mobility analytics taking into account mobility trends\n1.\tA Consumer requires UE mobility analytics taking into account UE mobility trends or specific pre-defined geographical area of a UE or group of UEs or UEs in a target area.\n2.\tConsumer sends a request for analytic including the analytic ID and as analytic filters.\n-\tA target area.\n-\tMotion Event Criteria specifying a threshold linear distance that the UE must make before the UE provides a location.\n3.\tThe NWDAF requests location reports from the GMLC/AMF using eLCS location procedures as described in TS 23.273 [13]. The NWDAF includes in the request to provide location information only if a motion event has been met as requested by the consumer in step 2. The NWDAF also collect location data from the AMF as per existing UE mobility analytics specified in TS 23.288 [5].\n4.\tNWDAF derives UE mobility analytics.\n5.\tAnalytics are reported to the consumer NF.\nThe following input data are required by the NWDAF to measure UE mobility analytics for specific UE mobility trends in addition to the input data defined in clause 6.7.2.2 of TS 23.288 [5].\nTable 6.58.2-1: Location measurement from LMF (via AMF)\n\nThe UE mobility analytics output to a consumer include the following, in addition to the analytic output data defined in clause 6.7.2.3 of TS 23.288 [5].\nTable 6.58.2-2: UE mobility statistics\n\nTable 6.58.2-3: UE mobility predictions\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.58.2-1: Location measurement from LMF (via AMF)",
                                    "table number": 55,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.58.2-2: UE mobility statistics",
                                    "table number": 56,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.58.2-3: UE mobility predictions",
                                    "table number": 57,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.58.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tNWDAF supporting eLCS SBI to retrieve UE location information from GMLC/AMF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.59\tSolution #59: Enhancement of NWDAF with location accuracy prediction",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.59.1\tFunctional Description",
                            "text_content": "This solution addresses the KI \"Key Issue #9: Enhancement of NWDAF with finer granularity of location information\".\nEditor's note:\tThis paper is only focused on NWDAF enhancement. For LCS related part coordination with eLCS_ph3 is needed and eNA_ph3 will start work only if eLCS_ph3 makes progress with stable outcome.\nIn eLCS_ph3 KI#4 interim conclusion relying on the present solution proposal have been agreed:\nNWDAF provides new analytics for Location Estimation Accuracy (e.g. horizontal or vertical accuracy, indoor/outdoor indication). LMF as a consumer of such analytics uses Location Estimation Accuracy analytics to determine Position Method in the area where a UE is located.\nTS 23.273 [13] defines LCS QoS to have the following attributes: (1) Location Accuracy, (2) Response time and (3) QoS Class. Among these, the QoS Class attribute gives the requirement on the other attributes like accuracy or response time. It could take as values Best Effort, Multiple QoS Class or Assured. While the Best Effort class is the least stringent one, the other two require the LMF to determine how accurate its location estimate is.\nFor example:\n-\tin the case of \"Multiple QoS Class\", if the accuracy is less than what is required, the LMF selects an appropriate localization method (e.g. with more TRP measurements) and re-runs the location estimate in order to reach the required accuracy.\n-\tin the case of \"Assured\" QoS Class, the procedure fails if the accuracy required is not met.\nTo provide a real-time estimate of location accuracy without need for benchmark/ground truth location, we propose a data analytics-based solution running in the NWDAF with a supervised Machine Learning model (e.g. Neural Network).\nA training should be first performed on the selected ML model with labelled data, i.e. input data with corresponding output data:\n-\tInput data: positioning estimate by two positioning methods, one of them (e.g. GPS information) used as ground truth to evaluate the accuracy of the other method and optionally: used positioning method, assistance data, UE ID, Area, see Table 6.59.1-1.\n-\tOutput data: corresponding accuracy (calculated with benchmark method such as the output of MDT), see Table 6.59.1-2.\nOnce the model is trained, there is no more need for ground truth (e.g. GPS information). This model is then subsequently used by the LMF to determine if its location estimate meets the accuracy required and take appropriate action. To enable this, the LMF makes use of a Service Based API that is exposed by the NWDAF.\nThe input data for the Location Accuracy analytics is shown in Table 6.59.1-1\nTable 6.59.1-1: Data collection for \"Location accuracy\" analytics\n\nThe Location Accuracy service output is defined in Table 6.59.1-2.\nTable 6.59.1-2: Output analytics for \"Location accuracy\"\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.59.1-1: Data collection for \"Location accuracy\" analytics",
                                    "table number": 58,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.59.1-2: Output analytics for \"Location accuracy\"",
                                    "table number": 59,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.59.2\tProcedure",
                            "text_content": "The figure depicts a location accuracy prediction and usage system, illustrating the various factors that influence the accuracy of location prediction. The system includes a location prediction model, a location accuracy prediction module, and a usage module, which are interconnected to provide real-time location accuracy predictions. The system's architecture is designed to be modular, allowing for easy integration and customization.\nFigure 6.59.2-1: Location accuracy prediction and usage\nPre-condition: NWDAF has a trained supervised ML model for predicting location accuracy.\n1.\tLCS Client requests to LMF the UE location with QoS Class set as either \"Multiple QoS Class\" or \"Assured\" along with the location accuracy required. The expected behaviour from the LMF is as given in clause 6.59.2.\n2.\tThe LMF initiates the LCS session as given in TS 23.273 [13] and derives the UE location estimate.\n3.\tThe LMF queries the NWDAF for the location accuracy giving as inputs the corresponding Analytics ID . Other inputs could be - location estimate, UE positioning method/assistance data and area (cell ID/TAI).\nNOTE 1:\tBoth Nnwdaf_AnalyticsSubscription and Nnwdaf_AnalyticsInfo services can be used to implement step 3. above. The Nnwdaf_AnalyticsSubscription service can be used by a service consumer to receive notifications about location accuracy, e.g. when a change is detected.\n4.\tThe NWDAF uses the corresponding model trained in the precondition and provides the location accuracy as the output to the LMF.\n5.\tLMF compares the location accuracy received in step 3 with the required location accuracy received in step 1 from the LCS Client.\n6.\tIf the required location accuracy is not met, the LMF takes subsequent actions like re-executing the LCS procedure with more stringent parameters (for example: higher periodicity measurements).\n7.\tThe LMF returns the location estimate with the required accuracy.\nNOTE 2:\tThe offline training gives the ML model the ability to predict the location accuracy without the need for a reference location estimate. This is made possible by the extensive training done using various accuracy/reference values, which result in the computing of weights in the ML model. Such a trained model can then be used for an inference/prediction of the location accuracy in this step 3.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.59.3\tImpacts on services, entities and interfaces",
                            "text_content": "NWDAF:\n-\tSupports a new Analytics ID for determining Location Accuracy.\n-\tSupports subscription from NFs like LMF to make use of this Analytics.\n-\tSupports data collection from LMF to generate the output of this Analytics.\nLMF:\n-\tprovide positioning estimates, preferably estimates (i.e. estaimates for the same UE at the same time) by several positioning methods.\n-\tConsume new Analytics ID to derive accuracy etimates for the less precise poitioning method.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.60\tSolution #60: Interactions with MDAF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.60.1\tDescription",
                            "text_content": "MDAS/MDAF functionality enables a service consumer to obtain management data analytics, and NWDAF can be one of such service consumers.\nFor Overserved Service Experience analysis, NWDAF can leverage the service experience analytics output from MDA defined in clause 8.4.2.1.3 of TS 28.104 [15] in addition to the input as described in clause 6.4.2 of TS 23.288 [5]. And also, analytics output for energy saving analysis, such as StatisticsOfCellsEsState, is the statistic result of current energy saving state of the cells at a certain time, which can be used by consumers to make analysis (e.g. observed service experience analysis made by NWDAF) as described in clause 8.4.4.3 of TS 28.104 [15].\nFor Redundant Transmission Experience related analytics, NWDAF can leverage the E2E latency analysis output from MDA as defined in clause 8.4.2.4.2 of TS 28.104 [15] in addition to the input as described in clause 6.13.2 of TS 23.288 [5].\nNWDAF collects following MDAF analytics output from clauses 8.4.2.1.3 and 8.4.4.3 of TS 28.104 [15] for Overserved Service Experience for a network slice in Table 6.60.1.1-1.\nTable 6.60.1.1-1: Data collection from MDAF for Service Experience analytics\n\nNWDAF collects following MDAF analytics output in clause 8.4.2.4.3 of TS 28.104 [15] for Redundant Transmission Experience related analytics in Table 6.60.1.1-2.\nTable 6.60.1.1-2: Data collection from MDAF for Redundant Transmission Experience related analytics\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.60.1.1-1: Data collection from MDAF for Service Experience analytics",
                                    "table number": 60,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.60.1.1-2: Data collection from MDAF for Redundant Transmission Experience related analytics",
                                    "table number": 61,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.60.2\tProcedures",
                            "text_content": "For Observed Service Experience related network data analytics, the procedure in Figure 6.4.5-1 of TS 23.288 [5] is re-used with additional data collection step from MDAF as defined in TS 28.104 [15].\nFor Redundant Transmission Experience related analytics, the procedure in Figure 6.13.4.1-1 of TS 23.288 [5] is re-used with additional data collection step from MDAF as defined in TS 28.104 [15].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.60.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.61\tSolution #61: Improving correctness by retrieval ML model from ADRF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.61.1\tDescription",
                            "text_content": "This solution addressed Key Issue #1 \"How to improve correctness of NWDAF analytics\" and Key Issue #4 \"How to Enhance Data collection and Storage \".\nThe correctness of NWDAF analytics largely depends on the accuracy of corresponding ML model. In most scenarios, if the training data and testing data of a ML model have different model information (e.g. area, time period, etc.), the accuracy of this ML model will be very low. This is because the distribution of data with different model information is different. It has been proved in many papers that using a historical ML model (with different model information) as Priori Knowledge and train it upon new datasets can achieve higher accuracy than retrain a new ML model(e.g. transfer learning). For example, it has been proved that using the historical model \"Xception\" as baseline model and using only 2000 pictures to conduct some further training can improve the top-5 accuracy from 94.5% to 99.1%.\nWhen an NWDAF containing MTLF receives ML model request from an NWDAF containing AnLF, it may have neither directly usable model that match the filter information, nor existing model that need further traininglocally. In this scenario, the NWDAF containing MTLF can achieve higher accuracy to do some further training on a previously stored ML model(may not match the filter information) than train a new ML model.\nFirst, the ADRF should be able to store ML model and send the ML model with wider range than the ML model filter information using new services of ADRF for ML model storage and provisioning. For example, the Area of interest of NWDAF containing MTLF is TA-1,2, while there are two ML models whose Spatial validity is TA-1,2,3 and TA-2,3,4 in the ADRF. The ADRF should consider the ML models whose Spatial validity is TA-1,2,3 can match the filter information. Then the ADRF should be able to send this ML model to NWDAF containing MTLF.\nSecond, the NWDAF containing MTLF should be able to modify the ML filter information received from the NWDAF containing AnLF, and the logic of the NWDAF containing AnLF are not affected (request/subscribe ML model to the NWDAF containing MTLF). For example, the Area of Interest in the filter information is TA-1,2, while the Spatial validity of a ML model is TA-2,3, which has included features of TA-2 but with extra feature of TA-3. If the difference between the data distribution of TA-1 and TA-3 is not particularly large (e.g. TA-1 and TA-2 are geographically adjacent), The NWDAF containing MTLF will achieve higher accuracy to do further training on the ML model than train a new ML model. The NWDAF may modify the Area of Interest from TA-1,2 to TA-2 (The NWDAF containing MTLF do not know the Spatial validity of ML models in ADRF. The NWDAF containing MTLF modify the filter information based on internal logic). The filter information mentioned in this solution includes the model characteristics (e.g. model performance such as model accuracy or MAE).\nThe following functionalities should be considered:\n-\tADRF should support ML model storage including the Analytics ID, ML model file, ML model serialization format, Validity period, Spatial validity, model performance (e.g. model accuracy or MAE) and other related information.\n-\tADRF should be able to create an identification (model ID) for each ML model stored in it.\n-\tADRF should be able to send ML model with wider range than the filter information to NWDAF containing MTLF.\n-\tNWDAF containing MTLF should be able to change the filter information received from NWDAF containing AnLF appropriately based on local configurations.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.61.2\tProcedures",
                            "text_content": "The figure depicts a procedure for retrieving a machine learning model from an ADRF (Automated Data Repository for Machine Learning) system. The figure shows a step-by-step process for accessing and retrieving the model, including the steps for data preparation, model selection, and model evaluation. The figure is a visual representation of the process, making it easy to understand and follow.\nFigure 6.61.2.1-1: Procedure for ML model Retrieval From ADRF\n1.\tThe NWDAF containing AnLF sends Nnwdaf_MLModelInfo_Request to NWDAF containing MTLF as described in clause 6.2A.3 of TS 23.288 [5].\n2.\tIf the NWDAF containing MTLF determines that no existing ML model can be used and determines to retrieval ML model(s) from ADRF, the steps 3,4,5 are performed. If the NWDAF containing MTLF determines that an existing model can be used for the request or an existing ML model needs further training, the steps 3,4,5 are skipped.\n3.\tThe NWDAF containing MTLF modify the filter information received from NWDAF containing AnLF appropriately. The NWDAF containing MTLF may take one of the following modification:\n-\tTurn one or some of the filter information(e.g. S-NSSAI, model performance) received from NWDAF containing AnLF to \"OPTIONAL\" or just remove one or some of the filter information.\n-\tChange the range of one or some of the filter information. For example, if the difference between the data distribution of TA-1 and TA-3 is not particularly large (e.g. TA-1 and TA-2 are geographically adjacent), the NWDAF containing MTLF may modify the Area of Interest from TA-1,2 to TA-2 so that it can retrieval a ML model from ADRF whose Spatial validity is TA-2,3.\nNOTE:\tThe NWDAF containing MTLF do not know the Spatial validity, Validity period and other information of the ML models stored in ADRF in this step. The specific algorithm to modify the filter information should be determined by NWDAF containing MTLF based on internal configuration, which is not included in this solution.\n4.\tThe NWDAF containing MTLF utilize the NRF to discover ADRF instance unless ADRF information is available by other means, e.g. locally configured in the NWDAF containing MTLF. The NWDAF containing MTLF may consider the following factors: S-NSSAI, Analytics ID, ML model information (e.g. Spatial validity ), etc.\n5.\tThe NWDAF containing MTLF sends ML model request to ADRF using a new ADRF service (e.g. Nadrf_MLModelManagement_RetrievalRequest, similar to solution#42 but with different contents). The following parameters should be included: Analytics ID(s), the original filter information (same as the filter information received from AnLF) and the updated filter information (updated by the NWDAF containing MTLF), and other information (e.g. a notification target address, etc.). The ADRF preferentially sends the ML model that match the original filter information to the NWDAF containing MTLF. If none of the ML models stored in ADRF can match the original filter information, the ADRF sends the ML model that match the modified filter information to the NWDAF containing MTLF. In addition to the parameters defined in TS 23.288 [5] (e.g. ML model file address, Spatial validity, Validity period), the ML model ID should be included.\n6.\tIf the retrieved ML model match the original filter information, the NWDAF containing MTLF sends the ML model to NWDAF containing AnLF directly. If the ML model do not match the original filter information, the NWDAF containing MTLF need to do some further training on the ML model until the ML model can match the original filter information.\n7.\tNWDAF containing MTLF sends Nnwdaf_MLModelInfo_Request response to NWDAF containing AnLF as described in clause 6.2A.3 of TS 23.288 [5].\n8.\tIf the NWDAF containing MTLF trained a new ML model or did some further training on a ML model stored in ADRF, the NWDAF containing MTLF may, send a request to ADRF to store the new ML model. The following parameters should be included: Analytics ID, ML model file, ML model serialization format, Spatial validity, Validity period, model performance and other related information. The ADRF then assigns a model ID to this ML model. The NWDAF containing MTLF shall use a new services to store the ML model (e.g. Nadrf_MLModelManagement_StorageRequest, which is similar to solution#42 and solution#43).\nNOTE:\tWhat is provided from MTLF to ADRF should align with KI#5.\nThe ADRF may register the ML model profile to NRF using Nnrf_NFManagement_NFRegister. One or more than one of the following parameters should be included: ADRF ID, ML model ID, Spatial validity, Validity period, model performance and other related information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.61.3\tImpacts on services, entities and interfaces",
                            "text_content": "ADRF:\n-\tSupport new services for ML model storage and provisioning (e.g. Nadrf_MLModelManagement_RetrevalRequest, Nadrf_MLModelManagement_StorageRequest);\n-\tSupport responding ML model with wider range than the filter information to NWDAF containing MTLF using the new services;\nNWDAF containing MTLF:\n-\tSupport filter information modification;\n-\tSupport ML model retrieval from ADRF;\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.62\tSolution #62: Improving the correctness of analytics based on the provision of context information",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.62.1\tDescription",
                            "text_content": "In the process of generating analytics reports by NWDAF, there are cases when more than one ML model is available to choose for an analytics ID.\nMeanwhile, NFs using the NWDAF service may have very different analytical computing needs depending on the use cases. These use cases may depend on the type of user, specific circumstances, or application. At present time, the NWDAF service interface allows specifying accuracy and time window parameters, but they are not explicit enough to guide the NWDAF towards choosing a relevant analytical model for a use case. The NWDAF has no explicit way to determine for what (semantic) reason a consuming NF requests its services. An explicit indication of the use case context that provided by the analytics consumer can help the NWDAF choose the most relevant model.\nThe proposed solution consists in guiding the NWDAF by providing it an additional optional parameter \"use case context\", at the initiative of the consuming NF, which, by targeting the context of use of the requested analytics, would allow it to take the appropriate measures (for example, to select a family of statistical models). The parameter \"use case context\" is a single string or scalar (to be determined by stage 3). The value of \"use case context\" to be used in requests to NWDAF is configured in the consuming NF and is valid in the whole PLMN.\nIf the NWDAF has been preconfigured for the value of the \"use case context\" parameter provided by the consuming NF to the NWDAF during a service request, the NWDAF is immediately able to select a model family. This corresponds to the case where the operator has decided to use some specific models for this specific use case, and preconfigured the NWDAF accordingly.\nIn the opposite case (if the NWDAF does not have a preconfiguration for the \"use case context\" parameter value provided by the consumer NF), the NWDAF may refine the choice of the relevant models during the training or re-training phases, by correlating a given value of the parameter, the chosen models, and the quality of the obtained results.\nSuch an optimization of the model by learning can also be implemented by the NWDAF when the NWDAF has been preconfigured for the value of the parameter \"use case context\" provided by the consumer NF.\nWhen AnLF and MTLF are contained in different NWDAF instances, the AnLF may use the \"use case context\" to determine optimal parameters of Nnwdaf_MLModelProvision service/Nnwdaf_MLModelInfo service as described above. In this case, the MTLF does not receive the use case context.\nAlternatively, depending on the situation (e.g. the AnLF does not have a preconfiguration) and implementation, the AnLF may include the \"use case context\" in the Nnwdaf_MLModelProvision service/Nnwdaf_MLModelInfo service. In this case, the MTLF selects the ML model according to a preconfiguration for the \"use case context\" parameter value provided by the AnLF. If the MTLF does not have such preconfiguration, the MTLF ignores the \"use case context\" and provides the ML model matching other parameters.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.62.2\tProcedures",
                            "text_content": "This solution uses existing procedures.\nThe analytics consumer may add the parameter \"use case context\" in the Nnwdaf_AnalyticsSubscription_Subscribe and the Nnwdaf_AnalyticsInfo_Request service operations.\nThe AnLF may add the parameter \"use case context\" in the Nnwdaf_MLModelProvision_Subscribe and the MLModelInfo_Request service operations.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.62.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tNnwdaf_AnalyticsInfo service: new parameter \"use case context\" for the Request operation.\n-\tNnwdaf_AnalyticsSubscription Service: new parameter \"use case context\" for the Subscribe operation.\n-\tNnwdaf_MLModelProvision service: new parameter \"use case context\" for the Subscribe operation.\n-\tNnwdaf_MLModelInfo Service: new parameter \"use case context\" for the Request operation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.63\tSolution #63: Improving the correctness of NWDAF by rating the quality of the data sources",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.63.1\tDescription",
                            "text_content": "This solution addresses Key Issue #1 and especially how to detect and improve correctness of NWDAF analytics by enabling a rating of the data sources.\nSuch rating can be based on (i) local estimation/calculation between the predicted and ground-truth data, (ii) the analytics consumer feedback, or (iii) provided by an AF in the forms of weights.\nHence, NWDAF relates a rating to the data source profiles/reputation, which can be used as criterion for selecting from which sources to collect data. In the selection of the appropriate data source, the NWDAF can also use as a criterion the expected confidence degree, i.e. that relates the outcome result with the input data sources.\nSuch solution is more relevant for data sources which are not within the network operator premises to control and check easily errors and security. For these types of sources, the quality of the data needs to be checked and shall not be consumed by the NWDAF MTLF especially if there is a significant change in the data distribution or if there is a significant drift between predictions and ground truth data, which impacts the performance of the accuracy.\nThe rating process can be performed by AnLF or by a new NF, like TRLF.\nWe assume here that AnLF is not biased, towards specific data sources (e.g. same vendor data source).\nThe proposed solution only applies to the data from 3rd party data sources.\nThe proposed solution cannot be applied for all types of data sources, but only for the ones that provide performance measurements or KPIs, which can be obtained via more than one way.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.63.2\tProcedures",
                            "text_content": "This process which is depicted in Figure 6.63.2.1-1 covers the enhancements at AnLF and the storage of ratings at ADRF\nThe figure depicts a network architecture with a focus on ANLF-based rating and storage at ADRF. It illustrates the use of ANLF (Adaptive Network Function Virtualization) to manage network resources, with a focus on rating and storage. The figure shows the network's architecture, including the role of ADRF (Adaptive Data Rate Forwarding) in managing network resources.\nFigure 6.63.2-1: ANLF-based rating and storage at ADRF\nOption 1:\n1a.\tOnce an analytics consumer uses an Analytics ID, NWDAF (AnLF) requests the consumer on the feedback / evaluation of the analytics service (good or bad, experience level, success, or failure of prediction, with a possible cause).\n1b.\tNWDAF (AnLF) receives the feedback requested from the analytics consumer.\nOption 2:\n2a.\tNWDAF (MTLF) evaluates the ML model correctness and notifies NWDAF (AnLF).\n2b.\tNWDAF (AnLF) receives the notification from NWDAF (MTLF), which indicates possible low performance or correctness, and optionally requesting AnLF to further check the inference data or data sources.\n3a-3b.\tNWDAF (AnLF) conditionally (i.e. if needed) requests and receives supplementary data from different data sources (if available) to verify the data source quality or correctness. Such data can be for example performance data from the OAM which are supplementary to AF, or data from UPF supplementary from AF.\n4.\tNWDAF (AnLF) updates the rating for the sources where data is deviated from the supplementary data (or in case step 3 is not implemented) the rating is automatically changed based on the analytics feedbacks in 2b.\n5.\tNWDAF stores the ratings to ADRF or any other repository function.\n6.\tA new analytics request arrives from an analytics consumer for analytics service with a certain Analytics ID = \"xx\".\n7.\tNWDAF (AnLF) retrieves the rating for the data sources corresponding to the requested Analytics ID\n8.\tIf the rating of one or more data sources is below a threshold (pre-set), then NWDAF (AnLF) triggers an action of:\n-\tselection of an alternative data source with highest rating;\n-\trequire supplementary data from other available data sources and uses them for verification of the data from low rated data source.\n9.\tIf a new data source is needed (for the supplementary data or to serve as alternative data source based on step 8), NWDAF (AnLF) subscribes to a new data source, and requests/receives new data.\n10.\tNWDAF (AnLF) obtains the data and checks whether the confidence level is above a request threshold. The derivation of the threshold considers the rating of data sources (or an aggregated rating of the data sources based on the individual ratings).\n11.\tNWDAF (AnLF) provides the analytics output to the analytics consumer.\nEditor's note:\tThe benefit to keep the data source rating in ARDF is FFS.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.63.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tNWDAF allows a consumer to provide rating of analytics service.\n-\tNWDAF supports the discovery of problematic data sources.\n-\tOther NF, e.g. TRLF may optionally assist the rating process and supports the discovery of problematic data sources.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.64\tSolution #64: Optimize the collection and reporting of network data",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.64.1\tDescription",
                            "text_content": "This solution addresses Key Issue #4 \"How to Enhance Data collection and Storage\".\nNWDAF collects data from NF for two purposes, one is to obtain training data during model training, and the other is to obtain inference data during model inference. Research points for these key Issue therefore include:\n-\tHow to optimize the performance of training data reporting. In the model training scenario, since most of the model training is offline training, the real-time data requirements are not high, but the amount of data to be reported may be large. When the device is busy, it needs to undertake a large number of data reporting tasks, which may affect normal services. The data reporting mode is currently defined in clause 4.15.1 of TS 23.502 [3]. The parameters that can be set for reporting include: maximum number of reports, fixed reporting frequency, and maximum duration of reporting. These parameters do not consider the data reporting time. How to optimize the performance of your device.\n-\tHow to optimize the performance and accuracy of data collection in model inference scenarios. In the model inference scenario, data collection is the input and basis for model inference, but data collection consumes the performance of the collection device. According to the existing fixed collection frequency mechanism, if the collection rate is too high, it will lead to excessive consumption of network resources. On the contrary, if the rate is too low, information loss and inaccurate measurement may be caused, and accurate analysis may not be possible in some key scenarios.\nTo address the above-mentioned challenges in data collection, the solution focuses on optimizing the collection and reporting of network data. Mainly divided into the following two points:\n-\tThrough the reporting mechanism by time period, the impact on the performance of the collection equipment can be minimized while meeting the data collection requirements, and the resource capacity of the idle time is fully utilized.\n-\tBy increasing the data collection method of changing frequency, the collection period can be defined as needed, which does not increase the burden on the collection equipment, and at the same time meets the required data collection frequency requirements.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.64.2\tProcedures",
                            "text_content": "NWDAF subscribes and requests data services from NF through Nnf_EventExposure_Subscribe. After receiving the subscription request, NF collects and reports data according to the collection frequency and data reporting mode defined in the subscription message. The Event Reporting Information parameter of the Nnf_EventExposure_Subscribe message is defined in clause 4.15.1 of TS 23.502 [3].\nIn order to solve the performance optimization problem of training data reporting, the solution of this solution is as follows: when NWDAF subscribes to training data, the time period for data reporting can be configured in the subscription message of data collection, that is, data reporting is performed when the device is idle, so that both It can reduce the performance pressure on the device caused by data reporting during busy hours, and can ensure the normal collection of data. The specific measures are to add the \"reporting within time period\" option to the Event reporting mode parameter of the subscription message, and at the same time add the time period field to set the time period for data reporting. The new parameters are shown in Table 6.64.2-1 below.\nTable 6.64.2-1: New parameters added in event reporting mode parameters in model training scenario\n\nThe figure depicts a procedure for reporting training data when the device is idle, with a focus on the steps involved in reporting data and the steps to be taken when the device is not in use.\nFigure 6.64.2-1: Procedure of Training data reporting when the device is idle\n1.\tNWDAF analyses the NF load to obtain the idle time period of the device.\nNOTE:\tClause 6.5 of TS 23.288 [5] describes how NWDAF can provide NF load analytics.\n2.\tNWDAF sends a subscription message for data collection to NF, carrying collection parameters. Event reporting mode is reporting within time period. The reporting period is set to the idle time period obtained by the first step of analysis, such as time period =0:00-3:00, Nnf_EventExposure_Subscribe(Event reporting mode=reporting within time period, time period=0:00-3:00).\nNOTE:\tWhen NWDAF sends Nnf_EventExposure_Subscribe to NF producer, exception handling indication in subscription message can be included. This exception handling indication is used to indicate the handling policy when the buffer is insufficient. For details, see solution#45.\n3.\tNF collects and reports information according to the configured collection requirements. NF reports Nnf_EventExposure_Notify to NWDAF.\nIn order to optimize the performance and accuracy of data collection in the model inference scenario, the frequency of data collection can be set to the dynamic change mode. For example, in the application scenario of fault diagnosis and repair, when the network quality is good, data can be collected at low frequency and used for NWDAF's routine evaluation of the current situation. When the network quality is not good, if the collected data is insufficient, the problem may not be located. , at this time, the acquisition device can increase the acquisition frequency based on preliminary judgment criteria, such as when the fault index is greater than a certain threshold, so as to obtain more abundant fault data for root cause location and problem solving. The new parameters are shown in Table 6.64.2-2 below.\nTable 6.64.2-2: New parameters added in event reporting mode parameters in model inference scenario\n\nThe figure depicts a collection frequency adjustment chart for a specific service failure rate, illustrating the relationship between the collection frequency and the service failure rate. The chart is used to optimize the collection frequency to minimize the impact of service failures on the network.\nFigure 6.64.2-2: Adjust the collection frequency according to the service failure rate\nThe above collection frequency is set to the dynamic Non-fixed sampling ratio. The collection frequency is adjusted according to the service failure rate. The collection frequency is divided into two levels. The first level is: when the service failure rate is less than 2%, the collection frequency is once per second; the second level is: when the service failure rate is >=2%, the collection frequency is once every 50 milliseconds.\nThe figure depicts a schematic of a communication system, specifically a 5G network, with various components such as base stations (gNB), user equipment (UE), and scatterers. The diagram illustrates the signal propagation in a 5G network, highlighting the multi-path signal path and beamforming techniques to mitigate interference. The figure also shows the fiber-optic backbone architecture, with core switches, optical line terminals (OLTs), and distributed nodes. Redundancy paths are shown in dashed lines to ensure failover reliability. The layered design aligns with SDN principles.\nFigure 6.64.2-3: Adjust the acquisition frequency according to the equipment load\nThe above sampling frequency is set to the dynamic Non-fixed sampling ratio, and the sampling frequency is adjusted according to the device load. The sampling frequency is divided into three levels. The first gear is: when NF load<70%, it is the normal collection frequency, once every 5 seconds; the second gear: 70%<NF load<90%, the collection frequency is once every 20 seconds; the third gear: NF load>90 %, the collection frequency is 0, that is, no collection. When data producer NF reports events / data, it includes data sampling ratio in the event / data notification.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.64.2-1: New parameters added in event reporting mode parameters in model training scenario",
                                    "table number": 62,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.64.2-2: New parameters added in event reporting mode parameters in model inference scenario",
                                    "table number": 63,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.64.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF:\n-\tWhen NWDAF subscribes to training data, the time period of data reporting can be configured in the subscription message of data collection to report data when the equipment is idle.\n-\tWhen NWDAF subscribes to training data in the model inference scenario, the frequency of data collection can be configured in the subscription message of data collection as a dynamic change mode.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.65\tSolution #65: Optimizing data collection and storage by NWDAF registration in UDM for all Analytics IDs",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.65.1\tDescription",
                            "text_content": "As stated in clause 6.1.C of TS 23.288 [5], NWDAF triggers a registration in UDM, e.g. based on local configuration in the NWDAF, the reception of a new Analytics subscription request, start of collection of UE related data or an OAM configuration action. During NWDAF discovery (clause 5.2) a consumer may select the same NWDAF.\nThe procedures in clause 6.1.C of TS 23.288 [5] are applicable to UE-related analytics (e.g. UE mobility analytics) for some network deployments, e.g. such with an NWDAF co-located to an AMF or SMF, where the NWDAF is configured to register in UDM for the UEs that it is serving or collecting data for, and for the related Analytics ID(s). This enables NWDAF service consumers to discover the NWDAF instance that is already serving the UE for one or more Analytics ID(s).\nThe value of UDM registration is to minimize the multiple NWDAF instances serving a given UE, and thus reduce the data collection signalling and storage volume.\nHowever, the principle is limited to cases of UE-related analytics. These analytics are defined in clause 6.1.7 as UE-mobility, UE-communication, Abnormal behaviour. However, many other analytics provide data specific to a UE, and collect data on NFs that serve this UE (e.g. Observed Service Experience, User Data Congestion).\nThis solution consists in allowing the NWDAF to register in the UDM for the served UE (as specified in clause 6.1C.2 of TS 23.288 [5]), also for Analytics IDs that are not UE-related. The NWDAF may do this when the NWDAF is collecting data specific to the UE for the indicated Analytics ID. The trigger to do so is still based on local configuration.\nThis further reduces signalling due to data collection and storage volume.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.65.2\tProcedures",
                            "text_content": "This solution does not require new procedures.\nThe procedure in clause 6.1C.2 of TS 23.288 [5] is used without modification but the text introducing this procedure needs to be updated to make the procedure applicable to all Analytics ID.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.65.3\tImpacts on services, entities and interfaces",
                            "text_content": "No impact on services since no restriction is specified on the Analytics ID(s) that can be indicated in Nudm_UECM_Registration service.\nNWDAF is impacted to support UDM registration for all Analytics IDs, triggered by local configuration.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.66\tSolution #66: DCCF relocation initiated by source DCCF or central DCCF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.66.1\tDescription",
                            "text_content": "This solution addresses Key Issue #4 \"How to Enhance Data collection and Storage\".\nAccording to the definition of the Rel-17, DCCF is the data acquisition coordination node of the core network, the data acquisition area of DCCF is fixed, and the data source NF or data source NF set in the same area should be associated with only one DCCF instance or DCCF set. As described in TS 23.501 [2], multiple instances of DCCF may be deployed in a network. The NF consumers shall utilize the NRF to discover DCCF instance(s). NF consumers can select an available DCCF based on parameters such as DCCF service area information, S-NSSAI, and NF type of the data source, etc.\nIn scenarios where multiple DCCF instances are deployed in the same 5G network, there are some cases that the serving DCCF may need to be changed during the operation due to, e.g. UE mobility, change in DCCF profile, new addition or removal of DCCF instances, etc.\nWhen the data consumer subscribes to the source DCCF directly, upon change of a source DCCF instance, it is required to inform the related data consumer of the event and possibly to update subscriptions between the DCCF and the data consumer. If the central DCCF is deployed, data consumer collects UE data via the central DCCF, thus, data consumer may not need to be notified of the UE mobility events and DCCF reselection events.\nThe following figure illustrates the DCCF relocation initiated by source DCCF or central DCCF.\nThe figure depicts a relocation initiated by a source DCCF or central DCCF, with the DCCF relocation process being highlighted. The relocation is a crucial aspect of network management, ensuring the efficient movement of data packets within the network.\nFigure 6.66.1-1: DCCF relocation initiated by source DCCF or central DCCF\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.66.2\tProcedures",
                            "text_content": "The figure depicts a procedure for DCCF relocation initiated by a source DCCF or central DCCF. It illustrates the steps involved in relocating DCCF, including the identification of the source DCCF, the initiation of the relocation process, and the subsequent steps to ensure the successful relocation.\nFigure 6.66.2-1: Procedure for DCCF relocation initiated by source DCCF or central DCCF\n0.\tThe data consumer subscribes source DCCF. The data consumer sends UE(s) ID, enabling DCCF to determine whether the UE(s) data subscription transfer procedure is applicable. If the central DCCF is deployed, the data consumer subscribes to central DCCF optionally, then central DCCF discovers and selects a source DCCF. The consumer NF sets to “False” the “No relocation” indicator in the subscription request.\nNOTE:\tThe \"No relocation\" indicator is used by DCCF to determine whether to execute the relocation procedure (No Relocation set to \"False\") or not (No Relocation set to \"True\").\n1.\tSource DCCF or central DCCF subscribes UE(s) mobility events from AMF.\n2.\tIf UE(s) moves out of the service area of the source DCCF, source DCCF or central DCCF determines UE(s) data subscription to be transferred to target DCCF(s), e.g. triggered by a UE mobility event notification from AMF.\n3.\tSource DCCF or central DCCF may query the NRF to perform a DCCF discovers and selects the target DCCF(s), e.g. based on the UE location information received from AMF.\n4.\tSource DCCF requests or central DCCF triggers source DCCF to request, using Ndccf_DataManagement_Transfer Request service operation, a transfer of UE(s) data subscription to the target DCCF(s).\n5.\tTarget DCCF(s) accepts the data subscription(s) transfer.\n6.\tTarget DCCF informs the data consumer or central DCCF about the successful UE(s) data subscription transfer using a Ndccf_DataManagement_Notify message. And central DCCF may not need to notify data consumer of UE mobility events and/or DCCF reselection events based on configuration.\n7.\t[Optional] Target DCCF subscribes to the relevant data source(s), if it is not yet subscribed to the data source(s) for the data required for the data subscription.\n8.\tTarget DCCF confirms UE(s) data subscription transfer to the source DCCF.\n9.\t[Optional] Source DCCF unsubscribes with the data source(s) that are no longer needed for the remaining UE(s) data subscriptions. And target DCCF may subscribe to relevant data source(s), if not yet subscribed.\nNOTE:\tAt this point, UE(s) data subscription transfer is deemed completed.\n10-11.\tTarget DCCF collects data from the data source(s) and notifies the data consumer using a Ndccf_DataManagement_Notify message or via central DCCF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.66.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "DCCF:\n-\tSupports UE(s) data subscription transfer procedure.\n-\tSupports Ndccf_DataManagemen_Transfer service operation to inform the target DCCF of handover preparation and handover of data subscriptions.\nData Consumer:\n-\tSupports subscription renewal with a target DCCF instance.\n-\tSupports Ndccf_DataManagement_Transfer service operation for DCCF relocation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.67\tSolution #67: Managing analytics input data from ADRF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.67.1\tDescription",
                            "text_content": "NWDAF and DCCF can request ADRF to store Analytics and data. ADRF exposes a retrieval service so that NWDAF and DCCF can fetch analytics and data. Fetched data might be useful for NWDAF to run analytics or training, but this is part of the NWDAF internal logic, and an NWDAF service consumer cannot control what data to use. There are cases in which an NWDAF service consumer requires NWDAF to use a specific input data set, e.g. because certain characteristics of the data set are known to the service consumer. Examples include testing, simulations and performance monitoring, but other use cases may be realized.\nTo realize the use cases above, this solution proposes to:\n-\tAdd a new attribute to the data records stored by ADRF, named DataSetTag, which contains, at least, an identifier and a descriptor, as illustrated in the Table 6.67.1-1.\n-\tInclude the DataSetTag attribute in the Nadrf_DataManagement service operations, so that a service consumer can request the storage of data records using the DataSetTag and/or retrieve the corresponding data records by specifying the DataSetTag.\n-\tInclude other consumers of the ADRF services, such as OAM and AF.\n-\tInclude the DataSetTag attribute in the Nnwdaf_AnalyticsInfo, Nnwdaf_AnalyticsSubscription, Nnwdaf_DataManagement and Nnwdaf_MLModelProvision service operations, so that a service consumer can request NWDAF to execute operations using a certain data set, and the output of the operations will be similarly tagged with the same attribute.\n-\tIn the cases where DCCF is used, then the DataSetTag attribute should be included also in the service operations exposed by DCCF.\nTable 6.67.1-1: DataSetTag attribute\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.67.1-1: DataSetTag attribute",
                                    "table number": 64,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.67.2\tProcedures",
                            "text_content": "The procedure illustrated in Figure 6.67.2-1 shows an example in which a service consumer requests ADRF to store a particular data set and then instruments NWDAF to use that same data set to produce the analytics.\nThe figure depicts a procedure to request ADRF to store data with a data set ID and to instrument NWDAF to use such data set to produce analytics.\nFigure 6.67.2-1: Procedure to request ADRF to store data with a data set ID and to instrument NWDAF to use such data set to produce the analytics\n1.\tA service consumer requests ADRF to subscribe to data and to store them using a DataSetTag.\n2.\tThe ADRF subscribes to corresponding data sources and stores the data using the specified DataSetTag.\n3.\tThe service consumer requests analytics from NWDAF, specifying to use as input data those that belong to the DataSetTag.\n4.\tIn case NWDAF is split into AnLF and MTLF, then AnLF requests MTLF to get an ML model trained with the data set indicated by DataSetTag.\n5.\tMTLF retrieves from ADRF the data that belongs to the specified DataSetTag.\n6.\tThe data belonging to DataSetTag is provided to MTLF.\n7.\tMTLF trains the ML model using the specified DataSetTag.\n8.\tIn case NWDAF is split into AnLF and MTLF, then MTLF provision the ML model to AnLF.\n9.\tNWDAF executes the ML model.\n10. NWDAF delivers the requested analytics to the service consumer.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.67.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tNWDAF:\n-\tInclude the DataSetTag attribute in the Nnwdaf_AnalyticsInfo, Nnwdaf_AnalyticsSubscription, Nnwdaf_DataManagement and Nnwdaf_MLModelProvision service operations.\n-\tDCCF/MFAF:\n-\tInclude the DataSetTag attribute in the Ndccf_DataManagement service operations.\n-\tADRF:\n-\tAdd a new attribute to the data records stored by ADRF, named DataSetTag.\n-\tInclude the DataSetTag attribute in the Nadrf_DataManagement service operations.\n-\tInclude other consumers of the ADRF services, such as OAM and AF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.68\tSolution #68: Using data synthesis and compression for data storage and transfer",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.68.1\tDescription",
                            "text_content": "With the increasing need in 5G and beyond mobile networks to use AI/ML, a multiplicity of ML tasks will be executed potentially leading to an explosion of amount of historical data to be stored. With the ADRF being the 5GC NF deputed to store historical data and analytics, it is important for it save or limit resources for historical data storage while maintaining quality of historical data stored. Also, in today's highly regulated environment, it's expected that privacy-preserving technologies will become increasingly pervasive for applications like NWDAF built around the privacy and security of using sensitive data.\nThe above are well-known limitations, which are often overcome by using techniques focusing on reducing the volume of data to be stored and anonymizing the data records. Compression is a reduction in the number of bits needed to represent data. Nevertheless, reduction techniques can bring an appropriate solution to offer a win-win trade-off between data quality, data quantity and resource saving or limiting for the Database ADRF. Also, Data Synthesis (DS) is a privacy-preserving technology that allows to also reduce the amount of stored data.\nThis solution proposes that NWDAF and ADRF can employ data synthesis tools and compression techniques respectively to produce input data for inference and/or training, and to reduce the volume of transferred and stored data. Few scenarios are possible:\n1.\tWhen NWDAF makes a request to retrieve data from ADRF, it includes the Data Synthesis and Compression (DSC) indicator which indicates its capability to use a data compression and/or data generation tool. The DSC indicator may also contain a list of supported techniques, including compression algorithms and ML models for data synthesis. Then ADRF provides the requested data along with a descriptor of the tool used to compress/generate data.\nNOTE:\tThe DSC indicator contains an attribute to indicate the support for data compression/generation which should be defined by 3GPP during stage 3, and a descriptor of the tool which can be configured by the operator.\n2.\tWhen NWDAF requests ADRF to store data, it also includes DSC indicator. This way, less data can be stored by ADRF, and when subsequent data retrieval requests are issued by NWDAFs for the same dataset, ADRF sends the data compression/generation descriptor along with the stored data, which are expected to be significantly less than the data actually needed by the requesting NWDAF for its operations.\nTable 6.68.1-1: Format of the DSC indicator\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.68.1-1: Format of the DSC indicator",
                                    "table number": 65,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.68.2\tProcedures",
                            "text_content": "The procedure illustrated in Figure 6.68.2.1-1 shows an example in which NWDAF requests ADRF to store a partial data set and the DSC tool used to create the full dataset.\nThe figure depicts a procedure to request ADRF (Automatic Data Retention and Reporting) to store data with a DSC (Data Classification Service) tool. The figure shows a step-by-step guide on how to initiate the process, including the necessary steps and the associated icons. The figure is essential for ensuring compliance with data retention regulations and maintaining accurate records of data usage.\nFigure 6.68.2-1: Procedure to request ADRF to store data with a DSC tool\n1.\tNWDAF uses a DSC tool to create the input data set needed for its operations, i.e. analytics and/or training.\n2.\tNWDAF requests ADRF to store the input data set, including the DSC indicator to inform that the data is synthetic/compressed along with the DSC descriptor of the tool used to create the data set.\n3.\tThe ADRF sends a response to NWDAF to acknowledge the operation.\nThe procedure illustrated in Figure 6.68.2.2-1 shows an example in which NWDAF retrieves from ADRF a partial data set and the DSC tool used to create the full dataset.\nThe figure depicts a procedure to request ADRF to retrieve data using a DSC tool. The figure includes a step-by-step guide on how to perform the request, including the necessary steps and the expected output.\nFigure 6.68.2-1: Procedure to request ADRF to retrieve data with a DSC tool\n1.\tNWDAF sends a request to ADRF in order to retrieve data, including the DSC indicator to inform that the data can be processed using a DSC tool, along with the DSC descriptor.\n2.\tThe ADRF sends the requested data to NWDAF, along with the supported DSC tool.\n3.\tNWDAF uses the DSC tool to generate the input data set needed for its operations, i.e. analytics and/or training.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.68.3\tImpacts on services, entities and interfaces",
                            "text_content": "NWDAF:\n-\tsupport to run DSC tool to create/transfer data sets.\n-\tAdd the DSC indicators in the service operations.\nADRF:\n-\tAdd the DSC indicator in the service operations.\n-\tsupport to run DSC tool to create/transfer data sets.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.69\tSolution #69: Model performance guarantee during Federated Learning",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.69.1\tDescription",
                            "text_content": "This solution addresses aspects of key issue #8 on the following aspects related to the key issue #8:\n-\tHow to decide whether Federated Learning is required or not?\n-\tWhether and how to perform model performance monitoring of the NWDAF Federated Learning operation?\n-\tHow to coordinate multiple NWDAFs including selection of participant NWDAF instances in the Federated Learning group?\nThe service may vary in different network areas, which leads to different data characteristics (i.e. data distribution) of the local dataset in different MTLFs for model training. If a MTLF has not enough dataset for training a model with required accuracy level from the AnLF, horizontal federated learning is required. An AI/ML model trained using data from network areas could be utilized in a network area served by the AnLF without experiencing performance degradation, if the characteristics of data used by the AnLF in its serving area are same or similar with the characteristics of the dataset used by the MTLFs joining the Federated Learning.\nBefore each iteration of Federated Learning, the FL server MTLF will deliver the common model (i.e. the shared initial model of each iteration of Federated Learning) to each FL client MTLF. The FL client MTLFs use the training datasets as the validity datasets to calculate the Accuracy-in-Training of the common model. The Accuracy-in-Training is to indicate the performance of ML model by comparing prediction with label data in validation dataset reserved from training dataset. The Accuracy-in-Use is to indicate the performance of ML model used in live network by comparing the result of inference with the observed label data, i.e. ground truth from the live network collected in history. For example:\n-\tWhen the model is a model for classification, the Accuracy-in-Training or Accuracy-in-Use of the model may be represented by Accuracy, Precision or Recall rate.\n-\tWhen the model is a model for regression, the Accuracy-in-Training or Accuracy-in-Use of the model may be represented by MAE (Mean Absolute Error), MAPE (Mean Absolute Percentage Error), or MSE (Mean Squared Error).\nIf the Accuracy-in-Training of the common model calculated by the MTLF is much different from the Accuracy-in-Use calculated by the AnLF, the characteristics of the local dataset of the MTLF must be different from the characteristics of data used by the AnLF. The FL server should remove the MTLF from the Federated Learning group before the iteration of Federated Learning to guarantee the model performance (i.e. the model can be used by the AnLF without performance degradation).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.69.2\tProcedures",
                            "text_content": "The figure depicts a procedure for model performance guarantee during Federated Learning, illustrating the steps involved in ensuring the accuracy and reliability of the model.\nFigure 6.69.2-1: Procedure for model performance guarantee during Federated Learning\nPre-condition: The NWDAFs containing MTLF register in the NRF with the \"FL capability\" support information, such as FL Server or FL Client. The MTLFs may register in the NRF with the information of available model, such as Analytics ID, Model Filter information and Model Accuracy Level.\n1.\tThe consumer NF requests the NWDAF for analytics subscription. The NWDAF containing AnLF receives Nnwdaf_AnalyticsSubscription_Subscribe request from the analytics consumer, in which there is preferred level of accuracy of the analytics required by the analytics consumer. The AnLF accepts the subscription and send the Nnwdaf_AnalyticsSubscription_Subscribe response to the analytics consumer.\n2.\tThe AnLF derives the Analytics ID, Model Filter information and Model Accuracy Level from the Analytics ID, Analytics Filter information and preferred level of accuracy of the analytics from the analytics consumer.\n3.\tIf the AnLF has no model satisfying the derived Analytics ID, Model Filter information and Model Accuracy Level, the AnLF try to discover a MTLF with the required model. If the discovered MTLF can provide or train a model that meets the Model Accuracy Level, the AnLF can get the model for the analytics and go to step 12 directly. Federated Learning is not required.\nIf there is no MTLF can provide the model with the required Model Accuracy Level, the AnLF discovers a MTLF supporting the FL Server (i.e. a MTLF registers in the NRF with the \"FL capability\" of FL server). Federated Learning is required.\n4.\tThe AnLF sends the Nnwdaf_MLModelInfo_Request to the FL Server MTLF, in which there are Analytics ID, Model Filter information and Model Accuracy Level. The FL Server MTLF discovers candidate FL Client MTLFs from the NRF and add them into the Federated Learning group.\n5.\tThe FL Server MTLF delivers the initial/common model to AnLF for accuracy evaluation before each iteration of Federated Learning by the Nnwdaf_MLModelEvaluation_Request operation.\n6.\tThe AnLF evaluate the accuracy level of the initial/common model with the collected data in history as the validation dataset. The AnLF provides the Accuracy-in-Use of the initial/common model to the FL Server MTLF by Nnwdaf_MLModelEvaluation_Request Response operation.\n7.\tThe FL Server MTLF delivers the initial/common model to each of the FL Client MTLF for accuracy evaluation before each iteration of Federated Learning by the Nnwdaf_MLModelEvaluation_Request operation.\n8.\tThe FL Client MTLFs evaluate the accuracy level of the initial/common model with the local training data as the validation dataset. The FL Client MTLFs provide the Accuracy-in-Training value of the initial/common model to the FL Server MTLF by Nnwdaf_MLModelEvaluation_Request Response operation.\n9.\tThe FL Server MTLF compares the Accuracy-in-Training of the initial/common model from the FL Client MTLFs with the Accuracy-in-Use of the initial/common model from the AnLF. If the Accuracy-in-Training calculated by a FL Client MTLF is much different from the Accuracy-in-Use calculated by the AnLF, it can be assumed that the characteristics of the local dataset of the MTLF would be different from the characteristics of the data used by the AnLF. Therefore the FL server can remove the FL Client MTLF from the FL group.\n10.\tThe FL Server MTLF carries out this iteration of the FL with the FL Client MTLFs in the FL group and generates the total Accuracy-in-Training by aggregating the received Accuracy-in-Training.\nNOTE:\tThe FL Server MTLF repeat the step 5 to step 10 for each iteration of Federated Learning, until getting a model with a satisfactory accuracy level. The FL Server may stop to begin a new iteration of Federated Learning when it finds that there is no accuracy improvement any more.\n11.\tThe FL Server MTLF provides the model getting from the Federated Learning to the AnLF.\n12.\tUsing the model getting from the Federated Learning, the AnLF provides analytics outputs to the analytics consumer.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.69.3\tImpacts on services, entities and interfaces",
                            "text_content": "The solution has the following impacts:\nNWDAF:\n-\tSupport for additional parameters \"Model Accuracy Level\" in the Nnwdaf_MLModelInfo service operation.\n-\tWhen acting as FL Server MTLF, before each iteration of Federated Learning, gets the accuracy value of the initial/common model from the FL Client MTLFs or the AnLF and removes the FL Client MTLF from the FL group if the Accuracy-in-Training of the initial/common model calculated by the FL Client MTLF is much different from the Accuracy-in-Use calculated by the AnLF.\n-\tWhen acting as FL Client MTLF, uses the local dataset as the validity datasets to calculate the Accuracy-in-Training of the initial/common model from the FL Server MTLF.\n-\tWhen acting as AnLF, use the network data collected in history as the validity datasets to calculate the Accuracy-in-Use of the initial/common model from the FL Server MTLF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.70\tSolution #70: Improved control of location granularity",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.70.1\tDescription",
                            "text_content": "The Analytics IDs that provide location information are: UE mobility, Observed Service Experience, QoS sustainability, Dispersion analytics. In the results (predictions or statistics), as currently specified in TS 23.288 [5], the NWDAF returns time-stamped lists of target areas associated with evaluated KPI values, whose generic model is given in table 6.70-1.\nTable 6.70-1: Generic model of timestamped result list in TS 23.288 [5]\n\nTS 23.288 [5] clause 6.1.3 already allows the NF consumer to control the granularity of the location analyses provided by the NWDAF.\n[OPTIONAL] Preferred granularity of location information: TA level or cell level.\nThis granularity control solution does not appear to be sufficient to implement the existing use cases:\n-\tDepending on the use case, it may be necessary to distinguish between use cases relating to trajectory analysis or presence in a given area. The specification of a trajectory implicitly assumes a temporal granularity, i.e. the Analytics target period is divided into time slots during which the UE changes location.\n-\tThe binary choice between a TA and a cell does not offer a progressive enough granularity setting. It may be necessary to specify an intermediate size of target area, for example consisting of a number of cells.\nAlso, it is proposed to add several optional parameters to specify how location information is required:\n-\t\"temporal granularity size\": minimum duration of each elementary time slot (or maximum number of time slots). When this parameter is provided, the NWDAF should provide analytics per elementary time slot accordingly.\n-\t\"spatial granularity size\": maximum number of TA or cells of each elementary area. When this parameter is provided, the NWDAF should provide analytics per group of TA of cells accordingly.\nNOTE:\tThe choice between TA or cells is provided by the existing parameter \"Preferred granularity of location information\". This principle can be extended to other techniques for describing location areas (e.g. geographical area of a given size).\nIn this case the results are provided in the table below.\nTable 6.70-2: Improved generic model of timestamped result list\n\nAdditionally, the Maximal number of objects parameter can be used as an additional limit to limit the size of the result list, especially if it is organized in a specific order.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.70-1: Generic model of timestamped result list in TS 23.288 [5]",
                                    "table number": 66,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.70-2: Improved generic model of timestamped result list",
                                    "table number": 67,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.70.2\tProcedures",
                            "text_content": "The parameters \"temporal granularity size\" and \"spatial granularity size\" are optional in requests or subscriptions.\nThe procedures described in TS 23.288 [5] are not modified.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.70.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "Consumer NF:\n-\tMay include those parameters in requests and subscriptions (Nnwdaf_AnalyticsSubscription service).\nAnLF:\n-\tShould consider these parameters in requests and subscriptions.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.71\tSolution #71: Traffic flow statistics use case with finer granularity location information",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.71.1\tDescription",
                            "text_content": "This solution addresses Key issue #9: Enhancement of NWDAF with finer granularity of location information.\nThe traffic flow statistics can help plan the efficient operation of rail and roadway networks during rush hours. The statistics of traffic flow collects the hotspot map in a certain region in a certain period of time. It enables traffic regulators and planners make more reasonable bus routes and road construction plans. In addition, the user can obtain the congestion situation on the road through statistics. These are all requirements that helps NWDAF consumers improve their own experience and optimize traffic conditions.\nIn this scenario, the NWDAF needs to collect traffic flow information from LCS, including UE ID, location, velocity, environment indication, etc. Then the NWDAF conducts calculations and predictions based on such information. For example, the transport tool may be determined by the speed and orientation information. Average speed information is used to reflect the current congestion of a certain transport tool.\nAs to the environment indication, the UE may be indicated aboveground or underneath, indoor or outdoor, inside or outside the vehicle, etc. The NWDAF determines which transport tool the UE is currently using based on the environment indication and other information it collects from the LCS. For example, if the indication is underneath and the vertical coordinate of the location is in a underground position, it can be judged that the current traffic environment of the terminal is in the subway or the probability of taking the subway is high. If the indicator is on the ground and outdoors, and the speed is 2-5km/h, it can judge that the current traffic environment of the user is walking, and the probability of walking is high.\nIn order to solve the aforementioned issue, this solution proposes that NWDAF requires some finer granularity location information of the UEs with location, velocity, environment indication, and so on, and then provide traffic flow statistics/prediction services for the NWDAF consumer.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.71.2\tInput Data",
                            "text_content": "The input data for the analytics are described in Table 6.71.2-1.\nTable 6.71.2-1: Input data for traffic flow statistics use case usage\n\nNOTE:\tFrom which network function to acquire the location information will have some coordination with the FS_eLCS_Ph3 study.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.71.2-1: Input data for traffic flow statistics use case usage",
                                    "table number": 68,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.71.3\tOutput Analytics",
                            "text_content": "The output analytics of NWDAF is defined in Table 6.71.3-1 and Table 6.71.3-2.\nTable 6.71.3-1: Traffic flow statistics use case usage statistics\n\nTable 6.71.3-2: Traffic flow statistics use case usage prediction\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.71.3-1: Traffic flow statistics use case usage statistics",
                                    "table number": 69,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.71.3-2: Traffic flow statistics use case usage prediction",
                                    "table number": 70,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.71.4\tProcedures",
                            "text_content": "Figure 6.71.4-1 depicts a procedure for traffic flow statistics use case provided by NWDAF.\nThe figure depicts a traffic flow statistics use case provided by NWDAF, illustrating the flow of data packets in a network. The flow is represented by a series of nodes, each with a unique identifier, and the flow is represented by a series of arrows indicating the direction of data transmission. The use case includes various metrics such as packet loss, packet delay, and packet delivery ratio, which are crucial for understanding the performance of the network. The figure is a visual representation of the data flow in a network, providing insights into the network's performance and the factors affecting it.\nFigure 6.71.4-1: Traffic flow statistics use case provided by NWDAF\n1.\tThe consumer requests or subscribes to analytics information on the traffic flow statistics use case provided by NWDAF.\n2.\tThe NWDAF collects the UE location information data from the LCS server including timestamp, location estimate, velocity estimate, environment indication, location accuracy, age of location, and so on.\n3.\tThe NWDAF conducts firstly transport tool evaluations based on the information collected from LCS architecture. The total number of users using the specific transport tool and the average speed at a specific time in the area of interest can be obtained.\n4.\tThe NWDAF responds to the traffic flow statistics to the consumer. The details for the analytics provided by the NWDAF are defined in the output analytics information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.71.5\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF:\n-\tThe NWDAF supports collecting data from LCS architecture used for the traffic flow statistics/predictions.\n-\tThe new Analytic ID supporting the traffic flow statistics use case needs to be supported.\nEditor's note:\tThe name of new analytic ID is FFS.\nLCS architecture:\n-\tThe LCS architecture supports to provide the necessary information required for the traffic flow use case to the NWDAF.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.72\tSolution #72: Use of MDAS analytics for improving AnLF/MTLF analytics accuracy and data collection",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.72.1\tDescription",
                            "text_content": "Management Data Analytics (MDA), is an enabler of automation and intelligence for services management and orchestration. An MDA MnS (also referred to as MDAS) defined in TS 28.104 [15] enables any authorized consumer to request and receive analytics. The architecture is shown in Figure 1.\nThe figure depicts a comprehensive overview of the MDA functional framework and service framework, providing a detailed understanding of the various components and their roles in the MDA process. The figure includes a flowchart, a list of key components, and a description of their functions, making it a valuable resource for understanding the MDA process and its components.\nFigure 6.72.1-1: MDA functional overview and service framework (source TS 28.104 [15])\nAccording to TS 28.104 [15], a management function (MDAF) may play the roles of MDA MnS producer, MDA MnS consumer, other MnS consumer, NWDAF consumer and LMF service consumer, and may also interact with other non-3GPP management systems.\nThe internal business logic related to MDA leverages the current and historical data related to:\n-\tPerformance Measurements (PM) according to TS 28.552 [7] and Key Performance Indicators (KPIs) according to TS 28.554 [9].\n-\tTrace data, including MDT/RLF/RCEF, according to TS 32.422 [22] and TS 32.423 [23].\n-\tQoE and service experience data according to TS 28.405 [24] and TS 28.406 [25].\n-\tAnalytics data offered by NWDAF according to TS 23.288 [5] including 5GC data and external web/app-based information (e.g. web crawler that provides online news) from AF.\n-\tAlarm information and notifications according to TS 28.532 [26].\n-\tCM information and notifications.\n-\tUE location information provided by LMF according to TS 23.273 [13].\n-\tMDA reports from other MDA MnS producers.\n-\tManagement data from non-3GPP systems.\nAnalytics output from the MDA internal business logic are made available by the management functions (MDAFs) playing the role of MDA MnS producers to the authorized consumers, (including but not limited to other management functions, network functions/entities, NWDAF, SON functions, optimization tools and human operators).\nThe analytics provided by MDAS include analytics for fault management predictions/statistics. The MDA can supervise the status of various network functions and resources, and predict the running trend of network and potential failures to intervene in advance. These predictions can be used by the management system to autonomously maintain the health of the network, e.g. speedy recovery actions on a network function related to the predicted potential failure.\nAs part of the analytic output the following information elements can be provided by the MDAF.\nTable 6.72.1-1: Analytics output for fault prediction analysis (source TS 28.104 [15])\n\nThe performance analytics from MDAS can assist the NWDAF AnLF to improve the accuracy of analytics or the NWDAF MTLF to determine if an ML model requires re-training.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.72.1-1: Analytics output for fault prediction analysis (source TS 28.104 [15])",
                                    "table number": 71,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.72.2\tProcedures",
                            "text_content": "The following call flow provides a detailed procedure on the NWDAF (AnLF) subscribing from MDAS/MDAF to receive information about fault predictions.\nThe figure depicts a schematic representation of a fault prediction system, with MDAS/MDAF (Machine Learning-based Fault Diagnosis and Prediction) interacting with the system to improve analytics. The system includes a fault prediction model, a fault detection module, and a fault prediction module. The fault prediction module uses machine learning algorithms to predict faults based on historical data, while the fault detection module uses machine learning to detect faults in real-time. The fault prediction module uses a fault prediction model to predict the likelihood of faults occurring in the future. The system is designed to improve the accuracy of fault prediction by providing more accurate predictions.\nFigure 6.72.2-1: Improving analytics by interacting with MDAS/MDAF for fault prediction\n1.\tA consumer requests analytics including an analytic ID according to TS 23.288 [5]. For example, a consumer can request analytics for an analytic ID for NF load.\n2.\tThe NWDAF determines the Data Producers to collect data to derive analytics for the analytic ID requested according to TS 23.288 [5].\n3.\tThe NWDAF collects data from the identified data producers according to TS 23.288 [5].\n4.\tThe NWDAF determines the parameters required when requesting fault predictions from the MDAS/MDAF. The NWDAF may request fault prediction targeting a service area or may request fault prediction for a Network Function acting as a data source in steps 2 and 3.\n5.\tThe NWDAF subscribes to the MDAS/MDAF for fault prediction according to TS 28.104 [15].\n6.\tThe MDAS/MDAF determines data producers and collects data according to TS 28.104 [15].\n7.\tMDAS/MDAF determines a fault.\n8.\tMDAS/MDAF report to the NWDAF fault prediction. The analytic output may include one or more parameters listed in Table 6.72.1-1.\n9.\tThe NWDAF based on the information provided in step 8 determines if the fault affects the accuracy of the analytics. The NWDAF can determine if the fault affects the inference model for generating analytics or whether the analytics predictions that are already provided to a consumer are inaccurate.\nFor example if the fault prediction from the MDAS/MDAF includes an NF identity (NF id or NF instance ID) indicating that the network function will be \"misbehaving\" for a specific period of time the NWDAF can disregard the data for the time duration where the NF is \"misbehaving\" and collect data from the NF when the NF is operating at its nominal conditions. Based on the data disregarded the NWDAF can estimate how the analytics accuracy is affected (i.e. the NWDAF will have less number of samples to generate analytics) and indicate to the consumer if the analytics accuracy is affected. If the NWDAF determines that the analytics are not affected by the fault prediction (e.g. the NF was at fault only for a small period of time and the NWDAF has enough samples to generate analytics at a requested accuracy) the NWDAF does not need to report to the consumer an indication that the analytics are not accurate.\nThe NWDAF may also use statistical information provided by the MDAS/MDAF (e.g. MDAS/MDAF can notify the NWDAF of an imminent network failure). If the NWDAF determines that fault indication will affect the analytics accuracy then the NWDAF notifies the consumer to stop using the analytics provided by the NWDAF until the network failure is resolved.\n10.\tIf the NWDAF determines that the fault analytics information affects the accuracy of the analytics the NWDAF reports to the consumer an indication to stop making decisions. The NWDAF may include a pause indication to the consumer.\n11.\tThe NWDAF determines that the analytics accuracy is restored, after the NWDAF has accumulated enough samples from the Data Producer(s) where faults were predicted.\n12.\tThe NWDAF indicates to the consumer to resume the analytics subscription.\nThe following call flow provides a detailed procedure on the NWDAF (MTLF) subscribing from MDAS/MDAF to receive information about fault predictions.\nThe figure depicts a training process for a machine learning model, specifically a fault prediction model, which is enhanced by interacting with the Multi-Dimensional Data Analysis and Fault Diagnosis (MDAS/MDAF) system. The figure illustrates the process of training the model on real-world data, with the model's performance being evaluated through fault prediction.\nFigure 6.72.2-2: Improving trained ML model by interacting with MDAS/MDAF for fault prediction\n1.\tA consumer requests a trained ML model including an analytic ID according to TS 23.288 [5].\n2.\tThe NWDAF determines the Data Producers to collect data to train an ML model for the analytic ID requested according to TS 23.288 [5].\n3.\tThe NWDAF collects data from the identified data producers according to TS 23.288 [5].\n4.\tThe NWDAF determines the parameters required when requesting fault predictions from the MDAS/MDAF. The NWDAF may request fault prediction targeting a service area or may request fault prediction for a Network Function acting as a data source in steps 2 and 3.\n5.\tThe NWDAF subscribes to the MDAS/MDAF for fault prediction according to TS 28.104 [15].\n6.\tThe MDAS/MDAF determines data producers and collects data according to TS 28.104 [15].\n7.\tMDAS/MDAF determines a fault\n8.\tMDAS/MDAF report to the NWDAF fault prediction. The analytic output may include one or more parameters listed in Table 6.72.1-1.\n9.\tThe NWDAF based on the information provided in step 8 determines if the fault affects the accuracy of the ML model.\n-\tThe NWDAF MTLF disregards the data collected for training the ML model based on the information provided in the fault prediction. For example, if the fault prediction from the MDAS/MDAF indicate that a fault is predicted for an NF for a specific time period the MTLF will disregard any data collected from this NF collected at the time period where a fault is predicted.\n10.\tIf the NWDAF MTLF determines that the fault affects the accuracy of the ML model the NWDAF reports to the consumer an indication to stop making decisions. The NWDAF may include a pause indication to the consumer.\n11.\tThe NWDAF MTLF re-train the ML model using data from the data producer where a fault is not predicted.\n12.\tWhen the NWDAF determines that the train ML model is valid, i.e. after the NWDAF has accumulated enough samples from the Data Producer(s) where faults were predicted .The NWDAF indicates to the consumer to resume the analytics subscription.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.72.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tExisting services are used.\n-\tNWDAF uses fault prediction from MDAS/MDAF to determine accuracy of analytics or ML model.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.73\tSolution #73: How NWDAF requests analytics from MDA Management Function",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.73.1\tDescription",
                            "text_content": "This solution addresses the Key Issue#10: Interactions with MDAS/MDAF which focus on define the framework for analytics feedback by MDAF.\nEditor's note:\tThe feasibility of this solution should be aligned with SA WG5.\nThis solution proposes to re-use the MDA functional overview and service framework in Figure 6.73.1-1 (i.e. Figure 5.1-1 as defined in TS 28.104 [15]). As an MDA MnS Consumer, NWDAF can trigger the MDA MnS to request analytics from the MDA Management Function.\nThe figure depicts a comprehensive overview of the MDA functional framework and service framework, specifically focusing on the TS 28.104 standard. It provides a detailed explanation of the various components and their roles in the MDA process, as well as the service framework that supports these components. The figure is a valuable resource for understanding the technical aspects of MDA and its role in the telecommunications industry.\nFigure 6.73.1-1: MDA functional overview and service framework, TS 28.104 [15]\nBefore NWDAF requests analytics from the MDA Management Function, the NWDAF firstly discover the MDA Management Function via the MnS discovery service producer as defined in clause 5 of TS 28.537 [28].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.73.2\tProcedures",
                            "text_content": "The figure depicts a procedure for data collection from the MDA Management Function, illustrating the steps involved in collecting data from the MDA Management Function.\nFigure 6.73.2-1: Procedure for data collection from MDA Management Function\n1.\tNWDAF discovers the MDA Management Function from the MnS discovery service producer by sending a MnS producer discovery service operation. The service operation may include the following parameters:\n-\trequestedMDAType: indicate a specific MDA capability such as Slice coverage analysis, Mobility performance analysis as defined in clause 7.2 of TS 28.104 [15];\n-\tArea of Interest;\n-\tNetwork Slice information (i.e. NetworkSliceInfo including a DN (Distinguished Name) of the NetworkSlice managed object relating to the network slice instance associated to the S-NSSAI and NSI ID if available as defined in TS 28.541 [29]).\n2.\tThe MnS discovery service producer feedback the address of the MDA Management Function.\n3.\tNWDAF requests analytics from the MDA Management Function by triggering a MDARequest service operation as defined in clause 9.3.2 of TS 28.104 [15]. The service operation may include the following parameters:\n-\trequestedMDAOutputs: MDAOutputPerMDAType;\n-\treportingMethod: periodic reporting mode, the periodicity or specified time of the report, etc.;\n-\tanalyticsScope: Area of Interest, Network Slice information, etc.;\n-\tstartTime;\n-\tstopTime;\n-\tanalyticsWindow.\n4.\tThe MDA Management Function provides the analytics to the NWDAF by triggering a MDAReporting service operation.\nNOTE:\tNWDAF and MDA Management Function/MnS discovery service producer, if from different operators, may interact via the Exposure Governance Management Function as defined in clause A.3 of TS 28.533 [27].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.73.3\tImpacts on Existing Nodes and Functionality",
                            "text_content": "NWDAF:\n-\tNWDAF discovers the MDA Management Function from the MnS discovery service producer.\n-\tNWDAF requests the OAM related analytics from the MDA Management Function.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.74\tSolution #74: Supporting NWDAF interactions with MDAF",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.74.1\tDescription",
                            "text_content": "This solution is based on the MDA functional overview and service framework in Figure 6.73.1-1 (i.e. Figure 5.1 1 as defined in TS 28.104 [15]) re-using the existing interfaces, i.e. Nnwdaf and MDAS (MDA MnS).\nThe figure depicts a comprehensive overview of the MDA functional framework and service framework, specifically focusing on the TS 28.104 standard. It provides a detailed explanation of the various components and their roles in the MDA process, including the role of the MDA functional manager, the MDA service manager, and the MDA service framework. The figure also includes a diagram illustrating the flow of data between the MDA functional manager and the MDA service manager, as well as the flow of data between the MDA functional manager and the MDA service framework. The figure is a valuable resource for understanding the MDA process and its components.\nFigure 6.74.1-1: MDA functional overview and service framework, TS 28.104 [15]\nWhen a consumer issues an NWDAF Analytics ID request that relies on management data analytics input from an MDAF or MDA MnS producer, this request needs to trigger once received at a particular NWDAF a subsequent request or subscription towards the appropriate MDAF. The interfaces that can be used for this interaction are the Nnwdaf for issuing a request or subscription to MDAF or MDA MnS producer and the MDAS interface for reporting to the NWDAF, as documented in clause 5.1 of TS 28.104 [15].\nA consumer request needs to be analysed and processed by the recipient NWDAF to issue the subsequent subscription request, i.e. by deriving the corresponding subscription attributes, towards the MDAF or MDA MnS producer. The new subscription request may include the following attributes:\n-\tMDA Type: It refers to the desired analytics capability, as specified in clause 8.1.1 of TS 28.104 [15], e.g. slice throughput analytics, slice coverage analysis, considering the use cases and requirements for MDA capabilities as documented in clause 7.2 of TS 28.104 [15]. The MDA type can be selected based on a pre-configured mapping between an Analytics ID and the necessary input that include the MDA type. Multiple MDA types can be potentially carried in a single request depending on the implementation of MDAF. For each MDA type the consumer can select specific MDA outputs, i.e. out of a pre-determined list of potential output results, as specified in clause 9.3.2 of TS 28.104 [15].\n-\tRelative time schedule: Considering the time schedule indicated by the consumer, the recipient NWDAF can estimate the corresponding time schedule calculating the upper bound time needed to receive the response from the respective MDAF or MDA MnS producer that relies upon. To achieve this:\ni.\teach MDAF or MDA MnS producer can register in a MnS discovery service producer as described clause 5.1 of TS 28.537 [28] its capability in terms of the upper bound time in preparing an analytics result based on the available CPU, storage resources and the current workload.\nii.\talternatively, an MDAF can respond to the requesting NWDAF its capability in terms of the upper bound time in preparing an analytics result based on the available CPU, storage resources and the current workload.\niii.\tthe NWDAF needs to have an estimation of the communications latency in receiving management data analytics. This can be determined by sending a round trip probe message to estimate the expected latency.\n-\tStart/stop time: It refers to the time schedule for starting and stopping an analytics subscription request where multiple MDA reporting may take place each with a specified reporting time window.\n-\tReporting time window: It refers to the desired reporting time window related to the management data analytics output from MDAF.\n-\tReporting analytics samples: This indicates how the reporting of the management data analytics samples can be presented, e.g. average value, min-max value, discrete time-based samples, etc.\n-\tAnalytics subscription type: Considering the request type from the consumer, i.e. on-demand request (immediate) or on-demand/periodic request at a specified timed, the NWDAF needs to select the appropriate timing related to the subsequent request towards the MDAF or MDA MnS producer.\n-\tReporting method: It refers to the way of receiving the result from MDAF or MDA MnS producer. The NWDAF may request an MDAF or MDA MnS producer to report in a file format when the result has a relatively bigger size, stream-based reporting that suits real-time data or notification based where the consumer receives a notification to fetch the data.\n-\tArea of Interest: Can be explicitly specified by the consumer and in this case the NWDAF requests the same area capability, i.e. be capable to produce analytics in the specified area, to MDAF or MDA MnS producer.\n-\tNetwork Slice: It refers to information (i.e. NetworkSliceInfo including a DN (Distinguished Name) of the NetworkSlice managed object relating to the network slice instance associated to the S-NSSAI and NSI ID if available as defined in TS 28.541 [29]).\n-\tTarget UE(s): NWDAF focuses on a particular UE ID (Subscription Permanent Identifier - SUPI), while the management plane, i.e. MDAF or MDA MnS producer considers the average UE in a particular location. Specifically, when NWDAF needs MDAF or MDA MnS producer output, e.g. resource utilization prediction, in relation to a UE or a group of UE, that reside in a particular area, it needs to translate the location of UE(s) into an area in the form of cells or TAs.\n-\tFiltering conditions: Refers to the conditions included in a consumer request, which indicate the report triggering criteria. The recipient NWDAF needs to identify where filtering conditions can be applied and include any of them that relate to the subsequent request towards MDAF or MDA MnS producer.\nThe NWDAF also needs to perform the discovery of the appropriate MDAF or MDA MnS producer needed, by contacting the respective MnS discovery service producer as in clause 5 of TS 28.537 [28]. MDAF or MDA MnS producers need to register themselves to the respective Service Directory with their management capabilities described by MnS information or MnS profile.\nNOTE:\tThe details for the MDA MnS producer discovery by the NWDAF may be based on the existing procedure defined in TS 28.537 [28].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.74.2\tProcedures",
                            "text_content": "If a consumer requires analytics from NWDAF that rely on input from MDAF the following apply.\nThe figure depicts a network-wide data aggregation and forwarding (NWDAF) interworking system, illustrating the interconnection of various network functions (NWFs) with the main data aggregation function (MDAF). The figure shows the interconnection of NWFs with MDAFrequest and response, highlighting the importance of interworking for efficient data distribution and management.\nFigure 6.74.2-1: Supporting NWDAF interworking with MDAFrequest and response\nPrecondition: Initially MDAF(s) or MDA MnS producers register their capabilities, i.e. MnS information or MnS profile as described in clause 5 of TS 28.537 [28] to a MnS discovery service producer. The MnS discovery service producer may contain all or partial information related to the capabilities of MDA MnS producer.\n1\tAn analytics consumer issues a request using either on-demand request or subscription method towards the selected NWDAF as described in TS 23.288 [5].\n2.\tThe recipient NWDAF uses the Analytics Request Processing or Analytics Logic (that resides within the same function or can alternative be a separated NF) to determine the requirements of the received analytics request to identify the corresponding attributes (i.e. as mentioned above: Analytics ID, Relative time schedule, Reporting time window, etc.).\n3.\tThe recipient NWDAF performs the discovery of the corresponding MDAF or MDA MnS producer. The discovery step can take place in two different ways:\ni.\tthe recipient NWDAF requests the Service Directory indicating the desired capabilities for a target MDAF or MDA MnS producer in step 3a and receives a reply in step 3b suggesting the set of MDAF or MDA MnS producer including the corresponding address to select from,\nii.\tthe recipient NWDAF only receives basic profile information, i.e. the address, from the Service Directory in steps 3a and 3b and needs in step 3c to request from each suggested MDAF or MDA MnS producer its capabilities before being able to select the desired one(s).\n4.\tIf the discovery process returns an empty set, i.e. with no results that can fulfil the desired capabilities, then the NWDAF may optionally negotiate with the analytics consumer, i.e. to change or downgrade, the requirements of the analytics request. The requirements that the NWDAF may negotiate with the consumer if the desired one(s) cannot be fulfilled may include the:\na\tReporting time window where the NWDAF can propose a new reporting time window based on the received MDAF or MDA MnS producer options set provided by the discovery process.\nb\tAnalytics subscription type where the NWDAF can degrade the analytics subscription type, e.g. from an on-demand immediate response to a response estimating an additional latency, based on the received set of MDAF or MDA MnS producer options provided by the discovery process.\nIf a solution cannot be reached in the negotiation step or if the negotiation step is not supported, then the process is terminated at this point.\n5.\tIf the suggested set of MDAF or MDA MnS producer that fulfils the desired capabilities is nonempty or a negation step assisted in reaching a solution, then the recipient NWDAF selects the desired MDAF or MDA MnS producer out of the suggested set and then prepares the format the corresponding MDA request, i.e. by deriving the requirements or corresponding attributes of the MDA request.\n6.\tThe MDA request is issued automatically towards the selected MDAF or MDA MnS producer.\n7.\tThe MDAF or MDA MnS producer prepares the MDA result.\n8.\tThe MDAF or MDA MnS producer returns the MDA responds providing the desired analytics output results.\n9.\tThe recipient NWDAF collects additionally raw data from other data sources, which may include NFs, MnSs, repository functions, e.g. NRF, UDR, URM, data collection entities, e.g. DCCF, ADRF, to calculate the requested analytics result.\n10.\tThe NWDAF prepares the analytics result.\n11.\tThe NWDAF provides the analytics response towards the analytics consumer that includes the requested result.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.74.3\tImpacts on services, entities and interfaces",
                            "text_content": "-\tNWDAF contains or interact with the Analytics Request Processing or Analytics Logic to determine the attributes of the MDAF on-demand request or subscription.\n-\tNWDAF discovers of the appropriate MDAF or MDA MnS producer form the MnS discovery service producer.\n-\tNWDAF requests or subscribes to the desired OAM related analytics from the corresponding MDAF or MDA MnS producer.\n-\tNWDAF may optionally negotiate with the analytics requirements related to a consumer request.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "7\tOverall Evaluation",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "7.1\tKey Issue #1: How to improve correctness of NWDAF analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "According to the Table 6.0-1, solutions #1-#7, solutions #28-#36, and solutions #61-#63 are proposed for Key Issue #1. All proposed solutions can be categorized in the following categories:\n-\tSupport for using multiple ML models (4 solutions).\n-\tDataset properties and ML model accuracy management (6 solutions).\n-\tDetection of drift of an ML model (6 solutions).\n-\tReceiving feedback from service consumers to NWDAF (3 solutions).\n-\tAccuracy report from NWDAF to the service consumer (2 solution).\nIn the following each category will be evaluated separately.\nSupport for using multiple ML models\nSolutions #1, #28, #31, #36 and #62 propose multiple ML models for improving overall accuracy of prediction generated by NWDAF. Having multiple ML models for a single analytics report helps NWDAF containing MTLF to provide more than one ML model during provisioning to NWDAF containing AnLF. When a prediction is being generated, NWDAF containing AnLF has more than one ML model available to use. This allows the NWDAF containing AnLF to choose a suitable ML model depending on, e.g. UE location, time of day, network load, or any other filter of information.\nSolution #1 is about using several ML models by NWDAF(AnLF) and them voting and choosing the best prediction using an internal scoring mechanism. It also includes enhancing provisioning procedure to provide pairs of unique identifiers of the ML model and its corresponding ML model information when multiple ML models are available for an analytics report.\nSolution #31 proposes providing several analytics reports to service consumer and let the service consumer to choose between delivered results for an analytics report. The service can use for instance confidence level in the analytics reports and choose the one with the highest value.\nSolution #36 enhances ML model provisioning in a way that NWDAF containing AnLF includes extra information i.e. inputs about the data used for inference to NWDAF containing MTLF, when ML model provisioning process is triggered. This allows the NWDAF containing MTLF to select one out of multiple ML models, or even generate a new one. In this solution, the NWDAF containing AnLF receives a single ML model as per existing procedures. Only the NWDAF containing MTLF is assumed to have access to multiple ML Models, from which one of them is selected and provisioned to the NWDAF containing AnLF.\nSolution #62 proposes a method to choose between multiple ML models when available for a single analytics ID, by introducing an additional optional parameter called \"use case context\" provided by the consumer. This parameter is used as a guideline to NWDAF to choose the best ML model that can be suitable for the context of the usage of the requested analytics report. NWDAF containing AnLF or NWDAF containing MTLF will use this parameter to choose between a set of already provisioned ML models or choose an ML model to provision. Since the new parameter \"use case context\" do not need to be standardized, a wide variety of use cases can be supported.\nSolution #28 proposes that different ML models can be associated with an analytics ID during the process of improving the Analytics ID performance. It proposes that upon identification an unstable Analytics ID (i.e. with performance degradation), MTLF can be triggered by a notification about such degradation and decide to change training configuration parameters of the ML model of an analytics ID, re-select a different ML model, or deactivate ML models, in order to improve the analytics ID performance.\nDataset properties and ML model accuracy management\nSolutions #2, #3, #33, #35, #61, and #63 propose technics for ML model accuracy management by providing information about the datasets used to train ML models.\nSolution #2 is applicable to the Service Experience analytics ID. The solution proposes that when the AF provides Service Experience Information for a group UEs, the AF also provides a \"Service Experience Contribution Weight\" with each UE's Service Experience value. The \"Service Experience Contribution Weight\" is determined by the AF and indicates the relative importance of each UE's Service Experience. This information can be used by the NWDAF containing MTLF to include more important values when predictions are generated.\nSolution #3 is about calculation of ML model validation in NWDAF containing MTLF (Accuracy in Training) and then ML model accuracy measurement in NWDAF containing AnLF. Then, NWDAF containing AnLF collects the actual data and reports the measured accuracy (Accuracy in Use) as feedback to NWDAF containing MTLF. Diverging between these two values is detected by NWDAF containing AnLF and will be a sign that NWDAF containing MTLF needs to take action to improve the analysed ML model. This solution can be useful to increase the quality of ML models trained by NWDAF containing MTLF where a metric can be used to evaluate the ML model's performance dynamically. However, the usage of Accuracy in Use needs to be elaborated in a clearer way, for example, it is not clear how to detect that the actions of the NFs based on predictions modify the result of a prediction, thus, invalidating the input for the Accuracy in Use.\nSolution #33 introduces a way for a service consumer to request corrections, in time, of analytics predictions NWDAF will then send corrected predictions within a time window to the service consumer.\nSolution #35 discusses a way to further classify a AoI into sub-areas with different properties. A service consumer subscribes to the area monitoring analytics service from NWDAF and NWDAF will provide information about expected environment properties. Also, NWDAF subscribes to a service to receive an identifier associated to the properties of the monitored area. Areas with similar properties will be associated to the same ID. The benefits consist in enabling the re-use of ML models based on similarity of input data sets, rather than based only on same AOI.\nSolution #61 considers further training of an existing ML model instead of training a new ML model. The solution assumes that previously training ML models are stored in ADRF which are referred as historical ML models. Such historical ML models are then trained with extra data to increase the accuracy and extending the spatial validity of and ML model. A further trained ML model is then provisioned by NWDAF containing MTLF to NWDAF containing AnLF. A further training process is initiated if no exact match for an ML model with respect to the filter information from a service consumer is found in ADRF. For instance, if filter information limits the analytics report to TA-1,2 NWDAF containing MTLF looks for historical ML models with the same TA, and if it didn't find a match but an ML model with TA-1,3 is found, then the model will be further trained to cover TA-1,2,3. Furthermore, NWDAF containing MTLF should be able to modify the ML filter information received from the NWDAF containing AnLF. When the training is completed, NWDAF containing MTLF will store the ML model in ADRF which can be provisioned to NWDAF containing AnLF for inference.\nSolution #63 proposes a rating mechanism for 3rd party data sources. It is proposed that the quality of the data needs to be checked and shall not be consumed by the NWDAF MTLF especially if there is a significant change in the data distribution or if there is a significant drift between predictions and ground truth data. There are two ways to conduct the data source performance monitoring and report:\nOption 1: A service consumer evaluates the quality of an analytics report on behalf of NWDAF containing AnLF and reports back the result of evaluation to NWDAF containing AnLF.\nOption 2: NWDAF containing MTLF performs an evaluation process on an ML model and informs NWDAF containing AnLF if any degradation is detected. Finally, NWDAF containing MTLF asks NWDAF containing AnLF for validation check of data sources.\nML model drift detection\nSolutions #4, #5, #7, #28, #29, #30, and #32 propose solutions for ML model drift detection.\nSolution #4 proposes the MTLF to determine model drift by comparing historical data with real-time data\nSolution #5 is about error monitoring of ML models when a model is provisioned. If any error is detected in an ML model, then proper action e.g. re-training will be triggered. Two options are presented for detecting the drift of the ML model. Option #1 is based on detection performed at an NWDAF containing AnLF. Option #2 is based on detection performed at an NWDAF containing MTLF.\nOption #1 is based on a comparison, performed at an NWDAF containing AnLF, between the result of a prediction and the actual value.\nOption #2 is based on the NWDAF containing MTLF collecting the data and/or events that have been previously collected by the NWDAF containing AnLF, and a subsequent computation of the differences between the set of trained data at step and the collected events/data. This option implies a duplication in the collection of data, on one side by the NWDAF containing AnLF and in another side by the NWDAF containing MTLF, which is not efficient, even in cases where ADRF is used to store the collected data.\nSolution #7 introduces the notion of a new Trusted Rating Logical Function, which delivers to the analytics consumers the rating of each Analytics ID for a given NWDAF and delivers to AnLF the rating of each ML model for a given MTLF. Also, the TRLF allows NWDAF service consumers to generate the rating for the Analytics ID and ML model, depending on the scenario. The ratings are determined based on metrics which are defined by the provider of the Analytics ID/ML model, but they can be set by the operator too and they might include accuracy. This allows the service consumer to select an NWDAF taking into account such rating. Then NWDAF can generate a token for rating the correctness of analytics reports, thus ensuring that only real consumers provide the rating. Despite the solutions may penalize an NWDAF with low rating, it enables an NWDAF with low rating to trigger re-training of the ML models used by that NWDAF. The task of evaluating NWDAF performance seems to be relevant to OAM and NWDAF (e.g. containing AnLF).\nSolution #28 proposes that a NWDAF with tracing capability assesses accuracy of prediction by comparing predicted and ground truth if the analytics consumer NF does not provide feedback about the quality of the analytics or it can calculate the impact of the analytics according to the change of relevant KPIs of the NF. The NWDAF can store the information of previous performance of Analytics IDs and their internal configuration, such as ML models. Based on this information, the NWDAF can identify unstable analytics IDs and notify NWDAF with MTLF that actions to improve the associated ML model to the unstable analytics ID are required.\nSolution #29 is about detecting ML model drift in by NWDAF containing AnLF and report it back to NWDAF containing MTLF for proper action. The solution enables the NWDAF containing MTLF to learn about NWDAF containing AnLF using already provisioned ML Models, and a subsequent subscription from the NWDAF containing MTLF to those NWDAFs containing AnLF, which send notifications when they detect the ML model degradation. The NWDAF containing MTLF marks degraded ML models and takes the proper action (e.g. ML Model retraining, indication of \"degraded\" ML model in ML Model provisioning service operation, choose another ML model for the same Analytics ID).\nSolution #30 is about a method where either NWDAF containing MTLF or AnLF will monitor one or multiple ML models for analytics report to evaluate the accuracy of an ML model. The overall solution is appropriate, but it needs to be established in a better way. For instance, it should be clear whether it is NWDAF containing MTLF or AnLF (NWDAF containing AnLF would be preferred) who is responsible for an ML model evaluation.\nSolution #32 proposes that the NWDAF containing MTLF subscribes to the NWDAFs containing AnLF in order to get the performance of previously provisioned ML Models. The NWDAF containing AnLF will then detect possible ML model degradation and will inform the NWDAF containing MTLF accordingly.\nReceiving feedback from service consumers to NWDAF\nSolutions #4, #6, and #28 are improving accuracy of NWDAF using feedback from the service consumers.\nSolution #4 is about feedback from the service consumer to NWDAF containing AnLF which will be forwarded to NWDAF containing MTLF. The analytics consumer reports a network behaviour change that may affect the analytics accuracy. The MTLF uses the information to evaluate the performance of the ML Model.\nSolution #6 is about sending feedback from the service consumer to NWDAF containing AnLF. The feedback which is mentioned in this proposal is simple and does not carry any extra information about type of the action which is not relevant to what NWDAF does. The proposed solution seems to be reasonable and feasible but needs more clarification for instance about how ML model accuracy parameters are calculated to detect if an ML model is degraded.\nSolution #28 proposes a method to assess accuracy of prediction based on feedback information related to the effect of an analytics on the changes in network status after the consumption of analytics. The feedback has information about performance of an analytics ID by monitoring relevant KPIs. The monitoring process will provide Analytics ID Grade Information and Unstable Analytics ID information which will be used to measure the correctness of each analytics ID.\nAccuracy report from NWDAF to the service consumer\nSolution #34 proposes documenting the accuracy of Analytics IDs into an accuracy report which can be used by a consumer NF to manage the subscription e.g. terminate the subscription is accuracy is low or take the reported accuracy into account when a decision is being taken or by OAM. The detailed accuracy report is meant to scope the measurement of accuracy in the same way as Analytics requests are scoped, i.e. per Analytics ID, for a specific area, slice, (group of) UEs, in a given time window. The accuracy report is instrumental to monitor the accuracy of predictions from NWDAF, which is a necessary to determine e.g. if training is required. This solution provides a procedure to monitor accuracy based on MTLF, assisted by AnLF and ADRF respectively to provide Analytics output data (i.e. predictions) and to store the data (i.e. output data and the true observed events) labelled by a MonitorCorrelationID needed by MTLF to fetch the right data. The benefit of such solution consists in relieving AnLF from executing accuracy monitoring and posing the burden of the task on MTLF which is designed for heavy tasks.\nSolution #28 proposes a method of NWDAF sending the Analytics Consumer the notifications about the status of Analytics (IDs). These notifications can indicate an unstable analytics ID, a stable analytics ID, or a cooling duration time. Additionally Solution #28 proposes that the NWDAF that detected a degradation of performance of an Analytics (ID) can inform other AnLF and/or MTLF about such information enabling improvement actions to be taken by NWDAFs without the capacity to determine by themselves the performance information of an Analytics ID.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.2\tKey Issue #2: NWDAF-assisted application detection",
                    "description": "",
                    "summary": "",
                    "text_content": "Table 7.2-1\n\nSimilarity:\nBoth of the solutions aim at the NWDAF assisted application detection for the packets which will not introduce any enhancement on PDR activation, SDF detection, QoS control, etc.\nThe NWDAF in both Sol#8 and Sol#9 needs to collect the QoS flow level traffic information in UPF.\nDifference:\nSol#8 introduces a new terminology, i.e. Service Type, to describe unknown applications. which leads to some new problems. E.g. how the Service Type detection and Service Type QoS control can co-exist with the existing SDF detection and QoS control, which will cause complexity to the existing mechanism of 5G system. However information omitting a service type would not be useful to derive policies for unknown applications. So that it is proposed that the handling of unknown applications is left to next release\nSol#8 assumes some input from the AF although the presumed underlying use case is to become independent of AF-provided information.\nSolution 9 covers only changes of PFDs for known applications (e.g. change of server address while other characteristics of the flow remain the same)\nOpen issues for both solutions:\nBoth solutions rely on new UDR reporting mechanism which are supposed to be introduced by FS_UPEAS and require coordination with the results of that study.\nBoth solutions do not answer the question how degradation of UPF performance due to excessive reporting load at the UDR can be avoided (as required in the key issue description). This may depend on FS_ UPEAS conclusions.\n",
                    "tables": [
                        {
                            "description": "Table 7.2-1",
                            "table number": 72,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.3\tKey Issue #3: Data and analytics exchange in roaming case",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "7.3.1\tSolution categorization",
                            "text_content": "Solution #10, #11, #17, #37, #38, #39 and #40 are proposed for Key Issue #3 \"Data and analytics exchange in roaming case\", which are categorized as shown in Table 7.3.1-1.\nTable 7.3.1-1: Solution Categories for Key Issue #3\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 7.3.1-1: Solution Categories for Key Issue #3",
                                    "table number": 73,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "7.3.2\tEvaluation of solutions on general architectural enhancements",
                            "text_content": "Table 7.3.2-1: Comparison of solutions on general architectural enhancements for KI#3 RRC_Inactive mode reception\n\nSolution #10, #38, #39 and #40 all suggest to use a central entry point for incoming requests for analytics and/or data, e.g. to authorize and filter those request and responses, to deliver the analytics and/or data. The differences are in the selection of the entry point:\nSolution #10 introduces a new 5GC NF, i.e. Gateway Exposure Function (GEF), which is responsible for:\n-\tdata/analytics exposure to other PLMNs, by enforcing constraints on the type and amount of data exposed to each PLMN according to roaming agreement;\n-\tobtaining the user consent for data collection where applicable.\nSolution #38 proposes that the NWDAF serves as central entry point for related requests, authorizes requests and restricts exposed data and analytical information. That is, data and analytics information are exchanged between the H-NWDAF and the V-NWDAF directly.\nSolution #39 proposes that the consumer NF (e.g. NWDAF or other 5GC NF) in HPLMN subscribes to data/analytics information of the VPLMN via the H-DCCF and V-DCCF. The V-DCCF checks whether the consumer NF from the HPLMN is authorized to obtain data/analytics from the VPLMN.\nSolution #40 proposes that the NWDAF in HPLMN (/VPLMN) behaves as an untrusted AF to the VPLMN (/HPLMN) and performs data collection or analytics subscription from the VPLMN (/HPLMN) via the NEF. The NEF is responsible for authorizing the data collection or analytics subscription request, by checking user consent, operator policy, regulatory constraints and/or roaming agreements.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 7.3.2-1: Comparison of solutions on general architectural enhancements for KI#3 RRC_Inactive mode reception",
                                    "table number": 74,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "7.3.3\tEvaluation of solutions on enhancements for specific use cases/functionalities/Analytics IDs",
                            "text_content": "Table 7.3.3-1: Comparison of solutions for specific use cases/functionalities/Analytics IDs for KI#3\n\nBoth Solution #11 and Solution #37 propose analytics information exchange for PDU Session management in home routed roaming cases:\n-\tboth Solution #11 and Solution #37 proposes that the AMF uses slice load level analytics of the HPLMN for Network Slice selection, while Solution #11 also proposes that the AMF uses NF load analytics of the HPLMN for SMF selection;\n-\tSolution #37 proposes that the H-PCF uses service experience analytics of the HPLMN to adjust QoS parameters for the PDU Session.\nSolution #17 proposes that the H-PCF uses service experience analytics (or slice load level analytics) of the VPLMN to decide on the NSSP in URSP rules provisioned to the UE roaming in the VPLMN.\nSolution#38 contains the following two aspects:\n-\tthe H-NWDAF collects VPLMN data from the V-NWDAF;\n-\tthe V-NWDAF retrieves the \"UE analytics profile\" from the H-NWDAF for an inbound roaming UE and use it for determining analytics related to that UE for consumers NFs in the VPLMN;\nwhere the data collection and \"UE analytics profile\" sharing between the PLMNs may raise security and privacy issues, and therefore rely on roaming agreements / operator policy and user consent.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 7.3.3-1: Comparison of solutions for specific use cases/functionalities/Analytics IDs for KI#3",
                                    "table number": 75,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "7.4\tKey Issue #4: How to Enhance Data collection and Storage",
                    "description": "",
                    "summary": "",
                    "text_content": "According to the Table 6.0-1, solution#12, #41 to #46, #61 and #64 to #68 are proposed for Key Issue 4.\nTable 7.4-1 gives the comparison of candidate solutions and the corresponding solutions can be classified into four categories:\nTable 7.4-1: Comparison of solutions for Key Issue#4\n\nThe solution evaluation for Category-1 is the following:\nModels are trained and retrieved from NWDAF containing MTLF. ADRF is suggested as an intermediate storage of models, before NWDAF containing AnLF retrieves them. Nothing prevents an NWDAF containing AnLF to retrieve the models directly from an NWDAF containing MTLF, this service is already available in Rel-17. Adding ADRF as an intermediate storage adds multiple ways to retrieve models, increase number of NFs included and thereby complexity and increase signalling between NFs. Models are viewed as business secrets and shall be protected. Model privacy when storing models in ADRF may be a concern, therefore, SA3 needs to investigate how to securely store the model without leaking privacy information.\nIn Rel-17, MTLF provides the model storage URL and FQDN information to the AnLF. In other words, the MTLF manages the repository where models are stored, obviously this repository is standardized in R17. Therefore, since the ADRF function is built to maintain a centralized repository for AIML operations across the network, it is logical that ADRF can be reused to store the ML models. In addition, saving the ML model generates the additional signalling, in R17 it is hidden under the implementation, now it has been shown due to the standardization of the procedure.\nThe solution evaluation for Category-2 is the following:\nSolution#12 proposes that the source DCCF initiates the DCCF and MFAF reselection due to UE mobility. Target DCCF (MFAF) gets the data subscription and pending outputs from the source DCCF (MFAF). This solution is aligned with the purpose of deploying a DCCF, which is managing the complexity of subscriptions on behalf of the data consumer. Indeed, the benefit of the solution is that the data consumer does not need to resend the data subscription to the target DCCF and data/notifications are not lost during the process. Also, the solution provides a procedure to cover MFAF re-location, in case MFAFs are deployed separately from DCCF. The solution works when the data subscription is for single UE, not for group UE or any UE.\nSolution#44 argues that it is good enough to terminate the data subscription to the old DCCF and the data consumer does the DCCF selection and subscribes to the new DCCF due to UE mobility. Ulike NWDAF relocation, where the target NWDAF may need the same data and ML model from the source NWDAF in order to have consistent analytics performance, nothing is really needed by the target DCCF from the source DCCF. Therefore, Solution#44 proposes a simple and clean solution that the old DCCF terminates the subscription and the data consumer select and subscribe to a new DCCF, which has no impact to the current standards.\nSolution#66 proposes that when the data consumer subscribes to the source DCCF directly, upon change of a source DCCF instance, it is required to inform the related data consumer of the event and possibly to update subscriptions between the DCCF and the data consumer. If the central DCCF is deployed, data consumer collects UE data via the central DCCF, data consumer may not need to be notified of the UE mobility events and DCCF reselection events.\nThe solution evaluation for Category-3 is the following:\nSolution#41 proposes that when the buffer of the data producer is about to overflow, the data producer informs the data consumer that it cannot keep the muted notifications and send all the muted notifications to the data consumer.\nSolution#45 covers Solution#41 and it also proposes that the data consumer can provide exception instruction to the data provider and the data provider will make the final decision on how to treat the muted notifications when its buffer is overflow.\nThe solution evaluation for Category-4 is the following:\nSolution#46 proposes enhancement for the ADRF/NWDAF data management. In particular, data consumer can provide Storage Handling Information to ADRF/NWDAF. In addition, ADRF/NWDAF is also provisioned with the storage policy of the operator. Note that, despite all the data belongs to the operator, it may not be enough to only have the storage policy applied at the data storage. Enabling Storage Handling Information from individual data consumer allows an operator to deploy flexible rules and to gain more granular control over the desired policies. Also, it is possible for the data consumer to be informed if some data is to be deleted.\nFurthermore, Solution#46 proposes the option in which DCCF maintains the data storage information, so that it executes tasks towards the data storage on behalf of the data consumer and informs the data consumer about the data deletions on behalf of the data storage.\nSolution#64 proposes enhancement for data collection and reporting of network data for NWDAF. In order to optimize the performance and accuracy of data collection and reduce the impact on data producers, data can be reported in a specified idle period of the device and data collection frequency can be set to the dynamic Non-fixed sampling ratio. However, notifications are generated when events occur, and it is not clear how the consumer (e.g. NWDAF) will know the best time for the producer to report events. It appears better to let the NF decide when it is too busy to send a report immediately and delay sending a report (which can be done via implementation). The non-fixed sampling ratio, which adjusts according to NF loading seems a more useful mechanism.\nSolution#65 proposes that the NWDAF to register in the UDM for the served UE, also for Analytics IDs that are not UE-related. The NWDAF may do this when the NWDAF is collecting data specific to the UE for the indicated Analytics ID. This further reduces signalling due to data collection and storage volume.\nSolution#67 proposes enhancement for the ADRF/NWDAF data management. In particular, data records stored at ADRF are associated to a DataSetTag which enables the service consumer to store and retrieve data sets by specifying such tag in the service request. The advantage of this solution is not only to group data that should belong together using a quick reference to the data set as a whole, but it also enables an analytics consumer (respectively an AnLF) to indicate what exact input data to be used by AnLF (respectively by MTLF) for inference (respectively for training).\nSolution#68 proposes enhancement for the ADRF/NWDAF data management to enable NWDAF and ADRF to employ data synthesis tools and compression techniques respectively to produce input data for inference and/or training, and to reduce the volume of transferred and stored data. In particular, the solution introduces the DSC Indicator as an attribute included in the Nadrf_DataManagement service operations which indicates the data processing executed over the stored/fetched data, let such processing be data synthesis or compression. The benefit of this solution is that it permits the re-use of synthetic data for privacy preserving purposes, as well as the re-use compressed data to reduce the volume of transferred and stored data.\n",
                    "tables": [
                        {
                            "description": "Table 7.4-1: Comparison of solutions for Key Issue#4",
                            "table number": 76,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.5\tKey Issue #5: Enhance trained ML Model sharing",
                    "description": "",
                    "summary": "",
                    "text_content": "According to the Table 6.0-1, solution#13, #14, #15, #43 and #47 are proposed for Key Issue 5.\nSolution #13 and #14 supports sharing of model via ML model file format. When the NWDAF (containing MTLF) registers its NF profile with NRF, the solution #13 and #14 provide means to include ML model file formats in its NF profile. In addition, Solution #14 also includes Supported AI Framework in its NF profile.\nSolution #15 introduces Interoperable Indicator indicating what an NWDAF containing MTLF decides to share based on business needs.\nSolution #47 introduces Interoperable Token indicating that a certain model is agreed to be share based on business agreements and interoperable testing. The solution supports sharing of models as OCI images and can also support ML model file serialization format. The solution supports multiple environments in which models run in different AnLFs. Neither the format nor the environment is specified in 3GPP, these are rather described in a container which is out of scope out 3GPP.\nSolution #47 supports all functionality specified in solution#13, #14 and #15.\nSolution #43 is mainly about storing models in ADRF and in KI#5 aspects to be studied are how to enhance trained ML Model sharing between NWDAFs from different vendors. Solution#43 is therefore not evaluated in this KI.\nThe common characteristics to enable trained ML model sharing between different vendors includes\na)\tInteroperability indicator (Solution 15),\nb)\tInteroperable Token (Solution 47),\nc)\tML model filter information i.e. ML model file format supported including serialization file formats (Solution 13 and 14), Supported AI Framework Information (Solution 14).\nBoth a) and c) parameters are complementary to each other. The interoperable indicator allows the MTLF to determine whether to expose the certain ML models to another provider's AnLF or not, and then if allowed select the model. For a selected trained ML model, the ML model filter information (ML model file format and AI Framework information) indicates the ML environment the ML model is trained in and associated output file format.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.6\tKey Issue #6: NWDAF-assisted URSPs",
                    "description": "",
                    "summary": "",
                    "text_content": "According to the Table 6.0-1, solution#16, #17, #48 and #49 are proposed for Key Issue 6.\nThe solutions are evaluated based on the following criteria, aligned with the description of the KI.\n1.\tWhether any and which components of the URSP rules can benefit from analytics.\n2.\tWhether and how existing Analytics IDs, or new Analytics ID(s) can be used to assist in the generation of URSP Rules.\n3.\tWhat procedures trigger the subscription to these Analytics IDs.\n4.\tWhether new (set of) interactions(s) are required to assist in the generation of URSP Rules as defined in Rel17, and how to define the new interactions if needed.\n5.\tWhat information should be collected (or provided) as input (or output) by the NWDAF for these Analytics IDs.\nThe table below shows a summary of the mapping between fields in URSP rules and the proposal of analytics used for assistance on these fields for the different solutions:\nTable 7.6-1: Mapping of fields in URSP and analyticIds\n\nSolution #16:\nThis solution proposes to use existing analytics to adjust the values of some fields in the URSP rules according to the table 1 above. It provides examples about how the analytics should be used by PCF for the adjustment of URSP fields:\n-\tS-NSSAI: Select the S-NSSAI that provides best results for an application for aspects as service experience, network slice load, Session management congestion control and/or average data rate in the network slice based on analytics for service experience, network slice load, Session management Congestion Control Experience and dispersion analytics respectively.\n-\tDNN: Similar to the first bullet but to obtaining best service experience for the application and/or session management control experience based on Service Experience and Session management Congestion Control Experience analytics.\n-\tNon-Seamless Offload Indication: The PCF may get first a prediction of the location where the UE will use an application, by subscribing to \"UE Communication\", and then get the information about the performance of the 3GPP and WLAN accesses on that location by subscribing to \"Network Performance\", \"User Data Congestion\" and \"WLAN performance\" analytics respectively. Then, if the prediction of the performance on the WLAN access is good enough, the PCF may decide to set the indication to reduce the load on the 3GPP access if needed.\n-\tSSC Mode Selection, PDU Session Type and Access Type preference: Select the combination of these parameters that provides best service experience for the application, based on the enhancement of \"Service Experience\" analytics, which considers also these parameters.\n-\tPDU Session Pair ID and RSN: The PCF decides whether to set these values based on the result of the analytic \"Redundant Transmission Experience\". While how the additional redundant PDU Session can be triggered is not mentioned in this solution.\n-\tTime Window and Location Criteria: It is proposed to set these values based on the time validity period and spatial validity in the analytics used as input for the other URSP fields adjustment.\nSimilar to other parameters as RAT type and Frequency already included in existing \"Service Experience\" analytics, this solution proposes to enhance existing \"Service Experience\" analytic in order to collect additional input data about the SSC mode, PDU session Type and Access Type used and then extend the output of the analytic with those parameters.\nThe PCF can also request analytic of combination of several RSCs in one RSD, for example the combination of S-NSSAI + DNN or the combination of PDU session type + SSC mode and etc. to NWDAF. The NWDAF should support to provide the analytic of combination of several RSCs to PCF. The PCF can adjust the RSD precedence according to the analytic from NWDAF, and also the PCF can receive the analytic of the whole RSD (if the combination of RSCs are the RSCs included in one RSD) or different arbitrary combination of RSCs in URSP rule.\nSolution #17:\nThis solution proposes the PCF may adjust the values of S-NSSAIs in URSP rules for an application in a UE in roaming, based on the result of analytics (\"Service Experience\", \"Network Slice load level\", etc..) obtained from the V-PLMN where the UE is roaming.\nIt proposes a procedure for the H-PCF to obtain the analytics from the V-PLMN, based on query to the H-NWDAF of the value of those analytics in the V-PLMN and then H-NWDAF contacting with V-NWDAF in the V-PLMN. It also proposes the H-NWDAF does the mapping of S-NSSAI values from the Home to the VPLMN and discovers the V-NWDAF by querying NSSF and v-NRF. However, it is considered this proposal is more related with KI#3 (\"Data and analytics exchange in roaming case\") and should be aligned with the conclusions of that KI.\nFS_UEPO, key issue 1, aims to enable the provisioning of URSP rules in the VPLMN and may thus remove the need for the H-PCF to determine NSSP. Coordination is required.\nSolution #48:\nIt proposes to use some existing analytics to adjust following URSP fields, according to the table 1:\n-\tS-NSSAI: Similar to solution #16, it proposes to select the values of S-NSSAI for an application based on the analytics result for \"Slice Load Level\" for the different candidates S-NSSAI.\n-\tDNN: Select the DNN which gets better predicted values for the DN performance for an application based on \"DN Performance\" analytics. The DN performance also applies to the traffic descriptors with application server IP address, S-NSSAI and DNN.\n-\tAccess Type: Based on the predictions of the performance/experience for 3GPP and non-3GPP accesses using Enhanced \"Service Experience\" and \"WLAN Performance\" analytics.\nAlso similar to solution #16, it is proposed an enhancement of \"Service Experience\" analytic to provide the service experience information depending on the access type of PDU session.\nThe analytic from NWDAF indicates both the single RSC performance and the combination of RSC in certain RSD under the Traffic Descriptor. For example, the NWDAF can provide the performance statistic/prediction of combination of RSC, e.g.: DNN, S-NSSAI, PDU session type, SSC mode and etc. And, also the NWDAF can provide the performance statistic/prediction of single of RSC to PCF. The PCF can update or modify the URSP rules for UE according to the analytic from NWDAF.\nFor the PCF, it generates the URSP rules according to the data from UDR and delivers the URSP rules to UE. But due to the URSP rules is a two-layer-mapping design, that including the Traffic Descriptor and Route Selection Descriptor, the PCF can benefit from the analytics of both performance and experience.\nSolution #49:\nSame than for solution#16, this solution proposes the PCF may use existing analytic \"Redundant Transmission Experience\" to determine whether to provision an URSP rule for redundant transmission to the UE by setting URSP fields RSN and PDU Session Pair ID.\nIn addition, this solution proposes an extension of existing \"Redundant Transmission Experience\" analytic including:\n-\tNew filter parameter PDU session ID, to indicate the target PDU Session on which whether redundant transmission is needed or not.\n-\tNew output parameters E2E UL/DL packet drop rate and packet delay.\nLast, the solution proposes an extension of the procedure for Service Specific Information provisioning, defined in clause 4.15.6.7 of TS 23.502 [3], to enable an AF to request the establishment of Redundant end to end user plane path for an application. This new procedure proposes the PCF may use the \"Redundant Transmission Experience\" analytic from NWDAF as input information to assist on the decision to activate E2E Redundant transmission. Further, the PCF notifies the AF to instruct the UE to trigger redundant transmission for the application.\n",
                    "tables": [
                        {
                            "description": "Table 7.6-1: Mapping of fields in URSP and analyticIds",
                            "table number": 77,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.7\tKey Issue #7: Enhancements on QoS Sustainability analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "The solutions in KI#7 can be classified into two categories according to the issues that they mainly address for achieving improvements on QoS Sustainability analytics:\na)\tEnhance the QoS Sustainability analytics with a finer granularity area (e.g. below Cell level): Sol #18 (without any specific solution provided), #19, #50.\nb)\tEnhance the QoS Sustainability analytics with additional input data: #18, #19, #20, #50.\nSolutions in group b can be then differentiated according to the type of change, either introducing new information elements used for data collection from OAM or adding new sources of information interacting with NWDAF:\n-\tAdditional data from OAM: #18, #19, #20\n-\tAdditional data from SMF: #19 (with PCF), #20 (optional), #50\n-\tAdditional data from UPF: #20 (optional), #50\nThe evaluation of the solutions in the category \"Enhancements with a finer granularity area\" is provided as follows:\n-\tSol #18 acknowledges the need for \"below cell level location information\" and modifies accordingly the output analytics with the \"Applicable Area with finer granularity\" information but does not provide any details on how to effectively obtain such information.\n-\tSol #19 proposes to add interactions with LMF and AMF to get UE positions located in the Cell or TA where requested area or path of Interest is included.\n-\tSol #50 is also relying on LMF and AMF as well as GMLC to retrieve the UE location information, e.g. cell ID or finer granularity below cell. This solution describes more in detail the overall procedure involving LCS Service and GLMC.\nThe evaluation of the solutions in the category \"Enhancements with additional input data\" is provided as follows:\n-\tSol #18 introduces the usage of \"Latency and delay of 5G networks\" from OAM, described more in details in clause 6.3 of TS 28.554 [9] referring to the Integrity KPI. Among possible specific KPIs, the \"Downlink/Uplink latency in gNB-DU\", \"Integrated Downlink/Uplink delay in RAN\" or \"E2E delay for network slice\" could be obtained for example to enhance the data collection for \"QoS Sustainability\" analytics.\n-\tSol #19 proposes also to add similar information from OAM called \"Packet Delay\", but referring this time more specifically to TS 28.552 [7], where for instance different performance measurements are described such as the \"Average delay UL/DL air-interface\", \"Round-trip GTP Data Packet Delay and packet delay between NG-RAN and PSA UPF\". This solution also introduces new input data from TS 28.552 [7] called \"RAN status, load and performance information\" referring at least to the \"Radio resource utilization\" described in clause 5.1.1.2 and \"Packet Loss and/or Drop\", certainly referring to clause 5.1.3 \"Performance measurements valid for split gNB deployment scenario\" describing the \"Packet Loss Rate\" and \"Packet Drop Rate\" measurements. In addition to OAM source, Sol#19 introduces the usage of \"QoS Notification Control of the QoS profiles or Alternative QoS Profiles\" and their corresponding \"QoS profiles\" from SMF and PCF. Additional input from UDM together with support of UE Context or Subscription information in the filters provided by the consumer can be used to further improve the accuracy of the analytics.\n-\tSol #20 proposes firstly to add the same \"Packet Delay\" from OAM already described in TS 28.552 [7] like for Sol#19. In addition, this solution proposes to extend the measurements related to QoS Monitoring defined in TS 23.501 [2] and TS 28.552 [7], to include the IP-layer section capacity and IP-layer available section capacity between UE, NG-RAN and UPF at GTP level. In this way, new data input could be obtained such as \"UL/DL capacity GTP between UPF and UE\" or \"UL/DL available capacity GTP between UPF and NG-RAN\" corresponding respectively to the \"IP-layer section capacity\" and \"IP-layer available section capacity\" definitions from ITU-T Y.1540. How OAM can perform capacity measurements is to be determined by SA WG5. Optionally, End-to-End measurements from UE to UPF like \"UL/DL packet delay GTP\" could be also obtained through SMF or UPF.\n-\tSol #50 does not rely on OAM but proposes to collect instead QoS information from the UPF directly or through the SMF. Such information may include the \"QoS flow Bit Rate\" representing the observed bit rate for UL and DL and \"QoS flow Packet Delay\" representing the observed packet delay for both directions. Additional input from UDM together with support of UE Context or Subscription information in the filters provided by the consumer can be used to further improve the accuracy of the analytics.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.8\tKey Issue #8: Supporting Federated Learning in 5GC",
                    "description": "",
                    "summary": "",
                    "text_content": "Table7.8-1: Solution evaluation for KI #8\n\nBased on the above analysis, we get the following observations:\nObservation 1: Sever NWDAF and Client NWDAF registers to NRF with their FL related information, e.g. Analytics ID, ML Filter Information, FL Capability.\nObservation 2: FL Consumer or local configuration in Server NWDAF triggers FL operation, and Server NWDAF selects Client NWDAFs from NRF.\nObservation 3: Server NWDAF performs model aggregation and Client NWDAFs perform local training. Server NWDAF exchanges FL training related information with Client NWDAFs, e.g. interim model, initial model configuration.\nObservation 4: For most solutions, model sharing between NWDAF instances is a prerequisite for FL operation. And it is a general issue studied in KI #5.\nObservation 5: There are solutions that propose to improve the FL model by providing FL Consumer's feedback (e.g. model accuracy in real application) to NWDAF Server. And this issue is related to KI #1.\nObservation 6: There are solutions that propose the maintenance of FL process, include the procedure which enables NWDAF Server to monitor the status update of the NWDAF Clients and the dynamic procedure which enables NWDAF Clients to join or quit the FL operation in execution phase.\nObservation 7: There is a solution that proposes model performance monitoring during federated learning. In order to guarantee model performance of the FL operation, the Server NWDAF should exclude a Client NWDAF from the FL group if the Accuracy-in-Training of the initial/common model calculated by the Client NWDAF is much different from the Accuracy-in-Use calculated by the AnLF.\nObservation 8: 7 out of 8 solutions focus on horizontal FL.\n",
                    "tables": [
                        {
                            "description": "Table7.8-1: Solution evaluation for KI #8",
                            "table number": 78,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.9\tKey Issue #9: Enhancement of NWDAF with finer granularity of location information",
                    "description": "",
                    "summary": "",
                    "text_content": "There are 11 solutions for KI#9 (Solutions #25, #26, #27, #54, #55, #56, #57, #58, #59, #70, #71). Table 7.9-1 provides details of how the NWDAF can be enhanced with finer granularity location information.\nTable 7.9-1: Evaluation of the KI#9\n\nBased on the above aspects, the detailed analysis is elaborated as follows:\nSolution #54, #55, #57 proposed that the NWDAF will determine from where to obtain the location information based on the received information from NWDAF consumer. If the received information indicates the NWDAF consumer needs finer granularity UE location, NWDAF will query LCS system to obtain it; if the received information indicates the NWDAF does not need finer granularity UE location, NWDAF will proceed based on legacy procedures as defined in TS 23.288 [5] (e.g. AMF, OAM, AF) to obtain UE location with TA/cell level.\n-\tIn Solution #54, the received information is new parameters (Location granularity, Location accuracy granularity as defined in clause 4.3 of TS 22.071 [6]) that is added to Analytics Filter Information. These parameters are valid for existing analytics IDs and new analytics ID that needs UE location as input data. However, it is not mentioned how the NWDAF can obtain UE location in TA, cell or finer granularity from LCS.\n-\tIn Solution #55, the received information is identified from the new analytics ID named \"finer granularity in 2 directions\". This is only valid for the new analytics ID.\n-\tIn Solution #57, the received information is identified from preferred location granularity and preferred LCS QoS analytics in the request. The following enhancement is needed to fulfil the granularity control purpose:\n-\tUE finer granularity location level should be added into \"preferred granularity for location information\". By this addition, NWDAF can clearly make the decision about from where to obtain the UE location.\n-\tNew preferred LCS QoS parameter is needed. However, how the NWDAF consumer is aware of this LCS QoS parameter is not discussed.\nSolution #26, #27, #55, #70 proposed that the NWDAF can request UE location information with TA/cell level from 5G NFs as currently specified in TS 23.288 [5].\n-\tSolution #26 proposed that the NWDAF provides UE locations in order.\n-\tSolution#27 proposes that the NWDAF consumer can request new analytics about collision avoidance from NWDAF. With the \"Time To Collision\" information and UE nearby vehicles (also 3GPP UEs) moving speed, moving direction and etc. the NWDAF consumer can make the decision to avoid collision to other UEs in proximity. However, it needs enhancement to current 5G NFs regarding UE location collection, especially:\n-\tFrom OAM, per UE level speed and orientation information is needed.\nNOTE 1:\tConfirmation from SA WG5 about whether and how the OAM can provide the required UE speed and orientation information with MDT is needed.\n-\tSolution #55 proposed that the NWDAF provides the UE location in both horizontal direction and vertical direction with different granularity (TA/cell or finer granularity).\n-\tSolution #70 proposed that the NWDAF can provide a more flexible UE location with time domain and space domain enhancements to enable the distinguishment of UE trajectory analysis and UE presence in a given area.\nSolutions #25, #54, #55, #56, #57, #58, #71 proposed that the NWDAF can request UE location information with finer granularity from LCS system, where solution #54, #55, #56, #57 require no enhancement from LCS system regarding UE location information provision.\n-\tSolution #25 requires LCS system to provide UE(s) location information (location estimate, velocity and etc) in a specific geographical area, which is different from the translated TA/cell level geographical area.\n-\tSolution #58 enables NWDAF to provide UE location under a specific Motion Event Criteria, i.e. when the UE moves a threshold linear distance that the UE makes before providing UE location. This enhancement can be done in NWDAF, or require the LCS system to provide UE location under such Motion Event Criteria.\n-\tSolution #71 requires LCS system to provide UE(s) location information (location estimate, UE velocity, location accuracy and etc), environment indication (e.g. indoor/outdoor), in a specific geographical area.\nNOTE 2:\tWhether all the data collected can be provided by LCS needs to be confirmed in eLCS_Ph3.\nSolution #59 proposes a new analytics service in NWDAF that can be used by the LMF to improve UE location accuracy. The new analytics ID shall take the UE location estimate as input and provide the predicted UE location accuracy as output. In the training phase location information determined by two methods is correlated to derive location accuracy for the less precise method.\nNOTE 3:\tThe eLCS_ph3 study agreed an conclusion to use this analytics as specified in TR 23.700-71 [30].\n",
                    "tables": [
                        {
                            "description": "Table 7.9-1: Evaluation of the KI#9",
                            "table number": 79,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.10\tKey Issue #10: Interactions with MDAS/MDAF",
                    "description": "",
                    "summary": "",
                    "text_content": "Evaluation of solutions for KI#10:\nThe following table provides an evaluation of each solution.\nTable 7.10-1: Evaluation of solutions for KI#10\n\n",
                    "tables": [
                        {
                            "description": "Table 7.10-1: Evaluation of solutions for KI#10",
                            "table number": 80,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "8\tConclusions",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "8.1\tKey Issue #1: How to improve correctness of NWDAF",
                    "description": "",
                    "summary": "",
                    "text_content": "For KI#1, it proposes the following principles:\nGeneral aspects:\n-\tAnalytics consumers and AnLF may indicate a \"Use case context\" when subscribing to or requesting analytics or ML model(s), respectively. The values of this parameter will not be standardized. The actions of the NWDAF based on the use case context are out of scope of 3GPP/implementation specific.\n-\tNWDAF has the accuracy checking capability of analytics IDs and/or ML models, where NWDAF can store for a period of time the necessary information to determine the analytics IDs and/or ML model accuracy and provide the accuracy information to consumers when requested or use it for its internal processes.\n-\tAn NWDAF containing AnLF with accuracy checking capability is able to provide or notify the accuracy information of Analytics IDs to the consumers of such service.\n-\tAn NWDAF containing MTLF with accuracy checking capability is able to provide or notify the ML model accuracy degradation to the consumers of such service.\nInput of accuracy check:\n-\tML Model accuracy improvement can be achieved by comparing prediction using the current trained ML model and its corresponding ground truth data i.e. the corresponding true observed events.\n-\tThe MTLF is to reselect a new ML model or retrain the existing ML model that provided to the AnLF when it determines ML model degradation by either:\n-\tMTLF determining ML model degradation by collecting new test data (including input data, ground truth data and the corresponding inference) and testing the ML model accuracy. MTLF can compute accuracy by comparing the predictions and the corresponding ground truth data.\nNOTE 1:\tInput data is the necessary data which is collected by AnLF to perform inference to generate prediction and the ground truth data is the actual measured data which corresponds toa prediction.\n-\tMTLF can collect data for monitoring purposes from AnLF, ADRF or other NF. When ADRF is used, the MTLF can retrieve the data by specifying in the request the DataSetTag.\nNOTE 2:\tThe DataSetTag is defined from the conclusions of KI#4.\n-\tMTLF subscribes to AnLF, that is registered in MTLF with its accuracy monitoring for a model provided by that MTLF, for getting notifications of the accuracy degradation of the analytics generated by the model, where the AnLF determines accuracy information based on any of the following:\n-\tComparing predictions and its corresponding ground truth data.\nNOTE 3:\tThe ground truth data and the corresponding prediction is to be defined per Analytics ID.\n-\tComparing changes in internal configuration for the analytics ID generation (e.g. data collection parameters).\n-\tPrevious existent records of analytics accuracy information.\n-\tThe analytics consumer performs action that may consequently affect the ground truth data and may provide the accuracy feedback information that indicates whether the analytics consumer NF performs actions to AnLF.\n-\tIn the case of AnLF with accuracy checking capability, the accuracy feedback information is taken into account by AnLF to improve Accuracy Calculating.\n-\tIn the case of MTLF with accuracy checking capability, AnLF further forward the accuracy feedback information to MTLF, which is taken into account by MTLF to improve Accuracy Calculating.\n-\tAnLF/MTLF can evaluate the quality of the data from the 3rd party data sources for input data selection.\nTriggers of performance check:\n-\tMTLF with accuracy checking capability of ML models can trigger the analytics accuracy checking based on its internal logic or configuration which may require to subscribe events, e.g. a change in the policy and/or a change in the subscription data for Target of ML Model Reporting, etc.\n-\tWhen requesting an ML model via the MLModelProvision service, the AnLF can specify in the request the additional parameters indicating the need for ML model accuracy check.\n-\tWhen MTLF provides an ML model to an AnLF, the MTLF requests/subscribes AnLF to determine accuracy of the analytics generated from that model by comparing predictions and its corresponding ground truth data, if the AnLF indicates it can provide accuracy feedback.\n-\tAn analytics consumer may request or subscribe to accuracy information about Analytics ID(s) from the AnLF with the performance checking capabilities. Accuracy information can be included in an accuracy report, scoped in the same way as Analytics requests are scoped, i.e. per Analytics ID, for a specific area, slice, (group of) UEs, in a given time window, etc. Such request or subscription triggers the monitoring and check of Analytics ID(s) and generation of analytics accuracy information.\nActions after accuracy check:\n-\tWhen accuracy information includes an indication that the accuracy of the analytics does not meet the consumer's requirements, the analytics consumer may stop using analytics for a period of time or obtain new analytics.\nIn addition, accuracy information may also include updated analytics for the provided analytics ID, if the updated analytics is able to be generated within the correction time period.\n-\tWhen accuracy information includes indications for the NF to stop or pause the consumption of the analytics, the NF may unsubscribe to the analytics ID, or provide an indication to AnLF that it is pausing an existing subscription of the analytics ID. Once AnLF determines the accuracy of the analytics is improved to meet the consumer's requirements for an analytics ID, the AnLF may notify the NF consumer with an indication for resuming consumption of analytics ID.\n-\tNF consumers of Analytics ID(s) upon receiving an accuracy information from an AnLF may request a pause or resume of notification from existing subscriptions.\n-\tNWDAF can rate untrusted AF data sources based on data source performance monitoring. Monitoring can be performed by NWDAF containing MTLF considering the data distribution or data drift, (i.e. between predictions and ground truth data) or alternatively by the NWDAF containing AnLF considering either the data drift or the evaluation feedback provided by service consumer.\nOther aspects:\n-\tIn order to improve correctness of NWDAF Service Experience analytics, the AF may provide \"Service Experience Contribution Weights\" to the NWDAF as described in Solution #2.\n-\tProviding Multiple ML models to AnLF may help improve Analytics accuracy. In this case, each ML model shall indicate the providing MTLF and is assigned a unique ML Model identifier (i.e. unique within a PLMN) by the providing MTLF.\nNOTE 4:\tThe structure and format of the ML Model identifier and its uniqueness are up to stage 3.\n-\tWhen requesting an ML model via the MLModelProvision service, the AnLF can specify in the request the information about input data type to assist MTLF in the ML model selection. Similarly, to assist the AnLF in selecting the appropriate ML model for inference, the ML model provisioning response includes information about the input data type, sources and parameters such as data granularity and sampling ratio, that have been actually used for the training of the ML model.\n-\tIn order to enable AnLF to know if a model can represent the group of UEs which are Target of ML Model Reporting, Representative Ratio may be provided from MTLF to AnLF as part of the model information. AnLF may provide a threshold of Representative ratio as part of the input parameters in the Model Provisioning request.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.2\tKey Issue #2: NWDAF-assisted application detection",
                    "description": "",
                    "summary": "",
                    "text_content": "It is concluded to focus on the use case of PFD updates for known applications in Solution#9, which is selected as baseline for the normative work.\nThe known application means an application for which the application ID is already known by the 5GC and can be referenced within PCC rules and for which PFD information (may not be the latest) is already available.\nIt is concluded, that the NEF(PFDF) as a consumer can request NWDAF to get a new Analytics ID for application detection, following the detail described in solution#9.\nNOTE 1:\tExtensive reporting related to all traffic flows at the UPF should be avoided due to the high UPF load. An NWDAF preferably subscribes only for reporting for some UEs to limit the load..\nNOTE 2:\tCoordination with the FS_UPEAS conclusions is required for procedures for UPF event exposure and the related subscription.\nNOTE 3:\tCoordination with SA WG3 for possible user consent checking is needed.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.3\tKey Issue #3: Data and analytics exchange in roaming case",
                    "description": "",
                    "summary": "",
                    "text_content": "For KI#3, the following architectural principles are agreed as conclusion:\n-\tAn NWDAF is used as entry point to exchange analytics in roaming scenario between HPLMN and VPLMN. It authorizes the request according to operator policies and user consent and it filters the information exposed in reply to the request.\nNOTE 1:\tHow to discover the NWDAF for the roaming case is determined in normative phase.\n-\tThe NWDAF offers new services to be accessed by the peer PLMN. This allows the NRF to be configured in such a manner that only access to those services is authorized from outside the PLMN. The new services will be defined with as much communality as possible to existing services to ease the implementation.\n-\tExposure of input data for analytics is allowed from VPLMN to HPLMN and vice versa. It may be restricted based on operator policy and user consent.\n-\tThe HPLMN may provide analytics to the VPLMN. The VPLMN may provide analytics to the HPLMN.\nNOTE 2:\tAnalytics that rely on input data from the HPLMN are preferbly not provided from VPLMN to HPLMN but generated in the HPLMN. Analytics that rely on input data from the VPLMN are preferbly not provided from HPLMN to VPLMN but generated in the VPLMN.\nNOTE 3:\tData and analytics exchange between HPLMN and VPLMN may be furter updated based on feedback from GSMA during the normative work.\nNOTE 4:\tThe user consent check procedure and security aspects will align with SA WG3's conclusion during normative work.\nThe following use cases are supported:\n-\tVPLMN may consume analytics generated by HPLMN or request input data and generate analytics on its own:\nNOTE 5:\tIt will be determined during the normative work whether an analytics profile is required in addition to analytics.\n-\tIn home routed roaming scenarios, HPLMN analytics (i.e. slice load level analytics, NF load analytics, etc.) can be leveraged by the AMF in the VPLMN for Network Slice selection and SMF selection for PDU Session management.\n-\tUE-related analytics provided by the HPLMN (e.g.. service experience analytics, etc.) can include statistics or predictions for outbound roaming UEs.\n-\tHPLMN may consume analytics generated by the VPLMN or request input data and generate analytics on its own.\n-\tIn home routed roaming scenarios, analytics information with statistics or predictions for outbound roaming UEs can be leveraged by the H-PCF for QoS control of the PDU Session.\n-\tAnalytics (i.e. service experience analytics, slice load level analytics, etc.) can be leveraged by the H-PCF for decision of NSSP in URSP rules provisioned to the UE roaming in the VPLMN.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.4\tKey Issue #4: How to Enhance Data collection and Storage",
                    "description": "",
                    "summary": "",
                    "text_content": "1.\tFor Managing Impact of storing data in NFp during muting, Solutions #41 and #45 are adopted for normative work.\n2.\tFor ADRF / NWDAF Data Storage Management, a consumer may request data deletion alert and provide life time of the data to the ADRF. NWDAF or ADRF may be configured with operator policies for data storage as defined in Solution#46.\n3.\tData records can be stored at ADRF with an associated DataSetTag. The DataSetTag can be used to retrieve the whole set of data records associated to such tag. The DataSetTag may be included in the service requests to AnLF and MTLF to indicate the data set to be used by the AnLF, respectively by MTLF.\n4.\tData can be stored at and retrieved from ADRF using techniques of data compression and/or data synthesis. The DSC indicator is used to represent the technique of data compression and/or data synthesis. The value of DSC is up to vendor agreement and up to implementation. How to support data transportation using the techniques of data compression and/or data synthesis is out of the scope of 3GPP.\nNOTE 1:\tHow DSC is conveyed in the SBI message is up to Stage-3 design.\n5.\tTo optimize the reporting of network data, data can be reported according to a non-fixed sampling ratio. Data consumer can indicate the non-fixed sample ratio in the data subscription request. Data consumer can update the data sampling ratio dynamically by updating the data subscription. Data provider can use different sampling ratio according to local configuration and provide the sampling ratio info in the data notifications to the data consumer.\n6.\tNormative change (only impacting stage 2) is recommended to allow NWDAF to register in the UDM for the served UE, also for Analytics IDs that are not UE-related, as defined in Solution #65.\n7.\tFor storing ML models in ADRF, MTLF can store ML model in ADRF based on MTLF policy.\n8.\tMTLF sends the ML model or ML model address to ADRF by using ADRF's ML model storage service.\nNOTE 2:\tHow MTLF sends the ML model by using 3GPP defined service-based interface is determined in normative phase.\n9.\tNF consumer(s) (MTLF or AnLF) retrieves the ML model or URL (where the model is stored) from ADRF by using ADRF ML model retrieval service. ADRF shall not duplicate the functionality as MLModelProvision Service.\nNOTE 3:\tWhether new service operation or re-use existing service operation to retrieve ML model from the ADRF will be decided during normative phase.\nNOTE 4:\tWhether the ADRF further downloads the ML model based on the ML model address and locally stores the ML model is left for implementation.\nNOTE 5:\tWhen storing ML models and retrieving ML models at the ADRF, whether and which additional security-related parameters need to be sent by MTLF to ADRF are to be determined with SA WG3.\nNOTE 6:\tThe NF consumer(s) may be authorized by the ML model provider (i.e. provider of MTLF) when retrieving the ML model from ADRF. The details of the authorization procedure will be discussed in SA3 WG.\n10.\tWhen a DCCF and optionally MFAF is no longer able to serve a data consumer due to data source change, procedures for DCCF and optionally MFAF re-location (respectively re-selection) are supported according to solutions 12 and 66 (respectively 44). The selection of the appropriate procedure is determined by the DCCF based on an optional \"No relocation\" indicator provided by the DCCF service consumer: when the indicator is absent or set to \"False\", the DCCF executes the relocation procedure, when set to \"True\", the DCCF does not execute the relocation.\n11.\tTransfer of Analytics subscription can be aligned to follow principle #9, i.e. source NWDAF will determine whether to initiate the Analytics subscription transfer based on a \"No Relocation\" indicator provided by the Analytics service consumer.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.5\tKey Issue #5: Enhance trained ML model sharing",
                    "description": "",
                    "summary": "",
                    "text_content": "It is recommended to use the following principles and procedures as the basis for the normative work.\n-\tThe following are the trained ML model sharing parameters to enable ML model sharing between different vendors - Interoperability indicator as specified in Sol#15 and optional Interoperability token as specified in Sol#47.\n-\tThe Interoperability indicator indicates a list of NWDAF providers (vendors) that are allowed to retrieve ML models from the NWDAF containing MTLF.\n-\tThe Interoperability indicator indicates that the NWDAF containing MTLF supports the interoperable ML models requested by the NWDAFs from the vendors in the list.\nNOTE:\tThe vendor list indicated by the Interoperability indicator is determined by the NWDAF vendor and is configured in the NWDAF.\n- \tThe Interoperability token implicitly maps to an interoperable model information, e.g. file format, platform, etc. The encoding, format and value of the Interoperability token is up to vendors' implementation, thus no normative work is needed except defining this IE.\n-\tDuring registration of NWDAF containing MTLF with NRF, Interoperability indicator and optional Interoperability token to trained ML model sharing are provided as part of NF profile to the NRF.\n-\tDuring NWDAF containing MTLF discovery procedure, the consumer i.e. NWDAF may include Interoperability indicator and optional Interoperability token per Analytics ID(s) in the discovery request.\nNOTE:\tWhen ML model provider MTLF and ML model consumer NWDAF belong to different vendors, how the ML model privacy is supported is in scope of SA WG3.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.6\tKey Issue #6: NWDAF-assisted URSPs",
                    "description": "",
                    "summary": "",
                    "text_content": "It is concluded the PCF may adjust the fields (i.e. RSCs) and even the RSD preference in URSP rules based on the analytics result from NWDAF according to the table below (based mainly on proposal from Solution#16 and Solution#48):\nTable 8.6-1: Mapping of fields in URSP and analytics\n\nIt is assumed that for every application the PCF first determines (e.g. per operator configured policies):\n-\tWhether some fields of the corresponding URSP rule may be adjusted by using analytics.\n-\tThe list of potential candidate values for every field in the URSP rule to be adjusted with analytics.\nThen the PCF uses analytics results from NWDAF to select the proper value from the list of candidates, according to the table 1.\nNOTE:\tCare needs to be taken with regards to signalling and processing load caused when requesting analytics targeting \"Any UE\". A PCF preferably limits the analytics requests to a smaller UE set to reduce the load.\nIt is proposed the extension of existing \"Service Experience\" analytic to include new input and new output information for SSC mode, PDU session Type and Access type based on proposal from Solution#16 and Solution#48. PDU Session type and SSC mode (and combinations of those and other RSCs) needs to be added to the request/subscription for Analytics of Service Experience, the full list of RSCs and what are the relevant combination will be defined in normative phase.\nIt is proposed that as defined in the subscription or request for Analytics, the PCF can request or subscribe to the analytics from NWDAF of combination of several URSP fields (i.e. RSCs, for example, the analytics of combination of PDU session type and SSC mode) or all URSP fields (i.e. the whole RSD, for example, that the analytics of the combination of all the RSCs in one RSD) listed in Table 1. Based on the analytics for combination of several RCSs or the whole RSD, the PCF can adjust the RSD precedence.\nWhether a new procedure for an AF to request the establishment of a Redundant end to end user plane path for an application is considered out of the scope of this study.\nIt is proposed that the PCF can update the URSP to the UE to establish the redundant PDU Session, taking Primary RAN Path Redundant Transmission Experience and Secondary (Redundant) RAN Path Redundant Transmission Experience into account to decide if the redundant transmission mechanism is needed or not for the corresponding application, as described in Sol#49.\n",
                    "tables": [
                        {
                            "description": "Table 8.6-1: Mapping of fields in URSP and analytics",
                            "table number": 81,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.7\tKey Issue #7: Enhancements on QoS Sustainability analytics",
                    "description": "",
                    "summary": "",
                    "text_content": "In addition to the RAN UE Throughput and the QoS flow Retainability, additional input data should be standardized for the QoS Sustainability analytics as proposed in Solution #18 and Solution #20, such as average UL or DL packet delay, average GTP metric (UL/DL packet delay, UL/DL capacity or UL/DL available capacity), as well as support for additional filter information related to the UE Context or Subscription in the request or subscription from the service consumer.\nFor NWDAF to derive QoS sustainability analytics in a finer granularity area smaller than cell, Alt#2 of Sol#19 and Sol#50 are selected as the baseline for the normative work. The selected proposals are as follows:\n-\tBased on the requested finer granularity area from AF, NWDAF derives the UE ID list within the finer granularity area based on the UE Location information from GMLC LMF/AMF, e.g. NWDAF identifies the UEs inside of the finer granularity area by comparing the UEs' geographical locations retrieved from GMLC/LMF with the finer granularity area provided from AF.\nNOTE:\tThe method of how to provide UE ID list within a finer geographical area is studied/concluded in KI#9, which needs coordination work with FS_eLCS_Ph3.\n-\tNWDAF collects the input data for the UE ID list within the finer granularity area such as QNC/AQP and QoS profile from SMF/PCF, or MDT data from OAM, or QoS flow information from UPF. In addition, the input data may also include QoS flow Bit Rate/QoS flow Packet Delay from UPF and additional input from UDM in Sol#50.\n-\tNWDAF derives QoS sustainability statistics or predictions for the finer granularity area by averaging these input data for the UE list.\n-\tIn order to limit impact on signalling, input data about QNC/AQP and QoS profile from SMF/PCF shall be collected only in case of GFBR can no longer be guaranteed.\nNOTE:\tThe additional input data required for finer granularity is only collected after the AF has requested/subscribed to the analytics. The UEs in the area of interest/UE path to be analysed by the NWDAF may not be the ones relevant to the analytics request/subscription. Therefore there is no guarantee that relevant input data for the generation of the analytics can be collected immediately after AF subscription. AF may need to request/subscribe to the analytics certain time (e.g. days, weeks, or months) before analytics are needed. Alternatively, NWDAF can use other mechanisms (e.g. non-standard) to collect input data prior to application request/subscription.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.8\tKey Issue #8: Supporting Federated Learning in 5GC",
                    "description": "",
                    "summary": "",
                    "text_content": "In conclusion, KI #8 proposes the following principles:\nPrinciple 1: NWDAF containing MTLF as FL server or FL clients register to NRF with their FL related information, including Analytics ID(s), Address information, FL capability Type (i.e. FL server or FL clients), and Service Area, etc.\nNOTE 1:\tThe meaning and usage of FL capability type, including FL server and FL client capability, are left to the normative phase to be determined.\nPrinciple 2: NWDAF containing MTLF determines ML model requires FL based on Analytic ID, Service Area/DNAI or data not available directly from data producer NF (e.g. due to privacy reasons).\nPrinciple 3: If NWDAF containing MTLF as FL sever determines ML model requires FL, the FL Server discovers and selects other NWDAF(s) containing MTLF as FL Client(s) from NRF. The following criteria are used for discovering a FL Client:\n-\tAnalytic ID of the ML model required.\n-\tFL client capability.\n-\tService Area.\n-\tData available by the FL Client.\n-\tTime Period of Interest.\nPrinciple 4: If NWDAF containing MTLF without FL server capability determines ML model requires FL, the MTLF discovers and selects FL sever from NRF. The following criteria are used for discovering a FL server:\n-\tAnalytic ID of the ML model required.\n-\tModel filter information as defined in TS 23.288 [5].\n-\tFL sever capability.\n-\tIf FL server is currently doing a FL for the Analytics ID.\n-\tTime Period of Interest.\n-\tService Area.\nPrinciple 5: NWDAF containing MTLF as FL server may determine the final list of NWDAF containing MTLF as FL clients via initial FL request to FL clients to determine the availability and compatibility of the FL clients. During the FL procedure, the NWDAF containing MTLF as FL server may trigger reselection, addition or removal of FL clients and may issue a new FL client discovery via NRF, based on local policy or status of FL clients, e.g. load, availability, capability, latency, accuracy, etc. FL clients can join or quit FL operation dynamically in the execution phase.\nNOTE 2:\tNWDAF containing MTLF as FL Server can monitor the accuracy level of the trained model and exclude a Client NWDAF from the FL group if the Accuracy feedback of the initial/common model calculated by the Client NWDAF is much different from the Accuracy calculated from the AnLF, FL clients calculate the accuracy of the initial/common model using its local dataset. How FL server receives the accuracy feedback from AnLF is following KI#1. How FL server receives the accuracy feedback from FL client is following Principle#6. FL server can also compare the accuracy from the FL clients with the accuracy calculated by itself, if the FL server has enough data to calculate the accuracy.\nPrinciple 6: NWDAF containing MTLF as FL Server exchanges FL training related information with NWDAF containing MTLF as FL Client. The FL training related information may contain the guideline information for the iterative FL training procedures between FL Server and FL Clients, the guideline information includes maximum response time for FL client to provide interim local ML model information. The FL Server provides to the FL client the initial ML model information to train the local ML Model, the FL client provides interim local ML model information back to FL Server during FL procedure, and the FL Server provides to the FL client the updated ML model information. Regarding the details information that FL server provides to the FL client, the conclusion should be aligned with KI #5, when it comes to the model sharing and interoperability between FL server and FL clients.\nNOTE 3:\tFor ML model exchange between NWDAF containing MTLF as FL Server and NWDAF containing MTLF as FL Client, whether to define new services or to extend the existing model provisioning service will be determined in the normative phase.\nNOTE 4:\tThe FL training related information exchanged between the FL Server and the FL client is aligned with the conclusion of KI#5.\nPrinciple 7: The services to enable the FL based ML model training should be generic enough for all ML model training mechanisms which require service provider trains the ML model provided by the service consumer.\nNOTE 5:\tIn this release of the specification, the service provider and consumer are limited to NWDAF containing MTLF.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.9\tKey Issue #9: Enhancement of NWDAF with finer granularity of location information",
                    "description": "",
                    "summary": "",
                    "text_content": "For KI#9, the following conclusions are agreed:\nThe following use cases will be addressed in normative work:\n-\tExisting analytics IDs that request UE location (i.e. Observed Service Experience, UE mobility, and Dispersion Analytics) are enhanced:\n-\tto provide finer granularity than cell/TA level based on related input data obtained from the LCS framework of the 5GS. Enhancements shall enable information on horizontal and vertical accuracy information as part of the output analytics;\n-\tto provide information about the order UE traversed the provided locations; and\n-\tto support the PSAP resolution use case.\n-\tNWDAF supports the following new Analytics IDs:\n-\tAnalytics ID that supports collecting UE location when the UE is exactly in the requested area instead of the translated TA/cell list.\n-\tAnalytics ID 'Relative Proximity' provides support for finer granularity of location information at NWDAF via relative proximity information of nearby UEs. The output analytics contain relative proximity and Time to Collision information.\n-\tAnalytic ID that supports the traffic flow statistics use case.\n-\tAnalytic ID that supports location accuracy estimate use case.\nNOTE 1:\tThat new Analytics IDs to support these use cases are required (instead of enhancing Analytics IDs) will be confirmed during normative work.\nThe NWDAF will determine from where to obtain the UE location considering different UE location granularity based on analytics ID, and/or the information (e.g. preferred location granularity) from Analytics Reporting Information.\n-\tIf the required UE location granularity is TA or cell level, the NWDAF may query with 5G NFs as currently specified in TS 23.288 [5] to obtain the UE location and related information, e.g. direction.\n-\tIf the required UE location granularity is finer e.g. coordinates, the NWDAF will query the LCS system to obtain the UE location and related information.\n-\tThe Analytics Reporting Information provided by NWDAF consumers is to be enhanced. The consumer can request:\n-\tthe AOI in form of shape and the coordinates of latitude and longitude;\n-\tthe accuracy requirements in horizontal direction and vertical direction of UE location;\n-\tLocation granularity: finer than cell/TA level, horizontal/vertical direction, indoor/outdoor;\n-\tLCS Accuracy, if known by the NWDAF consumer;\n-\ttemporal granularity size and spatial granularity size;\n-\tMotion Events for UE location reporting (e.g. UE reporting location when UE has moved a requested linear threshold distance).\nNOTE 2:\tWhere to include the preferred granularity of location information and the NWDAF consumer-provided enhanced information, e.g. in 'Analytics Filter Information' or in 'Analytics Reporting Information', is to be determined in the normative phase.\nIf the NWDAF determines to query 5G NFs as currently specified in TS 23.288 [5]:\n-\tThe NWDAF may collect data from AF and 5GC NF other than LCS, as in previous Releases, to assist with the derivation of output analytics with fine granularity.\n-\tThe NWDAF may collect data from OAM and DCAF, as in previous Releases, to derive analytics with fine granularity. New input data consists of per UE speed and orientation from OAM and UEs fulfilling a proximity criterion from DCAF, respectively.\nNOTE 3:\tIn the normative phase a confirmation from SA WG5 that OAM can provide UE speed and orientation information is required.\nIf the NWDAF determines to query the LCS system:\n-\tFrom LCS, NWDAF retrieves location data from the GMLC using the Ngmlc services.\nNOTE 4:\tThis is based on FS_eLCS_Ph3 KI#4 conclusion as specified in TR 23.700-71 [30].\n-\tFrom LCS, NWDAF can collect finer granularity location data from LCS including timestamp, age of location, UE location with requested granularity, velocity (speed and orientation), LCS QoS (e.g. LCS accuracy), the indication of motion event occurrence, indoor/outdoor indication;\nNOTE 5:\tIn normative phase, a confirmation that all those data can be provided by LCS based on FS_eLCS_Ph3 conclusions is required.\nTo benefit LCS system, the NWDAF provides a new analytic ID with location accuracy estimates as required by the conclusions of the eLCS-Ph3 study.\nNOTE 6:\tThe FS_eLCS_ph3 in TR 23.700-71 [30] contains a conclusion for Key Issue 4 to use this analytics.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.10\tKey Issue #10: Interactions with MDAS/MDAF",
                    "description": "",
                    "summary": "",
                    "text_content": "-\tNWDAF uses MDAS/MDAF analysis as extra input for generating analytics, e.g. Observed Service experience analytics and Redundant Transmission Experience analytics, improving accuracy or re-training ML model, Solutions #60 and #72 are adopted as baseline for normative work.\n-\tNWDAF, as an MDA MnS Consumer, reuse the MDA functional overview and service framework as defined in TS 28.104 [15]. NWDAF discover MDAS/MDAF by MnS Discovery service producer, and subscribes to MDAS/MDAF by MDA Request service operation, Solutions#73 and Solutions #74 are adopted as baseline for normative work.\n-\tNWDAF (MTLF) may leverage analytics for fault management predictions/statistics to improve data collection and accuracy of analytics as defined in Solution 72. This will be described in normative work as an example text.\n\n\n",
                    "tables": [
                        {
                            "description": "",
                            "table number": 82,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        }
    ]
}