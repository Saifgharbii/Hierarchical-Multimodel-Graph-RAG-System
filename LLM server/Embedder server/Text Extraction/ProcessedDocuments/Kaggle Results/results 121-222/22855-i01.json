{
    "document_name": "22855-i01.docx",
    "content": [
        {
            "title": "Foreword",
            "description": "This Technical Report has been produced by the 3rd Generation Partnership Project (3GPP).\nThe contents of the present document are subject to continuing work within the TSG and may change following formal TSG approval. Should the TSG modify the contents of the present document, it will be re-released by the TSG with an identifying change of release date and an increase in version number as follows:\nVersion x.y.z\nwhere:\nx\tthe first digit:\n1\tpresented to TSG for information;\n2\tpresented to TSG for approval;\n3\tor greater indicates TSG approved document under change control.\ny\tthe second digit is incremented for all changes of substance, i.e. technical enhancements, corrections, updates, etc.\nz\tthe third digit is incremented when editorial only changes have been incorporated in the document.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "1\tScope",
            "description": "The present document provides Stage 1 potential 5G service requirements for ranging based services. In the context of the present document, Ranging-based services are to be understood as the applications utilizing the distance between two UEs and/or the direction of one UE from the other one.\nThe aspects addressed in the present document include:\n-\tIdentify Use cases and potential requirements of ranging-based services directly between two or more UEs, e.g. accuracy of distance and direction, maximum range distance, ranging latency, energy/battery consumption.\n-\tGap analysis with existing mechanisms to enable ranging-based services.\nNOTE: the study does not intend to address V2X specific use cases and requirements.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "2\tReferences",
            "description": "The following documents contain provisions which, through reference in this text, constitute provisions of the present document.\n-\tReferences are either specific (identified by date of publication, edition number, version number, etc.) or non-specific.\n-\tFor a specific reference, subsequent revisions do not apply.\n-\tFor a non-specific reference, the latest version applies. In the case of a reference to a 3GPP document (including a GSM document), a non-specific reference implicitly refers to the latest version of that document in the same Release as the present document.\n3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".\n.\nhttp://www.chnmuseum.cn/zx/gbxw/201802/t20180220_1967.shtml.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "3\tDefinitions, symbols and abbreviations",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "3.1\tDefinitions",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the terms and definitions given in 3GPP TR 21.905 [1] and the following apply. A term defined in the present document takes precedence over the definition of the same term, if any, in 3GPP TR 21.905 [1].\nKey performance indicators and key attributes for Ranging use cases are defined as follows:\nRanging accuracy: describes the absolute value of the deviation of the measured distance and/or direction between two UEs to the true distance and/or direction value.\nConfidence level: describes the percentage of all the possible measured distance and/or direction that can be expected to include the true distance and/or direction considering the Ranging accuracy.\nEffective Ranging distance: the largest distance between the UE who initiates the Ranging and target UEs in the Ranging operation.\nEnvironment of use: the physical environment between the UE who initiate the Ranging and target UEs, such as LOS environment and NLOS environment. Also the physical environments of the UE who initiate ranging, such as in coverage and out of coverage.\nRelative UE velocity: the target UE can be either static or mobile relative to the UE who initiates the Ranging. In the latter, the attribute shall also provide some elements about its motion, e.g. maximum speed, trajectory.\nAvailability: percentage value of the amount of time when a ranging system is able to provide the required Ranging-related data within the performance targets or requirements divided by the amount of time the system is expected to provide the Ranging service in a targeted service area.\nLatency: time elapsed between the event that triggers the determination of the Ranging-related data and the availability of the Ranging-related data at the Ranging system interface.\nPower consumption: electrical power used by Ranging during Ranging operation.\nRanging interval: time difference between two consecutive Ranging operations.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "3.2\tAbbreviations",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the abbreviations given in 3GPP TR 21.905 [1] and the following apply. An abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in 3GPP TR 21.905 [1].\n<ACRONYM>\t<Explanation>\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "4\tOverview",
            "description": "Ranging service (or Ranging in short) in this document refers to the determination of the distance between two UEs and/or the direction of one UE from the other one via direct communication connection. As shown in the following celestial coordinate, the horizontal direction (i.e. the Azimuth) of the target UE is the angle formed between a reference direction and a line from the observer UE to target UE projected on the same plane as the reference direction orthogonal to the zenith. The elevation direction of the target UE is the angle above the horizontal plane [2].\nThe figure depicts a horizontal/elevation direction in celestial coordinates, illustrating the celestial coordinate system used in astronomy.\nFigure 4-1 illustration of horizontal/ elevation direction in celestial coordinate\nFor better understanding, Ranging in 2D coordinate system is taken as an example in Fig.4-2, where UE1 initiates the ranging operation and the coordinate system is centered at UE1. Furthermore, y-axis is the UE1’s pointing direction (reference direction). The ranging initiated by UE1 targets at knowing the distance of UE2 and UE3 to UE1 and also the direction (reference direction) of UE2 and UE3 relatively to UE1.\nAs illustrated in Fig.4-2, at T=t1 UE2 is located at the 2-o’clock direction to UE1 with the direction information as θ1 =30 ° and distance as d1. UE3 is located at the 9-o’clock direction to UE1 with the direction information as θ2 =-90° and distance as d2. When the UE1 switches its pointing direction to UE2 at T=t2, the ranging results of UE2 change to θ1’ =0° and distance remains as d1, while the ranging results of UE3 change to θ2’ =-120° and distance remains as d2.\nThe figure depicts two time-domain signals, T1 and T2, with their respective time-domain representations. The figure illustrates the relationship between the two signals, showing how they are related to each other in the time domain. The figure also includes a legend to help interpret the different symbols and their meanings.        The figure depicts two time-domain signals, T1 and T2, with their respective time-domain representations. The figure illustrates the relationship between the two signals, showing how they are related to each other in the time domain. The figure also includes a legend to help interpret the different symbols and their meanings.\n(a) T= t1                                        (b) T=t2\nFigure 4-2 Example of ranging (from T= t1 to T= t2)\nRanging service can be supported with or without 5G coverage. Fig. 4-3 is an illustration of 5G providing ranging service to UEs with or without 5G coverage. If licensed band is used for ranging, it shall be fully under operator control.\n\nThe figure depicts a 5G network with a range of UEs, illustrating the service provided by 5G technology. The service is designed to provide reliable and efficient communication for devices that are not covered by 5G coverage, while also ensuring coverage for devices that are. The figure shows the various components of the 5G network, including base stations (gNB), user equipment (UE), and scatterers, which are essential for the efficient and reliable operation of the network.\nFigure 4-3 illustration of 5G providing ranging service to UEs with or without 5G coverage\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "5\tUse cases",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "5.1\tDistance based Smart Home Device Control",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.1.1\tDescription",
                            "text_content": "Smart speaker has been playing a more and more important role in smart home. People tends to use smart speaker to control smart devices given its convenience, especially for simple interactions, such as turn on TV/light.\nIn a typical smart home scenario, there might be tens of smart devices, many of which may be with the same type. For example, people may have 5-10 smart lights, 2-3 smart TVs, etc.  As a consequence, user has to tell the smart speaker which device he or she intends to control. Often, it requires user to give a different name for the devices. To make things worse, user may have multiple smart speakers in different rooms to be able to pick up user’s voice, then the system may even not know which smart speaker to respond to user’s voice. Ranging capable devices can simplify the interaction: with distance aware, the smart home system can automatically choose the one closest to the user to control. Distance accuracy plays an important role in this automatic device selection. If wrong device is selected due to distance error, user experience will be badly degraded. In a typical 3m*4m bedroom, average distance between user and the smart device is 2 meter. If user intends to control a device based the distance, he/she needs to have enough confidence on which device is closer. On average, people can confidently tell the closer one if distance difference is more than 10-30% of distance, which corresponding to 0.2m~0.6m distance difference, and 0.1m~0.3m distance accuracy.\nService latency is another important factor to consider. The following figure shows an example service flow for distance-based device control with smart speaker:\nThe figure depicts a smart device control system using a smart speaker, illustrating the concept of distance-based smart device control. The system utilizes a smart speaker to communicate with the device, allowing for efficient and reliable communication. The smart speaker is equipped with a microphone and speaker, enabling it to receive and transmit voice commands. The figure also includes a diagram of the smart speaker's physical structure, including the microphone, speaker, and control panel, which helps to understand the device's design and functionality.\nFigure 5.1.1-1 Example of distance based smart device control using smart speaker\nIn the figure above, user instructs the smart speaker to turn on the light. For light control, typically around 1 second latency from user giving the voice instruction to the light being turned on/off  is satisfying to user. The speech recognition and semantics understanding is usually handled in the cloud and takes on average 500ms for processing and takes on average 60ms for round trip transmission. One message exchange between smart speaker and other smart devices would consume around 130ms. Therefore message 3+5+6 would take about 390ms. Then, the budget for ranging service would be around 50ms. Besides, due to user movement, service latency should also ensure that the acquired ranging result is still valid. For 1m/s movement, 50ms latency would result in 5cm distance change. Then service latency below 50ms should be ensured to keep the validity of ranging result. To reduce the response latency of smart device, it might be sometimes useful that ranging is performed in advance, e.g. before UE giving the voice instruction (e.g. when UE arouses the smart speaker) if power consumption is less a concern. In this case, UE may need to perform ranging with all the smart devices around the UE. Typically, there might be no more than 20 smart devices within LOS distance.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.1.2\tPre-conditions",
                            "text_content": "There are many smart Ranging enabled devices in Alice’s home, including:\n-\tSmart TV-1, smart light A and B, smart speaker A are in bedroom\n-\tSmart TV-2, smart light C, D and E, smart speaker B are in living room\nAlice wears a smart Ranging enabled watch.\nThe smart home devices are capable of determining the range of Alice’s wearable device.\nThe smart speaker is capable of recognizing Alice’s voice and identify her.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.1.3\tService Flows",
                            "text_content": "Alice enters the door of her house;\nAlice’s smart watch discovers smart TV-1/TV-2, smart speaker A/B, smart light A/B/C/D;\nRanging is performed between the wearable device and the discovered smart speakers;\nThe nearest smart speaker is chosen as the responder speaker for Alice;\nWhen Alice is moving in the house, responder speaker is updated based on the latest ranging results;\nAlice enters the bedroom, and would like to turn on the nearest light in the bedroom;\nAlice arouse the smart speaker and tell it to turn on the light;\nThe responder speaker responds, and the light nearest to the user is switched on.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.1.4\tPost-conditions",
                            "text_content": "Alice’s smart home system always knows which smart speaker to respond to Alice, and knows which smart device is closest to Alice, and thus being able to respond to Alice’s command by choosing the nearest device if multiple of the same type devices exist and user doesn’t tell which one to control.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.1.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.1.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.1.6-1] The 5G system shall be able to support Ranging enabled UEs to discover other Ranging enabled UEs.\n[PR 5.1.6-2] The 5G system shall be able to provide ranging service with following KPIs:\nTable 5.1.6-1 – KPIs for distance based smart home control\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.1.6-1 – KPIs for distance based smart home control",
                                    "table number": 1,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.2\tSmart Home TV control",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.2.1\tDescription",
                            "text_content": "Smart TVs, much like smartphones and smart home devices, offer internet connectivity and support for a range of apps. It typically provides an interactive interface, allowing users to stream on-demand music and videos, browse the internet, access to OTT content and online interactive media, etc.\nIn smart home scenario, smart TV is one of the most popular devices that people would heavily interact with.  Traditional TV remoter is less convenient in control of smart TV, where the interactive interface includes many elements to choose and control.  Ranging capable remoter can make the control of smart TV easier. An illustration of smart TV control using remoter is shown in Fig 5.2.1-1. In the figure, a1 and b1 are the horizontal direction and elevation direction of remoter from TV reference point as an observer. d is the distance between the TV reference point ant remoter. a2 and b2 are the horizontal direction and elevation direction of TV reference point from remoter as an observer. The TV reference point location in the TV coordinate system is known, the location of remoter relative to the TV reference point can be calculated based a1, b1 and d. The position on TV where the remoter is pointed can be calculated based on a2, b2 and the location of remoter.\nThe figure depicts a smart TV control system that utilizes remote direction to control the TV. The system utilizes a combination of infrared (IR) and radio frequency (RF) signals to transmit commands to the TV. The IR signals are used to control the TV's brightness, volume, and other settings, while the RF signals are used to control the TV's power settings and volume. The system is designed to be energy-efficient and can be used in various environments, including homes, offices, and public spaces.\nFigure 5.2.1-1 Illustration of smart TV control based on remoter direction\nBoth distance error and direction error would contribute to the error of estimated point on TV that the remote points at. From user point of view, what matters is the angle between the line from estimated point to the TV remote and the line from the TV remote to the actual point that TV remote points at, which is considered as angle error. The smaller the angle error, the better. The tolerable angle error is related to the direction range of the TV remote, i.e. the angle (call it alpha in the following discussion) between the line from the left side of the TV to the TV remote and the line from the TV remote to the right side of TV. Taking a 50 inch TV (110cm * 62 cm) as an example, the typical viewing distance is 3 meter. The angle alpha is about 20 degree. We can consider 10% of angle alpha as tolerable angle error, that is 2 degree, and it corresponds to 10 cm distance error (3 meter * tan(2)).\nDue to the fast TV remote movement, distance and direction need to be measured with very low service latency.  For 1m/s movement, the time for the mouse cursor on TV to move from left side to right side is on average 200ms for the case of 50 inch TV and 3 meter viewing distance. 10ms service latency would correspond to 5cm movement on TV. The distance and direction measurement result would also need to be updated frequently to trace the TV remote movement, 50ms ranging interval will provide a fine granularity for capturing TV remote movement.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.2.2\tPre-conditions",
                            "text_content": "Mary has a smart Ranging enabled TV and a Ranging enabled TV remoter.\nThe smart Ranging enabled TV and The Ranging enabled TV remoter are in Mary’s living room.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.2.3\tService Flows",
                            "text_content": "Mary turns on the smart TV using the TV remoter;\nSmart TV shows an interactive interface for user to interact with;\nSmart TV shows the cursor on the interactive interface; the position of the cursor is where the TV remoter is pointing at;\nMary points the TV remoter at a different position on the interactive interface, the cursor moves to that position accordingly;\nWhen Mary presses the OK button on the TV remoter, the element under the cursor is selected and clicked.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.2.4\tPost-conditions",
                            "text_content": "Mary’s smart TV responds to the click operation by e.g. entering a specific page corresponding to the clicked element.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.2.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.2.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.2.6-1] The 5G system shall be able to authorize Ranging for each individual UE.\n[PR 5.2.6-2] The 5G system shall be able to ensure that the use of ranging, if in licensed spectrum, is only permitted in network coverage under the full control of the operator who provides the coverage.\n[PR 5.2.6-3] The 5G system shall be able to provide ranging service with following KPIs:\nTable 5.2.6-1 – KPIs for smart home TV control\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.2.6-1 – KPIs for smart home TV control",
                                    "table number": 2,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.3\tSmart Vehicle Key",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.3.1\tDescription",
                            "text_content": "The smart key allows the driver to keep the key pocketed when unlocking, locking and starting the vehicle. Vehicles with a smart-key system can distinguish whether the user carrying the key is approaching or not. When the key is approaching to the vehicle, it will be automatically unlocked; when the key is in the vehicle, the vehicle can be automatically started; when the key moving away from the vehicle, the vehicle will be automatically locked.\nIn this case it is assumed that a standard parking slot is about 40 m2, and a parking place of 104 m2 can support 250 vehicles. We assume 20% of all the vehicles need ranging service at the same time of rush hour. So, the number of concurrent ranging operation in this parking place should be 50.\nIn lock and unlock scenario, user’s experience and security issues need to be balanced. There are several requirements need to be considered:\n1)\tThe vehicle should be unlocked and keep unlocked, when the UE is within a certain distance (e.g., 1 meter) to any door of the vehicle. So that user can get friendly experience.\n2)\tThe vehicle should be locked and keep locked, when the UE is out of a certain distance to all doors (e.g., 3 meters). So that the vehicle can keep safe.\n3)\tThe vehicle should keep the same status, when the UE moves to a certain distance range (e.g., from 1 meter to 3 meters) to the closest door, in case the vehicle switches status to often.\nAbove requirements need Ranging service to detect the smart key’s position and measure the distance of 1 meter accurately, which need a distance accuracy of lower by one order of magnitude than 1 meter, i.e., 10 cm.\nRanging interval should ensure that the measured result is still valid (with sufficient accuracy) during this period when user moves. For 2m/s user movement, 25ms ranging interval corresponds to 5cm distance change, which is acceptable for 10cm distance accuracy.\nLatency of 50 ms is needed to achieve 10 cm distance accuracy when the UE is moving at 2 m/s.\nIn extreme cases, a vehicle can be 10 meters long, and the ranging service need to measure 10 meters to the vehicle. Considering the ranging application needs at least 5 seconds to get ready to unlock the car, the ranging service should be active 10 meters before the user arrive at the unlock point, if he is running at 2 m/s. So, the total active ranging service distance should be 30 meters.\n99% availability will ensure a user-friendly experience for predicting moving UE’s position.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.3.2\tPre-conditions",
                            "text_content": "Alice’s car, Bill’s car and Jack’s car are supporting for the smart key system, and are Ranging enabled.\nAlice’ and Jack’s smart phone are set as the smart key for her/his vehicle.\nBill’s smart watch is set as the smart key for his vehicle.\nThe smart key is paired to the specific car (for Alice, Bill and Jack)\nThere are hundreds of cars parked in the parking area in front of the shopping mall.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.3.3\tService Flows",
                            "text_content": "A typical service flow is as following:\nThe figure depicts a smart vehicle key with a unique design, featuring a combination of RFID and NFC technology. The key is designed to be easily identifiable and tamper-proof, ensuring the security of the vehicle and the user. The figure also includes a QR code, which can be scanned to unlock the vehicle and access the smart features. The design of the key is sleek and modern, with a minimalist aesthetic that blends seamlessly with the vehicle's interior. The figure provides a clear visual representation of the key's functionality and design, making it easy for users to understand how to use it.\nFigure 5.3.3-1 use case for the smart vehicle key\nFor unlock case:\nAlice is walking out of the Shopping mall with her smart phone. Alice’s car discovers the Alice’s smart phone\nAlice’s car connects to Alice’s smart phone after successful authentication and authorization between them.\nAlice is walking towards to her car based on the location information provided on her smart phone.\nThe car is unlocked when it detects Alice has approached within certain distance (e.g., 1 meter)\nFor lock case:\nBill stops his car in the parking spot.\nBill is walking out of his car with his smart watch and moving away from his car.\nThe can is locked when it detects Bill has got out of a certain distance (e.g., 3 meters).\nFor engine start case:\n(Assuming that Jack’s car is already connecting to Jack’s smart phone)\nJack is approaching to his car within certain distance (e.g., 1meter)\nJack’s car is unlocked\nJack is getting closer to his car within e.g., 0.5meter or Jack is getting into his car.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.3.4\tPost-conditions",
                            "text_content": "Alice’s car is unlocked automatically when she is approaching to her car within certain distance, e.g., 2meters.\nBill’s car is locked automatically when he is moving away from his car more that certain distance, e.g., 2meters\nThe engine of Jack’s car is started automatically when he is getting into the car or he is 0.5meter away from the car.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.3.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.3.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.3.6-1] The 5G system shall be able to protect privacy of a UE and its user, ensuring that no identifiable information can be tracked by undesired entities during Ranging.\nTable 5.3.6-1 – KPIs for smart vehicle key\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.3.6-1 – KPIs for smart vehicle key",
                                    "table number": 3,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.4\tFinding items in a Supermarket",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.4.1\tDescription",
                            "text_content": "Most supermarkets are large and have an extensive product range which makes it difficult for customers to find their desired items straightaway. Customers regularly take detours inside the store in order to find a particular product.\nCustomers can download a mobile app which can help them to seek desired items in a supermarket. The mobile app can show the distance and direction between the mobile phone and the desired items. And thus, the customer can always take the best and shortest route to their desired items.\nIt is assumed that:\nRanging distance is 100m. So, the coverage that a user/UE performing Ranging service is a circle with 100m radius (S1=3.14*104 m2).\nShelves in supermarket are 50 cm wide.\nTo ensure the user to find the right aisle of the desired item, the distance accuracy of the ranging service would be 50 cm, which is shown in figure below:\nThe figure depicts a 3D representation of a retail store layout, with aisles numbered from 1 to 12. Each aisle is labeled with a corresponding distance from the store entrance. The figure is used to ensure that users can find the aisle they need by accurately measuring the distance from the store entrance.\nFigure 5.4.1-1: distance accuracy should ensure the user to find the right aisle\nIt’s assumed that the shelves are 50 cm(d) wide and the item is 5 meters away from Alice. If the direction mistake is larger than 5.73 degree (d/r*180/PI), Ranging service would guide to a wrong aisle. So, the direction accuracy of the ranging service would be 5 degree, which is shown below:\nThe figure depicts a 3D representation of a retail store layout, with aisles numbered from 1 to 12. Each aisle is labeled with a corresponding direction, such as North, East, South, and West. The figure is used to guide users in finding the correct aisle to access the desired product.\nFigure 5.4.1-2: direction accuracy should ensure the user to find the right aisle\nThe time budget would be 500 ms to ensure 1 second total latency, because the application needs 500 ms to show the information on the UE.\nRanging interval should ensure that the measured result is still valid (with sufficient accuracy) during this period when user moves. For 1m/s user movement 250ms ranging interval corresponds 25cm distance change, which is acceptable for 50cm distance accuracy.\n95% availability will ensure a user-friendly experience for Finding items in a Supermarket.\nA ranging service area of a supermarket can support 500 people at the same time. We suppose 20% of them need ranging service. There would be 100 UEs using Ranging service at the same time.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.4.2\tPre-conditions",
                            "text_content": "The shelf in area E carried the M-watch is tagged with tracker UE in the supermarket.\nA mobile app is installed on Alice’s smart phone.\nTracker UEs and the smart phone are Ranging enabled.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.4.3\tService Flows",
                            "text_content": "The figure depicts a supermarket's use case for 4G/LTE network coverage, illustrating the various technologies and infrastructure required to ensure seamless connectivity for customers.\nFigure 5.4.3-1 use case for supermarket\nAlice is walking into the supermarket with her smart phone. Alice opens the mobile app and search for the M-watch.\nAlice’s smart phone performs Ranging service and discovers the watch when Alice press the “find the item” button once the watch is found on the app.\nThe smart phone keeps showing the distance and direction from Alice’s smart phone to the watch when she moves.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.4.4\tPost-conditions",
                            "text_content": "Alice finds the M-watch as fast as possible according to the direction and distance information presented on the phone.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.4.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.4.6\tPotential New Requirements needed to support the use case",
                            "text_content": "Table 5.4.6-1 – KPIs for finding items in a supermarket\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.4.6-1 – KPIs for finding items in a supermarket",
                                    "table number": 4,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.5\tMuseum Tour",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.5.1\tDescription",
                            "text_content": "According to the visitor data report of National Museum of China (2017) [3], National Museum of China received totally 8,062,625 visitors in 2017, with an average of 26,000 visitors a day. The number of visitors reached a peak on China’s National day, which was 47,431. Given the National Museum of China opens 8 hours per day, from 9:00 to 17:00, it can be assumed that every minute of the peak day there were nearly 100 visitors who entered the museum and stood in front of the same significant exhibit almost at the same time.\nRegarding to museum tour, users always hope to get further information about the exhibits automatically so as to have a better understanding of them. Nowadays, the media types of museum interpretation can be various not limited to traditional audio. If users/UEs can be discovered and identified based on the distance and direction angle when passing through exhibits, and then get audio/video or even interaction from the specific exhibit according to the service policy, users will feel like there is a real tour guide around and definitely have a better experience.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.5.2\tPre-conditions",
                            "text_content": "There are a lot of valuable exhibits in the museum, each of which has a ranging capable device nearby.\nTom has a ranging capable UE (UE A).\nThere are also many tour groups in the museum. They are all equipped with ranging capable UEs too.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.5.3\tService Flows",
                            "text_content": "1.  Tom is visiting the museum with UE A.\n2.  When Tom comes to a famous exhibit, UE A discovers the ranging capable device (Device B) nearby based on a certain distance and angle between the device and UE A.\n3.  UE A connects to Device B.\n4.  Device B identifies UE A, and then pushes the introduction audio/video of the exhibit to which Tom is standing and facing in real time.\n5.  Tom keeps listening/watching the pushed media carefully, while a group of people are coming to the same exhibit.\n6.  All the ranging capable UEs of the tour group connect to Device B.\n7.  Device B discovers the tour group UEs and then performs the identification of the UEs belong to them.\n8.  Device B starts multicasting introduction media to the tour group again, while Tom is still listening/watching his media smoothly without any interruption.\n9.  Tom turns to another exhibit nearby after finished watching. Device B stops the media push to Tom.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.5.4\tPost-conditions",
                            "text_content": "Tom and the tour group can automatically get the introduction of the exhibits they are interested. They all enjoy their museum tours.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.5.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.5.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.5.6-1] The 5G system shall support identification of other ranging capable UE/UEs with which a ranging capable UE performs Ranging.\n[PR 5.5.6-2] The 5G system shall be able to support Ranging service between an initiating UE and up to 100 target UEs.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.6\tTouchless Self-checkout Machine Control",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.6.1\tDescription",
                            "text_content": "Currently, self-checkout machines could be found in almost every supermarket. If someone wants to use a self-checkout machine to pay for goods, he/she needs to click, slide or drag on the screen/keyboard to finish a series of control procedure until the payment is successful. However, because of the control device is a public device, it means that everyone can use it, so as to many people have to touch and use a same machine. This type of public touch mode would be risky, especially during the outbreak of a pandemic. For example, if an infected user leaves virus that may cause disease on a self-checkout machine through touching, then there would be a great health risk for subsequent users who may touch the public control device.\nTo deal with this problem, self-devices such as mobile phones could be utilized to obtain the control authority from a public device, e.g. a public self-checkout machine, and perform interactive operations to indirectly control the public device, as shown in Fig 5.6.1-1.\nThe touchless self-checkout machine in Figure 5 illustrates the use case of touchless self-checkout, where the user's hand is not required to interact with the machine. The machine uses a combination of sensors and AI algorithms to detect the user's touch, allowing for a seamless checkout experience. The use of touchless technology reduces the risk of contamination and ensures a hygienic checkout process.\nFigure 5.6.1-1 Illustration of touchless self-checkout machine control Use Case\nIn this case, UE needs to obtain an authority when it is close to a public self-checkout machine. So timely and reliable ranging would be required to trigger the authority procedure and to improve user experience. For example, when a UE finds there is a self-checkout machine nearby (already within an authority area of a public self-checkout machine, e.g. the distance between the UE and the machine is less than 1m), the UE can trigger a corresponding procedure to obtain the authority to get control interface and indirectly control the machine, as shown in Fig 5.6.1-2.\n\nThe touchless self-checkout machine in Figure 5 illustrates the use case of touchless self-checkout, where the user's hand is not required to interact with the machine. The machine uses a combination of sensors and AI algorithms to detect the user's touch, allowing for a seamless checkout experience. The use of touchless technology reduces the risk of contamination and ensures a hygienic checkout process.\nFigure 5.6.1-2 Illustration of touchless self-checkout machine control Use Case\nGiven that people occasionally go to supermarkets, this type of Ranging service can be turned on and off on demand. For example, when a customer enters a supermarket, a touchless self-checkout service can be enabled. When the customer leaves the supermarket, the service is disabled. In this way, the unnecessary ranging service can be avoided and the power consumption of UE can be reduced.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.6.2\tPre-conditions",
                            "text_content": "A supermarket has a public self-checkout machine.\nA user does not want to click, slide or drag on the screen of the public self-checkout machine considering the health risk during a pandemic period.\nThe user has a smartphone and wants to use the smartphone to control the self-checkout machine to finish the payment.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.6.3\tService Flows",
                            "text_content": "Dorina heads for a self-checkout machine in a supermarket.\nDorina’s smartphone is aware that there is a self-checkout machine nearby, i.e. the UE is in the authority area of a public self-checkout machine now.\nThe UE triggers an authority procedure to obtain the authority from the self-checkout machine.\nThe UE shows an interactive interface for Dorina to interact with.\nDorina presses a button on the shown interface on her smartphone, e.g. “purchase”, and corresponding purchase procedure then is triggered on the self-checkout machine accordingly.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.6.4\tPost-conditions",
                            "text_content": "Dorina indirectly controls the self-checkout machine through her smartphone and finishes the payment.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.6.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.6.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.6.6-1] The 5G system shall be able to enable or disable the Ranging service.\n[PR 5.6.6-2] The 5G system shall be able to provide ranging service with following KPIs:\nTable 5.6.6-1 – KPIs for touchless self-checkout machine control\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.6.6-1 – KPIs for touchless self-checkout machine control",
                                    "table number": 5,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.7\tHands Free Access",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.7.1\tDescription",
                            "text_content": "Hands free access is a better alternative to manual operations, especially in some public area. On one hand, it avoids many touches on public facilities so that they can keep clean for a long time. On the other hand, auto and smooth mechanism is good for public facilities’ life extension.\nFor example, hands free access can be used for opening the door. Once user takes unlocking devices with built-in ranging module, such as smart phones, smart watches, etc. The door with ranging module can automatically unlock and open according to the distance between the user and the door. Door and unlocking devices are able to pair flexibly and support encrypted communication to protect the user's private information. Depending on the location of areas, such procedures happen indoor or outdoor, even underground.\nFurthermore, hands free access can help the company keep some employees away from its sensitive or private area. Only employees with privileges can enter by ranging procedures. Under the circumstances, the unlocking device shall provide its credential information to the door (e.g. username and password) first, then the door checks its validation locally (e.g. cache in the door) or remotely (e.g. database in company server).\nConsidering the time needed from ranging discovery to application authorization, the ranging service need to discover the unlocking UE when it’s 10 meters away from the door, to ensure to open the door when the user get 5 meters away from the door.\nUnder the circumstances, ranging service needs check whether the user is very close to the door to open it, in case the employee just wants to pass by. For tuning the application to satisfy the users, 10 cm of distance accuracy is necessary.\nConsidering the user can move at 1 m/s and the distance accuracy is 10 cm, the time budget would be 50 ms (10cm / (1m/s) = 100 ms).\nRanging interval should ensure that the measured result is still valid (with sufficient accuracy) during this period when user moves. For 1m/s user movement 50ms ranging interval corresponds 5cm distance change, which is acceptable for 10cm distance accuracy.\n99% availability will ensure a user-friendly experience for predicting moving UE’s position.\nIn office scenario, people always move at 1 m/s.\nIt’s assumed that users walk in a line from both sides of the door. The distance between every 2 UEs is 1 meter. So, here are 20 unlocking UEs in the ranging area.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.7.2\tPre-conditions",
                            "text_content": "UE A is a ranging capable unlocking device(e.g. a smart phone or a wearable device) installed company App .\nTom is the owner of UE A and he is an employee of Company A.\nUE B is a ranging capable door. UE A and UE B are able to discover each other under 5G coverage.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.7.3\tService Flows",
                            "text_content": "Tom carrying UE A gets close to UE B under a particular speed (e.g. 1m/s).\nUE B discovers UE A.\nUE B estimates the distance between itself and UE A. If the distance meets the criteria (e.g. smaller than 5 meter), UE B start performing ranging with the door.\nWhen Tom gets closer to the door, the distance between UE A and the door meets the criteria (e.g. smaller than 0.5 meter),\nif Tom is authorized or no authorization needed, the door automatically unlocks and opens.\nif Tom is unauthorized, the door keeps closed and alarms Tom by audio equipment.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.7.4\tPost-conditions",
                            "text_content": "Follow option a) in Step 4, Tom enters without manually opening the door.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.7.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "The interactions for authorization between the two UEs before Step 4 can be fully covered by existing sidelink or PC5 communications.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.7.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.7.6-1] The 5G system shall be able to support for a UE to discover other UEs supporting Ranging.\n[PR 5.7.6-2] The 5G system shall be able to provide Ranging service with following performance KPIs.\nTable 5.3.6-1 – KPIs for hands free access\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.3.6-1 – KPIs for hands free access",
                                    "table number": 6,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.8\tSmart Transportation Metro/Bus Validation",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.8.1\tDescription",
                            "text_content": "Nowadays, heavy passenger flow shock the current public transportation system. However, passengers have to actively touch the billing device using public transportation card, which is so slow at rush time that it is easy to meet congestion. This problem can be effectively solved through the hands free metro/bus validation. It determines whether the user gets on or off the bus according to the relative distance, and then provides the information about getting on or off the bus/metro to a billing node. The billing node automatically deducts the corresponding fee from the user's account.\nAt rush time, crowd get close to an entrance simultaneously, and the Ranging module inside the entrance performs Ranging with lots of smart phones (e.g. 20 smart phones) at the same time. Since entrance machines are always built in a row closely, one smart phone may perform Ranging procedures with 2 or more entrances simultaneously while it appears within their effective ranging distances (e.g. ranging distance < 2m). In this way, smart phones can distinguish which entrance is the nearest one to enter. A typical distance based metro entrance access is shown in figure below. There is one Ranging module for each aisle. The Ranging module can only perform Ranging with devices falling within the angle of view α, which is to avoid for performing Ranging with devices at backside. The threshold distance for triggering access to an aisle should be no more than 0.3+0.55=0.85m for normal size entrance and 0.5+0.9=1.4 for larger size entrance to avoid mistakenly triggering aisle access by UE at another aisle. A safer distance threshold would be 0.6m with 0.1m distance accuracy for normal size entrance and 1m with 0.2m distance accuracy for larger size entrance. Then, effective Ranging distance 2m would be enough.\nThe figure depicts a metro entrance access scenario, illustrating the distance-based approach to access control. The entrance is marked by a red line, indicating the required distance to be maintained for pedestrians to pass through. The figure also includes a scale, allowing for precise measurements of the distance. The presence of a pedestrian crossing symbol signifies the need for pedestrians to pass through the entrance, while the red line ensures that they maintain a safe distance from the entrance. The figure is a visual representation of the concept of distance-based metro entrance access, emphasizing the importance of maintaining a safe distance for pedestrians to ensure their safety and the smooth flow of traffic.\nFigure 5.8.1-1 Illustration of distance based metro entrance access\nTypically, UE will move at 3km/h speed, it will result in 4cm distance change in 50ms. Thus, 50ms service latency and Ranging interval is able to ensure the distance change is well tracked.\nIn case of crowded entrance, there could be over 20 UEs within the 2 meter radius of the entrance, so the Ranging module on the entrance would need to perform Ranging with more than 20 UEs simultaneously. Considering that there are 5 entrances in a row, the number of UEs within the 2 meter radius of these  entrances(the size of the area would be 0.8*5*2=8m2) would be 100.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.8.2\tPre-conditions",
                            "text_content": "Tom downloads an app on his smart phone with Ranging module. The hands free metro/bus validation function is enabled on this APP, and the automatic payment function is also enabled.\nThe metro and bus system have Ranging module, which can do ranging with the smart phone.This Ranging module can use a combination of 3GPP technologies and non-3GPP technologies. This includes, but not limited to, GNSS (e.g. BeiDou, Galileo, GLONASS, and GPS), Terrestrial Beacon Systems (TBS), Bluetooth, WLAN, RFID, UWB and sensors.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.8.3\tService Flows",
                            "text_content": "Tom carries his smart phone near the metro entrance.\nAfter the metro entrance detects the smart phone, it implements Ranging with the smart phone.\nWhen Tom gets close to the metro entrance from outside the station, if the Ranging results reach a certain distance, the entrance is automatically opened.\nThe metro entrance detects the change of position relative to the mobile phone and determines whether Tom enters the station. If Tom enters the station, continue the following procedure, or close the entrance in time.\nTom has completed his trip. When Tom gets close to the metro exit from inside the station, if the Ranging result reaches a certain distance, the exit is automatically opened.\nThe metro exit detects the change of position relative to the mobile phone and determines whether Tom leaves the station. If Tom leaves the station, continue the following procedure, or close the exit in time.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.8.4\tPost-conditions",
                            "text_content": "The billing node get his trip from the metro system, and deducts the corresponding fee from the Tom’s account.\na)\tIf the deduction is successful, the procedure ends.\nb)\tIf the deduction is unsuccessful, the hands free metro/bus validation function will be suspended. Tom needs to manually complete the payment on the APP to re-enable the function.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.8.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.8.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.8.6-1] The 5G system shall be able to support for a UE to discover other UEs supporting Ranging.\n[PR 5.8.6-2] The 5G system shall be able to provide Ranging service with following performance KPIs.\nTable 5.8.6-1 – KPIs for smart transportation metro/bus validation\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.8.6-1 – KPIs for smart transportation metro/bus validation",
                                    "table number": 7,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.9\tDistance based Intelligent Perception for Public Safety",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.9.1\tDescription",
                            "text_content": "Nowadays, COVID-19 outbreaks all over the world without mercy, it has seriously affected people life and economics. Even we are capable to find out who has gone to the infected zone, or the track of infected people based on the interaction between UE and base station, there is still no clue to figure out who is close contact with the one infected.\nA smart device with distance based technique brings chances, it can record smart devices which appears nearby and stays for a long time. Ranging module makes it possible. Under emergency circumstances, people can active such a function to help government find out potential infected people more precisely and plot spreading diagram so as to stop serious spread at early time. In this way, many medical resources can be saved for testing or curing only the individual who is close exposure to the infected rather than wasting on everyone appears in high risk area.\nThere is no difference for the ranging in both indoor and outdoor case. When the two UEs are getting close to each other less than specific distance (e.g., 5m), one UE will mark the presence of the other UE (vice versa), so it is assumed that ranging distance is less than 20m. The availability is relax with 99%, since it is just used to track the presence of other UEs.  It assumes that there are 100UEs within the specific area (e.g., radius = 20m). The static/low moving UEs are still possible to get close to each other and being infected. The low moving UE could be for example pedestrian UE, or UE on bike/electrical bike, so the relative UE velocity is small than 20km/h.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.9.2\tPre-conditions",
                            "text_content": "Alice and Bob both wear smart devices (e.g. smarts phone, smart watch, etc), UE A and UE B, which are ranging capable and discoverable.\nThe function of distance based intelligent perception for public safety is already switched on.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.9.3\tService Flows",
                            "text_content": "Alice with UE A meets Bob with UE B, they walk or run towards to each other under a particular relative velocity (e.g. 5km/h).\nUE A discovers UE B and UE B discovers UE A.\nBoth UE A and UE B estimates the distance between each other. If the distance meets the criteria (e.g. smaller than 5 meter), both start a timer.\nAfter a talk, Alice and Bob say goodbye to each other, they walk towards different directions. If the distance between UE A and UE B exceed the limit (e.g. larger than 8 meter), the timers stop. At the same time, UE A generates a record including UE B’s identifier, location, time length, etc. And UE B performs same actions.\nUE A and UE B periodically upload records to the server in department responsible for public safety.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.9.4\tPost-conditions",
                            "text_content": "Alice feels bad and goes to hospital, and medical testing shows Alice is infected. Hospital report Alice as one infected to the public safety department. Then, the department alarms people Alice met based on the record UE A uploaded. Bob is told to go to hospital for testing infection.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.9.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.9.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.9.6-1] The 5G system shall be able to support for a UE to discover other UEs supporting Ranging.\nTable 5.9.6-1 – KPIs for distance based intelligent perception for public safety\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.9.6-1 – KPIs for distance based intelligent perception for public safety",
                                    "table number": 8,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.10\tPicture and video sharing based on ranging results",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.10.1\tDescription",
                            "text_content": "Picture and video sharing is popularly used in recent smart phone market and brings life fun. More interesting functions can be introduced when the target for sharing is visible to the user by using ranging.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.10.2\tPre-conditions",
                            "text_content": "This use case is about Mary and her friends who have a birthday party and take some pictures and videos by smart phone. These pictures and videos can be shared with each other and also displayed on some other devices with big screen, e.g., smart TV, laptop, pad, based on the ranging results between different devices. For example, Mary can share the picture to all of her friends or some friend by smart phone based on the distance and/or pointing direction of Mary’s phone.\nWe use a simple 2D example involving two smart phones and one pad to show how ranging works. In Fig 5.10.2-1, the smart phone 1 initiates the ranging operation towards smart phone 2 and the Pad, where the coordinate system changes with the movement of the smart phone 1. The accuracy for the ranging may affect the identification of multiple UEs. Considering various realistic scenarios, a direction accuracy of 2° is considered acceptable estimation. For example, when the distance between two smart phones is 3m, 2° direction accuracy results in about 10 cm deviation perpendicular to distance. For the media sharing between a smart phone and a smart screen, where the distance is around 10m, the same 2° direction accuracy results in about half a meter deviation. For the latter case, it’s worth mentioning that the 2° direction accuracy still applies because larger surface screen area of the smart screen will naturally compensate for a larger deviation on the tangent line in this case.\nThe figure depicts a scenario where a smart phone-1 is located at a specific location (t1) and points to a specific device (Pad) at a different location (t2). This scenario illustrates the concept of location-based services (LBS) and how they can be used to provide location-based services to users. The figure also highlights the importance of location-based services in the context of mobile communication, as they can help users find nearby services, businesses, and other points of interest.    The figure depicts a scenario where a smart phone-1 is located at a specific location (t1) and points to a specific device (Pad) at a different location (t2). This scenario illustrates the concept of location-based services (LBS) and how they can be used to provide location-based services to users. The figure also highlights the importance of location-based services in the context of mobile communication, as they can help users find nearby services, businesses, and other points of interest.\n(a) Smart phone-1 points nowhere at t1\t\t             (b) Smart phone-1 points to Pad at t2\nFigure 5.10.2-1: Ranging of smart phone-1 with coordinate system centred at smart phone-1\nTo achieve the ranging accuracy, the latency of the ranging needs to fulfill some requirements when the UE is moving. Even when UE is moving with a relatively low speed, if the latency is too large, the ranging result will be out of date, which leads to the derivation between the ranging results and the ground truth.\nIn a typical scenario that smart phone-1 ranging a pad to share the video to the pad, where the distance between the smart phone-1 and pad is d1=3 meters as shown in Figure 5.10.2-2. According to the direction accuracy requirement  = 2°, the derivation d1* is around 10cm.\nThe figure depicts a smart phone-1 with a coordinate system centered at the device, illustrating the ranging accuracy of the device in relation to the reference point. The figure shows the range of the device's signal strength relative to the reference point, with the device's position represented by a circle and the reference point represented by a square. The figure provides a visual representation of the device's range, allowing for a quick and easy comparison of its range to the reference point.\nFigure 5.10.2-2: Ranging accuracy of smart phone-1 with coordinate system centred at smart phone-1\nService latency should ensure that the acquired ranging result is still valid even when there exists relatively movement. Consider the movement of the user’s hand during ranging may be up to 1m/s, the derivation in distance is about 1m/s*50ms = 5cm or derivation in direction is about arctan(5cm/3m)= 0.95°, which can fulfill the requirements of the ranging accuracy.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.10.3\tService Flows",
                            "text_content": "Mary selects the pictures and/or videos and decides to share or display, where Jay’s smart phone is not far from Mary’s smart phone.\nMary’s smart phone performs ranging based on the coordinate system defined by Mary’s smart phone,\nBased on the ranging results, Jay’s smart phone is detected and accordingly mapped in the coordinate system, which is visualized in Mary’s UE screen with distance and direction information,\nMary selects Jay’s smart phone by touching Jay’s phone icon in the screen or pointing at Jay’s phone,\nMary’s smart phone starts to transmit picture and/or videos to jay’s smart phone.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.10.4\tPost-conditions",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.10.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.10.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.10.6-1] The 5G system shall be able to provide ranging service with following KPIs:\nTable 5.10.6-1 – KPIs for picture and video sharing\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.10.6-1 – KPIs for picture and video sharing",
                                    "table number": 9,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.11\tRanging of UE’s in front of vending machine",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.11.1\tDescription",
                            "text_content": "Vending machines are popular on many public places. A lot of work has been done in improving the shopping experience. Contactless payment is one of those. Since most phones have some type of payment, a further enhanced experience can be created if the UE of the person who is going to buy goods can be accurately ranged in front of the vending machine. Additional authentication and authorization of the user prior to taking payment can then be enabled.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.11.2\tPre-conditions",
                            "text_content": "In a subway station there are a lot of people moving around and multiple vending machines. Bob has decided to buy a soda from one of them. The vending machines has the capability to accurately and with high precision determine which of all UE’s that are right in front of the vending machine. Bobs phone also has the ranging functionality as well as possibility to do mobile payment. The vending machine might be in out of coverage area. The vending machine is located in a busy subway station and there may be in the magnitude of 10 other UE’s in the vicinity that can have same ranging functionality.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.11.3\tService Flows",
                            "text_content": "Bob walks up to the vending machine and decides what soda he should buy. Since he is determined (by the vending machine) to be in the right position in front of the machine, he will be allowed to do the selection and his mobile wallet will be deducted accordingly.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.11.4\tPost-conditions",
                            "text_content": "The experience of buying the soda is safe and effortless.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.11.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "There are several online and offline methods for mobile payment, and this is not described here.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.11.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.11.6-1] The 5G system shall support mutual ranging, i.e. the two UE’s involved shall be able to range each other.\n[PR 5.11.6-2] The 5G system shall be able to provide ranging service with following KPIs:\nTable 5.11.6-1 – KPIs for ranging of UE’s in front of vending machine\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.11.6-1 – KPIs for ranging of UE’s in front of vending machine",
                                    "table number": 10,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.12\tFinding pets in a long distance based on energy efficient Ranging",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.12.1\tDescription",
                            "text_content": "Pets provide company for people. They are friends and family of the human beings.  For various reasons a pet can get lost. An indoor pet that often sits by windows could escape. Children that enjoy playing with pets outdoors usually have pets slip through the neighbourhood by missing to latch backyard gates. When walking a pet, even professional pet sitters or dog walkers could have pets escape by accident. When this happens, anxious owners would try their best to find them back. This use case focuses on how ranging can help to get people and pets together again by accurately and efficiently finding the missing pets.\nSome additional information on the technologies based on Time of Flight can be found below.\nNowadays, there are multiple technologies which are used to measure the distance or angle between two radio transceivers based on multiplying the Time of Flight (ToF) by the speed of light, for example, Two Way Ranging (TWR), Time Difference of Arrival (TDoA), and Phase Difference of Arrival (PDoA). We provide some examples for better understanding on how it works in figure 5.12.1-1.\n\n5.12.1-1 examples of different methods using ToF\nThe TDoA method is similar to GPS with the condition of the time synchronization of multiple reference points. For UWB, the UE sends beacons signal, which is marked by multiple reference points with timestamps. Then the timestamps from multiple reference points need to process together to compute the location of the UE that sent the beacon.\nThe TWR method relies on two-way communication between two UEs. The initiated UE measures the Time of Flight of the signal between them. By multiplying the round trip time of the signal by the speed of light, and then dividing by 2, the actual distance between the two UEs can be derived.\nThe PDoA method combines the TWR scheme to measure the Time of Flight between two UEs. The initiated UE also needs to carry multiple antennas and can measure the Phase Difference of Arrival of the signals sending by target UE.\nEffective Ranging Distance\nTo ensure the accuracy of the ToF based methods, it is important to have LOS communication. The probability of having LOS communication decreases when the distance between two UEs increases. With LOS communication, the effective ranging distance can be several kilometres.\nNOTE:   Line-of-sight propagation is a characteristic of electromagnetic radiation or acoustic wave propagation which means the waves are not diffracted, refracted, reflected, or absorbed by the atmosphere and obstructions with material.\nPower consumption\nBased on the TWR method, which relies on the two-way communication between two UEs, the target UE has to scan for ranging signals that can consume a lot of power. It is important to make the ranging operation energy efficient, especially for the target UEs.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.12.2\tPre-conditions",
                            "text_content": "This use case is about Tom and his pet dog Jerry. Jerry is a new family member of Tom’s. For safety reasons, Tom bought Jerry a smart collar that is very simple.  It only support ranging service (only response) to make sure that Tom can find Jerryy, for example, with his phone or his drone, or via the smartphones of the friendly volunteers,  that support initiating the ranging service. Tom can charge the smart collar weekly, and that is sufficient to ensure responses, whenever Tom seeks to find Jerry by initiating the ranging service.\nOne day, Tom took Jerry out for a walk in a park.  As a young puppy, curious Jerry got overly excited and ran to chase after a pitchy barn swallow. Soon Tom lost sight of Jerry and Jerry does not seem to return any time soon. Tom called Jerry but heard no answers. The park is too large for Tom to search every corner on foot. Considering Jerry might run away over a long distance, and worried that Jerry might even end up a stray dog, Tom decided to find Jerry immediately.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.12.3\tService Flows",
                            "text_content": "Tom decided to use his drone to search for Jerry.\nTom switched on the ranging service of the drone and controlled it to a height under the restriction of regulation by Tom’s smart phone.\nThanks to the good channel condition of the drone, the drone received Jerry’s smart collar’s response and found Jerry was about several hundreds meters away from Tom’s home and the moving direction was still not right.\nThe figure depicts a scene with a person searching for a pet in a long distance, using a smartphone to search for the animal. The smartphone is equipped with a camera and a GPS system, allowing the person to locate the pet's location. The figure illustrates the use of technology to assist in finding a lost pet, highlighting the importance of using GPS and smartphone technology in our daily lives.\nFigure 5.12.3-1: Finding pets in a long distance\nOtherwise, if there is not a drone ready to hand, Tom can also ask the smartphones of the friendly volunteers to operate the ranging service like the drone as showed above, to find the Jerry as fast as possible.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.12.4\tPost-conditions",
                            "text_content": "According to the ranging results, Tom went to the place and found Jerry back.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.12.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "TS 22.261 clause 6.15 energy efficiency:\nThe 5G access network shall support an energy saving mode with the following characteristics:\n-\tthe energy saving mode can be activated/deactivated either manually or automatically;\n-\tservice can be restricted to a group of users (e.g. public safety user, emergency callers).\nNOTE:\tWhen in energy saving mode the UE's and Access transmit power may be reduced or turned off (deep sleep mode), end-to-end latency and jitter may be increased with no impact on set of users or applications still allowed.\nThe 5G system shall support UEs using small rechargeable and single coin cell batteries (e.g. considering impact on maximum pulse and continuous current).\nTS 22.261 clause 6.27 Positioning services\nThe 5G system shall support mechanisms to configure dynamically the update rate of the position-related data to fulfil different performances (e.g. power consumption, position service latency) or different location modes.\nNOTE 5: \tfor example, the 5G System needs to be able to request the UE to provide its location periodically with an update rate ranging from one location every [1 s to 10 s] in location normal mode to one location every [30 s to 300 s, or more] in location power saving mode. The 5G System needs to allow UEs to sleep for extended periods (e.g. one week), without requiring the UE to update its position data.\nTS 22.261 clause 7.3 High-accuracy positioning:\nThe 5G system shall support positioning technologies that allow the UE to operate at Service Level 1 for at least 12 years using less than 1800 mWh of battery capacity, assuming multiple position updates per hour.\nNOTE 2:\tThis requirement aims energy-efficient positioning technologies draining a minimal energy on the UE battery. It derives from use cases, such as asset tracking, with a small form-factor battery representative of an IoT device. This requirement may translate into an energy consumption for the UE’s positioning functions in the order of 20 mJ per fix.\nNOTE 3:\tThis requirement does not preclude the use of higher energy consumption to fulfil higher position update rates than the one above, or other KPIs than those of Service Level 1 (e.g. more accurate service levels).\nIn recent requirments captured in TS 22.261, 5G access network has been required to support energy saving mode and 5G system shall support UE using small batteries. In the positioning related requirements, power consumption is one of the considered factors for positioning service.\nHowever, ranging service that occurs between two UEs is not equal to positioning service that is usually operated by the network. For ranging service, the requirement is missing to require a energy efficient ranging.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.12.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.12.6-1] The 5G system shall support energy efficient UE ranging services and operation.\n[PR 5.12.6-2] The 5G system shall be able to provide ranging service with following KPIs.\nTable 5.12.6-1 – KPIs for finding pets in a long distance based on energy efficient Ranging\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.12.6-1 – KPIs for finding pets in a long distance based on energy efficient Ranging",
                                    "table number": 11,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.13\tPower efficient Ranging Operation",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.13.1\tDescription",
                            "text_content": "Ranging service requires ranging UE to operate ranging action after the ranging service starts. And it is assumed that users can switch on or switch off the ranging service through application installed his or her smart phone. But in fact, users always switch on ranging service in his/her convenience time not just in the location where the ranging service goes well. Considering the use cases in the TR22.855, it is obviouse that only in the ranging efficient distance, the ranging operation is required to operate with specified ranging interval e.g. 50ms and related performance.\nSo, it makes sense for ranging service to consider more efficient operation when the distance is greater than the ranging efficient distance. For example, operating ranging with slow frequency if the distance is greater than ranging efficient distance and operating ranging with required ranging interval when the distance is within efficient ranging distance. Thus, the 5G system is required to change ranging working mode in time when the distance changes.\nThe frequent/infrequent ranging operation transformation condition can be configured by ranging service application provider e.g.:\nwhen the measured ranging distance <= Effective Ranging distance, to trigger frequent ranging operation;\nor when the measured ranging distance > Effective Ranging distance, to trigger infrequent ranging operation;\nor after some time (e.g. > (ranging service latency + ranging interval)), ranging information can’t be received, to trigger infrequent ranging operation etc.\nFigure 5.13.1-1 illustrates the smart car key example considering frequent/infrequent ranging operations after ranging service is started. When the ranging service is started, the initial UE may or may not receive ranging information because the actual distance may exceed the effective ranging distance.\n\nFigure 5.13.1-1 infrequent and frequent ranging operation\nFollowing service flow give an example of effective smart car key ranging operation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.13.2\tPre-conditions",
                            "text_content": "The Tom’s car support ranging service. Its paired ranging UE is Tom’s smart phone.\nTom’s car is usually parked in his house during the night. And in working days, it is always parked in Tom’s office underground parking port.\nTom’s car and his smart phone have registered one of Operator’s Ranging service: Smart Car Key.  The “infrequent ranging interval” is configured by the “Smart Car key” service as 10s through the interface supplied by 5G system and via the 5G system, the configuration is delivered to his car and his smart phone.\nTom’s car ranging operation is always switched on while his smart phone is switched on when needed.\nThe following parameters refer to TR22.855 Table 5.3.6-1.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.13.3\tService Flows",
                            "text_content": "Tom’s car is parking at home park garage and operating ranging with large ranging interval 10s.\nIn the morning, Tom goes to his car with his smart phone switch on ranging service.\nThe car detects that the distance with the paired smart phone is less than “Effective Ranging Distance” 30m.\nThe car starts frequent ranging operation with required ranging Interval 50ms.\nThe car automatically unlocks and opens the door when Tom is nearby <=1m.\nTom drives the car to his office, then parks his car in the office underground parking port.  Tom leaves his car. His car identifies the distance between the car and Tom’s smart phone exceeds the configured “lock door distance” 3m. The car automatically locks.\nThe car continuously operates frequent ranging with Ranging Interval is 50ms until it detects that the distance exceeds “Effective Ranging Distance” i.e. 30m. It enters the infrequent ranging operation the ranging interval is 10s.\nTom leaves his office and goes to his car. His car identifies the distance less than “Effective Ranging Distance” 30m.\nThe car starts frequent ranging operation with the ranging interval back to 50ms.\nThe car automatically opens the door when Tom is nearby. Tom drives his back home.\nAt his home, Tom switches off ranging service in his phone.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.13.4\tPost-conditions",
                            "text_content": "Tom’s car can be automatically lock and unlock with more power efficiently.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.13.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "TS 22.261 clause 6.27 Positioning services\nThe 5G system shall support mechanisms to configure dynamically the update rate of the position-related data to fulfil different performances (e.g. power consumption, position service latency) or different location modes.\nNOTE 5: \tfor example, the 5G System needs to be able to request the UE to provide its location periodically with an update rate ranging from one location every [1 s to 10 s] in location normal mode to one location every [30 s to 300 s, or more] in location power saving mode. The 5G System needs to allow UEs to sleep for extended periods (e.g. one week), without requiring the UE to update its position data.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.13.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.13.6 -1] The 5G system shall be able to start ranging and stop ranging according to the application layer’s demand.\n[PR 5.13.6 -2] The 5G system shall be able to provide mechanisms for a MNO, or authorized 3rd party, to provision and manage ranging operation and configurations.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.14\tFinding and Tracking Objects",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.14.1\tDescription",
                            "text_content": "There are many practical situations in which people need to find or locate objects or other people or to track them while they are moving. In this case consider a family with a young child in a very crowded environment in a fire breakout emergency. If the parents are separated from the child, locating him or her takes priority over all other activities and the process can be quite upsetting to the parents and the child. Of course this is not the only example possible: one may need to find missing objects in almost any environment, or track people or objects in situations in which it is difficult to maintain contact or when it is important to locate people as fast as possible.\nThis use case does not require low latency interaction.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.14.2\tPre-conditions",
                            "text_content": "Marigold, three years old, is very venturesome and curious. She wears a wristwatch that is a smart Ranging enabled device.\nFrancis, Marigold’s father has a smartphone capable of determining the location of smart Range enabled devices.\nMarigold’s watch has been configured so that Francis’ smart phone is able to locate it.\nFrancis and Marigold go shopping in an enormous Carrefour complex.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.14.3\tService Flows",
                            "text_content": "This use case covers two events: ‘normal shopping’ and ‘fire breaks out.’\nOne moment, Marigold was there, the next moment, she vanished! Francis looks up and down the aisle in the store, and cannot see her. After searching for a minute or so, he activates his Smart Ranging application on his smartphone.\nMarigold moved fast. She is already 200m away examining toys in a distant portion corner of the Carrefour market.\nFrancis’ smartphone uses Ranging functionality to identify her direction and approximate range. This gets Francis moving in the right direction.\nOnce Francis is within 30m, he can use precision location capabilities to identify his daughter wandering along the 25m length of the toy aisle, even though she is hard to spot through the crowd of other children, similarly separated from their parents (during normal shopping,) or just beyond the emergency exit in the crowd of people who have exited the building (during the emergency situation.)\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.14.4\tPost-conditions",
                            "text_content": "Francis has successfully located his daughter, though he needed to traverse the enormous Carrefour complex. The longer range approximate location sufficed to close the distance between himself and Marigold, even while she continued to move. Once near enough, he could use the precise 5G Ranging facility to find her amongst the crowd.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.14.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.14.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.14.6-1]\tThe 5G system shall be able to provide ranging service with the following KPIs:\nTable 5.14.6-1 – KPIs for Object Finding and Tracking\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 5.14.6-1 – KPIs for Object Finding and Tracking",
                                    "table number": 12,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "5.15\tClustering of devices",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.15.1\tDescription",
                            "text_content": "A mass casualty incident (MCI) describes an event in which the emergency medical services may get overwhelmed by the number and severity of the casualties. An MCI may include e.g. chemical, biological, radiological emergencies, mass shootings, major road accidents, buildings being on fire, natural disasters such as earthquakes, etc. which can cause result in loss of human lives in the MCI area. Digital technologies can help to improve the response time of the first responders and reduce the amount of damage and/or loss of life by improving the logistics of clinical and non-clinical operations in an MCI event and real-time victim monitoring in the MCI area. Triaging is a process applied when there are more casualties requiring aid than there are medical personal available in the MCI area. Real-time positioning and grouping of the victims in the triage area and health monitoring can aid the first responders to save a lot of precious time for the first responders to make swift yet accurate and group-level decisions to reduce loss of life in the MCI area. A triage generally consists of a quick check for immediate life-threatening concerns for the victims present in the triage area. An example of the triaging process is the START system (simple triage and rapid treatment) in which the first responder assigns each patient to one of four color-coded triage levels, based on their breathing, circulation, and mental status. The triage levels as described in START system are:\nImmediate (Red color): Victims with major life-threatening injuries, but are salvageable given the resources available\nDelayed (Yellow color): Victims with non-life-threatening injuries, but are unable to walk or exhibit an altered mental status\nWalking wounded (Green color): Victims who are able to move themselves out of the incident area to a treatment area\nDeceased or expectant (Black color): Victims who are dead, or whose injuries make survival unlikely.\nThe figure depicts a triage area with colored tarps, illustrating the use of color-coding to differentiate between different types of patients, such as those with different medical conditions or severity levels. The triage area is a crucial component of healthcare facilities, allowing healthcare professionals to quickly assess and treat patients based on their needs. The use of colored tarps can help healthcare professionals quickly identify and treat patients with specific conditions, improving the overall efficiency and effectiveness of the triage process.\nFigure 5.15.1-1 Example of a triage area with colored tarps\nIn this use case, a massive earthquake has taken place in a metropolitan city of Asgard. One of the multistorey buildings in the central market area have collapsed to rubbles with more than 100 victims injured, classifying the event as a mass casualty incident (MCI). The public telecommunication services are majorly interrupted. A first responder crew of 3 members have arrived at the scene to identify, triage, and transport the injured victims prioritized based on triage status to the nearest hospitals. Tom, a first responder, has arrived at the scene with a first responding vehicle which can serve as a temporary non-public mobile network AmbCel. Tom has started to triage the victims based on the severity of the injuries using color coding scheme similar to the START system. After being triaged, every victim receives a body-worn ranging-enabled victim-tags (e.g. wearable patient monitor) from Tom. The victims who are triaged as green can walk themselves to the designated safe area just outside of the MCI area, and the victims who are triages as yellow and red will be moved by a logistics team who will arrive later at the scene. Colored tarps based on triage colors are not yet set in the MCI area, since Tom and his small crew are currently focusing on triaging. However, virtual tarps can be formed digitally with predetermined tarp size and location so that Tom can instruct the later arriving logistics team about the location of virtual tarps and set up a physical tarp to deliver treatment based on the triage status of each tarp. Moreover, each tarp can have their own QoS requirements, so that a network can provide a variety of network services to various medical devices in each tarp. The triage application of Tom will seek assistance from 5G network in order to have an overview of clusters in the MCI area, and optimize the allocation of network resources for various network services required by the first responders and their devices.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.15.2\tPre-conditions",
                            "text_content": "Tom has a 5G enabled mobile phone UE with a USIM and a valid 5G subscription and registered as a first responder device which has ranging service.\nThe victim-tags are 5G enabled wearable monitoring devices such as smartwatches that can capture vitals and support distance measurement through the ranging service.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.15.3\tService Flows",
                            "text_content": "Tom triaged Jerry as a yellow victim and attached a victim tag digitally marked as yellow onto his wrist\nJerry is moved by the logistics team to a designated area for yellow victims. Before doing so, the logistics team has designated yellow, red and green triage areas. This may be done in multiple ways, e.g.by configuring some virtual areas through an application (e.g. with reference coordinate system or floorplan), by putting some anchor devices in the center of an area and registering these as reference points to the AmbCel network. The AmbCel network also offers a feature to automatically detect areas where people are clustered together and for each of the clusters designate one of the devices in such cluster as the center of the cluster, which the logistics team can use to find these clusters and/or to quickly subdivide the area in different triage areas.\nThe logistics team may also configure some network parameters (such as QoS/URLLC requirements) for each triage area to the AmbCel cellular network.\nAs soon as Jerry is moved to the yellow tarp, it is recognized, by performing ranging between the victim tag of Jerry and other devices (including anchor devices or other device designated as a center of a group), that Jerry gets in close proximity of the yellow triage area (e.g. yellow tarp) and send this information to the AmbCel network, so that the AmbCel network can automatically allocate the specified network resources for medical devices in the yellow triage area.\nAfter some time, the health condition of Jerry starts to deteriorate. One of the first responders moves Jerry to the red triage area (e.g. red tarp). Through the ranging functionality of Jerry’s tag, it is recognized that Jerry has moved to the red triage area. The AmbCel network automatically allocates the specified network resources for medical devices in the red triage area. Also, the logistics team is notified about the change in triage status.\nIn parallel, Tom has moved to the other side of the building. Also there he found victims. Tom triaged James as a green victim and asked him to move to a safe place in the north of the market area.\nTom triages several other victims as green and asks them to gather near the safe place in the north of the market area. Ranging service in the victim tags are active, which starts to discover the neighbouring tags as people starts to move toward the north so they can be given directions and find each other.\nA remotely located commanding officer of the first responding crew can request the AmbCel system information about the newly formed green cluster, receives the number of victims in that cluster and the relative location of the cluster.\nA victim-tag is designated as the centre of the cluster based on the center of gravity of the cluster. As the cluster size grows beyond the predetermined tarp size, a new cluster is formed with set of green victim tags with a new center of gravity\nThe location of the clusters and the associated victims are continuously monitored as they walk towards the designated area of green tarp\nDepending on the number of victim tags in each of the clusters, first responders can be directed to the relative location of the various clusters or triage areas by using their mobile phone UEs (that also support ranging).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.15.4\tPost-conditions",
                            "text_content": "Tom and his crew are not exhausted about monitoring the location of the victims and time for triaging is significantly reduced. Therefore, they can pay more attention to the victims and their health conditions saving more lives in the MCI event.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.15.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.15.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.15.6-1] The 5G system shall be able to support mechanisms for a UE to assist another UE to perform ranging of a third UE (if all UEs are in LOS conditions).\nNOTE: It cannot be assumed that all ranging UEs support the same application for exchange of information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.16\tTracking of devices",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.16.1\tDescription",
                            "text_content": "A mass casualty incident (MCI) describes an event in which the emergency medical services may get overwhelmed by the number and severity of the casualties. An MCI may include chemical, biological, radiological emergencies, mass shootings, major road accidents, buildings being on fire, natural disasters such as earthquakes, etc., which can cause result in loss of human lives in the MCI area. Digital technologies can help to improve the response time of the first responders and reduce the amount of damage and/or loss of life by improving the logistics of clinical and non-clinical operations in an MCI event and real-time victim monitoring in the MCI area. Triaging is a process applied when there are more casualties requiring aid than there are medical personal available in the MCI area. Real-time positioning and grouping of the victims in the triage area and health monitoring can aid the first responders to save a lot of precious time for the first responders to make swift yet accurate and group-level decisions to reduce loss of life in the MCI area. A triage generally consists of a quick check for immediate life-threatening concerns for the victims present in the triage area. An example of the triaging process is the START system (simple triage and rapid treatment) in which the first responder assigns each patient to one of four color-coded triage levels, based on their breathing, circulation, and mental status. The triage levels as described in START system are:\nImmediate (Red color): Victims with major life-threatening injuries, but are salvageable given the resources available\nDelayed (Yellow color): Victims with non-life-threatening injuries, but are unable to walk or exhibit an altered mental status\nWalking wounded (Green color): Victims who are able to move themselves out of the incident area to a treatment area\nDeceased or expectant (Black color): Victims who are dead, or whose injuries make survival unlikely.\nIn this use case, a massive terrorist attack has taken place in an airport at the arrivals hall located in the second floor of the airport building. More than 100 victims are injured, classifying the event as a mass casualty incident (MCI). The public telecommunication services are majorly interrupted, with no positioning system accessible within the airport building. A first responder crew of 3 members have arrived at the scene to identify, triage, and transport the injured victims prioritized based on triage status to the nearest hospitals. Tom, a first responder, has arrived at the scene with a first responding vehicle which can serve as a temporary non-public mobile network AmbCel. Tom have started to triage the victims based on the severity of the injuries using color coding scheme similar to the START system. After being triaged, every victim receives a body-worn ranging-enabled victim-tags (e.g. wearable patient monitor) from Tom. Once the logistics team has arrived, they started to deploy anchor nodes in the airport floor to enable accurate tracking of victims’ tags in the airport. This allows later arriving teams (such as ambulance personnel) to be able to quickly find the respective victims and bring them to the hospital.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.16.2\tPre-conditions",
                            "text_content": "Tom has a 5G enabled mobile phone UE with a USIM and a valid 5G subscription and registered as a first responder device which has ranging service.\nThe victim-tags are 5G enabled wearable monitoring devices such as smartwatches that can capture vitals and uses ranging services to measure distances.\nAnchor nodes have higher power rating therefore, can range over longer distances.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.16.3\tService Flows",
                            "text_content": "Tom triaged Victor as a red victim and attached a victim tag digitally marked as red onto his wrist\nLogistics team have arrived and started to deploy anchor nodes in the airport floor to enable accurate tracking of victims tags in the airport\nA treatment team has arrived at the scene, which is notified about the number of red victims and their priority to receive treatment based on triage score\nWhile arriving at the scene, the treatment team finds that there are multiple red victims that are scattered across the airport floors\nA treatment officer, who has a treatment device and a mobile UE, picks Jerry from the list of victims. The mobile UE of the treatment officer shows that Jerry is located in bay two, row four of the departure halls in the first floor of the airport building.\nThe treatment officer is guided t to the exact location of Jerry in the airport building.\nWithin seconds, Jerry is provided the first-aid treatment for his injuries. His bleeding is temporarily stopped and he is immediately transported to the nearest hospital in an helicopter ambulance.\nThanks to the ranging services of the AmbCel 5G system, many lives are saved at an unfortunate time of this tragic incident.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.16.4\tPost-conditions",
                            "text_content": "Tom and his crew can easily track the location of all the victims and time for re-triaging is significantly reduced.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.16.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.16.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.16.6-1] The 5G system shall be able to support ranging enabled UEs to determine the ranging capabilities (e.g. capabilities to perform distance and/or angle measurement) of other ranging enabled UEs.\n[PR 5.16.6-2] The 5G system shall be able to allow a ranging enable UE to determine if another ranging enabled UE is stationary or mobile, before and/or during ranging.\nNOTE: this may require assistance from other ranging enabled UEs.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.17\tImmersive sound based on multiple-UE ranging",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.17.1\tDescription",
                            "text_content": "When considering the ranging based on time or time difference of flight, LOS path among UEs is very important for accuracy. However, LOS paths among UEs do not always exist. In all timing-based positioning methods, additional random bias due to non-line-of-sight condition deteriorates performance of position estimation. This makes the accuracy of an initiating UE to range another UE who has no LOS path with the initiating UE unpredictable.\nIn some scenarios, there may be multiple UEs which may provide help with ranging if the UE have both LOS paths with the UE initiating ranging and the target UE. For example, in home scenarios there may be multiple UEs and even if there is no LOS paths between the UE who initiates the ranging and the target UE, some UEs may “create” a LOS path for the two, i.e., some UE have LOS paths with both of the two UEs.  For example in Fig. 5.17.1-1, UE A needs to range UE B but there is an obstacle between them which results in no LOS path. UE A needs to first find a UE who has a LOS path with UE A and also a LOS path with UE B, i.e., UE A needs to find a UE C. Also according to the requirement on the ranging accuracy, UE A may also needs to check the ranging accuracy level of UE C when ranging UE B. In this use case, we only consider the one-hop LOS path “creation”, i.e., only one UE helps with the ranging.\nThe figure depicts a LOS path between two users (UE A and UE B) in a 5G network. The path is created by reflecting signals off buildings, which is a key component of 5G signal propagation. The figure illustrates the various components involved in the signal path, including the base station (gNB), user equipment (UE), and scatterers. The diagram highlights the use of beamforming techniques to mitigate interference, ensuring reliable communication.\nFig. 5.17.1-1 Create LOS path between UE A and UE B\nSince the ranging operation proposed in other use cases is about peer to peer, the UE ranges other UE based on its own coordinate system. For example, UE A knows UE C is on its 4 o’clock direction, and UE C tells UE A that UE B is on its 11 o’clock direction. However, with the UE C’s information about UE B, UE A cannot know where the UE B is. This is because UE A does not know which direction UE C is facing.  To help UE A, UE C needs to first calibrate its own coordinate system with UE A to make sure they have the same understanding on the coordinate system, e.g., by providing and compensating for the UE C direction reference point. Then with the information collected from UE C and UE B, UE A can determine the range to UE B accurately even though UE B has no LOS path with UE A.\nIt will be fantastic to have an immersive audio experience when watching movies in home. The speakers can provide this kind of experience if they can know the position of each other and also the user.\nUsually, to have immersive audio experience, several speakers are needed. Ranging may help the speakers to determine position relative to each other and to the listener. With the relative position of each other and to the listener, the speakers can adjust the sound field and provide a better experience to the listeners. The scenarios without LOS path may occur frequently due to the uncertainty of the interior design and decoration of the space. In a home, the speakers may be placed in any part of a room.  In some cases, there may be no LOS path between two of them. The NLOS path results in inaccurate ranging between the two speakers, and it is hard to build the immersive audio experience. In addition, a NLOS scenario between any speaker and the UE representing the listener can be adapted for based on this method.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.17.2\tPre-conditions",
                            "text_content": "This use case is about Tom’s home theatre plan. Tom bought a set of speakers, and placed them in his home to create an immersive audio experience. According to the instruction of the speakers, and also based on the availability of audio and power wiring Tom distributed the speakers in his living room. However, speaker A has detected that there is no LOS path to speaker B. Speaker A can detect that speaker C has LoS path with speaker A. And speaker C can detect that speaker B has LoS path with speaker B. This detection mechanism is outside the scope of this document.\nTom's home theatre is equipped with a 5G network, featuring a 5G signal path that demonstrates the signal propagation in a 5G network. The diagram highlights the multi-path signal propagation, with key components including the base station (gNB), user equipment (UE), and scatterers. Beamforming techniques are employed to mitigate interference, ensuring reliable communication.\nFig. 5.17.2-1 Tom’s home theatre\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.17.3\tService Flows",
                            "text_content": "1) Configuration procedure\nTom switched on the power to speakers A, B and C to perform calibration. Speaker A discovers all UEs in the area to assist with ranging of a target UE. Speaker A discovers speaker B and C, and Tom’s UE.\nSpeaker A, speaker B and speaker C began ranging each other to adjust the sound field when in later use.\nSpeaker A identifies by itself that it has NLOS path with speaker B, and a LOS path with speaker C and Tom’s UE.\nSpeaker B identifies by itself that it has NLOS path with speaker A and Tom’s UE, and a LOS path with speaker C.\nSpeaker C identifies by itself that it has LOS path with speaker A, B and Tom’s UE.\nNote: the UE procedure for determining LOS and NLOS is out of scope of this document.\nSpeaker A determines the relative position of speaker B through ranging with help of speaker C. Ranging service in this scenario only includes three UEs  where Speaker A uses the ranging result of Speaker A to Speaker C, and the ranging result of Speaker B to Speaker C to calculate/calibrate/corroborate the ranging result of Speaker A to Speaker B. Therefore, Speaker A gathers the ranging results from the other speakers in order to perform these calculations.\nSpeaker A prepares to adjust the sound field.\n2) Listening set-up procedure Speakers A, B and C began to range Tom’s phone, when Tom places the phone near to his head and uses the phone as a reference point of his head. The speakers give quick feedback to Tom and adjust the sound field to provide an immersive audio experience to Tom.\nThe figure depicts a range-finding device, specifically a range-finding microphone, used in a wireless communication system. The device is shown in a three-dimensional perspective, with the microphone's head and the receiver's receiver antenna clearly visible. The microphone is positioned at a distance from the receiver, and the receiver is shown in a three-dimensional perspective, with the receiver's antenna and the receiver's receiver antenna clearly visible. The figure provides a visual representation of the range-finding process, which is an essential component of wireless communication systems.\nFig. 5.17.3-1 Ranging the listener\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.17.4\tPost-conditions",
                            "text_content": "Thanks to supporting ranging service, Tom gets a fantastic home theatre audio experience.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.17.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.17.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.17.6-1] The 5G system shall be able to support mechanisms for a UE to assist another UE to perform ranging of a third UE (if the requesting UE is LOS with the assisting UE and the assisting UE is LOS with the third UE).\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.18\tRemote Access Right Authorization",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.18.1\tDescription",
                            "text_content": "In many companies, suppliers can get temporary access right to get into some rooms or labs.\nA supplier, Alice, takes a UE with ranging capability. If Alice gets access right for some doors, her UE is authorized to use ranging service with the UEs on these doors. When she is getting closed to one of the doors, the UE on the door can get distance to Alice’s UE and let the door open automatically.\nTo follow the company’s security policy, the supplier needs to get authorization every day from a particular employee of the company.\nThe employee, Bill, needs to check the supplier’s UE and authorize the UE access right for some doors.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.18.2\tPre-conditions",
                            "text_content": "A company, CICI, has very strict security policy. People need access right to get into some doors, each of which has a UE on it. All the doors’ UEs have ranging capability to check people’s access right.\nAlice is a supplier of company. She has a UE with ranging capability to get access right into some doors. But each time she arrives at the company, she needs to get permitted by a particular employee, Bill, so that she can get access right.\nBill has a UE, with which Bill can authorize access right to Alice’s UE via the 5G system.\n5.18.3\tService Flows\nScenario 1\nAlice contacts Bill about her plan to visit CICI and her phone number. Bill needs to make sure that Alice herself has arrived at CICI to authorise her access right. Bill provides CICI door’s ID, So that Alice’s phone can be discovered by the door of CICI using internal IT system.\nIn this figure, Alice is attempting to contact Bill using a CICI door's ID. The CICI door is a key component in the security system, allowing only authorized personnel to access the door. The door's ID is a unique identifier that is used to authenticate the user's identity.\nFig. 5.18.3-1 Alice contacts Bill and gets CICI door’s ID from Bill\nAlice arrivals at CICI and her phone is discovered by the door of CICI. Bill gets alerted that Alice’s phone is within the range of ranging service to the door. Then, Bill triggers ranging service between Alice’s phone and CICI’s doors, and provides a distance threshold, e.g., 10cm, to the doors for ranging service to Alice’s UE. When Alice places her phone within distance of 10cm to one of CICI’s doors, the door is opened automatically.\nAlice, a curious individual, arrives at CICI, a renowned research center, and her phone is discovered by the door. Upon entering, she gets the access right, indicating that her phone has been successfully authenticated.\nFig. 5.18.3-2 Alice arrives at CICI. Her phone is discovered by the door of CICI and gets the access right\nWhen Alice finishes her job and leaves the area of the company, ranging service on her UE is disabled.\nAlice's phone is disabled for ranging service due to the presence of a CICI (Coarse-Grain Interference Cancellation) filter, which is designed to reduce interference in the range of her phone.\nFig. 5.18.3-3 Alice leaves CICI and ranging service on her phone is disabled\nScenario 2\nAlice contacts Bill about her plan to visit CICI and her phone number. Bill needs to make sure that Alice herself has arrived at CICI to authorise her access right. Bill provides CICI door’s ID and a distance threshold, e.g., 10cm, for ranging service to Alice’s UE.\nThe figure depicts a scenario where Alice, a user, contacts Bill, a server, and gets the ID of the CICI door. The figure illustrates the communication process between the user and the server, with Alice initiating the communication and Bill responding. The figure also includes the CICI door, which is a key component in the system, and the ID, which is a unique identifier for the door.\nFig. 5.18.3-4 Alice contacts Bill and gets CICI door’s ID from Bill\nAlice places her phone close to the door of CICI. Bill gets alerted from the door that Alice’s phone is within 10cm distance to the door and allow CICI’s door to be unlocked for Alice’s UE.\nThe figure depicts a scenario where Alice places her phone close to the door, triggering an alert. Bill unlocks the door after receiving the alert. This illustrates the concept of door-to-door communication in a 5G network, where devices can communicate with each other without the need for a central network.\nFig. 5.18.3-5 Alice place her phone close to the door. Bill unlocks the door after gets alerted\nWhen Alice finishes her job and leaves the area of the company, ranging service on her UE is disabled.\nAlice's phone is disabled for ranging service due to the presence of a CICI (Coarse-Grain Interference Cancelling) filter, which effectively cancels out the signal from CICI.\nFig. 5.18.3-6 Alice leaves CICI and ranging service on her phone is disabled\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.18.4\tPost-conditions",
                            "text_content": "Bill can use ranging service to authorize Alice’ UE to use ranging service with particular doors in CICI.\nAfter Alice leaves the area of the company, ranging service on her UE is disabled. When she gets back to the company, she cannot get into any door of the company.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.18.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.18.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.18.6-1] The 5G system shall be able to support ranging service authorization for a UE or a group of UE.\n[PR 5.18.6-2] The 5G system shall be able to support ranging service policy/parameter provisioning to UE.\n[PR 5.18.6-3] The 5G system shall allow ranging service between 2 UEs trigged by and exposed to a third UE.\n[PR 5.18.6-4] The 5G system shall allow ranging service between 2 UEs trigged by and exposed to the application serve.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "5.19\tSharing Content to a Particular UE",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.19.1\tDescription",
                            "text_content": "When we want to share a content to a UE in proximity, it may take a long time to find the target UE on the phone, as the UE always shows a long list of candidate UEs which can have direct communication. Sometimes, mistakes are unavoidable for distinguishing the name of the target UE when there are similar UE names in the list, especially when the list is changing on the fly.\nTo efficiently find the target UE, the user who wants to share the content can hold his UE, which is the source UE, pointing to the target UE. With the help of ranging service running on both of the UEs, the source UE can easily find the target UE whose direction is the same as the reference direction of the source UE.\nIn this use case, Bill wants to share different content from his phone to Alice and Cassie. Alice and Cassie’s UEs are always shown at the bottom of UE list. Bill has to swipe screen for a long time to find their UEs on the list. But with ranging service, Bill’s phone shows Alice’s UE when Bill points to Alice with his phone. Bill’s phone shows Cassie’s phone when he points to Cassie with his phone.\nIn this scenario, we need to consider: UEs of different users may subscribe to and use network of different operators. The 5G system shall be able to support ranging service of this scenario.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.19.2\tPre-conditions",
                            "text_content": "Alice, Bill and Cassie are chatting in a restaurant which is covered by network of both operator A and operator B. Their UEs subscribe to different operators:\nAlice’s phone subscribes to operator A.\nBill’s phone subscribes to operator B.\nCassie’s phone subscribes to operator C and is roaming to B’s network.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.19.3\tService Flows",
                            "text_content": "The UEs of Alice Bill and Cassie subscribe to different operators. They want to share content based on ranging service.\nBill wants to share different pictures to Alice and Cassie. He chooses a picture on his phone and clicks “share”. A mini map is shown on Bill’s phone. UEs around Bill’s phone are shown on the map if they have authorized Bill’s phone to discover them by ranging service. If Bill turns around, any phone his phone is pointing to is highlighted on the map.\nWhen Bill points to Alice with his phone, Alice’s phone is shown on the map in the direction he is pointing to and is highlighted.\nBill clicks Alice’s phone. Then, the picture is sent to Alice.\nBill shares another picture to Cassie using the same procedure.\nThe figure depicts a content sharing scenario among UEs subscribing to different operators, illustrating the various ways in which content can be shared and accessed by users.\nFig. 5.19.3-1 Content sharing among UEs subscribing to different operators\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.19.4\tPost-conditions",
                            "text_content": "Bill’s phone discoveries Alice and Cassie’s UEs with ranging service.\nBill’s phone can not discovery Daniel’s UE, because Bill and Daniel are not friends.\nBill’s phone shows the right UE’s name when Bill point Alice or Cassie with his phone.\nBill selects right UE to share the right content.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.19.5\tExisting features partly or fully covering the use case functionality",
                            "text_content": "None.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.19.6\tPotential New Requirements needed to support the use case",
                            "text_content": "[PR 5.19.6-1] The 5G system shall be able to support ranging service authorization for a UE or a group of UEs when a UE or a group of UEs will use ranging in licenced band.\n[PR 5.19.6-2] The 5G system shall be able to support ranging service policy/parameter provisioning to UE.\n[PR 5.19.6-3] The 5G system shall be able to support one UE initiates ranging service to the other UE.\n[PR 5.19.6-4] The 5G system shall be able to support ranging service between UEs which subscribe to different operators.\n[PR 5.19.6-5] The 5G system shall be able to provide ranging service to roaming UEs.\n[PR 5.19.6-6] The 5G system shall be able to authenticate the UE supporting Ranging service.\n[PR 5.19.6-7] The 5G system shall be able to authorize the UE for enabling Ranging service.\n[PR 5.19.6-8] The 5G system shall be able to ensure the integrity and confidentiality of Ranging information used by Ranging-enabled UEs.\n[PR 5.19.6-9] The 5G system shall be able to ensure that user privacy is not violated during Ranging service, e.g., based on regulatory requirements.\n[PR 5.19.6-10] The 5G system shall be able to ensure security protection (e.g., interworking security) when the Ranging service concerns UEs subscribed with different operators.\n[PR 5.19.6-11] The level of security provided by the existing 5G system shall not be adversely affected when Ranging service is enabled.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "6\tConsolidated requirements",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "6.1\tFunctional requirements",
                    "description": "",
                    "summary": "",
                    "text_content": "[CPR-1] The 5G system shall be able to support for a UE to discover other UEs supporting Ranging.\n[CPR-2] The 5G system shall be able to authorize Ranging for a UE or a group of UE when using licensed spectrum.\n[CPR-3] The 5G system shall be able to protect privacy of a UE and its user, ensuring that no identifiable information can be tracked by undesired entities during Ranging.\n[CPR-4] The 5G system shall be able to enable or disable Ranging.\n[CPR-5] The 5G system shall support mutual Ranging, i.e. two UEs shall be able to initiate Ranging to each other.\n[CPR-6] The 5G system shall be able to ensure that the use of Ranging, if in licensed spectrum, is only permitted in network coverage under the full control of the operator who provides the coverage.\n[CPR-7] The 5G system shall support energy efficient Ranging operation.\n[CPR-8] The 5G system shall be able to start ranging and stop ranging according to the application layer’s demand.\n[CPR-9] The 5G system shall be able to provide mechanisms for a MNO, or authorized 3rd party, to provision and manage ranging operation and configurations.\n[CPR-10] The 5G system shall be able to support mechanisms for a UE to assist another UE to perform ranging of a third UE (if the requesting UE is LOS with the assisting UE and the assisting UE is LOS with the third UE).\nNOTE: It cannot be assumed that all ranging UEs support the same application for exchange of information.\n[CPR-11] The 5G system shall be able to support ranging enabled UEs to determine the ranging capabilities (e.g. capabilities to perform distance and/or angle measurement) of other ranging enabled UEs.\n[CPR-12] The 5G system shall be able to allow a ranging enable UE to determine if another ranging enabled UE is stationary or mobile, before and/or during ranging.\nNOTE: This may require assistance from other ranging enabled UEs.\n[CPR-13] The 5G system shall allow ranging service between 2 UEs triggered by and exposed to a third UE.\n[CPR-14] The 5G system shall allow ranging service between 2 UEs triggered by and exposed to the application server.\n[CPR-15] The 5G system shall be able to support one UE initiating Ranging to the other UE.\n[CPR-16] The 5G system shall be able to support ranging service between UEs which subscribe to different operators.\n[CPR-17] The 5G system shall be able to allow roaming UEs to perform Ranging.\n[CPR-18] The 5G system shall be able to ensure the integrity and confidentiality of Ranging information used by Ranging-enabled UEs.\n[CPR-19] The 5G system shall be able to ensure that user privacy is not violated during Ranging service, e.g., subject to regional or national regulatory requirements.\n[CPR-20] The 5G system shall be able to ensure security protection (e.g., interworking security) when the Ranging service concerns UEs subscribed with different operators.\n[CPR-21] The level of security provided by the existing 5G system shall not be adversely affected when Ranging service is enabled.\n[CPR-22] The 5G system shall support a means to securely identify other ranging capable UEs with which a ranging UE performs ranging.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "6.2\tPerformance requirements",
                    "description": "",
                    "summary": "",
                    "text_content": "Table 6.2-1 – KPIs for Ranging\n\n\n",
                    "tables": [
                        {
                            "description": "Table 6.2-1 – KPIs for Ranging",
                            "table number": 13,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "7\tConclusions and recommendations",
            "description": "The TR provides a number of use cases for Ranging-based services such as distance based smart home device control, smart home TV control, smart vehicle key, finding items in a supermarket, museum tour, touchless self-checkout machine, hands free access, smart transportation metro/bus validation, distance based intelligent perception for public safety, picture and video sharing, ranging of UE’s in front of vending machine, finding pets in a long distance based on energy efficient Ranging.\nThe potential new requirements for each use cases are compiled into a set of potential consolidated Ranging requirements, including functional requirements and performance requirements, wherein a set of KPIs are defined, such as distance accuracy, direction accuracy, availability, latency, effective Ranging distance, coverage, NLOS/LOS, ranging interval, number of concurrent Ranging operation for a UE or within an area.\nThe resulting potential requirements identified in this TR can be considered for the development of normative requirements. It is therefore proposed to consider the inclusion of these requirements in existing specifications for 5G services (e.g. TS 22.261).\nRanging accuracy is divided into distance accuracy and direction accuracy.\nFor better understanding, we give an example for the ranging accuracy in 2D coordinate system in Fig.A-1. From the distance perspective, the ranging accuracy on distance is described as Δd. Then the distance of UE3 from UE1 is d±Δd with confidence level 95%. The direction of UE2 to UE1 is θ±Δθ with confidence level 95%. Similar situation applied to the 3D coordinate system centred at the UE who initiates the ranging service.\nThe figure depicts an example of ranging accuracy in a 5G network, showing how signals are received and reflected off buildings, with key components such as base stations (gNB), user equipment (UE), and scatterers. The diagram highlights beamforming techniques to mitigate interference, and the layered design aligns with SDN principles.\nFigure A-1. Example of ranging accuracy\nTo represent an object in some coordinates, it is important to set appropriate origin and reference axis, and for all parties to have same understanding of these.\n\nThe figure depicts various results obtained from different sources, illustrating the impact of different factors on the outcome.\nFigure B-1: Different results depending on different origins\nThe Figure B-1 show how results can change, depending on how origin is defined. For example, in the figure which shows how the distance and direction between TV and remote controller is measured, the result can vary.\nFollowing is assumed in the Figure B-1.\nThe television has three candidates for the selection of reference point of measurement. ,  and  . I.e, in the left side of Figure B-1, the reference point is set to , and in the right side of Figure B-1, the reference point is set to .\nThe Red line shows the reference axis from which the angle and distance are determined.\nThe remote controller is directed toward .\nAs the figure shows, distance and angle between the TV and the remote controller change depending on which point among ,  and  is selected as reference. When the target object is small, then this is not a major issue. However, as the target object gets larger, the setting of reference point has impact on the outcome.\nIn addition, as the figure shows, angle between the TV and the remote controller can be further dependent on how reference axis is selected.\nTo represent where an object is located, applications typically use Cartesian Coordinates. The object in the following figure can be represented as located in (a,b) in the Cartesian Coordinates, with perpendicular axis X and Y.\nThe figure depicts a 3D object in Cartesian coordinates, with axes labeled as x, y, and z. The object is represented as a cube with dimensions 10 units in each direction. The figure is used to illustrate the concept of object-oriented programming, where objects are defined in terms of their attributes and behaviors.\nFigure C-1: Object in Cartesian Coordinates\nHowever, this object can also be represented in other ways. For example, following figure shows how Polar Coordinates can be used, with reference axis K. In Polar Coordinates, the location of an object is represented with r and θ. r is the distance from the origin to the object and θ is the angle from a reference direction.\nThen, the location of the object in the figure C-2 can be represented with (r,θ) in Polar Coordinate.\nThe figure depicts a 3D object in polar coordinates, illustrating its position and orientation in a three-dimensional space.\nFigure C-2: Object in Polar Coordinates\nBoth representations are valid representations in locating the object. Furthermore, one form of representation can be easily converted to other form of representation, if all parameters in the original coordinates are available. I.e, the conversion from Polar Coordinates to Cartesian Coordinates are well knows as:\na  =  r * COS θ\nb  =  r * SIN θ\nUsing this formula, the measured result of distance and angle can be converted easily into points in Cartesian coordinates. Similar, the measured result in Cartesian Coordinates can be easily converted into values in Polar Coordinates.\nSimilarly, as shown in the figure C-3, the accuracy and error of one coordinate can be easily converted to values in coordinates.\nThe figure depicts the conversion of error range between Polar Coordinates and Cartesian Coordinates, illustrating the process of converting a polar coordinate system into a Cartesian coordinate system. The figure shows the conversion of error range from polar coordinates to Cartesian coordinates, with the error range being represented by the error range conversion factor. The figure is a visual representation of the mathematical process used to convert polar coordinates into Cartesian coordinates, which is an essential concept in many fields such as physics, engineering, and computer science.\nFigure C-3: Error range conversion between Polar Coordinates and Cartesian Coordinates\n\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "",
                    "table number": 14,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        }
    ]
}