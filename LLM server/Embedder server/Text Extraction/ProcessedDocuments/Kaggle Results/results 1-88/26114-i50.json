{
    "document_name": "26114-i50.docx",
    "content": [
        {
            "title": "Foreword",
            "description": "This Technical Specification has been produced by the 3rd Generation Partnership Project (3GPP).\nThe contents of the present document are subject to continuing work within the TSG and may change following formal TSG approval. Should the TSG modify the contents of the present document, it will be re-released by the TSG with an identifying change of release date and an increase in version number as follows:\nVersion x.y.z\nwhere:\nx\tthe first digit:\n1\tpresented to TSG for information;\n2\tpresented to TSG for approval;\n3\tor greater indicates TSG approved document under change control.\ny\tthe second digit is incremented for all changes of substance, i.e. technical enhancements, corrections, updates, etc.\nz\tthe third digit is incremented when editorial only changes have been incorporated in the document.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Introduction",
            "description": "Multimedia Telephony Service for IMS (MTSI), here also referred to as Multimedia Telephony, is a standardized IMS telephony service that builds on the IMS capabilities to establish multimedia communications between terminals within and in-between operator networks. The terminals connect to the IMS using either a fixed access network or a 3GPP access network.\nThe objective of defining a service is to specify the minimum set of capabilities required in the IP Multimedia Subsystem to secure multi-vendor and multi-operator inter-operability for Multimedia Telephony and related Supplementary Services. The objective also includes defining procedures for inter-working between different clients and networks.\nThe user experience of multimedia telephony is expected to be equivalent to or better than corresponding circuit-switched telephony services. Multimedia telephony also exploits the richer capabilities of IMS. In particular, multiple media components can be used and dynamically added or dropped during a session.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "1\tScope",
            "description": "The present document specifies a client for the Multimedia Telephony Service for IMS (MTSI) supporting conversational speech (including DTMF), video and text transported over RTP, and flexible data channel handling, with the scope to deliver a user experience equivalent to or better than that of Circuit Switched (CS) conversational services using the same amount of network resources. It defines media handling (e.g. signalling, transport, jitter buffer management, packet-loss handling, adaptation), as well as interactivity (e.g. adding or dropping media during a call). The focus is to ensure a reliable and interoperable service with a predictable media quality, while allowing for flexibility in the service offerings.\nThe present document describes two client types:\n-\tAn MTSI client in terminal which uses a 3GPP access (NR, LTE, HSPA, or EGPRS) to connect to the IMS. These clients are described in Clauses 5 – 17 and Annexes A – M.\n-\tAn MTSI client in terminal which uses a fixed access (corded interface, fixed-wireless interface, e.g. Wi-Fi, Bluetooth or DECT/NG DECT) to connect to the IMS. These clients are described in Clause 18.\nMTSI clients using 3GPP access and MTSI clients using fixed access have many common procedures for the media handling. This specification aligns the media handling by using cross references whenever possible. This does not mean that 3GPP terminals must support fixed access, nor does it mean that fixed terminals must support 3GPP access.\nThe scope includes maintaining backward compatibility in order to ensure seamless inter-working with existing services available in the CS domain, such as CS speech and video telephony, as well as with terminals of earlier 3GPP releases. In addition, inter-working with other IMS and non-IMS IP networks as well as traditional PSTN is covered.\nThe client may also support the IMS Messaging service and Group 3 facsimile transmission. The scope therefore also includes media handling for non-conversational media using MSRP and UDPTL-based Facsimile over IP (FoIP).\nThe specification is written in a forward-compatible way in order to allow additions of media components and functionality in releases after Release 7.\nNOTE 1:\tMTSI clients can support more than conversational speech, video and text, which is the scope of the present document. See TS 22.173 [2] for the definition of the Multimedia Telephony Service for IMS.\nNOTE 2:\tTS 26.235 [3] and TS 26.236 [4] do not include the specification of an MTSI client, although they include conversational multimedia applications. Only those parts of TS 26.235 [3] and TS 26.236 [4] that are specifically referenced by the present document apply to Multimedia Telephony Service for IMS.\nNOTE 3:\tThe present document was started as a conclusion from the study in TR 26.914 [5] on optimization opportunities in Multimedia Telephony for IMS (TR 22.973 [6]).\nNOTE 4:\tFor ECN, the present specification assumes that an interface enables the MTSI client to read and write the ECN field. This interface is outside the scope of this specification.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "2\tReferences",
            "description": "The following documents contain provisions which, through reference in this text, constitute provisions of the present document.\n-\tReferences are either specific (identified by date of publication, edition number, version number, etc.) or non-specific.\n-\tFor a specific reference, subsequent revisions do not apply.\n-\tFor a non-specific reference, the latest version applies. In the case of a reference to a 3GPP document (including a GSM document), a non-specific reference implicitly refers to the latest version of that document in the same Release as the present document.\n[1]\t3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".\n[2]\t3GPP TS 22.173: \"IP Multimedia Core Network Subsystem (IMS) Multimedia Telephony Service and supplementary services; Stage 1\".\n[3]\t3GPP TS 26.235: \"Packet switched conversational multimedia applications; Default codecs\".\n[4]\t3GPP TS 26.236: \"Packet switched conversational multimedia applications; Transport protocols\".\n[5]\t3GPP TR 26.914: \"Multimedia telephony over IP Multimedia Subsystem (IMS); Optimization opportunities\".\n[6]\t3GPP TR 22.973: \"IMS Multimedia Telephony service; and supplementary services\".\n[7]\t3GPP TS 24.229: \"IP multimedia call control protocol based on Session Initiation Protocol (SIP) and Session Description Protocol (SDP); Stage 3\".\n[8]\tIETF RFC 4566 (2006): \"SDP: Session Description Protocol\", M. Handley, V. Jacobson and C. Perkins.\n[9]\tIETF RFC 3550 (2003): \"RTP: A Transport Protocol for Real-Time Applications\", H. Schulzrinne, S. Casner, R. Frederick and V. Jacobson.\n[10]\tIETF RFC 3551 (2003): \"RTP Profile for Audio and Video Conferences with Minimal Control\", H. Schulzrinne and S. Casner.\n[11]\t3GPP TS 26.071: \"Mandatory Speech Codec speech processing functions; AMR Speech CODEC; General description\".\n[12]\t3GPP TS 26.090: \"Mandatory Speech Codec speech processing functions; Adaptive Multi-Rate (AMR) speech codec; Transcoding functions\".\n[13]\t3GPP TS 26.073: \"ANSI C code for the Adaptive Multi Rate (AMR) speech codec\".\n[14]\t3GPP TS 26.104: \"ANSI-C code for the floating-point Adaptive Multi Rate (AMR) speech codec\".\n[15]\t3GPP TS 26.093: \"Mandatory speech codec speech processing functions; Adaptive Multi-Rate (AMR) speech codec; Source controlled rate operation\".\n[16]\t3GPP TS 26.103: \"Speech codec list for GSM and UMTS\".\n[17]\t3GPP TS 26.171: \"Speech codec speech processing functions; Adaptive Multi-Rate - Wideband (AMR-WB) speech codec; General description\".\n[18]\t3GPP TS 26.190: \"Speech codec speech processing functions; Adaptive Multi-Rate - Wideband (AMR-WB) speech codec; Transcoding functions\".\n[19]\t3GPP TS 26.173: \"ANCI-C code for the Adaptive Multi Rate - Wideband (AMR-WB) speech codec\".\n[20]\t3GPP TS 26.204: \"Speech codec speech processing functions; Adaptive Multi-Rate - Wideband (AMR-WB) speech codec; ANSI-C code\".\n[21]\t3GPP TS 26.193: \"Speech codec speech processing functions; Adaptive Multi-Rate - Wideband (AMR-WB) speech codec; Source controlled rate operation\".\n[22]\tVoid.\n[23]\tVoid.\n[24]\tRecommendation ITU-T H.264 (04/2017): \"Advanced video coding for generic audiovisual services\" | ISO/IEC 14496-10:2014: \"Information technology – Coding of audio-visual objects – Part 10: Advanced Video Coding\".\n[25]\tIETF RFC 6184 (2011): \"RTP Payload Format for H.264 Video\", Y.-K. Wang, R. Even, T. Kristensen, R. Jesup.\n[26]\tITU-T Recommendation T.140 (02/1998): \"Protocol for multimedia application text conversation\".\n[27]\tITU-T Recommendation T.140 (02/2000): \"Protocol for multimedia application text conversation - Addendum 1\".\n[28]\tIETF RFC 4867 (2007): \"RTP Payload Format and File Storage Format for the Adaptive Multi-Rate (AMR) and Adaptive Multi-Rate Wideband (AMR-WB) Audio Codecs\", J. Sjoberg, M. Westerlund, A. Lakaniemi and Q. Xie.\n[29]\tVoid\n[30]\tVoid.\n[31]\tIETF RFC 4103 (2005): \"RTP Payload for Text Conversation\", G. Hellstrom and P. Jones.\n[32]\tVoid.\n[33]\t3GPP TR 25.993: \"Typical examples of Radio Access Bearers (RABs) and Radio Bearers (RBs) supported by Universal Terrestrial Radio Access (UTRA)\".\n[34]\t3GPP TS 22.105: \"Services and service capabilities\".\n[35]\t3GPP TS 26.131: \"Terminal acoustic characteristics for telephony; Requirements\".\n[36]\t3GPP TS 26.132: \"Speech and video telephony terminal acoustic test specification\".\n[37]\t3GPP TS 28.062: \"Inband Tandem Free Operation (TFO) of speech codecs; Service description; Stage 3\".\n[38]\t3GPP TS 23.153: \"Out of band transcoder control; Stage 2\".\n[39]\tIETF RFC 0768 (1980): \"User Datagram Protocol\", J. Postel.\n[40]\tIETF RFC 4585 (2006): \"Extended RTP Profile for Real-time Transport Control Protocol (RTCP) - Based Feedback (RTP/AVPF)\", J. Ott, S. Wenger, N. Sato, C. Burmeister and J. Rey.\n[41]\tRTP Tools: .\n[42]\tIETF RFC 3556 (2003): \"Session Description Protocol (SDP) Bandwidth Modifiers for RTP Control Protocol (RTCP) Bandwidth\", S. Casner.\n[43]\tIETF RFC 5104 (2008): \"Codec Control Messages in the RTP Audio-Visual Profile with Feedback (AVPF)\", S. Wenger, U. Chandra, M. Westerlund and B. Burman.\n[44]\tVoid.\n[45]\t3GPP TS 26.111: \"Codec for circuit switched multimedia telephony service; Modifications to H.324\".\n[46]\t3GPP TS 23.172: \"Technical realization of Circuit Switched (CS) multimedia service; UDI/RDI fallback and service modification; Stage 2\".\n[47]\t3GPP TS 23.002: \"Network Architecture\".\n[48]\tIETF RFC 3388 (2002): \"Grouping of Media Lines in the Session Description Protocol (SDP)\", G. Camarillo, G. Eriksson, J. Holler and H. Schulzrinne.\n[49]\tIETF RFC 4102 (2005): \"Registration of the text/red MIME Sub-Type\", P. Jones.\n[50]\tITU-T H.248 (06/2000): \"Packages for text conversation, fax and call discrimination\".\n[51]\tETSI EG 202 320, v1.2.1 (2005-10): \"Human Factors (HF); Duplex Universal Speech and Text (DUST) communications\".\n[52]\t3GPP TS 26.226: \"Cellular text telephone modem; General description\".\n[53]\tIETF RFC 4504 (2006): \"SIP Telephony Device Requirements and Configuration\", H. Sinnreich, Ed., S. Lass and C. Stredicke.\n[54]\tITU-T Recommendation V.151 (05/2006): \"Procedures for end-to-end connection of analogue PSTN text telephones over an IP network utilizing text relay\".\n[55]\tITU-T Recommendation V.152 (09/2010): \"Procedures for supporting Voice Band Data over IP networks\".\n[56]\tIETF RFC 3448 (2003): \"TCP Friendly Rate Control (TFRC): Protocol Specification\", M. Handley, S. Floyd, J. Padhye and J. Widmer.\n[57]\t3GPP TS 24.173: \"IMS Multimedia Telephony Communication Service and Supplementary Services\".\n[58]\tIETF RFC 3264 (2002): \"An Offer/Answer Model with the Session Description Protocol (SDP)\", J. Rosenberg and H. Schulzrinne.\n[59]\t3GPP TS 26.141: \"IP Multimedia System (IMS) Messaging and Presence; Media formats and codecs\".\n[60]\t3GPP TS 26.234: \"Transparent end-to-end Packet-switched Streaming Service; Protocols and codecs\".\n[61]\tIETF RFC 4733 (2006): \"RTP Payload for DTMF Digits, Telephony Tones, and Telephony Signals\", H. Schulzrinne and T.Taylor.\n[62]\t3GPP TS 23.014: \"Support of Dual Tone Multi-Frequency (DTMF) signalling\".\n[63]\tETSI ES 201 235-2, v1.2.1: \"Specification of Dual Tone Multi-Frequency (DTMF); Transmitters and Receivers; Part 2: Transmitters\".\n[64]\t3GPP TS 23.107: \"Quality of Service (QoS) concept and architecture\".\n[65]\t3GPP TS 29.163: \"Interworking between the IP Multimedia (IM) Core Network (CN) subsystem and Circuit Switched (CS) networks\".\n[66]\tVoid.\n[67]\tOMA-ERELD-DM-V1_2-20070209-A: \"Enabler Release Definition for OMA Device Management, Approved Version 1.2\".\n[68]\tVoid.\n[69]\tIETF RFC 5939 (2010): \"Session Description Protocol (SDP) Capability Negotiation\", F. Andreasen.\n[70]\tVoid\n[71]\tIETF RFC 1952 (May 1996): \"GZIP file format specification version 4.3\", P. Deutsch.\n[72]\tIETF RFC 2326 (1998): \"Real Time Streaming Protocol (RTSP)\".\n[73]\tIETF RFC 2616 (June 1999): \"Hypertext Transfer Protocol -- HTTP/1.1\".\n[74]\t3GPP TS 26.346 \"Multimedia Broadcast/Multicast Service (MBMS); Protocols and codecs\".\n[75]\tVoid\n[76]\tIETF RFC 6236 (2011): \"Negotiation of Generic Image Attributes in the Session Description Protocol (SDP)\", I. Johansson and K. Jung.\n[77]\tITU-T G.711 (11/1988): \"Pulse code modulation (PCM) of voice frequencies\".\n[78]\tITU-T G.722 (09/2012): \"7 kHz audio-coding within 64 kbit/s\".\n[79]\tIETF RFC 4821 (2007): \"Packetization Layer Path MTU Discovery\".\n[80]\t3GPP TS 23.003: \"Numbering, addressing and identification\".\n[81]\tIETF RFC 4796 (2007): \"The Session Description Protocol (SDP) Content Attribute\", J. Hautakorpi and G. Camarillo.\n[82]\t3GPP TS 24.247: \"Messaging service using the IP Multimedia (IM) Core Network (CN) subsystem\".\n[83]\tIETF RFC 3168 (2001): \"The Addition of Explicit Congestion Notification (ECN) to IP\", K. Ramakrishnan, S. Floyd and D. Black.\n[84]\tIETF RFC 6679 (2012): \"Explicit Congestion Notification (ECN) for RTP over UDP\", M. Westerlund, et. al.\n[85]\t3GPP TS 36.300: \"Evolved Universal Terrestrial Radio Access (E-UTRA) and Evolved Universal Terrestrial Radio Access Network (E-UTRAN); Overall description\".\n[86]\tVoid\n[87]\tIETF RFC 5506 (2009):  \"Support for Reduced-Size Real-Time Transport Control Protocol (RTCP): Opportunities and Consequences\".\n[88]\tIETF RFC 3611 (2003): \"RTP Control Protocol Extended Reports (RTCP XR) \", T. Friedman, R. Caceres and A. Clark.\n[89]\t3GPP TS 25.401: \"UTRAN overall description\".\n[90]\t3GPP TS 23.203: \"Policy and charging control architecture\".\n[91]\tITU-T Recommendation T.4 (07/2003): \"Standardization of Group 3 facsimile terminals for document transmission\".\n[92]\tITU-T Recommendation T.30 (09/2005): \"Procedures for document facsimile transmission in the general switched telephone network\".\n[93]\tITU-T Recommendation T.38 (09/2010): \"Procedures for real-time Group 3 facsimile communication over IP networks\".\n[94]\tIETF RFC 3362 (2002): \"Real-time Facsimile (T.38) - image/t38 MIME Sub-type Registration\".\n[95]\tIETF RFC 5285 (2008): \"A General Mechanism for RTP Header Extensions\", D. Singer, H. Desineni.\n[96]\tIETF RFC 5168 (2008): \"XML Schema for Media Control\", O. Levin, R. Even and P. Hagendorf.\n[97]\t3GPP2 C.S0055-A, version 1.0: \"Packet Switched Video Telephony Service (PSVT/MCS)\".\n[98]\tETSI TS 181 005, v3.3.1: \"Telecommunications and Internet converged Services and Protocols for Advanced Networking (TISPAN); Service and Capability Requirements\".\n[99]\t3GPP2 C.S0014-E, version 1.0: \"Enhanced Variable Rate Codec (EVRC)\".\n[100]\tITU-T Recommendation G.729 (06/2012): \"Coding of speech at 8 kbit/s using conjugate-structure algebraic-code-excited linear prediction (CS-ACELP)\".\n[101]\tITU-T Recommendation G.729.1 (05/2006): \"G.729-based embedded variable bit-rate coder: An 8-32 kbit/s scalable wideband coder bitstream interoperable with G.729\".\n[102]\t3GPP2 C.S0076, version 1.0: \"Discontinuous Transmission (DTX) of Speech in cdma2000 Systems\".\n[103]\tIETF RFC 5188 (2008):\"RTP Payload Format for the Enhanced Variable Rate Wideband Codec (EVRC-WB) and the Media Subtype Updates for EVRC-B Codec\".\n[104]\tIETF RFC 4749 (2006): \"RTP Payload Format for the G.729.1 Audio Codec\".\n[105]\tIETF RFC 5459 (2009): \"G.729.1 RTP Payload Format Update: Discontinuous Transmission (DTX) Support\".\n[106]\tIETF RFC 4788 (2007): \"Enhancements to RTP Payload Formats for EVRC Family Codecs\".\n[107]\tIETF RFC 4855 (2007): \"Media Type Registration of RTP Payload Formats\".\n[108]\tITU-T Recommendation P.10 (07/2006): \"Vocabulary and effects of transmission parameters on customer opinion of transmission quality\".\n[109]\tETSI TS 103 737, v1.1.2: \"Speech and multimedia Transmission Quality (STQ); Transmission requirements for narrowband wireless terminals (handset and headset) from a QoS perspective as perceived by the user\".\n[110]\tETSI TS 103 738, v1.1.2: \"Speech and multimedia Transmission Quality (STQ); Transmission requirements for narrowband wireless terminals (handsfree) from a QoS perspective as perceived by the user\".\n[111]\tETSI TS 103 739, v1.1.2: \"Speech and multimedia Transmission Quality (STQ); Transmission requirements for wideband wireless terminals (handset and headset) from a QoS perspective as perceived by the user\".\n[112]\tETSI TS 103 740, v1.1.2: \"Speech and multimedia Transmission Quality (STQ); Transmission requirements for wideband wireless terminals (handsfree) from a QoS perspective as perceived by the user\".\n[113]\tETSI TS 202 737, v1.3.2: \"Speech and multimedia Transmission Quality (STQ); Transmission requirements for narrowband VoIP terminals (handset and headset) from a QoS perspective as perceived by the user\".\n[114]\tETSI TS 202 738, v1.3.2: \"Speech and multimedia Transmission Quality (STQ); Transmission requirements for narrowband VoIP loudspeaking and handsfree terminals from a QoS perspective as perceived by the user\".\n[115]\tETSI TS 202 739, v1.3.2: \"Speech and multimedia Transmission Quality (STQ); Transmission requirements for wideband VoIP terminals (handset and headset) from a QoS perspective as perceived by the user \".\n[116]\tETSI TS 202 740, v1.3.2: \"Speech and multimedia Transmission Quality (STQ); Transmission requirements for wideband VoIP loudspeaking and handsfree terminals from a QoS perspective as perceived by the user \".\n[117]\tETSI EN 300 175-8, v2.5.1: \"Digital Enhanced Cordless Telecommunications (DECT); Common Interface (CI); Part 8: Speech and audio coding and transmission\".\n[118]\tETSI TS 300 176-2, v2.2.1: \"Digital Enhanced Cordless Telecommunications (DECT); Test specification; Part 2: Audio and speech\".\n[119]\tRecommendation ITU-T H.265: \"High efficiency video coding\" | ISO/IEC 23008-2:2020: \"High Efficiency Coding and Media Delivery in Heterogeneous Environments – Part 2: High Efficiency Video Coding\". [120]\tIETF RFC 7798 (2016): \"RTP Payload Format for High Efficiency Video Coding (HEVC)\", Y.-K. Wang, Y. Sanchez, T. Schierl, S. Wenger, M. M. Hannuksela.\n[121]\t3GPP TS 26.441: \"Codec for Enhanced Voice Services (EVS); General Overview\".\n[122]\t3GPP TS 26.442: \"Codec for Enhanced Voice Services (EVS); ANSI C code (fixed-point)\".\n[123]\t3GPP TS 26.443: \"Codec for Enhanced Voice Services (EVS); ANSI C code (floating-point)\".\n[124]\t3GPP TS 26.444: \"Codec for Enhanced Voice Services (EVS); Test Sequences\".\n[125]\t3GPP TS 26.445: \"Codec for Enhanced Voice Services (EVS); Detailed Algorithmic Description\".\n[126]\t3GPP TS 26.446: \"Codec for Enhanced Voice Services (EVS); AMR-WB Backward Compatible Functions\".\n[127]\t3GPP TS 26.447: \"Codec for Enhanced Voice Services (EVS); Error Concealment of Lost Packets\".\n[128]\t3GPP TS 26.448: \"Codec for Enhanced Voice Services (EVS); Jitter Buffer Management\".\n[129]\t3GPP TS 26.449: \"Codec for Enhanced Voice Services (EVS); Comfort Noise Generation (CNG) Aspects\".\n[130]\t3GPP TS 26.450: \"Codec for Enhanced Voice Services (EVS); Discontinuous Transmission (DTX)\".\n[131]\t3GPP TS 26.451: \"Codec for Enhanced Voice Services (EVS); Voice Activity Detection (VAD)\".\n[132]\t3GPP TS 45.003: \"Radio Access Network; Channel coding\".\n[133]\t3GPP TS 23.216: \"Single Radio Voice Call Continuity (SRVCC); Stage2\".\n[134]\t3GPP TS 23.237: \"IP Multimedia Subsystem (IMS) Service Continuity; Stage2\".\n[135]\tITU-T Recommendation H.224 (01/05): \"A real time control protocol for simplex applications using the H.221 LSD/HSD/MLP channels \".\n[136]\tITU-T Recommendation H.224 (2005): Corrigendum 1 (08/07).\n[137]\tITU-T Recommendation H.281 (11/94): Transmission of non-telephone signals \"A far end camera control protocol for videoconferences using H.224\".\n[138]\tITU-T Recommendation H.323 (12/2009): \"Packet-based multimedia communications systems\".\n[139]\tIETF RFC 4573 (2006): \"MIME Type Registration for RTP Payload Format for H.224\".\n[140]\tIETF RFC 4588 (2006): \"RTP Retransmission Payload Format\", J. Rey, D. Leon, A. Miyazaki, V. Varsa and R. Hakenberg.\n[141]\tIETF RFC 8627 (2019): \"RTP Payload Format for Flexible Forward Error Correction (FEC)\".\n[142]\tTR 26.922:  \"Video Telephony Robustness Improvements Extensions (VTRI_EXT): Performance Evaluation\".\n[143]\tIETF RFC 5956 (2010): \"Forward Error Correction Grouping Semantics in the Session Description Protocol\", A. Cengiz.\n[144]\t3GPP TR 26.924: \"Multimedia telephony over IP Multimedia Subsystem (IMS); Study on improved end-to-end Quality of Service (QoS) handling for Multimedia Telephony Service for IMS (MTSI)\".\n[145]\tVoid\n[146]\tVoid.\n[147]\t3GPP TS 24.147: \"Conferencing Using IP Multimedia Core Network; Stage 3\".\n[148]\tIETF RFC 4575 (2006): \"A Session Initiation Protocol (SIP) Event Package for Conference State\".\n[149]\tIETF RFC 4582 (2006): \"The Binary Floor Control Protocol (BFCP)\".\n[150]\tIETF RFC 4583 (2006): \"Session Description Protocol (SDP) Format for Binary Floor Control (BFCP) Streams\".\n[151]\tVoid.\n[152]\t3GPP TR 26.980: \"Multimedia telephony over IP Multimedia Subsystem (IMS); Media handling aspects of multi-stream multiparty conferencing for Multimedia Telephony Service for IMS (MTSI)\".\n[153]\tIETF RFC 5234 (2008): \"Augmented BNF for Syntax Specifications: ABNF\", D. Crocker and P. Overell.\n[154]\tIETF RFC 8853 (2021): \"Using Simulcast in Session Description Protocol (SDP) and RTP Sessions\"\n[155]\tIETF RFC 8851 (2021): \"RTP Payload Format Restrictions\"\n[156]\tIETF RFC 7728 (2016): \"RTP Stream Pause and Resume\".\n[157]\t3GPP TS 36.321: \"Evolved Universal Terrestrial Radio Access (E-UTRA); Medium Access Control (MAC) protocol specification\".\n[158]\t3GPP TS 25.331: \"Radio Resource Control (RRC); Protocol specification\".\n[159]\t\"Mobile Location Protocol (MLP)\", Open Mobile Alliance, OMA-LIF-MLP-V3_1, Approved Version 3.1 – 20 Sep 2011.\n[160]\t3GPP TS 36.331: \"Evolved Universal Terrestrial Radio Access (E-UTRA); Radio Resource Control (RRC); Protocol specification\".\n[161]\t3GPP TS 27.007: \" Technical Specification Group Core Network and Terminals; AT command set for User Equipment (UE)\".\n[162]\tVoid\n[163]\t3GPP TS 38.331: \"NR; Radio Resource Control (RRC); Protocol Specification\".\n[164]\t3GPP TS 38.300: \"NR; NR and NG-RAN Overall Description; Stage 2\".\n[165]\t3GPP TS 26.452: \"Codec for Enhanced Voice Services (EVS); ANSI C code; Alternative fixed-point using updated basic operators\".\n[166]\t3GPP TS 38.321: \"NR; Medium Access Control (MAC) protocol specification\".\n[167]\t3GPP TS 23.228: \"IP Multimedia Subsystem (IMS); Stage 2\".\n[168]\t3GPP TR 26.952: \"Codec for Enhanced Voice Services (EVS); Performance characterization\".\n[169]\t3GPP TR 26.959: \"Study on enhanced Voice over LTE (VoLTE) performance\".\n[170]\t3GPP TS 36.323: \"Evolved Universal Terrestrial Radio Access (E-UTRA); Packet Data Convergence Protocol (PDCP) specification\".\n[171]\t3GPP TS 37.324: \"Evolved Universal Terrestrial Radio Access (E-UTRA) and NR; Service Data Adaptation Protocol (SDAP) specification\".\n[172]\tIETF RFC 8864 (2021): \"Negotiation Data Channels Using the Session Description Protocol (SDP)\"\n[173]\tIETF RFC 4960 (2007): \"Stream Control Transmission Protocol\"\n[174]\tIETF RFC 8261 (2017): \"Datagram Transport Layer Security (DTLS) Encapsulation of SCTP Packets\"\n[175]\tIETF RFC 8831 (2021): \"WebRTC Data Channels\".\n[176]\t3GPP TS 23.501: \"System Architecture for the 5G System; Stage 2\".\n[177]\tIETF RFC 5688 (2010): \"A Session Initiation Protocol (SIP) Media Feature Tag for MIME                    Application Subtypes\".\n[178]\t3GPP TS 28.405; \"Management of Quality of Experience (QoE) measurement collection; Control and configuration\"\n[179]\tISO/IEC 23090-2:2019: \" Information technology -- Coded representation of immersive media -- Part 2: Omnidirectional media format\".\n[180]\t\t3GPP TS 26.118: \"3GPP Virtual reality profiles for streaming applications\".\n[181]\tITU-T Recommendation G.1028 (06/2019): \"End-to-end quality of service for voice over 4G mobile networks\".\n[182]\t3GPP TS 24.526: \"User Equipment (UE) policies for 5G System (5GS); Stage 3\".\n[183]\t\tISO/IEC 23090-14: Information technology — Coded representation of immersive media — Part 14: Scene Description for MPEG Media.\n[184]\tIETF RFC 8839 (2021): \"Session Description Protocol (SDP) Offer/Answer Procedures for Interactive Connectivity Establishment (ICE)\".\n[185]\tIETF RFC 9071(2021): “RTP-Mixer Formatting of Multiparty Real-Time Text”.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "3\tDefinitions and abbreviations",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "3.1\tDefinitions",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the terms and definitions given in TR 21.905 [1] and the following apply:\nNOTE:\tA term defined in the present document takes precedence over the definition of the same term, if any, in TR 21.905 [1].\nexample: text used to clarify abstract rules by applying them literally.\n360-degree video: A real-world visual scene captured by a set of cameras or a camera device with multiple lenses and sensors covering the sphere in all directions around the centre point of the camera set or camera device. The term 360-degree video may be used to include also limited 360-degree video.\nLimited 360-degree video: A 360-degree video in which the visual scene does not cover the entire sphere around the center point of the camera set or camera device but only a part of it. A limited 360-degree video may be limited i) in the horizontal field to less than 360 degrees, or ii) in the vertical field to less than 180 degrees or iii) in both the vertical and horizontal fields.\nAMR, AMR-NB: Both names refer to the AMR codec (TS 26.071 [11]) and are used interchangeably in this specification.\nBitstream: A bitstream that conforms to a video or audio encoding format.\nbitstream: A sequence of bits that forms the representation of one or more coded video or audio sequences.\nCHEM: The Coverage and Handoff Enhancements using Multimedia error robustness feature.\nCodec mode: Used for the AMR and AMR-WB codecs to identify one specific bitrate. For example AMR includes 8 codec modes (excluding SID), each of different bitrate.\nConstrained terminal: UE that is (i) operating in radio access capability category series \"M\" capable of supporting conversational services, and/or (ii) a wearable device which is constrained in size, weight or power consumption (e.g. connected watches), excluding smartphones and feature phones.\nDCMTSI client: A data channel capable MTSI client supporting data channel media as defined in clause 6.2.10.\nDCMTSI client in terminal: A DCMTSI client that is implemented in a terminal or UE. The term \"DCMTSI client in terminal\" is used in this document when entities such as MRFP, MRFC or media gateways are excluded.\nDual-mono: A variant of 2-channel stereo encoding where two instances of a mono codec are used to encode a 2-channel stereo signal.\nEvolved UTRAN: Evolved UTRAN is an evolution of the 3G UMTS radio-access network towards a high-data-rate, low-latency and packet-optimized radio-access network.\nEVS codec: The EVS codec includes two operational modes: EVS Primary operational mode (‘EVS Primary mode’) and EVS AMR-WB Inter-Operable (‘EVS AMR-WB IO mode’). When using EVS AMR-WB IO mode the speech frames are bitstream interoperable with the AMR-WB codec [18]. Frames generated by an EVS AMR-WB IO mode encoder can be decoded by an AMR-WB decoder, without the need for transcoding. Likewise, frames generated by an AMR-WB encoder can be decoded by an EVS AMR-WB IO mode decoder, without the need for transcoding.\nEVS Primary mode: Includes 11 bit-rates for fixed-rate or multi-rate operation; 1 average bit-rate for variable bit-rate operation; and 1 bit-rate for SID (TS 26.441 [121]). The EVS Primary can encode narrowband, wideband, super-wideband and fullband signals. None of these bit-rates are interoperable with the AMR-WB codec.\nEVS AMR-WB IO mode: Includes 9 codec modes and SID. All are bitstream interoperable with the AMR-WB codec (TS 26.171 ‎‎[17]).\nField of View: The extent of visible area expressed with vertical and horizontal angles, in degrees in the 3GPP 3DOF reference system as defined in TS 26.118 [180].\nFisheye Video: Video captured by a wide-angle camera lens that usually captures an approximately hemispherical field of view and projects it as a circular image.\nFrame Loss Rate (FLR): The percentage of speech frames not delivered to the decoder. FLR includes speech frames that are not received in time to be used for decoding.\nITT4RT client: MTSI client supporting the Immersive Teleconferencing and Telepresence for Remote Terminals (ITT4RT) feature, as defined in Annex Y.\nITT4RT-Tx client: ITT4RT client only capable of sending immersive video.\nITT4RT-Rx client: ITT4RT client only capable of receiving immersive video\nITT4RT MRF: An ITT4RT client implemented by functionality included in the MRFC and the MRFP.\nITT4RT client in terminal: An ITT4RT client that is implemented in a terminal or UE. The term \"ITT4RT client in terminal\" is used in this document when entities such as ITT4RT MRF is excluded.\nMode-set: Used for the AMR and AMR-WB codecs to identify the codec modes that can be used in a session. A mode-set can include one or more codec modes.\nMSMTSI client: A multi-stream capable MTSI client supporting multiple streams as defined in Annex S. An MTSI client may support multiple streams, even of the same media type, without being an MSMTSI client. Such an MTSI client may, for example, add a second video to an ongoing video telephony session as shown in Annex A.11. In that case, the MTSI client is an MSMTSI client only if it is fully compliant with Annex S.\nMSMTSI MRF: An MSMTSI client implemented by functionality included in the MRFC and the MRFP.\nMSMTSI client in terminal: An MSMTSI client that is implemented in a terminal or UE. The term \"MSMTSI client in terminal\" is used in this document when entities such as MRFP, MRFC or media gateways are excluded.\nMTSI client: A function in a terminal or in a network entity (e.g. a MRFP) that supports MTSI.\nMTSI client in terminal: An MTSI client that is implemented in a terminal or UE. The term \"MTSI client in terminal\" is used in this document when entities such as MRFP, MRFC or media gateways are excluded.\nMTSI media gateway (or MTSI MGW): A media gateway that provides interworking between an MTSI client and a non MTSI client, e.g. a CS UE. The term MTSI media gateway is used in a broad sense, as it is outside the scope of the current specification to make the distinction whether certain functionality should be implemented in the MGW or in the MGCF.\nOmnidirectional media: Media such as image or video and its associated audio that enable rendering according to the user's viewing orientation, if consumed with a head-mounted device, or according to user's desired viewport, otherwise, as if the user was in the spot where and when the media was captured.\nOperational mode: Used for the EVS codec to distinguish between EVS Primary mode and EVS AMR-WB IO mode.\nOverlay: A piece of visual media, rendered over omnidirectional video or image, or a viewport.\nPose: Position and rotation information associated to a viewport.\nProjected picture: Picture that has a representation format specified by an omnidirectional video projection format.\nProjection: Inverse of the process by which the samples of a projected picture are mapped to a set of positions identified by a set of azimuth and elevation coordinates on a unit sphere.\nSimulcast: Simultaneously sending different encoded representations (simulcast formats) of a single media source (e.g. originating from a single microphone or camera) in different simulcast streams.\nSimulcast format: The encoded format used by a single simulcast stream, typically represented by an SDP format and all SDP attributes that apply to that particular SDP format, indicated in RTP by the RTP header payload type field.\nSimulcast stream: The RTP stream carrying a single simulcast format in a simulcast.\nViewport: Region of omnidirectional image or video suitable for display and viewing by the user.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "3.2\tAbbreviations",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the abbreviations given in TR 21.905 [1] and the following apply:\nNOTE:\tAn abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in TR 21.905 [1].\n3DOF\t3 Degrees of freedom\n5GC\t5G Core Network\nAC\tAlternating Current\nAL-SDU\tApplication Layer - Service Data Unit\nAMR\tAdaptive Multi-Rate\nAMR-NB\tAdaptive Multi-Rate - NarrowBand\nAMR-WB\tAdaptive Multi-Rate - WideBand\nAMR-WB IO\tAdaptive Multi-Rate - WideBand Inter-operable Mode, included in the EVS codec\nANBR\tAccess Network Bitrate Recommendation\nANBRQ\tAccess Network Bitrate Recommendation Query\nAPP\tAPPlication-defined RTCP packet\nARQ\tAutomatic repeat ReQuest\nAS\tApplication Server\nATCF\tAccess Transfer Control Function\nATGW\tAccess Transfer GateWay\nAVC\tAdvanced Video Coding\nBFCP\tBinary Floor Control Protocol\nCCM\tCodec Control Messages\nCDF\tCumulative Distribution Function\ncDRX\tConnected Mode DRX\nCHEM\tCoverage and Handoff Enhancements using Multimedia error robustness feature\nCMP\tCube-Map Projection\nCMR\tCodec Mode Request\ncps\tcharacters per second\nCS\tCircuit Switched\nCSCF\tCall Session Control Function\nCTM\tCellular Text telephone Modem\nCVO\tCoordination of Video Orientation\nDBI\tDelay Budget Information\nDRB\tData Radio Bearer\nDRX\tDiscontinuous Reception\nDTLS\tDatagram Transport Layer Security\nDTMF\tDual Tone Multi-Frequency\nDTX\tDiscontinuous Transmission\nECN\tExplicit Congestion Notification\nECN-CE\tECN Congestion Experienced\nECT\tECN Capable Transport\neNodeB\tE-UTRAN Node B\nERP\tEquiRectangular Projection\nE-UTRAN\tEvolved UTRAN\nEVS\tEnhanced Voice Services\nFECC\tFar End Camera Control\nFIR\tFull Intra Request\nFLR\tFrame Loss Rate\nFoIP\tFacsimile over IP\nFOV\tField Of View\nGIP\tGeneric IP access\nGOB\tGroup Of Blocks\nH-ARQ\tHybrid - ARQ\nHEVC\tHigh Efficiency Video Coding\nHMD\tHead Mounted Display HSPA\tHigh Speed Packet Access\nICM\tInitial Codec Mode\nIDR\tInstantaneous Decoding Refresh\nIFP\tInternet Facsimile Protocol\nIFT\tInternet Facsimile Transfer\nIMS\tIP Multimedia Subsystem\nIP\tInternet Protocol\nIPv4\tInternet Protocol version 4\nIRAP\tIntra Random Access Point\nITT4RT\tImmersive Teleconferencing and Telepresence for Remote Terminals\nITU-T\tInternational Telecommunications Union - Telecommunications\nJBM\tJitter Buffer Management\nMGCF\tMedia Gateway Control Function\nMGW\tMedia GateWay\nMIME\tMultipurpose Internet Mail Extensions\nMO\tManagement Object\nMPEG\tMoving Picture Experts Group\nMRFC\tMedia Resource Function Controller\nMRFP\tMedia Resource Function Processor\nMSMTSI\tMulti-Stream Multimedia Telephony Service for IMS\nMSRP\tMessage Session Relay Protocol\nMTSI\tMultimedia Telephony Service for IMS\nMTU\tMaximum Transfer Unit\nNACK\tNegative ACKnowledgment\nNNI\tNetwork-to-Network Interface\nNTP\tNetwork Time Protocol\nOMAF\tOmnidirectional MediA Format\nPCM\tPulse Code Modulation\nPDCP\tPacket Data Convergence Protocol\nPDP\tPacket Data Protocol\nPLI\tPicture Loss Indication\nPLR\tPacket Loss Ratio\nPOI\tPoint Of Interconnect\nPSTN\tPublic Switched Telephone Network\nPTZF\tPan, Tilt, Zoom and Focus\nQCI\tQoS Class Identifier\nQMC\tQoE Measurement Collection\nQoE\tQuality of Experience\nQoS\tQuality of Service\nQP\tQuantization Parameter\nRoHC\tRobust HeaderCompression\nROI\tRegion of Interest\nRR\tReceiver Report\nRTCP\tRTP Control Protocol\nRTP\tReal-time Transport Protocol\nRWP\tRegion-Wise Packing\nSB-ADPCM\tSub-Band Adaptive Differential PCM\nSC-VBR\tSource Controlled VBR\nSCTP\tStream Control Transmission Protocol\nSDAP\tService Data Adaptation Protocol\nSDP\tSession Description Protocol\nSDPCapNeg\tSDP Capability Negotiation\nSEI\tSupplemental Enhancement Information\nSID\tSIlence Descriptor\nSIP\tSession Initiation Protocol\nSR\tSender Report\nSRVCC\tSingle Radio Voice Call Continuity\nTFO\tTandem-Free Operation\nTISPAN\tTelecoms and Internet converged Services and Protocols for Advanced Network\nTMMBN\tTemporary Maximum Media Bit-rate Notification\nTMMBR\tTemporary Maximum Media Bit-rate Request\nTrFO\tTranscoder-Free Operation\nUDP\tUser Datagram Protocol\nUDPTL\tFacsimile UDP Transport Layer (protocol)\nUE\tUser Equipment\nVDP\tViewport Dependent Processing\nVoIP\tVoice over IP\nVOP\tVideo Object Plane\nVR\tVirtual Reality\nWebRTC\tWeb Real-Time Communication\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "4\tSystem description",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "4.1\tSystem",
                    "description": "",
                    "summary": "",
                    "text_content": "A Multimedia Telephony Service for IMS call uses the Call Session Control Function (CSCF) mechanisms to route control-plane signalling between the UEs involved in the call (see figure 4.1). In the control plane, Application Servers (AS) should be present and may provide supplementary services such as call hold/resume, call forwarding and multi-party calls, etc.\nThe scope of the present document is to specify the media path.  In the example in figure 4.1, it is routed directly between the PS Domains outside the IMS.\nFigure 4.1 illustrates a high-level architecture with two Multi-Technology Switching (MTSI) clients in terminals, utilizing 3GPP access to establish a call setup. The terminals are connected to the IP Multimedia Subsystem (IMS) network over a 3GPP radio access network. The figure highlights the interaction between the MTSI clients, the IMS network, and the radio access network, showcasing the integration of different communication technologies within the system.\nFigure 4.1: High-level architecture figure showing two MTSI clients in terminals using 3GPP access involved in an MTSI call set-up. The terminals connect to the IMS network over a 3GPP radio access network.\nThe call setup for an MTSI client in terminal using fixed access is the same as shown in Figure 4.1 for 3GPP terminals except that a fixed access is used instead of the 3GPP access and that the PS Domain is not necessarily used.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "4.2\tClient",
                    "description": "",
                    "summary": "",
                    "text_content": "The functional components of a terminal including an MTSI client in terminal using 3GPP access are shown in figure 4.2. An MTSI client in terminal using fixed access can have the same functional components except that it does not have any 3GPP Layer 2 protocol.\nThe given telecommunication figure, marked as \"NOTE: The grey box marks the scope of the present document,\" provides a visual representation of a specific area within a larger telecommunication system. The grey box indicates the boundaries of the information being presented, focusing on a particular aspect of the system. The figure likely contains various components and connections that are relevant to the scope, depicted in detail to provide a clear understanding of the system's structure and functionality within those boundaries.\nNOTE:\tThe grey box marks the scope of the present document.\n\nFigure 4.2: Functional components of a terminal including an MTSI client in terminal using 3GPP access\nThe scope of the present document is to specify media handling and interaction, which includes media control, media codecs, as well as transport of media and control data. General control-related elements of an MTSI client, such as SIP signalling (TS 24.229 [7]), fall outside this scope, albeit parts of the session setup handling and session control for conversational media are defined here:\n-\tusage of SDP (RFC 4566 [8]) and SDP capability negotiation (RFC 5939 [69]) in SIP invitations for capability negotiation and media stream setup.\n-\tset-up and control of the individual media streams between clients. It also includes interactivity, such as adding and dropping of media components.\nTransport of media consists of the encapsulation of the coded media in a transport protocol as well as handling of coded media received from the network. This is shown in figure 4.2 as the \"packet based network interface\" and is displayed, for conversational media, in more detail in the user-plane protocol stack in figure 4.3. The basic MTSI client defined here specifies media codecs for speech, video, still images and text (see clause 5). Data channels do not require use of any codec but allows for real-time interaction in parallel to the conversational media (see clause 6.2.10). The User interface in Figure 4.2 interacts with a web page and a related script received through a downlink data channel to handle the data channel I/O and data formatting. All conversational media components are transported over RTP with each respective payload format mapped onto the RTP (RFC 3550 [9]) streams. The data channels are using SCTP (RFC 4960 [173]) over DTLS (RFC 8261 [174]), used as specified for WebRTC data channels (RFC 8831 [175]).\nFigure 4.3 illustrates the user plane protocol stack for a basic MTSI (Multiplexed Traffic Signal Interface) client, showcasing the various layers involved in data transmission. The stack begins with the physical layer, which handles the transmission of raw bits over the air interface. Moving up, the data link layer ensures reliable data transfer between devices, while the network layer manages routing and addressing. The transport layer, responsible for error detection and correction, follows, and the application layer at the top provides a user-friendly interface for applications to interact with the network. The figure also highlights the role of the MTSI client in managing multiple connections and signaling protocols within the network.\nFigure 4.3: User plane protocol stack for a basic MTSI client\nAn MTSI client may also support non-conversational media, for example IMS messaging. The functional entities and the protocols used for IMS messaging are described in TS 24.247 [82].\nThe 3GPP Layer 2 protocol to be interfaced with MTSI client is PDCP [170] for EPC. For 5GC, another user-plane protocol, SDAP [171], is used on top of PDCP as shown in clause 4.4.1 of [164]. It is assumed that the SDAP would be configured without header for both directions in the typical MTSI cases, effectively interfacing with PDCP, as SDAP header would be needed only when more than one QoS flows are multiplexed in a DRB or reflective mapping is enabled.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "4.3\tMRFP and MGW",
                    "description": "",
                    "summary": "",
                    "text_content": "A Media Resource Function Processor (MRFP), see TS.23.002 [47], may be inserted in the media path for certain supplementary services (e.g. conference) and/or to provide transcoding and may therefore act as a MTSI client together with other network functions, such as a MRFC.\nA Media Gateway (MGW), see TS 23.002 [47], may be used to provide inter-working between different networks and services. For example, a MTSI MGW may provide inter-working between MTSI and 3G-324M services. The MTSI MGW may have more limited functionality than other MTSI clients, e.g. when it comes to the supported bitrates of media. The inter-working aspects are described in more detail in clause 12.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "5\tMedia codecs",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "5.1\tMedia components",
                    "description": "",
                    "summary": "",
                    "text_content": "The Multimedia Telephony Service for IMS supports simultaneous transfer of multiple media components with real-time characteristics. Media components denote the actual components that the end-user experiences.\nThe following media components are considered as core components. Multiple media components (including media components of the same media type) may be present in a session. At least one of the first three of these components is present in all conversational multimedia telephony sessions.\n-\tSpeech: The sound that is picked up by a microphone and transferred from terminal A to terminal B and played out in an earphone/loudspeaker. Speech includes detection, transport and generation of DTMF events.\n-\tVideo: The moving image that is, for example, captured by a camera of terminal A, transmitted to terminal B and, for example, rendered on the display of terminal B.\n-\tText: The characters typed on a keyboard or drawn on a screen on terminal A and rendered in real time on the display of terminal B. The flow is time-sampled so that no specific action is needed from the user to request transmission.\n-\tData: Any other data for real-time interaction, closely related to the multimedia telephony session that may be generated or consumed by either one of terminal A or terminal B, possibly via terminal external connections and/or physical connectors, optionally processed by application-specific logic at one or both terminals, and optionally presented on and controlled by the user interface at one or both terminals.\nThe first three of the above core media components are transported in real time from one MTSI client to the other using RTP (IETF RFC 3550 [9]). The \"data\" media component for real-time interaction is transported using SCTP (IETF RFC 4960 [173]) over DTLS (IETF RFC 8261 [174]), as described by WebRTC data channels [175]. All media components can be added or dropped during an ongoing session as required either by the end-user or by controlling nodes in the network, assuming that when adding components, the capabilities of the MTSI client support the additional component.\nNOTE:\tThe terms voice and speech are synonyms. The present document uses the term speech. The media type is called \"audio\" in SDP and therefore also the term \"audio\" is used as synonym.\nMTSI specifications also support other media types than the core components described above, for example facsimile (fax) transmission.\nFacsimile transmission is described in Annex L.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "5.2\tCodecs for MTSI clients in terminals",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "5.2.1\tSpeech",
                            "text_content": "MTSI clients in terminals offering speech communication shall support narrowband, wideband and super-wideband communication. The only exception to this requirement is for the MTSI client in constrained terminal offering speech communication, in which case the MTSI client in constrained terminal shall support narrowband and wideband, and should support super-wideband communication.\nIn addition, MTSI clients in terminals offering speech communication shall support:\n-\t.AMR speech codec (TS 26.071 [11], TS 26.090 [12], TS 26.073 [13] and TS 26.104 [14]) including all 8 modes and source controlled rate operation ‎TS 26.093 [15]. The MTSI client in terminal shall be capable of operating with any subset of these 8 codec modes. More detailed codec requirements for the AMR codec are defined in clause 5.2.1.2.\nMTSI clients in terminals offering wideband speech communication at 16 kHz sampling frequency shall support:\n-\tAMR-WB codec (TS 26.171 ‎‎[17], TS 26.190 ‎[18], TS 26.173 ‎[19] and TS 26.204 [20]) including all 9 modes and source controlled rate operation ‎TS 26.193 [21]. The MTSI client in terminal shall be capable of operating with any subset of these 9 codec modes. More detailed codec requirements for the AMR-WB codec are defined in clause 5.2.1.3. When the EVS codec is supported, the EVS AMR-WB IO mode may serve as an alternative implementation of AMR-WB as defined in clause 5.2.1.4.\nMTSI clients in terminals offering super-wideband or fullband speech communication shall support:\n-\tEVS codec ( TS 26.441 [121], TS 26.444 [124], TS 26.445 [125], TS 26.447 [127], TS 26.451 [131], TS 26.442 [122], TS 26.452 [165] and TS 26.443 [123]) as described below including functions for backwards compatibility with AMR-WB ( TS 26.446 [126]) and discontinuous transmission ( TS 26.449 [129] and TS 26.450 [130]). More detailed codec requirements for the EVS codec are defined in clause 5.2.1.4.\nEncoding of DTMF is described in Annex G.\nWhen transmitting, the MTSI client in terminal shall be capable of aligning codec mode changes to every frame border, and shall also be capable of restricting codec mode changes to be aligned to every other frame border, e.g. like UMTS_AMR_2 (TS 26.103 [16]). The MTSI client in terminal shall also be capable of restricting codec mode changes to neighbouring codec modes within the negotiated codec mode set. When receiving, the MTSI client in terminal shall allow codec mode changes at any frame border and to any codec mode within the negotiated codec mode set.\nThe codec modes and the other codec parameters (mode-change-capability, mode-change-period, mode-change-neighbor, etc), applicable for each session, are negotiated as described in clauses 6.2.2.2 and 6.2.2.3.\nWhen transmitting, the MTSI client in terminal shall be capable of aligning codec mode changes to every frame border, and shall also be capable of restricting codec mode changes to be aligned to every other frame border, e.g. like UMTS_AMR_WB‎ (TS 26.103 [16]). The MTSI client in terminal shall also be capable of restricting codec mode changes to neighbouring codec modes within the negotiated codec mode set. When receiving, the MTSI client in terminal shall allow codec mode changes at any frame border and to any codec mode within the negotiated codec mode set.\nThe codec modes and the other codec parameters (mode-change-capability, mode-change-period, mode-change-neighbor, etc), applicable for each session, are negotiated as described in clauses 6.2.2.2 and 6.2.2.3.\nWhen the EVS codec is supported, the MTSI client in terminal may support dual-mono encoding and decoding.\nWhen the EVS codec is supported, EVS AMR-WB IO may serve as an alternative implementation of the AMR-WB codec, [125]. In this case, the requirements and recommendations defined in this specification for the AMR-WB codec also apply to EVS AMR-WB IO.\nNOTE:\tThe DTX operation of EVS Primary and AMR-WB IO can be configured in sending direction with either a fixed SID update interval (from 3 to 100 frames) or an adaptive SID update interval - more details can be found in clauses 4.4.3 and 5.6.1.1 of TS 26.445 [125]. Implementers of MTSI clients are advised to take into account this SID flexibility of EVS.\nMTSI clients in terminals offering wideband speech communication shall also offer narrowband speech communications.\nWhen offering super-wideband speech, both wideband speech and narrowband speech shall also be offered. When offering fullband speech, super-wideband speech, wideband speech and narrowband speech shall also be offered.\nMTSI clients in terminals offering dual-mono, shall also offer mono.\nWhen offering both wideband speech and narrowband speech communication, payload types offering wideband shall be listed before payload types offering only narrowband speech in the ‘m=’ line of the SDP offer (RFC 4566 [8]).\nWhen offering super-wideband speech, wideband and narrowband speech communication, payload types offering super-wideband shall be listed before payload types offering lower bandwidths than super-wideband speech in the ‘m=’ line of the SDP offer (RFC 4566 [8]).\nFor an MTSI client in terminal supporting EVS the following rules apply when creating the list of payload types on the m= line:\n-\tWhen the EVS codec is offered for NB by an MTSI client in terminal supporting NB only, it shall be listed before other NB codecs.\n-\tWhen the EVS codec is offered for up to WB, it shall be listed before other WB codecs.\nWhen dual-mono is offered then this may be preferable over mono depending on the call scenario.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.2.2\tVideo",
                            "text_content": "MTSI clients in terminals offering video communication shall support:\n-\tH.264 (AVC) [24] Constrained Baseline Profile (CBP) Level 1.2;\n-\tH.265 (HEVC) [119] Main Profile, Main Tier, Level 3.1. The only exception to this requirement is for the MTSI client in constrained terminal offering video communication, in which case the MTSI client in constrained terminal should support H.265 (HEVC) Main Profile, Main Tier, Level 3.1.\nIn addition, they should support:\n-\tH.264 (AVC) [24] Constrained High Profile (CHP) Level 4.0;\n-\tH.265 (HEVC) [119] Main Profile, Main Tier, Level 4.0.\nFor backwards compatibility to previous releases, if H.264 (AVC) [24] Constrained High Profile Level 3.1 is supported, then H.264 (AVC) [24] Constrained Baseline Profile (CBP) Level 3.1 should also be offered.\nH.264 (AVC) shall be used without requirements on output timing conformance (annex C of [24]). Each sequence parameter set of H.264 (AVC) shall contain the vui_parameters syntax structure including the num_reorder_frames syntax element set equal to 0.\nH.265 (HEVC) Main Profile shall be used with general_progressive_source_flag equal to 1, general_interlaced_source_flag equal to 0, general_non_packed_constraint_flag equal to 1, general_frame_only_constraint_flag equal to 1, and sps_max_num_reorder_pics[ i ] equal to 0 for all i in the range of 0 to sps_max_sub_layers_minus1, inclusive, without requirements on output timing conformance (annex C of [119]).\nFor both H.264 (AVC) and H.265 (HEVC), the decoder needs to know the Sequence Parameter Set (SPS) and the Picture Parameter Set (PPS) to be able to decode the received video packets. A compliant H.265 (HEVC) bitstream must include a Video Parameter Set (VPS), although the VPS may be ignored by the decoder in the context of the present specification. When H.264 (AVC) or H.265 (HEVC) is used it is recommended to transmit the parameter sets within the SDP description of a stream, using the relevant MIME/SDP parameters as defined in RFC6184 [25] for H.264 (AVC) and in [120] for H.265 (HEVC), respectively. Each media source (SSRC) shall transmit the currently used parameter sets at least once in the beginning of the RTP stream before being referenced by the encoded video data to ensure that the parameter sets are available when needed by the receiver. If the video encoding is changed during an ongoing session such that the previously used parameter set(s) are no longer sufficient then the new parameter sets shall be transmitted at least once in the RTP stream prior to being referenced by the encoded video data to ensure that the parameter sets are available when needed by the receiver.  When a specific version of a parameter set is sent in the RTP stream for the first time, it should be repeated at least 3 times in separate RTP packets with a single copy per RTP packet and with an interval not exceeding 0.5 seconds to reduce the impact of packet loss. A single copy of the currently active parameter sets shall also be part of the data sent in the RTP stream as a response to FIR. Moreover, it is recommended to avoid using a sequence or picture parameter set identifier value during the same session to signal two or more parameter sets of the same type having different values, such that if a parameter set identifier for a certain type is used more than once in either SDP description or RTP stream, or both, the identifier always indicates the same set of parameter values of that type.\nThe video decoder in a multimedia MTSI client in terminal shall either start decoding immediately when it receives data, even if the stream does not start with an IDR/IRAP access unit (IDR access unit for H.264, IRAP access unit for H.265) or alternatively no later than it receives the next IDR/IRAP access unit or the next recovery point SEI message, whichever is earlier in decoding order. The decoding process for a stream not starting with an IDR/IRAP access unit shall be the same as for a valid video bit stream. However, the MTSI client in terminal shall be aware that such a stream may contain references to pictures not available in the decoded picture buffer. The display behaviour of the MTSI client in terminal is out of scope of the present document.\nAn MTSI client in terminal offering H.264 (AVC) CBP support at a level higher than Level 1.2 shall support negotiation to use a lower Level as described in [25] and [58].\nAn MTSI client in terminal offering H.264 (AVC) CHP support at a level higher than Level 3.1 shall support negotiation to use a lower Level as described in [25] and [58].\nAn MTSI client in terminal offering video support shall include in the SDP offer H.264 CBP at Level 1.2 or higher.\nAn MTSI client in terminal offering video support for H.265 (HEVC) [119] Main Profile, Main Tier, Level 3.1, should normally set it to be preferred.\nAn MTSI client in terminal offering H.265 (HEVC) shall support negotiation to use a lower Level than the one in the offer, as described in [120] and [58].\nIf a codec is supported at a certain level, then all (hierarchically) lower levels shall be supported as well.\nNOTE 1:\tAn example of a lower level than Level 1.2 is Level 1 for H.264 (AVC) Constrained Baseline Profile.\nNOTE 2:\tAll levels are minimum requirements. Higher levels may be supported and used for negotiation.\nNOTE 3:\tMTSI clients in terminals may use full-frame freeze and full-frame freeze release SEI messages of H.264 (AVC) to control the display process. For H.265 (HEVC), MTSI clients may set the value of pic_output_flag in the slice segment headers to either 0 or 1 to control the display process.\nNOTE 4:\tAn H.264 (AVC) encoder should code redundant slices only if it knows that the far-end decoder makes use of this feature (which is signalled with the redundant-pic-cap MIME/SDP parameter as specified in RFC 6184 [25]). H.264 (AVC) encoders should also pay attention to the potential implications on end-to-end delay. The redundant slice header is not supported in H.265 (HEVC).\nNOTE 5:\tIf a codec is supported at a certain level, it implies that on the receiving side, the decoder is required to support the decoding of bitstreams up to the maximum capability of this level. On the sending side, the support of a particular level does not imply that the encoder will produce a bitstream up to the maximum capability of the level. This method can be used to set up an asymmetric video stream. For H.264 (AVC), another method is to use the SDP parameters ‘level-asymmetry-allowed’ and ‘max-recv-level’ that are defined in the H.264 payload format specification, [25]. For H.265 (HEVC) it is possible to use the SDP parameter ‘max-recv-level-id’ defined in the H.265 payload format specification, [120], to indicate a higher level in the receiving direction than in the sending direction. See also clause 6.2.3.2, Annex A.4.5 for SDP examples with asymmetric video using H.264 (AVC) and Annex A.4.8 for SDP examples with asymmetric video using both H.264 (AVC) and H.265 (HEVC). Other methods for asymmetric video transmission are also possible.\nNOTE 6:\tIf video is used in a session, an MTSI client in terminal should offer at least one video stream with a picture aspect ratio in the range from 0.7 to 1.4. For all offered video streams, the width and height of the picture should be integer multiples of 16 pixels. For example, 224x176, 272x224, and 320x240 are image sizes that satisfy these conditions.\nNOTE 7:\tFor H.264 (AVC) and H.265 (HEVC), respectively, multiple sequence and picture parameter sets can be defined, as long as they have unique parameter set identifiers, but only one sequence and picture parameter set can be active between two consecutive IDRs and IRAPs, respectively.\nNOTE 8:\tFor H.264 (AVC), Constrained High Profile (CHP) Level 3.1 is not required to be supported as it is less bit rate efficient than H.265 (HEVC) Main Profile, Main Tier, Level 3.1.  However, it is recommended for interoperability.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.2.3\tReal-time text",
                            "text_content": "MTSI clients in terminals offering real time text conversation shall support:\n-\tITU-T Recommendation T.140 [26] and [27].\nT.140 specifies coding and presentation features of real-time text usage. Text characters are coded according to the UTF-8 transform of ISO 10646-1 (Unicode).\nA minimal subset of the Unicode character set, corresponding to the Latin-1 part shall be supported, while the languages in the regions where the MTSI client in terminal is intended to be used should be supported.\nPresentation control functions from ISO 6429 are allowed in the T.140 media stream. A mechanism for extending control functions is included in ITU-T Recommendation T.140 [26] and [27]. Any received non-implemented control code must not influence presentation.\nA MTSI client in terminal shall store the conversation in a presentation buffer during a call for possible scrolling, saving, display re-arranging, erasure, etc. At least 800 characters shall be kept in the presentation buffer during a call.\nNote that erasure (backspace) of characters is included in the T.140 editing control functions. It shall be possible to erase all characters in the presentation buffer. The display of the characters in the buffer shall also be impacted by the erasure.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "5.2.4\tStill Images",
                            "text_content": "MTSI clients supporting still images shall support HEVC encoded encoded images conforming to the HEVC bitstream requirements of 5.2.2.\nStill images encoded using the HEVC shall have general_progressive_source_flag equal to 1, general_interlaced_source_flag equal to 0, general_non_packed_constraint_flag equal to 1, general_frame_only_constraint_flag equal to 1.\nFor HEVC encoded images/image sequence, the display properties are carried as SEI and VUI within the bitstream, and the RTP timestamps determine the presentation time of the images.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "6\tMedia configuration",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "6.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "MTSI uses SIP, SDP and SDPCapNeg for media negotiation and configuration. General SIP signalling and session setup for IMS are defined in TS 24.229 [7], whereas this clause specifies SDP and SDPCapNeg usage and media handling specifically for MTSI, including offer/answer considerations in the capability negotiation. The MTSI client in the terminal may use the OMA-DM solution specified in Clause 15 for enhancing SDP negotiation and resource reservation process.\nThe support for ECN [83] in E-UTRAN is specified in [85]. The support for ECN in UTRA/HSPA is specified in [89].  The support of ECN in NR is specified in [164]. MTSI may use Explicit Congestion Notification (ECN) to perform rate adaptation for speech and video. When the MTSI client in terminal supports, and the session allows, adapting the media encoding at multiple bit rates and the radio access bearer technology is known to the MTSI client to be E-UTRAN or UTRA/HSPA, the MTSI client may negotiate the use of ECN [83] to perform ECN triggered media bit-rate adaptation. An MTSI MGW supporting ECN supports ECN in the same way as the MTSI client in terminal as described in clauses 12.3.3 and 12.7.3.\nThe support of ECN is optional for both MTSI client in terminal and MTSI MGW.\nIt is assumed that the network properly handles ECN-marked packets as described in [84] end-to-end between the MTSI clients in terminals.\nAn MTSI MGW can be used for inter-working with:\n-\ta client that does not use ECN;\n-\ta client that supports ECN in different way than what is specified for MTSI clients;\n-\ta CS network;\n-\ta network which does not handle ECN-marked packets properly.\nIn such cases, the ECN protocol, as specified for MTSI clients, is terminated in the MTSI MGW.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "6.2\tSession setup procedures",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "6.2.1\tGeneral",
                            "text_content": "The session setup for RTP transported media shall determine for each media: IP address(es), RTP profile, UDP port number(s); codec(s); RTP Payload Type number(s), RTP Payload Format(s). The session setup may also determine: ECN usage and any additional session parameters.\nThe session setup for UDP transported media without RTP shall determine: IP address(es), UDP port number(s) and additional session parameters.\nThe session setup for data channel (SCTP over DTLS over UDP transported) media shall determine for each media: IP address(es), UDP port number(s), SCTP port number(s), DTLS server/client role(s), DTLS ID(s), DTLS certificate fingerprint(s), and ICE-related information for data channel media as described in clause 6.2.10. The session setup may also determine use of ICE Lite for data channel media and may determine additional session parameters.\nThe session setup for RTP and data channel transported media shall, when the port number is not set to zero, determine the maximum bandwidth that is allowed in the session, see also clause 6.2.5. The maximum bandwidth for the receiving direction is specified with the \"b=AS\" bandwidth modifier. Additional requirements and/or recommendations on the bandwidth negotiation are found in clause 6.2.2.1 for speech, in clause 6.2.3.2 for video, and in clause 6.2.10 for data channel.\nAn MTSI client shall offer at least one RTP profile for each RTP media stream. Multiple RTP profiles may be offered using SDPCapNeg as described in Clause 6.2.1a. For voice and real-time text, the first SDP offer shall include at least the AVP profile. For video, the first SDP offer for a media type shall include at least the AVPF profile. Subsequent SDP offers may include only other RTP profiles if it is known from a preceding offer that this RTP profile is supported by the answerer. The MTSI client shall be capable of receiving an SDP offer containing both AVP and AVPF offers in order to support interworking.\nThe configuration of ECN for media transported with RTP is described in clause 6.2.2 for speech and in clause 6.2.3.2 for video. The negotiation of ECN at session setup is described in [84]. The adaptation response to congestion events is described in clause 10.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.1a\tRTP profile negotiation",
                            "text_content": "MTSI clients should support SDPCapNeg to be able to negotiate RTP profiles for all media types where AVPF is supported. MTSI clients supporting SDPCapNeg shall support the complete SDPCapNeg framework.\nSDPCapNeg is described in [69]. This clause only describes the SDPCapNeg attributes that are directly applicable for the RTP profile negotiation, i.e. the tcap, pcfg and acfg attributes. TS 24.229 [7] may outline further requirements needed for supporting SDPCapNeg in SDP messages.\nNOTE:\tThis clause describes only how to use the SDPCapNeg framework for RTP profile negotiation using the tcap, pcfg and acfg attributes. Implementers may therefore (incorrectly) assume that it is sufficient to implement only those specific parts of the framework that are needed for RTP profile negotiation. Doing so would however not be future proof since future versions may use other parts of the framework and there are currently no mechanisms for declaring that only a subset of the framework is supported. Hence, MTSI clients are required to support the complete framework.\nFor voice and real-time text, SDPCapNeg shall be used when offering AVPF the first time for a new media type in the session since the support for AVPF in the answering client is not known at this stage. For video, an MTSI client shall either offer AVPF and AVP together using SDPCapNeg, or the MTSI client shall offer only AVPF without using SDPCapNeg. If an MTSI client has offered only AVPF for video, and then receives as response either an SDP answer where the video media component has been rejected, or an SIP 488 or 606 failure response with an SDP body indicating that only AVP is supported for video media, the MTSI client should send a new SDP offer with AVP as transport for video. Subsequent SDP offers, in a re-INVITE or UPDATE, may offer AVPF without SDPCapNeg if it is known from an earlier re-INVITE or UPDATE that the answering client supports this RTP profile. If the offer includes only AVP then SDPCapNeg does not need to be used, which can occur for: text; speech if RTCP is not used; and in re-INVITEs or UPDATEs where the RTP profile has already been negotiated for the session in a preceding INVITE or UPDATE.\nWhen offering AVP and AVPF using SDPCapNeg, the MTSI client shall offer AVP on the media (m=) line and shall offer AVPF using SDPCapNeg mechanisms. The SDPCapNeg mechanisms are used as follows:\n-\tThe support for AVPF is indicated in an attribute (a=) line using the transport capability attribute ‘tcap’. AVPF shall be preferred over AVP.\n-\tAt least one configuration using AVPF shall be listed using the attribute for potential configurations ‘pcfg’.\nAn invited MTSI client should accept using AVPF whenever supported. If AVPF is to be used in the session then the MTSI client:\n-\tShall select one configuration out of the potential configurations defined in the SDP offer for using AVPF.\n-\tIndicate in the media (m=) line of the SDP answer that the profile to use is AVPF.\n-\tIndicate the selected configuration for using AVPF in the attribute for actual configurations ‘acfg’.\nIf AVP is to be used then the MTSI shall not indicate any SDPCapNeg attributes for using AVPF in the SDP answer.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.2\tSpeech",
                            "text_content": "For AMR or AMR-WB encoded media, the session setup shall determine the applicable bandwidth(s) as defined in clause 6.2.5, what RTP profile to use; if all codec modes can be used or if the operation needs to be restricted to a subset; if the bandwidth-efficient payload format can be used or if the octet-aligned payload format must be used; if codec mode changes shall be restricted to be aligned to only every other frame border or if codec mode changes can occur at any frame border; if codec mode changes must be restricted to only neighbouring modes within the negotiated codec mode set or if codec mode changes can be performed to any mode within the codec mode set; the number of speech frames that should be encapsulated in each RTP packet and the maximum number of speech frames that may be encapsulated in each RTP packet. For EVS encoded media, the session setup shall determine the RTP profile to use in the session.\nIf the session setup negotiation concludes that multiple configuration variants are possible in the session then the default operation should be used as far as the agreed parameters allow, see clause 7.5.2.1. It should be noted that the default configurations are slightly different for different access types.\nAn MTSI client offering a speech media session for narrow-band speech and/or wide-band speech should generate an SDP offer according to the examples in Annexes A.1 to A.3. An MTSI client offering EVS should generate an SDP offer according to the examples in Annex A.14.\nAn MTSI client in terminal supporting EVS should support the RTCP-APP signalling for speech adaptation defined clause 10.2.1, and shall support the RTCP-APP signalling when the MTSI client in terminal supports adaptation for call cases where the RTP-based CMR cannot be used.\nNOTE 1:\tExamples of call cases where the RTP-based CMR cannot be used are: when the RTP-based CMR is disabled; or for uni-directional media (sendonly or recvonly).\nSome of the request messages are generic for all speech codecs while other request messages are codec-specific. Request messages that can be used in a session are negotiated in SDP, see clause 10.2.3.\nAn MTSI client shall at least offer AVP for speech media streams. An MTSI client should also offer AVPF for speech media streams. An MTSI client shall offer AVPF for speech media streams when offering to use RTCP-APP signalling. RTP profile negotiation shall be done as described in clause 6.2.1a. When AVPF is offered then the RTCP bandwidth shall be greater than zero.\nIf an MTSI client in terminal offers to use ECN for speech in RTP streams then the MTSI client in terminal shall offer ECN Capable Transport as defined below. If an MTSI client in terminal accepts an offer for ECN for speech then the MTSI client in terminal shall declare ECN Capable Transport in the SDP answer as defined below. The SDP negotiation of ECN Capable Transport is described in [84].\nECN shall not be used when the codec negotiation concludes that only fixed-rate operation is used.\nAn MTSI client may support multiple codecs where ECN-triggered adaptation is supported only for some of the codecs. An SDP offer for ECN may therefore include multiple codecs where ECN-triggered adaptation is supported only for some of the codecs. An MTSI client receiving an SDP offer including multiple codecs and an offer for ECN should first select which codec to accept and then accept or reject the offer for ECN depending on whether ECN-triggered adaptation is supported for that codec or not. An MTSI client receiving an SDP answer accepting ECN for a codec where ECN-triggered adaptation is not supported should re-negotiate the session to disable ECN.\nNOTE 2:\tECN-triggered adaptation is currently undefined for EVS. This does not prevent ECN-triggered adaptation from being negotiated and used for AMR or AMR-WB.\nThe use of ECN for a speech stream in RTP is negotiated with the ‘ecn-capable-rtp’ SDP attribute, [84]. ECN is enabled when both clients agree to use ECN as configured below. An MTSI client in terminal using ECN shall therefore also include the following parameters and parameter values for the ECN attribute:\n-\t‘leap’, to indicate that the leap-of-faith initiation method shall be used;\n-\t ‘ect=0’, to indicate that ECT(0) shall be set for every packet.\nAn MTSI client offering ECN for speech may indicate support of the RTCP AVPF ECN feedback messages [84] using \"rtcp-fb\" attributes with the \"nack\" feedback parameter and the \"ecn\" feedback parameter value. An MTSI client offering ECN for speech may indicate support for RTCP XR ECN summary reports [84] using the \"rtcp-xr\" SDP attribute [88] and the \"ecn-sum\" parameter.\nAn MTSI client receiving an offer for ECN for speech without an indication of support of RTCP AVPF ECN feedback messages [84] within an \"rtcp-fb\" attribute should accept the offer if it supports ECN.\nAn MTSI client receiving an offer for ECN for speech with an indication of support of the RTCP AVPF ECN feedback message [84] should also accept the offer and may indicate support of the RTCP AVPF ECN feedback messages [84] in the answer.\nAn MTSI client accepting ECN for speech in an answer may indicate support for RTCP XR ECN summary reports in the answer using the \"rtcp-xr\" SDP attribute [88] and the \"ecn-sum\" parameter.\nThe use of ECN is disabled when a client sends an SDP without the ‘ecn-capable-rtp’ SDP attribute.\nAn MTSI client may initiate a session re-negotiation to disable ECN to resolve ECN-related error cases. An ECN-related error case may, for example, be detecting non-ECT in the received packets when ECT(0) was expected or detecting a very high packet loss rate when ECN is used.\nSDP examples for offering and accepting ECT are shown in Annex A.12.\nSession setup for sessions including speech and DTMF events is described in Annex G.\nWhen speech is offered, an MTSI client in terminal sending a first SDP offer in the initial offer-answer negotiation shall include at least one RTP payload type for AMR-NB according to RFC4867 [28] and the MTSI client in terminal shall support and offer a configuration, where the MTSI client in terminal includes the parameter settings as defined in Table 6.1. When EVS-NB is also offered, the MTSI client in terminal shall support and offer a configuration, where the MTSI client in terminal includes the parameter settings for EVS (both EVS Primary and AMR-WB IO modes) as defined in Table 6.2a.\nIf wideband speech is also offered, then the SDP offer shall also include at least one RTP payload type for AMR-WB according to RFC4867 [28] and the MTSI client in terminal shall support and offer a configuration, where the MTSI client in terminal includes the parameter settings as defined in Table 6.1. When EVS-WB is also offered, the MTSI client in terminal shall support and offer a configuration, where the MTSI client in terminal includes the parameter settings for EVS (both Primary and AMR-WB IO modes) as defined in Table 6.2a. AMR-WB and EVS (including the EVS AMR-WB IO mode) are thus offered using different RTP payload types.\nIf super-wideband speech is also offered, the SDP offer shall include at least one RTP payload type for EVS and the MTSI client in terminal shall support a configuration where the MTSI client in terminal includes the parameter settings as defined in Table 6.2a.\nIf fullband speech is also offered, the SDP offer shall include at least one RTP payload type for EVS and the MTSI client in terminal shall support a configuration where the MTSI client in terminal includes the parameter settings as defined in Table 6.2a.\nWhen EVS is offered, the RTP payload type for EVS shall also use parameters for EVS AMR-WB IO mode as defined in Table 6.2a, except for the ‘ecn-capable-rtp’ and ‘leap ect’ parameters. AMR-WB and EVS (including the EVS AMR-WB IO mode) are thus offered using different RTP payload types.\nNOTE 1:\tRFC4867 can also be used for EVS AMR-WB IO when EVS is supported. This may happen after SRVCC when the EVS payload format is used between the ATGW and the MTSI client in terminal while RFC4867 is used between the CS-MGW and the ATGW.\nNOTE 2:\tECN-triggered adaptation is currently undefined for EVS. This does not prevent ECN-triggered adaptation from being negotiated and used for AMR or AMR-WB.\nNOTE 3:\tWhen EVS is offered, the audio bandwidths may be different for different directions for the EVS Primary mode, even for ‘sendrecv’ media.\nClause 5.2.1.6 describes the preference order for how different configurations should be ordered in the list of payload type numbers that is given on the m= line.\nTable 6.1: SDP parameters for AMR-NB or AMR-WB, when the MTSI client in terminal offers the bandwidth-efficient payload format\n\nTable 6.2: SDP parameters for AMR-NB or AMR-WB, when the MTSI client in terminal offers the octet-aligned payload format\n\nTable 6.2a: SDP parameters for EVS (both Primary and AMR-WB IO modes, when the MTSI client in terminal offers EVS\n\nWhen the channels parameter is omitted then this means that one channel is being offered.\nThe mode-set parameter is omitted, allowing maximum freedom for the visited network.\nThe mode-change-capability parameter is included and set to 2 for AMR-NB and AMR-WB, to support potential interworking with 2G radio access (GERAN). For EVS AMR-WB IO it is not required to include the mode-change-capability parameter.\nAn example of an SDP offer for AMR-NB is shown in Table A.1.1. An example of an SDP offer for both AMR-NB and AMR-WB is shown in Table A.1.2. An example of SDP offer for AMR-NB, AMR-WB, and EVS is shown in Table A.14.1.\nAn SDP example for offering and accepting a dual-mono session for EVS is shown in Annex A.14.1 and A.14.3.\nAn MTSI client in terminal may divide the offer-answer negotiation into several phases and offer different configurations in different SDP offers. If this is done then the first SDP offer in the initial offer-answer negotiation shall include the most preferable configurations. For AMR-NB, this means that the first SDP offer in the initial offer-answer negotiation shall include at least one RTP payload type for AMR-NB with the parameters as defined in Table 6.1. If wideband speech is offered then the first SDP offer in the initial offer-answer negotiation shall include also at least one RTP payload type for AMR-WB with the parameters as defined in Table 6.1. This also means that offers for octet-aligned payload format do not need to be included in the first SDP offer. If super-wideband or fullband speech is offered, the first SDP offer in the initial offer-answer negotiation shall include at least one RTP payload type for EVS with the parameters as defined in [125]. One example of dividing the offer-answer negotiation into two phases, and the corresponding SDP offers, is shown in clause A.1.1.2.2.\nNOTE 4:\tDividing the offer-answer negotiation into several phases may lead to never offering the less preferred configurations, if the other end-point accepts to use at least one of the configurations offered in the initial SDP offer.\nIf the speech media is re-negotiated during the session then the knowledge from earlier offer-answer negotiations should be used in order to shorten the session re-negotiation time. I.e., failed offer-answer transactions shall not be repeated.\nAn MTSI client in terminal must understand all the payload format options that are defined in RFC 4867 [28], and in [125]. It does not have to support operating according to all these options but must be capable to properly accepting or rejecting all options.\nThe SDP answer depends on many factors, for example:\n-\twhat is included in the SDP offer and in what preference order that is defined. The SDP offer will probably be different if it is generated by another MTSI client in terminal, by an MTSI MGW, a TISPAN client or some other VoIP client that does not follow this specification;\n-\tif terminal and/or network resources are available; and:\n-\tif there are other configurations, for example defined with OMA-DM, that mandate, recommend or prevent some configurations.\nTable 6.3 describes requirements and recommendations for handling of the AMR payload format parameters and for how to generate the SDP answer.\nNOTE 1:\tAn MTSI client in terminal may support more features than what is required by this specification, e.g. crc, robust sorting and interleaving. Table 6.3 describes the handling of the AMR payload format parameters when the MTSI client implementation supports only those features that are required by this specification. Tables 6.3a-6.3c describe the handling of the EVS payload format parameters.\nTable 6.3: Handling of the AMR-NB and AMR-WB SDP parameters in the received SDP offer and in the SDP answer\n\nIf an SDP offer is received from another MTSI client in terminal using the AMR-NB or AMR-WB codec, then the SDP offer will include configurations as described in Table 6.1 and Table 6.2. If the MTSI client in terminal chooses to accept the offer for using the AMR-NB or AMR-WB codec, as configured in Table 6.1 or Table 6.2 then the MTSI client in terminal shall support a configuration where the MTSI client in terminal creates an SDP answer containing an RTP payload type for the AMR-NB and AMR-WB codec as shown in Table 6.4.\nTable 6.3a: Handling of SDP parameters common to EVS Primary and EVS AMR-WB IO in the received SDP offer and in the SDP answer\n\nTable 6.3b: Handling of the EVS Primary SDP parameters in the received SDP offer and in the SDP answer\n\nTable 6.3c: SDP parameters for the EVS AMR-WB IO parameters in the received SDP offer and in the SDP answer\n\nNOTE 2:\tECN-triggered adaptation is currently undefined for EVS. This does not prevent ECN-triggered adaptation from being negotiated and used for AMR or AMR-WB.\nTable 6.4: SDP parameters for AMR-NB or AMR-WB for SDP answer when the SDP offer is received from another MTSI client in terminal\n\nIf an SDP offer is received from a MTSI MGW inter-working with CS GERAN/UTRAN, and when the MTSI MGW supports ECN (see also clause 12.3.3), then it is likely to be configured as shown in Table 6.5 if the MTSI MGW does not support redundancy.\nTable 6.5: Expected configuration of SDP parameters for AMR-NB or AMR-WB in an SDP offer from an MTSI MGW inter-working with CS GERAN/UTRAN\n\nIf the MTSI client in terminal accepts the offer included in Table 6.5 then the MTSI client in terminal shall support a configuration where the MTSI client in terminal creates an SDP answer containing an RTP payload type for the AMR-NB and AMR-WB codecs as shown in Table 6.6.\nTable 6.6: SDP parameters for AMR-NB or AMR-WB for SDP answer when the SDP offer is received from another MTSI MGW\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.1: SDP parameters for AMR-NB or AMR-WB, when the MTSI client in terminal offers the bandwidth-efficient payload format",
                                    "table number": 5,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.2: SDP parameters for AMR-NB or AMR-WB, when the MTSI client in terminal offers the octet-aligned payload format",
                                    "table number": 6,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.2a: SDP parameters for EVS (both Primary and AMR-WB IO modes, when the MTSI client in terminal offers EVS",
                                    "table number": 7,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.3: Handling of the AMR-NB and AMR-WB SDP parameters in the received SDP offer and in the SDP answer",
                                    "table number": 8,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.3a: Handling of SDP parameters common to EVS Primary and EVS AMR-WB IO in the received SDP offer and in the SDP answer",
                                    "table number": 9,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.3b: Handling of the EVS Primary SDP parameters in the received SDP offer and in the SDP answer",
                                    "table number": 10,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.3c: SDP parameters for the EVS AMR-WB IO parameters in the received SDP offer and in the SDP answer",
                                    "table number": 11,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.4: SDP parameters for AMR-NB or AMR-WB for SDP answer when the SDP offer is received from another MTSI client in terminal",
                                    "table number": 12,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.5: Expected configuration of SDP parameters for AMR-NB or AMR-WB in an SDP offer from an MTSI MGW inter-working with CS GERAN/UTRAN",
                                    "table number": 13,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.6: SDP parameters for AMR-NB or AMR-WB for SDP answer when the SDP offer is received from another MTSI MGW",
                                    "table number": 14,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.2.3\tVideo",
                            "text_content": "The common session setup procedures for video are described in clause 6.2.3.2.  Session setup procedures for Coordination of Video Orientation (CVO) and Video Region of Interest (ROI) are described in clauses 6.2.3.3 and 6.2.3.4, respectively. Session setup procedures for RTP Retransmission and Forward Error Correction (FEC) are described in clauses 6.2.3.5 and 6.2.3.6, respectively.\nIf video is used in a session, the session setup shall determine the applicable bandwidth(s) as defined in clause 6.2.5, RTP profile, video codec, profile and level. The \"imageattr\" attribute as specified in IETF RFC 6236 [76] should be supported. The \"framesize\" attribute as specified in [60] shall not be used in the session setup.\nAn MTSI client shall offer AVPF for all media streams containing video. RTP profile negotiation shall be done as described in clause 6.2.1a.\nAn MTSI client is required to support the AVPF feedback messages trr-int, NACK and PLI [40] and the CCM feedback messages FIR, TMMBR and TMMBN [43], see Clauses 7.3.3 and 10.3. These feedback messages can only be used together with AVPF and shall be negotiated in SDP offer/answer before they can be used in the session [40]. An MTSI client sending an SDP offer for AVPF shall also include these AVPF and CCM feedback messages in the offer. An MTSI client accepting an SDP offer for AVPF for video shall also accept these AVPF and CCM feedback messages if they are offered.\nIf an MTSI client offers to use ECN for video in RTP streams then the MTSI client shall offer ECN Capable Transport as defined below. If an MTSI client accepts an offer for ECN for video then the MTSI client shall declare ECN Capable Transport in the SDP answer as defined below. The SDP negotiation of ECN Capable Transport is described in [84].\nThe use of ECN for a video stream in RTP is negotiated with the \"ecn-capable-rtp\" SDP attribute, [84]. ECN is enabled when both clients agree to use ECN as configured below. An MTSI client using ECN shall therefore also include the following parameters and parameter values for the ECN attribute:\n-\t‘leap’, to indicate that the leap-of-faith initiation method shall be used;\n-\t‘ect=0’, to indicate that ECT(0) shall be set for every packet.\nAn MTSI client offering ECN for video shall indicate support of TMMBR [43] by including the \"ccm tmmbr\" value within an \"rtcp-fb\" SDP attribute [40]. An MTSI client offering ECN for video may indicate support for RTCP AVPF ECN feedback messages [84] using the \"rtcp-fb\" SDP attribute with the \"nack\" feedback parameter and the \"ecn\" feedback parameter value. An MTSI client offering ECN for video may indicate support for RTCP XR ECN summary reports [84] using the \"rtcp-xr\" SDP attribute and the \"ecn-sum\" parameter.\nAn MTSI client receiving an offer for ECN for video with an indication of support of TMMBR [43] within an \"rtcp-fb\" attribute should accept the offer if it supports ECN. It shall then indicate support for TMMBR using an \"rtcp-fb\" attribute in the SDP answer.\nAn MTSI client receiving an offer for ECN for video with an indication of support of RTCP AVPF ECN feedback message but without support for TMMBR should accept the offer if it supports ECN and also the RTCP AVPF ECN feedback message. It shall then indicate support of the RTCP AVPF ECN feedback message using the \"rtcp-fb\" attribute in the SDP answer.\nAn MTSI client receiving an offer for ECN for video with an indication of support of RTCP XR ECN summary reports [84] without support for TMMBR should accept the offer if it supports ECN and also the RTCP XR ECN summary reports. It shall then indicate support of RTCP XR ECN summary reports in the SDP answer.\nThe use of ECN is disabled when a client sends an SDP without the \"ecn-capable-rtp\" SDP attribute.\nAn MTSI client may initiate a session re-negotiation to disable ECN to resolve ECN-related error cases. An ECN-related error case may be, for example, detecting non-ECT in the received packets when ECT(0) was expected or detecting a very high packet loss rate when ECN is used.\nExamples of SDP offers and answers for video can be found in clause A.4. SDP examples for offering and accepting ECT are shown in Annex A.12.2.\nNOTE:\tFor H.264 / MPEG-4 (Part 10) AVC, the optional max-rcmd-nalu-size receiver-capability parameter of RFC 6184 [25] should be set to the smaller of the MTU size (if known) minus header size or 1 400 bytes (otherwise).\nThe \"framerate\" attribute as specified in [8] indicates the maximum frame rate the offerer wishes to receive. If the \"framerate\" attribute is present in the SDP offer, its value may be modified in the SDP answer when the answerer wishes to receive video with a different maximum frame rate than what was indicated in the offer.\nAn MTSI client in terminal setting up asymmetric video streams with H.264 (AVC) should use both the ‘level-asymmetry-allowed’ parameter and the ‘max-recv-level’ parameter that are defined in the H.264 payload format, [25]. When the ‘max-recv-level’ parameter is used then the level offered for the receiving direction using the ‘max-recv-level’ parameter must be higher than the default level that is offered with the ‘profile-level-id’ parameter.\nAn SDP offer-answer example showing the usage of the ‘level-asymmetry-allowed’ and ‘max-recv-level’ parameters is included in Annex A.4.5.\nAn MTSI client in terminal setting up asymmetric video streams with H.265 (HEVC) should use the ‘max-recv-level-id’ parameter that is defined in the H.265 payload format, [120]. The level offered for the receiving direction using the ‘max-recv-level-id’ parameter must be higher than the default level that is offered with the ‘level-id’ parameter.\nAn SDP offer-answer example showing the usage of the ‘max-recv-level-id’ parameter is included in Annex A.4.8.\nThe resolutions in the \"imageattr\" attribute correspond to the image size information in the encoded video bitstream such that the x-component corresponds to the image width, and the y-component corresponds to the height component. When the bit-rate is being adapted, values of image width or image height smaller than the x- or y-component(s) in the negotiated \"imageattr\" attribute may be temporarily used.\nMTSI clients should indicate all their preferred resolutions in the SDP offer and answer exchanges using the \"imageattr\" attribute. MTSI clients should not renegotiate SDP in case of no agreement on resolution, i.e., no new SDP offer-answer exchanges are expected in case of a mismatch of resolutions as indicated by the \"imageattr\" attribute. This is an MTSI-specific relaxation of the requirement in IETF RFC 6236 [76], according to which SDP renegotiation is expected in case of no agreed resolution. Related SDP offer-answer examples based on this expected behavior for MTSI clients can be found in Annex A.4.4a.\nAn MTSI client should support Coordination of Video Orientation (CVO) as specified in clause 7.4.5.\nAn MTSI client supporting CVO shall offer Coordination of Video Orientation (CVO) in SDP for all media streams containing video. CVO is offered by including the a=extmap attribute [95] indicating the CVO URN under the relevant media line scope. The CVO URN is: urn:3gpp:video-orientation. Here is an example usage of this URN to signal CVO relative to a media line:\na=extmap:7 urn:3gpp:video-orientation\n\nThe number 7 in the example may be replaced with any number in the range 1-14. The above SDP line indicates 2 bits of granularity for rotation and shall be present when offering CVO.\nHigher granularity CVO supports up to 6 bits of precision and may additionally be offered for the rotation value by also including the following line of SDP in the offer:\na=extmap:5 urn:3gpp:video-orientation:6\n\nFor terminals with asymmetric capability (e.g. the ability to process video orientation information but not detect orientation), the sendonly and recvonly attributes [95] may be used. Terminals should express their capability in each direction sufficiently clearly such that signals are only sent in each direction to the extent that they both express useful information and can be processed by the recipient; for example, 6-bit signals would not be sent when the sending terminal can only detect orientation to a precision of 2 bits, and terminals incapable of detecting orientation would not send the header.\nAn MTSI client supporting CVO shall respond to receive CVO when CVO is offered to be sent in SDP, by including exactly one of the offered extmap attributes. An MTSI client supporting CVO shall respond to send CVO when CVO is offered to be received in SDP, by including exactly one of the offered extmap attributes. An MTSI client shall not answer with CVO in a direction when not offered CVO in that direction in SDP.\nAn MTSI client should support Video Region-of-Interest (ROI) signaling as specified in clause 7.3.7.\nAn MTSI client supporting ROI shall support at least one of the following modes to request a desired region of interest (signalled from an MTSI receiver to an MTSI sender):\n-\tFar End Camera Control’ (FECC), as specified in [135]-[139] and clause 7.3.7\n-\t‘Arbitrary ROI’, as specified in clause 7.3.7\n-\t‘Pre-defined ROI’, as specified in clause 7.3.7\nAn MTSI client supporting FECC using H.224 shall offer FECC in SDP for all media streams containing video, where FECC capabilities are desired. FECC shall be offered via the syntax and semantics defined in IETF RFC 4573 [139]. The MIME type ‘application/h224’ corresponding to the RTP payload format for H.224 shall be used as in [139], which also defines the SDP parameters needed to indicate support for FECC using H.224.\nAn MTSI client supporting ‘Arbitrary ROI’ mode shall offer ‘Arbitary ROI’ in SDP for all media streams containing video, where ‘Arbitrary ROI’ capabilities are desired. ‘Arbitrary ROI’ shall be offered by including the a=rtcp-fb attribute [40] with the ‘Arbitrary ROI’ type under the relevant media line scope. The ‘Arbitrary ROI’ type in conjunction with the RTCP feedback method shall be expressed with the following parameter: 3gpp-roi-arbitrary. A wildcard payload type (\"*\") may be used to indicate that the RTCP feedback attribute for ‘Arbitrary ROI’ signaling applies to all payload types. If several types of ROI signaling are supported and/or the same ‘Arbitary ROI’ shall be specified for a subset of the payload types, several \"a=rtcp-fb\" lines can be used. Here is an example usage of this attribute to signal ‘Arbitrary ROI’ relative to a media line based on the RTCP feedback method:\na=rtcp-fb:* 3gpp-roi-arbitrary\n\nAn MTSI client supporting ‘Pre-defined ROI’ mode shall offer ‘Pre-defined ROI’ in SDP for all media streams containing video, where ‘Pre-defined ROI’ capabilities are desired. ‘Pre-defined ROI’ shall be offered by including the a=rtcp-fb attribute [40] with the ‘Pre-defined ROI’ type under the relevant media line scope. The ‘Pre-defined ROI’ type in conjunction with the RTCP feedback method shall be expressed with the following parameter: 3gpp-roi-predefined. A wildcard payload type (\"*\") may be used to indicate that the RTCP feedback attribute for ‘Pre-defined ROI’ signaling applies to all payload types. If several types of ROI signaling are supported and/or the same ‘Pre-defined ROI’ shall be specified for a subset of the payload types, several \"a=rtcp-fb\" lines can be used. Here is an example usage of this attribute to signal ‘Pre-defined ROI’ relative to a media line based on the RTCP feedback method:\na=rtcp-fb:* 3gpp-roi-predefined\n\nThe IANA registration information on the new RTCP feedback types for ‘Arbitrary ROI’ and ‘Pre-defined ROI’ are provided in Annex R.1.\nThe ABNF for rtcp-fb-val corresponding to the feedback types \"3gpp-roi-arbitrary\"and \"3gpp-roi-predefined\" is given as follows:\nrtcp-fb-val =/ \"3gpp-roi-arbitrary\"\nrtcp-fb-val =/ \"3gpp-roi-predefined\"\nAn MTSI sender supporting the ‘Pre-defined ROI’ feature shall offer detailed pre-defined ROI information in the initial offer-answer negotiation by carrying it in SDP. Pre-defined ROIs shall be offered by including the \"a=predefined_ROI\" attribute under the relevant media line. The following parameters shall be provided in the attribute for each pre-defined ROI:\n-\tROI_ID – identifies the pre-defined ROI\n-\tPosition_X - specifies the x-coordinate for the upper left corner of the ROI area covered in the original content (i.e., uncompressed captured content) in units of pixels\n-\tPosition_Y - specifies the y-coordinate for the upper left corner of the ROI area covered in the original content in units of pixels\n-\tSize_X - specifies the horizontal size of the ROI area covered in the original content in units of pixels\n-\tSize_Y - specifies the vertical size of the ROI area covered in the original content in units of pixels\n-\tName- specifies the name of the pre-defined ROI.\nThe syntax for the \"a=predefined_ROI\" attribute shall conform to the following ABNF:\npredefined_ROI = \"predefined_ROI:\" PT 1*WSP attr-list\nPT = 1*DIGIT / \"*\"\nattr-list = ( set *(1*WSP set) ) / \"*\"\n;  WSP and DIGIT defined in [RFC5234]\nset= \"[\" \"ROI_ID=\" idvalue \",\" \"Position_X=\" posvalue \",\" \"Position_Y=\" posvalue \",\" \"Size_X=\" sizevalue \",\" \"Size_Y=\" sizevalue \",\" \"Name=\" namevalue \"]\"\nidvalue= onetonine*2DIGIT\n; Digit between 1 and 9 that is\n; followed by 0 to 2 other digits\nposvalue = sizevalue / \"0\"\n; position may be \"0\"\nsizevalue = onetonine *5DIGIT\n; Digit between 1 and 9 that is\n; followed by 0 to 5 other digits\nonetonine = \"1\" / \"2\" / \"3\" / \"4\" / \"5\" / \"6\" / \"7\" / \"8\" / \"9\"\n; Digit between 1 and 9\nnamevalue = byte-string\n; byte-string defined in RFC 4566\nThe SDP offer with a=predefined_ROI parameter shall contain the full-size view of the video indicated via ROI_ID=0.\nHere is an example use of the \"a=predefined_ROI\" attribute relative to a media line:\na=predefined_ROI:99\n[ROI_ID=0,Position_X=1,Position_Y=1,Size_X=1080,Size_Y=720,Name=fullview] [ROI_ID=1,Position_X=1,Position_Y=1,Size_X=540,Size_Y=360,Name=museum] [ROI_ID=2,Position_X=541,Position_Y=1,Size_X=540,Size_Y=360,Name=cinema] [ROI_ID=3,Position_X=1,Position_Y=361,Size_X=540,Size_Y=360,Name=park] [ROI_ID=4,Position_X=541,Position_Y=361,Size_X=540,Size_Y=360,Name= zoo]\nThe IANA registration information for the \"a=predefined_ROI\" SDP attribute is provided in Annex M.5.\nIn response to the SDP offer with the set of offered pre-defined ROIs provided using the \"a=predefined_ROI\" line(s), an MTSI client accepting ‘Pre-defined ROI’ shall provide an SDP answer using the \"a=predefined_ROI\" line(s) containing the accepted set of pre-defined ROIs. Such an SDP answer shall also contain the \"a=rtcp-fb:* 3gpp-roi-predefined\" line. The accepted set of pre-defined ROIs shall be a subset of the offered set of pre-defined ROIs. If the SDP answer contains the a=rtcp-fb:* 3gpp-roi-predefined\" line, but does not contain a \"a=predefined_ROI\" line, this indicates that the MTSI client supports the ‘Pre-defined ROI’ mode, but none of the ROIs in the offered set of pre-defined ROIs is acceptable for this MTSI client. Following the successful negotiation of ‘Pre-defined ROI’, the MTSI receiver uses the RTCP feedback method to request from the accepted set of pre-defined ROIs and MTSI sender encodes the sent video accordingly to provide the requested pre-defined ROI.\nIf the SDP offer just provides the \"a=predefined_ROI\" but not \"a=rtcp-fb:* 3gpp-roi-predefined \", then the \"a=predefined_ROI\" lines should be ignored.\nA new SDP offer-answer negotiation can be performed to modify the set of pre-defined ROIs. The MTSI sender may update all the content of pre-defined ROIs, including the total number of pre-defined ROIs, and the position, size and name of each of the pre-defined ROIs.\nThe ROI information parameters exchanged via the a=predefined_ROI parameter in the SDP signalling defined above are independent of the negotiated video resolution for the encoded content. Instead, the ROI information parameters defined above take as reference the original video content, i.e., uncompressed captured video content. Therefore, no modifications or remappings of ROI parameters are necessary during any transcoding that results in changes in video resolution or during potential dynamic adaptations of encoded video resolution at the sender.\nAn MTSI client supporting ‘Arbitrary ROI’ or ‘Pre-defined ROI’ should also offer ‘Sent ROI’ in SDP for all media streams containing video. An MTSI sender accepting \"Arbitrary ROI’ or ‘Pre-defined ROI’ shall also accept an accompanying ‘Sent ROI’ offer. An MTSI sender accepting ‘FECC’ should also accept an accompanying ‘Sent ROI’ offer. ‘Sent ROI’ is specified in clause 7.3.7 and is offered by including the a=extmap attribute [95] indicating the ‘Sent ROI’ URN under the relevant media line scope. The ‘Sent ROI’ URN corresponding to an arbitrary ROI is: urn:3gpp:roi-sent, on which the IANA registration information is provided in Annex O.4. The ‘Sent ROI’ URN corresponding to a pre-defined ROI is: urn:3gpp:predefined-roi-sent, on which the IANA registration information is provided in Annex O.5. Here is an example usage of this URN to signal ‘Sent ROI’ relative to a media line:\na=extmap:7 urn:3gpp:roi-sent\n\nThe number 7 in the example may be replaced with any number in the range 1-14.\nAn MTSI client should support RTP Retransmission as specified in clause 7.4.6.\nAn MTSI client supporting RTP Retransmission shall offer retransmission for all media streams containing video. The binding used for retransmission stream to the payload type number is indicated by an rtpmap attribute. The MIME subtype name used in the binding is \"rtx\". The \"apt\" (associated payload type) parameter shall be used to map the retransmission payload type to the associated original payload type. The \"rtx-time\" payload-format-specific parameter indicates the maximum time a sender will keep an original RTP packet in its buffers available for retransmission [140]. An MTSI client offering RTP retransmission shall specify \"rtx-time\" parameter.\nAn SDP offer/answer example showing the usage of the \"apt\" and \"rtx-time\" is included in Annex A.4.2c.\nBandwidth allocation for video with RTP Retransmission is discussed in clause 6.2.5.3.\nAn MTSI client should support Forward Error Correction (FEC) as specified in clause 7.4.7.\nAn MTSI client supporting FEC shall offer FEC for all media streams containing video. The MIME subtype name used for FEC stream is \"flexfec\". The \"ssrc-group\" attribute is used to designate FEC grouping association according to \"ssrc\" identifiers along with the \"FEC-FR\" grouping semantics for FEC Framework.  The \"repair-window\" parameter indicates the time span of the source and repair packets [141] [143]. An example for FEC grouping relative to a media line is:\na=ssrc:1234\na=ssrc:2345\na=ssrc-group:FEC-FR 1234 2345\n\nAn SDP offer/answer example showing the usage of the \"flexfec\",\"repair-window\" and \"ssrc-group\" is included in Annex A.4.2d.\nBandwidth allocation for video with FEC is discussed in clause 6.2.5.3.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.4\tText",
                            "text_content": "An MTSI client should offer AVP for all media streams containing text. Only in cases where there is an explicit demand for the AVPF RTCP reporting timing or feedback messages AVPF shall be used. If AVPF is offered then RTP profile negotiation shall be done as described in clause 6.2.1a.\nExamples of SDP offers for text can be found in clause A.5.\nAn MTSI client supporting multiparty real-time text shall indicate this by including the \"a=rtt-mixer\" attribute in SDP.\nAn MTSI client configured to automatically enable global text telephony (GTT), e.g. because the MTSI client is used by a deaf or hearing-impaired person or a person wanting to communicate with such an impaired person, shall accept an initial INVITE request for a SIP dialogue if the SDP offer does not include real time text media. It shall then send a new SDP offer (e.g. in a SIP UPDATE request during call establishment) adding text media for real time text conversation.\nNOTE:\tAs one example, incoming calls from a PSTN interworked by an MGCF will not contain media for real time text conversation in the initial SDP offer. The new offer adding media for real time text conversation enables the transport of real time text towards the MTSI client.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.5\tBandwidth negotiation",
                            "text_content": "The SDP shall include bandwidth information for each media stream and also for the session in total. The bandwidth information for each media stream and for the session is defined by the Application Specific (AS) bandwidth modifier as defined in RFC 4566 [8].\nAn MTSI client in terminal should include the ‘a=bw-info’ attribute in the SDP offer. When accepting a media type where the ‘a=bw-info’ attribute is included the MTSI client in terminal shall include the ‘a=bw-info’ attribute in the SDP answer if it supports the attribute. The ‘a=bw-info’ attribute and the below used bandwidth properties are defined in clause 19.\nWhen the ‘a=bw-info’ attribute is supported, the following bandwidth properties shall be included for each RTP payload type in the SDP:\n-\tMaximum Supported Bandwidth for sending direction.\n-\tMaximum Desired Bandwidth for sending direction.\n-\tMinimum Desired Bandwidth for sending direction.\n-\tMinimum Supported Bandwidth for sending direction.\n-\tMaximum Supported Bandwidth for receiving direction with the following exception:\n-\tThe b=AS bandwidth modifier indicates the bandwidth needed for the RTP payload type that requires the highest bandwidth. The Maximum Supported Bandwidth for this RTP payload type is therefore indicated with the b=AS bandwidth modifier and does not need to be indicated with the ‘a=bw-info’ attribute for this RTP payload type. It is still allowed to include the ‘a=bw-info’ attribute for this RTP payload type but the value shall then be aligned with the b=AS value when sending the SDP. When receiving the SDP,the b=AS bandwidth modifier and the Maximum Supported Bandwidth for the receiving direction may not be aligned. In this case, the maximum sending rate is determined as defined below.\n-\tMaximum Desired Bandwidth for receiving direction.\n-\tMinimum Desired Bandwidth for receiving direction.\n-\tMinimum Supported Bandwidth for receiving direction.\nRecommended bandwidths for several codec configurations are provided in the media-specific sections.\nFor a media stream that has been removed by either the offerer or answerer, the inclusion of bandwidth information is optional. This is in accordance with clause 8.2 of RFC 3264 [58].\nSDP examples incorporating bandwidth modifiers are shown in annex A. SDP examples using the ‘a=bw-info’ attribute are shown in annex A.6.3.\nWhen an MTSI client in terminal receives an SDP offer or answer it shall determine the maximum sending rate for the selected codec by selecting the smallest of the following:\n-\tthe bandwidth value, if the b=AS parameter was included in the received SDP offer or answer\n-\tthe Maximum Supported Bandwidth for the receiving direction, if included in the received SDP\n-\tthe preconfigured data rate for the selected codec, if the MTSI client has been preconfigured by the operator to use a particular data rate for the selected codec\n-\tthe maximum data rate for the selected codec as determined by examining the codec information (e.g., codec, mode, profile, level) and any other media information (e.g., ptime and maxptime) included in the received SDP offer or answer.  This maximum data rate is determined assuming no extra bandwidth is allowed for redundancy.\nThe maximum sending rate may be further updated by the MTSI client in terminal based on receiving an indication of the granted QoS (see clause 6.2.7).\nThe MTSI client in terminal shall not transmit at a rate above the maximum sending rate.  For speech, the MTSI client should transmit using the codec mode with the highest data rate allowed by the maximum sending rate, except if limited to a lower codec mode by the initial codec mode procedures (see clause 7.5.2.1.6) or by the adaptation procedures (see clause 10.2).\nThe MTSI client in terminal should support access network bitrate recommendation (ANBR, see clause 10.7). SDP offer/answer re-negotiation shall not be used as a replacement for dynamic media bitrate adaptation. ANBR contains information on short-term bandwidth and SDP offer/answer re-negotiations should be avoided or minimized since they consume network resources. Therefore, SDP offer/answer re-negotiation (e.g. in SIP UPDATE) shall not be initiated based on ANBR information other than in the following cases:\nIf;\n1.\tThe received ANBR from the access network is below the established GBR; and\n2.\tThe received ANBR cannot be supported by any of the negotiated codec configurations; and\n3.\tPotentially increased loss and/or delay due to not lowering the bitrate are not acceptable; and\n4.\tThe MTSI client in terminal supports one or more codec configurations that supports the received ANBR; and\n5.\tANBR messages with values meeting all conditions in 1-4 above are received consistently for an extensive period of time (e.g. 5 seconds or more, see also clause 10.7.2)\nthen the MTSI client in terminal:\n-\tmay re-negotiate the session\n-\tTo switch to a codec or codec configuration that can support the lower bitrate in the ANBR (if any); and/or\n-\tTo reduce the number of used RTP streams (e.g. turning off the affected media); and\n-\tIf the session re-negotiation fails, shall not initiate further re-negotiation based on ANBR for that bearer in the session.\nFor video, if:\n-\tTMMBR/TMMBN are not supported in the session; and\n-\tFor an extensive period of time (e.g. 5 seconds), the MTSI client in terminal consistently receives ANBR messages with values significantly below the video bitrate sent (as estimated by the receiving MTSI client in terminal) from the remote peer\nThen the MTSI client in terminal may re-negotiate the session:\n-\tTo set the session bitrate for video (see clause 6.2.5) to a value corresponding to the minimum of the received ANBR and GBR (if > 0); or\n-\tTo turn video off\nNOTE 1:\tAn ANBR below GBR does not change the GBR semantics in any way. GBR is defined as a guarantee that for a packet stream not exceeding the GBR, 98 percent of the packets do not experience a delay exceeding the QCI’s Packet Delay Budget (see clause 6.1.7.2 of TS 23.303 [90]). Temporarily reducing bitrate below GBR to comply with an ANBR can increase the probability that loss and/or delay can be kept within the bounds set by the used QCI.\nNOTE 2:\tFor GBR=MBR bearers, an ANBR below the GBR can frequently be supported by the negotiated codec configuration.\nNOTE 3:\tFor GBR<MBR bearers, an ANBR below the GBR can typically not be supported by the negotiated codec configuration.\nNOTE 4:\tIf the above conditions are not met, the MTSI client in terminal will ignore ANBR values below the GBR (see also clause 10.7.2).\nIf an MTSI client includes an AMR or AMR-WB mode-set, or EVS Primary mode br or br-recv parameter in the SDP offer or answer, the MTSI client shall set the b=AS parameter to a value matching the maximum codec mode in the mode-set or the highest bit-rate in the br or br-recv, the packetization time (ptime), and the intended redundancy level. For example, b=AS for AMR-WB at IPv6 should be set to 38 if mode-set includes {6.60, 8.85, 12.65}, the packetization time is 20, and if no extra bandwidth is allocated for redundancy. Likewise, b=AS for EVS Primary mode at IPv4 should be set to 42 if br=7.2-24.4, the packetization is header-full payload format, ptime=20, and no extra bandwidth is allocated for redundancy.\nIf an MTSI client does not include an AMR or AMR-WB mode-set, or EVS Primary mode br or br-recv parameter in the SDP offer or answer, the MTSI client shall set the b=AS parameter in the SDP to a value matching the highest AMR/AMR-WB mode, i.e., AMR 12.2 and AMR-WB 23.85, or the highest bit-rate of EVS Primary mode depending on negotiated bandwidth(s), i.e., EVS 24.4 for NB and EVS 128 for WB, SWB and FB, respectively.\nNOTE 1:\tWhen no mode-set is defined, then this should be understood as that the offerer or answerer is capable of sending and receiving all codec modes of AMR or AMR-WB. An MTSI client in terminal will not include the mode-set parameter in SDP offer in the initial offer-answer negotiation. See Clause 6.2.2.2, Tables 6.1 and 6.2. It is however expected that the mode-set is defined when an SDP offer is received from an MTSI MGW inter-working with CS GERAN/UTRAN, see Clause 6.2.2.3, Table 6.5.\nThe bandwidth to use for b=AS for AMR and AMR-WB, and EVS Primary mode should be computed as shown in Annexes K and Q respectively. Tables 6.7 and 6.8 shows the bandwidth for the respective AMR and AMR-WB codec when the packetization time is 20 and no extra bandwidth is allocated for redundancy. The b=AS value is computed without taking statistical variations, e.g., the effects of DTX, into account. Such variations can be considered in the scheduling and call admission control. Detailed procedures to compute b=AS of AMR and AMR-WB, and EVS Primary mode can be found in Annexes K and Q.\nNOTE 2:\tFor any payload format, b=AS of EVS Primary mode at 5.9 kbps source controlled variable bit-rate (SC-VBR) coding is computed as the b=AS of its highest component bit-rate, 8 kbps.\nNOTE 3:\tb=AS of EVS AMR-WB IO mode can be computed as in the octet-aligned payload format of AMR-WB as shown in Annex K.\nb=AS of EVS shall be equal to the maximum of b=AS of the highest included EVS primary mode and b=AS of the highest included EVS AMR-WB IO mode, regardless of the presence and configuration of evs-mode-switch.\nTable 6.7: b=AS for each codec mode of AMR when ptime is 20\n\nTable 6.8: b=AS for each codec mode of AMR-WB when ptime is 20\n\nTable 6.9: b=AS for each bit-rate of EVS Primary mode when ptime is 20\n\nTables 6.10-1 to 6.10-3 describe the setting of the bandwidth properties that should be used for the ‘a=bw-info’ attribute for a few possible combinations of codec, codec rate, packetization schemes and redundancy levels. The Minimum Supported Bandwidth does not prevent encoding the speech with an even lower bitrate, for example when EVS is used in the 5.9 kbps VBR mode or during DTX periods when SID frames are encoded with a very low bit rate and are generated with a reduced frame rate. Bit rates lower than the Minimum Supported Bandwidth may also be used when sending DTMF. Additional combinations and corresponding bandwidth properties are found in Annex K for AMR, AMR-WB and EVS AMR-WB IO mode and in Annex Q for EVS primary mode.\nTable 6.10-1: Recommended bandwidth properties for AMR to be used with the ‘a=bw-info’ attribute when codec modes up to 12.2 are negotiated\n\nTable 6.10-2: Recommended bandwidth properties for AMR-WB to be used with the ‘a=bw-info’ attribute when codec modes up to 12.65 are negotiated\n\nTable 6.10-3: Recommended bandwidth properties for EVS to be used with the ‘a=bw-info’ attribute when codec modes up to 13.2 are negotiated\n\nSDP examples using the ‘a=bw-info’ attribute for speech are shown in annex A.6.3.\nThe b=AS parameter is set to match the maximum bit rate desired for the media in the receiving direction.\nVideo codecs are usually capable of adapting the bit rate over a large bit rate range. This allows for dynamic addition of redundancy (see clauses 6.2.3.5 and 6.2.3.6) without explicitly allocating any additional bandwidth for the redundancy information. Therefore, when the ‘a=bw-info’ attribute is used, the Maximum Supported Bandwidth and the Maximum Desired Bandwidth properties should be set to the same value.\nSDP examples using the ‘a=bw-info’ attribute for video are shown in annex A.6.3.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.7: b=AS for each codec mode of AMR when ptime is 20",
                                    "table number": 15,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.8: b=AS for each codec mode of AMR-WB when ptime is 20",
                                    "table number": 16,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.9: b=AS for each bit-rate of EVS Primary mode when ptime is 20",
                                    "table number": 17,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.10-1: Recommended bandwidth properties for AMR to be used with the ‘a=bw-info’ attribute when codec modes up to 12.2 are negotiated",
                                    "table number": 18,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.10-2: Recommended bandwidth properties for AMR-WB to be used with the ‘a=bw-info’ attribute when codec modes up to 12.65 are negotiated",
                                    "table number": 19,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 6.10-3: Recommended bandwidth properties for EVS to be used with the ‘a=bw-info’ attribute when codec modes up to 13.2 are negotiated",
                                    "table number": 20,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.2.6\tThe Synchronization Info attribute \"3gpp_sync_info\"",
                            "text_content": "Synchronization jitter (also known as synchronization or inter-media skew) is defined as the amount of synchronization delay between media streams that needs to be maintained during the synchronization process (at the receiver side), which is acceptable to a session (or the sender of the multimedia streams) for a good user experience.\nTight synchronization between the constituent streams is not necessary for all types of MTSI sessions. For instance, during a VoIP call, one of the call participants may wish to share a video clip or share his/her camera view. In this situation, the sender may want to relax the requirement on the receiver to synchronize the audio and the video streams in order to maintain a good video quality without stressing on tight audio/video synchronization. The Synchronization Info attribute defined in the present document is not just limited to lip-sync between audio/video streams, but is also applicable to any two media streams that need to be synchronized during an MTSI session. This attribute allows an MTSI client to specify whether or not media streams should be synchronized. In case the choice is to have synchronization between different streams, it is up to the implementation, use case and application to decide the exact amount of synchronization jitter allowed between the streams to synchronize.\nThe ABNF for the synchronization info attribute is described as follows:\nSynchronization-Info\t= \"a\" \"=\" \"3gpp_sync_info\" \":\" sync-value\nsync-value\t= \"Sync\" / \"No Sync\"\nThe value \"Sync\" indicates that synchronization between media shall be maintained. The value \"No Sync\" indicates that No Synchronization is required between the media.\nThe parameter \"3gpp_sync_info\" should be included in the SDP at the session level and/or at the media level. Its usage is governed by the following rules:\n1.\tAt the session level, the \"3gpp_sync_info\" attribute shall be used with the group attribute defined in RFC 3388 [48]. The group attribute indicates to the receiver which streams (identified by their mid attributes) that are to be synchronized. The \"3gpp_sync_info\" attribute shall follow the \"group: LS\" line in the SDP.\n2.\tAt the media level, the \"3gpp_sync_info\" attribute shall assume a value of \"No Sync\" only. It indicates to the receiver that this particular media stream is not required to be synchronized with any other media stream in the session. The use of the \"mid\" attribute of RFC 3388 [48] is optional in this case. If the \"mid\" attribute is used for any other media in the session, then \"mid\" with this media line shall be used also according to RFC 3388 [48]. Otherwise, it is not necessary to tie the \"3gpp_sync_info\" attribute with the \"mid\" attribute.\n3.\tWhen the \"3gpp_sync_info\" attribute is defined at both session level (with the \"group\" attribute) and media level, then the media level attribute shall override the session level attribute. Thus if the \"3gpp_sync_info\" attribute is defined at the media level, then that particular media stream is not to be synchronized with any other media stream in the session (even if the \"3gpp_sync_info\" is defined at the session level for this media stream).\nThe calling party (or the initiator or offerer of the multimedia stream) should include the \"3gpp_sync_info\" attribute in the SDP which is carried in the initial INVITE message. Upon reception of the INVITE message that includes the \"3gpp_sync_info\" attribute, the other party in the session should include its own \"3gpp_sync_info\" attribute (with its own wish for synchronization or no synchronization) in the 200/OK response message.\nThere are no offer/answer implications on the \"3gpp_sync_info\" attribute; it provides synchronization requirement between the specified media streams to the receiver. The \"3gpp_sync_info\" attribute in the calling party SDP is only an indication to the called party of the synchronization requirement that should be maintained between the specified media streams that it receives. Similarly the \"3gpp_sync_info\" attribute value from the called party is an indication to the calling party of the synchronization requirements between specified media streams. The \"3gpp_sync_info\" attribute value can be different for the calling and the called parties.\nSDP examples using the \"3gpp_sync_info\" attribute are given in clause A.7.\nNOTE:\tDefault operation in the absence of the \"3gpp_sync_info\" attribute in SDP is to maintain synchronization between media streams.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.7\tNegotiated QoS parameters",
                            "text_content": "The MTSI client in the terminal may support the negotiation of the QoS. The term \"negotiated\" in the present document describes the end result of a QoS negotiation between an MTSI client in terminal and the network (or the end result of what the network grants to the MTSI client in terminal even if no negotiation takes place).\nAn MTSI client in terminal supporting the transport level QoS negotiation should verify that the QoS parameters, e.g. MBR and GBR, are aligned with the media configurations negotiated in SDP. While checking whether the different bandwidth parameters are aligned or not, the MTSI client in terminal should take into account the following areas where differences are likely to occur: parameter encoding; units used; packetization schemes related to the IP/UDP/RTP overhead; the amount of RTCP bandwidth. The MTSI client in terminal needs to compensate for the differences if found.\nNOTE:\tThe transport level QoS negotiation applies only to 3GPP accesses.\nIn the following sections it is assumed that the MTSI client in terminal supports the QoS negotiation and is made aware of the negotiated bandwidth properties and other QoS hints (if supported and used, see clause 6.2.7.4).\nIn SDP offer-answer, the b=AS bandwidth modifier is used to describe the maximum bandwidth for the receiving direction. The IP/UDP/RTP overhead is included in the bandwidth value for RTP-based media but the RTCP bandwidth is not included. The IP/UDP/DTLS/SCTP overhead is included in the bandwidth value for SCTP-based media such as the data channel (see clause 6.2.10). The bandwidth value is an integer and the unit is kbps.\nIf, at session setup or at session re-negotiation, the MTSI client in terminal detects that the negotiated downlink QoS Maximum Bit Rate (MBR) is not aligned with the b=AS bandwidth modifier in the sent SDP then it should try to align the bandwidth properties in a subsequent SDP offer-answer.\nIf, during the session, the negotiated downlink Maximum Bit Rate(s) (MBR) for the bearer(s) has been updated from the network then the MTSI client in terminal should check if the bandwidth(s) it sent within b=AS bandwidth modifiers in previous SDP (e.g. during the initial session setup or earlier session re-negotiation, if any) are aligned with the downlink MBR(s) allocated for the bearer(s) and its receiving capabilities.\nThe rules for alignment are different depending on how many media streams that are handled by the bearer, as follows:\n-\tWhen a bearer carries a single media stream, then it is the media-level b=AS bandwidth for that media stream that should be aligned with the MBR of the bearer.\n-\tWhen a bearer carries several media streams, then it is the sum of the media-level b=AS bandwidths for those media streams that should be aligned with the MBR of the bearer.\nThe rules for alignment are also different depending on whether the media stream(s) are bi-directional (sendrecv) or uni-direction (sendonly or recvonly), as follows:\n-\tIf the MTSI terminal receives (and possibly sends) a media stream, it should consider the sent b=AS bandwidth(s) in SDP for that media stream in comparison with the downlink MBR.\n-\tIf the MTSI terminal only sends a media stream, it should not consider the sent b=AS bandwidth(s) in SDP for that media stream in comparison with the downlink MBR.\nNOTE 1:\tThe b=AS bandwidth and the MBR bandwidth are not directly comparable since the b=AS bandwidth does not include the RTCP bandwidth while the MBR bandwidth allocation for RTP media must include some headroom for RTCP. The bandwidths will therefore almost always be different. The MBR bandwidth may also differ from the b=AS bandwidth because of other reasons, for example: bearer allocation and header compression. It is an implementation consideration to handle such impacts and how to judge whether the bandwidth values differ and what bandwidth value to send in the UPDATE message.\nIf the MTSI client in terminal determines that the b=AS bandwidth(s) are not aligned with the MBR and the receiving capabilities of the MTSI client, then it should align the media-level b=AS bandwidth(s) to the MBR and its receiving capabilities by sending to the other party an SDP offer with the new b=AS bandwidth value(s). In the process of this alignment it is also likely that the session-level b=AS bandwidth needs to be updated. In addition, the MTSI client in terminal may modify other parts of the SDP, e.g., to replace the codecs or adjust codec parameters (such as the AMR or AMR-WB mode-set).\nNOTE 2:\tIt could be necessary to reconfigure the codec(s), or even to drop some media streams, to be able to operate within the bandwidth constraints defined with the MBR of the bearer.\nNOTE 3:\tA situation when the MTSI client in terminal could not align the b=AS bandwidth(s) with the MBR, due to its receiving capabilities, is when it does not support rate adaptation.\nThis alignment may require re-negotiation, which should preferably be performed when there is session re-negotiation for other reasons. When additional re-negotiation is required, which adds load to the SIP bearer and the SIP servers, it is not desirable to repeat the re-negotiation multiple times. Therefore, if re-negotiation fails to align the b=AS bandwidth modifier and the QoS parameters then it should not be repeated unless new re-negotiation is needed for other reasons, e.g. to add or remove media components.\nIf an MTSI client in a terminal receives a new SDP offer with new b=AS bandwidth value(s) (e.g., in a SIP UPDATE or in a SIP re-INVITE) and it accepts the session update then it shall generate an SDP answer as described in clause 6.2.\nAny subsequent QoS changes indicated to the MTSI client in terminal during an MTSI session (including the cases described in Clause 10.3) shall be signalled by the MTSI client in terminal (subject to the QoS update procedure) to the other party using the same signalling described above.\nExamples of SDP using negotiated QoS are given in clause A.8.\nWhen the MTSI client in terminal receives an indication that the negotiated uplink Maximum Bit Rate (MBR) is less than the current maximum sending rate of its sender, the MTSI client in terminal should configure the maximum sending rate of its sender to align with the negotiated uplink Maximum Bit Rate (MBR).\nWhen the MTSI client in terminal receives an indication that the negotiated uplink Maximum Bit Rate (MBR) is greater than the current maximum sending rate of its sender and rate adaptation is possible for the session, the MTSI client in terminal should configure the maximum sending rate of its sender to align with the smallest of the following:\n-\tthe negotiated uplink Maximum Bit Rate (MBR)\n-\tthe bandwidth value, if the b=AS parameter was included in the last SDP offer or answer received by the client\n-\tthe preconfigured data rate for the selected codec, if the MTSI client has been preconfigured by the operator to use a particular data rate for the selected codec\nThe Maximum Supported Bandwidth for the sending direction should be aligned with the uplink MBR.\nThe Minimum Desired Bandwidth for the sending direction should be aligned with the uplink GBR.\nThe Maximum Supported Bandwidth for the receiving direction should be aligned with the downlink MBR.\nThe Minimum Desired Bandwidth for the receiving direction should be aligned with the downlink GBR.\nThe procedures for aliging the above listed bandwidth properties with the above listed QoS parameters are the same as given above in clauses 6.2.7.1 and 6.2.7.2 for other bandwidth-related information.\nIn some cases, it is not possible to uniquely map a media type in SDP to an appropriate QoS without additional information on the intended usage of that media from the application or the end-user of that application.\nThe MTSI client in terminal may include a non-authoritative QoS hint in one or more SDP media description(s), for use by local and remote policy control functions, by adding an \"a=3gpp-qos-hint\" media-level SDP attribute with a value that is set based on the intended media usage. The QoS hints included on the \"a=3gpp-qos-hint\" line applies jointly to the aggregate of all packets (e.g. if more than one media stream is part of the same media description), and equally in both directions (uplink and downlink) unless restricted by the inclusion of \"a=sendonly\" or \"a=recvonly\" in the same media description.\nIf this attribute is included in an SDP media description, policy control can choose to take this additional information into account for the affected media.\nAn \"a=3gpp-qos-hint\" attribute shall not occur more than once for an SDP media description.\nSDP examples are provided in Annex A.16.\nNOTE:\tIf a media GBR bearer that was set up assisted by 3gpp-qos-hint information is dropped by the network due to insufficient resources, an attempt to re-establish the bearer can be made through a re-offer in an UPDATE or re-INVITE with less demanding QoS values included in the 3gpp-qos-hint and/or bandwidth attributes (e.g. \"b=AS\" and \"a=bw-info\"; see clause 19) for that media. How to get information on what values that will be acceptable to include in such re-offer is not specified.\n3gpp-qos-hint-value = qos-hint *(\";\" qos-hint)\nqos-hint = qos-hint-property [\"=\" qos-hint-end-to-end-value *(qos-hint-split)]\nqos-hint-property = \"loss\" / \"latency\" / token\nqos-hint-end-to-end-value = qos-hint-value\nqos-hint-split = \"/\" qos-hint-split-method \":\" qos-hint-split-value\nqos-hint-split-method = \"local\" / token\nqos-hint-split-value = qos-hint-value\nqos-hint-value = zero-based-integer / non-zero-real / token\n; token as defined by IETF RFC 4566\n; zero-based-integer and non-zero-real as defined by IETF RFC 8866The IANA registration information for this attribute is provided in Annex M.11.\nA qos-hint-property value shall only occur once on the \"a=3gpp-qos-hint\" line. If a qos-hint-property value is not included on the \"a=3gpp-qos-hint\" line, it should be interpreted as the UE and application have no preference of any qos-hint-value for that qos-hint-property but anything the network can provide is equally acceptable.\nIf a qos-hint-property has no qos-hint-end-to-end-value, it is of boolean (on/off) type.\nIf the qos-hint-propery has a qos-hint-end-to-end-value but doesn’t include any explicit qos-hint-split, the qos-hint-end-to-end-value is split equally between the SDP offerer and the SDP answerer. If an explicit qos-hint-split is included, it specifies how the split of the qos-hint-end-to-end-value between SDP offerer and SDP answerer is made. The following qos-hint-split-method values are currently defined:\n\"local\":\tThe qos-hint-split-value specifies the SDP sender’s part of the qos-hint-end-to-end-value that is applied across its local link, in the same format and units used by the associated qos-hint-end-to-end-value, the value being the same in both send and receive directions. The SDP sender of the SDP offer is the SDP offerer and the SDP sender of the SDP answer is the SDP answerer.\nThe following qos-hint-property values are currently defined:\n\"loss\":\tThis qos-hint-property qos-hint-end-to-end-value describes the maximum desirable end-to-end transport level packet loss rate in percent (without \"%\" sign) as a zero-based-integer or as a non-zero-real value.\n\"latency\":\tThis qos-hint-property qos-hint-end-to-end-value describes the maximum desirable end-to-end transport level packet latency in milliseconds as a zero-based-integer or as a non-zero-real value. The value excludes any application-level processing in the sender and receiver, such as e.g. application-level retransmission or encoding/decoding.\nAn \"a=3gpp-qos-hint\" line may be included in any media description in an SDP offer.\nIf there is no \"a=3gpp-qos-hint\" line included in a media description in the SDP offer, it shall not be included in the corresponding media description in the SDP answer.\nIf a qos-hint with an unknown or malformed qos-hint-property or qos-hint-value is received in an SDP offer, that qos-hint shall be ignored, shall be omitted from the SDP answer, and shall neither cause the \"a=3gpp-qos-hint\" line nor the entire media description to be rejected in the SDP answer.\nAn SDP answerer shall not add any qos-hint-property values on the \"a=3gpp-qos-hint\" line that are not present in the received SDP offer.\nA \"loss\" qos-hint-end-to-end-value received in the SDP offer that is accepted by the SDP answerer shall be kept unmodified in the SDP answer. A \"loss\" qos-hint-end-to-end-value received in the SDP offer that cannot be supported by the SDP answerer even when making use of an allowable qos-hint-split-value (see below) may be increased in the SDP answer to a value that can be supported by the SDP answerer. A \"loss\" qos-hint-end-to-end-value received in the SDP offer that is higher than required by the SDP answerer may be decreased in the SDP answer to a value that is required by the SDP answerer. Figures 6.2.7.4.4-1 and 6.2.4.4.4-2 provide illustrated examples of these principles. If the \"loss\" qos-hint-property is known by the SDP answerer but if there are no known, supported qos-hint-values for it, the entire qos-hint shall be omitted from the SDP answer.\nA \"latency\" qos-hint-value received in the SDP offer that cannot be supported by the SDP answerer as the desirable maximum end-to-end packet latency should be increased in the SDP answer to a value that can be supported by the SDP answerer. A \"latency\" qos-hint-end-to-end-value received in the SDP offer that is higher than required by the SDP answerer may be decreased in the SDP answer to a value that is required by the SDP answerer. Figures 6.2.7.4.4-1 and 6.2.7.4.4-2 provide illustrated examples of the principles for \"loss\" that is also applicable for \"latency\". If the \"latency\" qos-hint-property is known by the SDP answerer but if there are no known, supported qos-hint-values for it, the entire qos-hint shall be omitted from the SDP answer.\nIf, as a result of the above procedures, there are no qos-hints to be included in the SDP answer, the entire \"a=3gpp-qos-hint\" line shall be omitted from the SDP answer.\nNOTE:\tIf the qos-hint-end-to-end-value is changed from what was included in the offer, or if the implicit or explicit qos-hint-split-value applicable to the SDP offerer is decreased between the SDP offer and the SDP answer, there’s a risk that the resulting QoS will not be acceptable to the SDP offerer or, if anyway accepted, at least cause sub-optimal user experience.\nFigure 6.2.7.4.4-1 illustrates the 3GPP-QoS-Hint \"loss\" UE-to-UE offer/answer, depicting the process of Quality of Service (QoS) hint exchange between user equipment (UEs) in a mobile network. The figure shows the interaction between the network elements, including the Serving Gateway (SGW), Home Location Register (HLR), and User Equipment (UE), as they negotiate and establish the appropriate QoS parameters for data transmission. This process is crucial for ensuring that UEs receive the best possible service quality, taking into account factors such as latency, throughput, and jitter. The figure highlights the importance of efficient communication between network components to maintain a high level of service for mobile users.\nFigure 6.2.7.4.4-1 Illustration of 3gpp-qos-hint \"loss\" UE-to-UE offer/answer\nFigure 6.2.7.4.4-2 illustrates a 3GPP-QoS-hint \"loss\" UE-to-Network offer/answer, depicting the process of Quality of Service (QoS) hint exchange between a user equipment (UE) and a network element. The figure shows the various stages of the process, including the initial offer from the UE, the network's answer, and the final loss indication. The diagram highlights the importance of QoS hints in ensuring that the network can prioritize and manage traffic efficiently, particularly in high-demand scenarios. The figure is essential for understanding the mechanisms by which mobile networks can optimize resource allocation and ensure a high level of service quality for their users.\nFigure 6.2.7.4.4-2 Illustration of 3gpp-qos-hint \"loss\" UE-to-Network offer/answer\nIf a qos-hint with an unknown or malformed qos-hint-split-method or qos-hint-split-value is received in an SDP offer, the entire qos-hint-split shall be ignored, shall be omitted from the SDP answer, and shall neither cause the \"a=3gpp-qos-hint\" line nor the entire media description to be rejected in the SDP answer.\nThe qos-hint-split provides the SDP offerer’s opinion on how that qos-hint-end-to-end-value should be split between the SDP offerer’s and the SDP answerer’s local links. As stated above, if no qos-hint-split is provided the qos-hint-end-to-end-value is split equally between SDP offerer and SDP answerer local links and is equivalent to a qos-hint-split being provided with a value that is half of the qos-hint-end-to-end-value.\nIf the SDP answerer accepts a default split (without explicit qos-hint-split in the SDP offer) it shall not include any qos-hint-split in the SDP answer.\nIf the SDP answerer accepts an explicitly provided qos-hint-split proposed by the SDP offer, it shall include a qos-hint-split in the SDP answer with a qos-split-hint-value being equal to qos-hint-end-to-end-value in the SDP answer minus the corresponding qos-hint-split-value from the SDP offer.\nIf the SDP answerer does not accept the qos-hint-split-value proposed in the SDP offer, regardless if that qos-hint-split-value is explicit or not, it can make one of the following choices for the SDP answer:\n-\tIf the SDP offerer qos-hint-split-value is smaller than what the SDP answerer requires (i.e., qos-hint-end-to-end-value in the SDP offer minus the corresponding qos-hint-split-value from the SDP offer is larger than required across the SDP answerer’s local link), the SDP answerer may include a qos-hint-split-value in the SDP answer that is less than the qos-hint-end-to-end-value in the SDP answer minus the corresponding qos-hint-split-value from the SDP offer. The SDP answerer may use the value 0 if the actual (non-zero) qos-hint-split-value can be considered insignificant compared to the qos-hint-split-value in the SDP offer.\n-\tIf the SDP offerer qos-hint-split-value is larger than what the SDP answerer considers feasible (i.e., qos-hint-end-to-end-value in the SDP offer minus the corresponding qos-hint-split-value from the SDP offer is smaller than feasible across the SDP answerer’s local link), the SDP answerer may include a qos-hint-split-value in the SDP answer that is larger than the qos-hint-end-to-end-value included in the SDP offer minus the corresponding qos-hint-split-value from the SDP offer, but the included value shall then also be less than or equal to half of the qos-hint-end-to-end-value included in the SDP answer. The exception to that rule is when the qos-hint-end-to-end-value included in the SDP answer is less than the qos-hint-end-to-end-value included in the SDP offer (see also above), in which case the qos-hint-split-value should instead be the qos-hint-end-to-end-value included in the SDP answer minus the corresponding qos-hint-split-value from the SDP offer, unless the SDP answerer cannot support such qos-hint-split-value. In that case the included value shall be less than or equal to half of the qos-hint-end-to-end-value included in the SDP answer.\nIf there is no \"a=3gpp-qos-hint\" line included in a media description in the SDP answer, it shall be interpreted as the answerer either does not support the attribute at all or cannot accept any of the qos-hint-property values from the offer, and QoS hints will therefore not be used for that media description.\nIf a qos-hint with an unknown or malformed qos-hint-property or qos-hint-value is received in an SDP answer, that qos-hint shall be ignored, and shall neither cause the \"a=3gpp-qos-hint\" line nor the entire media description to be rejected (e.g. by issuing a new SDP offer with that \"m=\" line disabled).\nA \"loss\" property value received in the SDP answer that is identical to the SDP offer shall be taken as the SDP answerer accepting to share end-to-end packet loss budget equally. A \"loss\" property value received in the SDP answer that is larger than in the SDP offer shall be taken as the SDP answerer being incapable of sharing end-to-end packet loss budget with the proposed split from the SDP offer while keeping the end-to-end packet loss value that was included in the SDP offer (see illustrative examples in Figures 6.2.7.4.4-1 and 6.2.7.4.4-2).  A \"loss\" property value received in the SDP answer that is smaller than in the SDP offer shall be taken as the SDP answerer requiring a lower end-to-end packet loss for the media.\nA \"latency\" property value received in the SDP answer that is identical to the SDP offer shall be taken as the SDP answerer accepting to share end-to-end packet latency budget equally. A \"latency\" property value received in the SDP answer that is larger than in the SDP offer shall be taken as the SDP answerer being incapable of sharing end-to-end packet latency budget with the proposed split from the SDP offer while keeping the end-to-end packet latency value that was included in the SDP offer (the principles in the illustrative examples for \"loss\" in Figures 6.2.7.4.4-1 and 6.2.7.4.4-2 apply also for \"latency\").  A \"latency\" property value received in the SDP answer that is smaller than in the SDP offer shall be taken as the SDP answerer requiring a lower end-to-end latency for the media.\nIf a qos-hint with an unknown or malformed qos-hint-split-method or qos-hint-split value is received in an SDP answer, the entire qos-hint-split shall be ignored, and shall neither cause the \"a=3gpp-qos-hint\" line nor the entire media description to be rejected (e.g. by issuing a new SDP offer with that \"m=\" line disabled).\nIf no qos-hint-split is included in the received SDP answer and if no qos-hint-split was included in the SDP offer, the SDP answerer has accepted the offered default, equal split.\nIf a qos-hint-split is included in the received SDP answer with a qos-split-hint-value equal to the qos-hint-end-to-end-value in the SDP answer minus the corresponding qos-hint-split-value from the SDP offer, the SDP answerer has accepted the qos-hint-split proposed by the SDP offer.\nIf a qos-hint-split is included in the received SDP answer with a qos-split-hint-value different than the above, the SDP answerer has modified the qos-hint-split-value allocation from the SDP offer, regardless if that qos-hint-split-value was explicit or not in the SDP offer, and the resulting split is described by the SDP answer.\nTable 6.2.7.4.5-1 below shows what resulting QoS hint values from the SDP answer that can be used during resource reservation at the SDP offerer and SDP answerer sides, respectively, for each of the defined qos-hint-property-values.\nTable 6.2.7.4.5-1: Resulting summary of QoS hint values from SDP answer\n\nNOTE:\tThe following non-authoritative mapping of the qos-hint-end-to-end-values (no explicit split applied, for simplicity) to, for example, the 5 defined FLUS-related 5QI/QCI would then be possible for the PCF/PCRF (other mappings are possible, left for the originating and terminating policy control to decide, and need not even be exactly the same for originating and terminating network for a UE-to-UE session):\nloss=0.0002;latency=300\t\t=>\tQCI 71 (150 ms, 10-6) \nloss=0.02;latency=600\t\t\t=>\tQCI 72 (300 ms, 10-4) \nloss=0.000002;latency=600\t\t=>\tQCI 73 (300 ms, 10-8) \nloss=0.000002;latency=1000\t=>\tQCI 74 (500 ms, 10-8) \nloss=0.02;latency=1000\t\t\t=>\tQCI 76 (500 ms, 10-4)\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.2.7.4.5-1: Resulting summary of QoS hint values from SDP answer",
                                    "table number": 21,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.2.8\tDelay Budget Information (DBI) Signaling",
                            "text_content": "An MTSI client may support Delay Budget Information (DBI) signaling as specified in sub-clause 7.3.8.\nAn MTSI client supporting DBI shall offer ‘Delay Budget Information’ (DBI) signaling in SDP for all media streams containing speech. An MTSI client supporting DBI may also offer ‘Delay Budget Information’ (DBI) signaling in SDP for all media streams containing video.  DBI shall be offered by including the a=rtcp-fb attribute [40] with the DBI type under the relevant media line scope. The DBI type in conjunction with the RTCP feedback method shall be expressed with the following parameter: 3gpp-delay-budget. A wildcard payload type (\"*\") shall be used to indicate that the RTCP feedback attribute for DBI signaling applies to all payload types. Here is an example usage of this attribute to signal DBI relative to a media line based on the RTCP feedback method:\na=rtcp-fb:* 3gpp-delay-budget\nThe IANA registration information on the new RTCP feedback type for DBI signaling is provided in Annex R.2.\nThe ABNF for rtcp-fb-val corresponding to the feedback type \"3gpp-delay-budget\" is given as follows:\nrtcp-fb-val =/ \"3gpp-delay-budget\"\nAs described in sub-clause 7.3.8, DBI signalling involves RTCP feedback signalling to carry both (i) available additional delay budget from the MTSI receiver to the MTSI sender, and (ii) requested additional delay budget from the MTSI sender to the MTSI receiver.\nAnnex V.3 presents SDP examples on DBI signalling capability.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.9\tANBR Support attribute \"anbr\"",
                            "text_content": "Access network bitrate recommendation (ANBR) is described in clause 10.7. Use of ANBR with dynamic bitrate adaptation is described in clause 10.7.3 and related adaptation of sent and received media is described in clauses 10.7.3.2 and 10.7.3.3, respectively. At the radio signalling level, ANBR signaling capability, also known as RAN-assisted codec adaptation, is specified in TS 36.321 [157] for LTE access and TS 38.321 [166] for NR access respectively.\nThe media-level SDP attribute \"anbr\" is specified in this clause to indicate ANBR support. The MTSI client in terminal supporting \"anbr\" shall only signal this attribute in the SDP offer and answer if all of the following are true:\n-\tMTSI client in terminal supports ANBR as described in clause 10.7, including the use of ANBR with dynamic bitrate adaptation as described in clause 10.7.3.\n-\tThe UE of the MTSI client in terminal is capable of RAN-assisted codec adaptation specified in TS 36.321 for LTE access and/or TS 38.321 for NR access. For LTE access, inclusion of \"anbr\" in the SDP indicates that the UE is able to query and receive ANBR information (for both downlink and uplink ANBR) from its eNB. Likewise, for NR access inclusion of this attribute indicates that the UE is able to query and receive ANBR information (for both downlink and uplink ANBR) from its gNB.\n-\tThe P-CSCF has indicated to the UE of the MTSI client in terminal its ability to handle this SDP attribute, as described in clause E.10 of TS 23.228 [167], and specified in TS 24.229 [7] through the respective SIP registration procedures via the corresponding feature capability indicator g.3gpp.anbr.\nSignalling of ANBR capabilities in the SDP via \"a=anbr\" enables end-to-end coordination of ANBR capabilities across the UEs, access networks, and PCF/PCRF. In particular, such ANBR capability signalling can be useful for the PCF/PCRF when setting GBR<MBR bearers.\nHere is an example use of the \"a=anbr\" attribute relative to a media line:\na=anbr\nThe IANA registration information for the \"a=anbr\" SDP attribute is provided in Annex M.8.\nSDP examples on ANBR capability signalling are provided in Annex A.15.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.10\tData channel",
                            "text_content": "Support of data channel media is optional for an MTSI client and an MTSI client in terminal. For brevity, an MTSI client supporting data channel is henceforth denoted as a DCMTSI client or DCMTSI client in terminal, respectively.\nTo indicate support for the procedures in this clause, a DCMTSI client shall when including media feature tags as specified in TS 24.229 [7] include a +sip.app-subtype media feature tag, as specified by RFC 5688 [177], with a value of \"webrtc-datachannel\" (the application media format used by [172]), regardless of data channel media being part of the SDP or not.\nOne or more data channel SDP media descriptions formatted according to [172] may be added to the SDP, alongside other SDP media descriptions such as e.g. speech, video, and text. A data channel SDP media description shall not be placed before the first SDP speech media description. SDP examples are provided in Annex A.17.\nIf data channels are used in a session, the session setup shall determine the applicable bandwidth limit(s) as defined in clause 6.2.5.\nMultiple data channels may be mapped to a single data channel SDP media description, each with a corresponding \"a=dcmap\" SDP attribute and stream IDs that are unique within that media description. There is no limit to the number of data channels in an SDP media description, but the aggregate of all defined data channels shall keep within the set bandwidth limit and care should be taken to avoid excessive SDP size. If the session is re-negotiated to include a changed number of data channels in an SDP media description, the bandwith limit may either be kept constant, changing the share of bandwidth available to each individual data channel, or the bandwidth limit may be changed to accommodate the changed number of data channels, keeping individual data channel bandwidth shares. Regardless of what approach is used when changing number of used data channels in a media description, the aggregate of all defined data channels shall keep within the re-negotiated bandwidth limit.\nIf there is a need to use data channels with either different transport IP addresses, different UDP ports, or different SCTP ports, separate data channel SDP media descriptions shall be used, as IP address, UDP port and SCTP port are all constant per SDP media description. Multiple SCTP associations for a single channel, commonly denoted as \"multi-homing\", defined in IETF RFC 4960 [173] for reasons of redundancy and basically using one destination transport address at a time, is not described for use with WebRTC data channel and shall therefore not be used in this specification.\nNOTE 1:\tThe main reasons to not specify multi-homing are because it cannot use the needed separation of signalling paths for redundancy purposes in the applicable usage scenarios, and it is also not considered feasible when using SCTP on top of DTLS.\nTo ease data channel media implementation and ease interworking with WebRTC data channels, DCMTSI clients shall support ICE Lite and may support full ICE [184], for data channel media. DCMTSI clients supporting full ICE shall only use host candidate addresses. SDP \"a=candidate\" line host address information shall match corresponding SDP \"c=\" and \"m=\" line information.\nNOTE 2:\tIn typical IMS deployments, it is expected that DCMTSI clients have no need to use STUN or TURN servers with ICE. This is in line with what constitutes an ICE Lite agent.\nA \"data channel application\" consists of an HTML web page including JavaScript(s), and optionally image(s) and style sheet(s). A \"bootstrap data channel\" is henceforth defined as a data channel used to retrieve data channel application(s) for a DCMTSI client in terminal, with a data channel stream ID below 1000, and using the HTTP [73] protocol as data channel subprotocol. The data channel application accessible at the HTTP root (\"/\") URL through a bootstrap data channel describes the graphical user interface and the logic needed to handle any further data channel usage beyond the bootstrap data channel itself. The meaning of the \"authority\" (host) part of the URL and consequently the \"Host\" HTTP header are not defined, shall be ignored on reception, and shall be set to the empty value by a DCMTSI client in terminal.\nNOTE 3:\tData channel stream IDs below 1000 may use a well-defined subprotocol for other features than retrieving data channel application(s). For example, the “mpeg-sd” subprotocol can be used for a data channel stream ID below 1000 for scene description-based overlays as specified in Annex Y.6.9.\n\nThe data channel application is created prior to the DCMTSI call where it is intended to be used, by means left out of scope for this specification. The data channel application workflow is depicted by Figure 6.2.10.1-1 below.\nFigure 6.2.10.1-1 illustrates the data channel workflow in a telecommunication system, showcasing the process of data transmission from the user equipment (UE) to the base station (gNB) and back. The figure depicts the various stages of data processing, including modulation, channel coding, and signal transmission. Key components such as the gNB, UE, and intermediate nodes are highlighted, emphasizing the role of each in the data channel workflow. The figure also highlights the importance of error detection and correction mechanisms, such as the use of cyclic redundancy check (CRC) and forward error correction (FEC) codes. Overall, the figure provides a comprehensive overview of the data channel workflow in a telecommunication system, emphasizing the complexity and precision required for efficient data transmission.\nFigure 6.2.10.1-1: Data Channel Workflow\nThe data channel application is, referring to the numbered arrows in Figure 6.2.10.1-1:\n1.\tUploaded to the network, by the UE user or some other authorized party.\n2.\tStored in a data channel application repository in the network.\n3.\tDuring the DCMTSI call where it should be used, retrieved from the repository.\n4.\tSent through a bootstrap data channel to the local UE A.\n5.\tSent through a bootstrap data channel to the remote UE B. This may happen in parallel with and rather independent of step 4.\n6.\tAny additional data channels created and used by the data channel application itself are established (logically) between UE A and UE B. Data transmission on data channels shall not start until there is confirmation that both peers have instantiated the data channel, using the same procedures as described for WebRTC in section 6.5 of [172]. The traffic may effectively go through the Data Channel Server, e.g., when the bootstrap and end-to-end data channels have the same anchoring point. This traffic may pass across an inter-operator border if UE A and UE B belong to different operators’ networks.\nThe bootstrap data channel is not intended for use directly between DCMTSI clients in terminal. DCMTSI clients in terminal that receive HTTP requests on a bootstrap data channel shall ignore such request and shall update the session by removing the SDP \"a=dcmap\" line with the stream ID where such HTTP request was received, and closing that stream ID.\nThe data channel application sent in a bootstrap data channel may be updated at any time, automatically or interactively, using normal HTTP procedures.\nA bootstrap data channel shall be configured as ordered, reliable, with normal SCTP multiplexing priority. The sub-protocol for a bootstrap data channel shall be HTTP (not encapsulating HTTP in TCP), represented by the following, example SDP \"a=dcmap\" line, which therefore shall be present in each data channel media description in an SDP offer from a DCMTSI client in terminal:\na=dcmap:0 subprotocol=\"http\"\nWhen the HTTP subprotocol is used, any other data channels used by the data channel application JavaScript(s) sent in the bootstrap data channel shall be represented in an updated SDP as additional \"a=dcmap\" lines with stream ID values starting from 1000, using stream ID numbers from the JavaScript(s).\nThere are multiple, possible providers of data channel applications. In Figure 6.2.10.1-1, assume that UE A is local to the operator hosting the data channel server. Further assume that UE B belongs to a different operator (remote). The user of UE A can create and use data channel applications (steps 1-4), which can also be sent to UE B (step 5). Similarly, some other authorized part associated with UE A’s operator can create data channel applications for use by UE A (steps 1-4), which can also be sent to UE B (step 5). For simplicity, there’s no data channel server and data channel application repository depicted for UE B in Figure 6.2.10.1-1, but those could be present in a more general case. Seen from the perspective of a single UE, there are then at least four possible data channel application providers:\n1.\tThe local UE user.\n2.\tOther authorized parties associated with the local network (e.g. the local operator).\n3.\tThe remote UE user.\n4.\tOther authorized parties associated with the remote network (e.g. the remote operator).\nThe HTML web content making up a data channel application in each bootstrap data channel represents a different context of user interaction and should open in a separate tab, or some corresponding user interface construct, but the details are out of scope for this specification and left open for individual implementations. It shall be possible to use and navigate between different data channel applications from different bootstrap data channels with different stream IDs that are open simultaneously.\nTable 6.2.10.1-2 describes a mandatory mapping between stream ID and bootstrap channel data channel application content sources, as seen from a single (local) DCMTSI client in terminal, each of which shall be listed as separate \"a=dcmap\" lines with \"http\" subprotocol in SDP when the DCMTSI client in terminal supports receiving data channel application content from that source.\nTable 6.2.10.1-2: Bootstrap Data Channel Content Sources\n\nNOTE 4:\tWhen the local user has defined and stored multiple, different data channel applications in the local data channel application repository, the local network provider may provide functionality in the stream ID 0 data channel application that enables a dynamic choice of which user-defined data channel application to use with stream ID 10 in the DCMTSI call.\nNOTE 5: To help the SDP answerer's network to distinguish the two media descriptions (m= lines) containing bootstrap data channels with the same stream ID values transferred between two networks, the SDP offerer's network adds an \"a=3gpp-bdc-used-by:sender\" attribute in the media description of the bootstrap data channel(s) established between the originating UE and the terminating network, and optionally adds \"a=3gpp-bdc-used-by:receiver\" attribute in the media description of the bootstrap data channel(s) established between the originating network and the terminating UE, before it sends the SDP offer to the remote network.\nFigure 6.2.10.1-3, referring to Figure 6.2.10.1-1 and Table 6.2.10.1-2, is depicting the stream IDs used for distribution of a data channel application owned by UE A from its local data channel repository to both UE A (stream ID 10) and its remote UE B (stream ID 110).\nFigure 6.2.10.1-3 illustrates the distribution of local data channel applications to both user equipment (UE) in a telecommunication network. The figure shows how data is transmitted and received between the base station (BS) and the UE, with multiple access categories represented by different colors. The figure highlights the importance of efficient data channel allocation and management in ensuring seamless communication and optimal network performance.\nFigure 6.2.10.1-3: Distribution of local data channel application to both UE\nA DCMTSI client in terminal may include a data channel media description for the \"bootstrap\" data channels in the initial SDP offer, as described above and according to [172] [184]. A DCMTSI client in terminal may add or disable (by setting port 0, as for RTP media) additional data channel media descriptions as needed in subsequent SDP offers.\nA DCMTSI client in terminal that desires to use data channels with stream IDs from a data channel application retrieved from its local \"bootstrap\" data channel stream ID 0 or 10, shall initiate a subsequent SDP offer after the initial SDP offer, opening those data channels by adding corresponding \"a=dcmap\" and (optionally) \"a=dcsa\" lines. A DCMTSI client in terminal that retrieves a data channel application from a stream ID different than 0 or 10 (e.g. a data channel application from the peer), shall not initiate any subsequent offer to open data channels used by that data channel application.\nA data channel media description with specific loss or latency requirements should use \"a=3gpp-qos-hint\" in the SDP offer, as detailed in section 6.2.7.4. If subsequent SDP offers or answers adds data channels with more strict loss or latency requirements that cannot be met by keeping current \"a=3gpp-qos-hint\" and providing suitable SCTP \"a=dcmap\" parameters, the existing \"a=3gpp-qos-hint\" should be modified accordingly. Similarly, if subsequent SDP offers or answers closes (removes) data channels that are known to be the limiting factor for choosing the existing \"a=3gpp-qos-hint\", a more relaxed \"a=3gpp-qos-hint\" should be chosen to better fit the remaining data channels.\nAn answering DCMTSI client in terminal may accept an SDP offer with data channel as described by [172] [184].\nAn answering DCMTSI client in terminal that desires to reject the entire SCTP association for all offered data channels shall set the port to 0 (zero) on the corresponding \"m=application\" line in SDP, as described in [172]. An SCTP association that initially, or as a result of session modification, has no open data channels (\"a=dcmap\" lines) should be rejected or closed by modifying the session, setting port number to 0 (zero).\nAn answering DCMTSI client in terminal that desires to accept some offered data channels and reject others shall indicate this by removing the non-desired data channel \"a=dcmap\" and \"a=dcsa\" lines from the SDP answer, as described in [172]. The DCMTSI client in terminal accepting a data channel must also accept the corresponding, supported \"bootstrap\" data channels with stream ID <1000 (e.g. a=dcmap:0 …).\nAn offering DCMTSI client in terminal receiving an SDP answer where the data channel SCTP association is accepted (port is not 0) may use any offered stream ID that has a corresponding \"a=dcmap\" line in the SDP answer, as described by section 6.5 in [172]. Data channels with \"a=dcmap\" lines in the SDP offer that are not included in the SDP answer must be considered as rejected and shall not be used, as described by section 6.5 in [172].\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 6.2.10.1-2: Bootstrap Data Channel Content Sources",
                                    "table number": 22,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "6.2.11\tStill Images",
                            "text_content": "If still images are used in a session, then the imageseq SDP attribute shall be present in the offer of the corresponding video media session. The syntax is defined below\nimageseq = \"a=imageseq:\" PT [SP item_count]\nPT is the payload type number to which the attribute applies to as indicated by the \"m=video\" line. Optional parameters can be ignored by an MTSI client if not understood. The parameters have the following semantics:\nitem_count: provides the number of images in the corresponding image collection or image sequence. For ITT4RT, the parameter is informational from the ITT4RT-Tx client to the ITT4RT-Rx client. An ITT4RT-Rx client shall not include item_count in the SDP offer. If an ITT4RT-Rx client receives item_count in the SDP offer, it should include the same value in the response.\nAn MTSI client that supports still images shall support long and varying time distances between RTP time stamps. An MTSI client that supports still images should support the HEVC display orientation SEI message as defined in clause D.3.17 and HEVC VUI parameters. An MTSI client that supports and desires to use still images shall in the SDP offer media description of such a bitstream include the \"a=imageseq\" attribute. An MTSI client that supports still images and that receives the \"a=imageseq\" attribute in the SDP offer shall keep the \"a=imageseq\" attribute in the corresponding media description in the SDP answer.\nAn MTSI client that doesn’t support still images shall remove the image attribute in the answer. An MTSI client that sent the \"imageseq\" attribute in the SDP offer but does not receive it in the corresponding SDP answer, shall not use still images. In such case, the sender should transmit the still image as a regular continuous video stream that conforms to the requirements in 7.4.3 for an HEVC compressed video stream. If that is not possible, the sender shall initiate a session re-negotiation to remove the still image media line.\nThe \"imageattr\" attribute as specified in IETF RFC 6236 [76] shall be supported and shall indicate the image size.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "6.2.12\tThe a=3gpp-bdc-used-by SDP attribute",
                            "text_content": "The \"a=3gpp-bdc-used-by\" attribute indicates which party uses the bootstrap data channel(s) in the media description. It’s a media level attribute, and each data channel SDP media description has at most one \"a=3gpp-bdc-used-by\" attribute.\nBefore the SDP offerer's network sends the SDP offer to its peer network, it should add the \"a=3gpp-bdc-used-by\" attribute into the media description(s) to help the SDP answerer's network to distinguish m= lines containing the bootstrap data channels with the same stream ID.\n3gpp-bdc-used-by-value = bdc-used-by\nbdc-used-by = \"sender\" / \"receiver\"\n\nThe bdc-used-by parameter indicates which party uses the bootstrap data channel(s) in the media description. The following bdc-used-by values are defined:\n-\t\"sender\": It shall indicate that the stream ID values of the bootstrap data channel(s) in the corresponding media description (m= line) are mapped to data channel application contents sources as seen from the UE sending this SDP. It means that the bootstrap data channel(s) are used by the UE sending this SDP. Thus the bootstrap data channel(s) are established between the UE sending this SDP and the remote network of the UE sending this SDP and need to be terminated by the remote network of the UE sending this SDP.\n-\t\"receiver\": It shall indicate that the stream ID values of the bootstrap data channel(s) in the corresponding media description (m= line) are mapped to data channel application contents sources as seen from the UE receiving this SDP. It means that the bootstrap data channel(s) are used by the UE receiving this SDP. Thus the bootstrap data channel(s) are established between the UE receiving this SDP and the local network of the UE sending this SDP, and need to be terminated by the UE receiving the SDP.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "6.3\tSession control procedures",
                    "description": "",
                    "summary": "",
                    "text_content": "Addition and removal of media components shall be performed based on the SDP-based offer-answer model as specified in RFC 3264 [58].\nDuring session renegotiation for adding or removing media components, the SDP offerer should continue to use the same media (m=) line(s) from the previously negotiated SDP for the media components that are not being added or removed.\nAn MTSI client in terminal may support multiple media components including media components of the same media type. An MTSI client in terminal may support adding one or more media components to an on-going session which already contains a media component of the same media type. If an MTSI client in terminal needs to have multiple media components of the same media type in a single MTSI session, then the MTSI client in terminal should use the SDP content attributes as defined in [81] for identifying different media components.\nSDP examples for adding a second video stream to an ongoing video telephony session and removing a video stream from an ongoing video telephony session are given in Annex A.11.\nThe content attribute can be used in combination with the group attributes defined in RFC 3388 [48] and also in combination with the synchronization attributes defined in Clause 6.2.6, for example to identify two (or more) media components are related to each other and if synchronization is needed.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "7\tData transport",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "7.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "MTSI clients shall support an IP-based network interface for the transport of session control and media data. Control-plane signalling is sent using SIP; see TS 24.229 [7] for further details. Real-time user plane media data is sent over RTP/UDP/IP. Real-time interaction is using data channels over SCTP/DTLS/UDP/IP. Non-real-time media may use other transport protocols, for example UDP/IP or TCP/IP. An overview of the user plane protocol stack can be found in figure 4.3 of the present document.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.2\tRTP profiles",
                    "description": "",
                    "summary": "",
                    "text_content": "MTSI clients shall transport speech, video and real-time text using RTP (RFC 3550 [9]) over UDP (RFC 0768 [39]). The following profiles of RTP shall be supported for all media types:\n-\tRTP Profile for Audio and Video Conferences with Minimal Control (RFC 3551 [10]), also called RTP/AVP;\nThe following profiles of RTP shall be supported for video and should be supported for all other media types:\n-\tExtended RTP Profile for RTCP-based Feedback (RTP/AVPF) (RFC 4585 [40]), also called RTP/AVPF.\nThe support of AVPF requires an MTSI client in terminal to implement the RTCP transmission rules, the signalling mechanism for SDP and the feedback messages explicitly mentioned in the present document.\nFor a given RTP based media stream, the MTSI client in terminal shall use the same port number for sending and receiving RTP packets. This facilitates interworking with fixed/broadband access. However, the MTSI client shall accept RTP packets that are not received from the same remote port where RTP packets are sent by the MTSI client.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.3\tRTCP usage",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "7.3.1\tGeneral",
                            "text_content": "The RTP implementation shall include an RTCP implementation.\nFor a given RTP based media stream, the MTSI client in terminal shall use the same port number for sending and receiving RTCP packets. This facilitates interworking with fixed/broadband access. However, the MTSI client shall accept RTCP packets that are not received from the same remote port where RTCP packets are sent by the MTSI client.\nThe bandwidth for RTCP traffic shall be described using the \"RS\" and \"RR\" SDP bandwidth modifiers at media level, as specified by RFC 3556 [42]. Therefore, an MTSI client shall include the \"b=RS:\" and \"b=RR:\" fields in SDP, and shall be able to interpret them. There shall be an upper limit on the allowed RTCP bandwidth for each RTP session signalled by the MTSI client. This limit is defined as follows:\n-\t8 000 bps for the RS field (at media level);\n-\t6 000 bps for the RR field (at media level).\nThe RS and RR values included in the SDP answer should be treated as the negotiated values for the session and should be used to calculate the total RTCP bandwidth for all terminals in the session.\nIf the session described in the SDP is a point-to-point speech only session, the MTSI client may request the deactivation of RTCP by setting its RTCP bandwidth modifiers to zero.\nIf a MTSI client receives SDP bandwidth modifiers for RTCP equal to zero from the originating MTSI client, it should reply (via the SIP protocol) by setting its RTCP bandwidth using SDP bandwidth modifiers with values equal to zero.\nRTCP packets should be sent for all types of multimedia sessions to enable synchronization with other RTP transported media, remote end-point aliveness information, monitoring of the transmission quality, and carriage of feedback messages such as TMMBR for video and RTCP APP for speech. The RR value should be set greater than zero to enable RTCP packets to be sent when media is put on hold and during active RTP media transmission, including real-time text sessions which may have infrequent RTP media transmissions.\nPoint-to-point speech only sessions may not require the above functionalities and may therefore turn off RTCP by setting the SDP bandwidth modifiers (RR and RS) to zero. When RTCP is turned off (for point-to-point speech only sessions) and the media is put on hold, the MTSI client should re-negotiate the RTCP bandwidth with the SDP bandwidth modifier RR value set greater than zero, and send RTCP packets (i.e., Receiver Reports) to the other end. This allows the remote end to detect link aliveness during hold. When media is resumed, the resuming MTSI client should request to turn off the RTCP sending again through a re-negotiation of the RTCP bandwidth with SDP bandwidth modifiers equal to zero.\nWhen RTCP is turned off (for point-to-point speech only sessions) and if sending of an additional associated RTP stream becomes required and both RTP streams need to be synchronized, or if transport feedback due to lack of end-to-end QoS guarantees is needed, a MTSI client should re-negotiate the bandwidth for RTCP by sending an SDP with the RR bandwidth modifier greater than zero. Setting the RR bandwidth modifier greater than zero allows sending of RTCP Receiver Reports even when the session is put on hold and neither terminal is actively sending RTP media.\nNOTE:\tDeactivating RTCP will disable the adaptation mechanism for speech defined in clause 10.2.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.3.2\tSpeech",
                            "text_content": "MTSI clients in terminals offering speech should support AVPF (RFC 4585 [40]). When allocating RTCP bandwidth, it is recommended to allocate RTCP bandwidth and set the values for the \"b=RR:\" and the \"b=RS:\" parameters such that a good compromise between the RTCP reporting needs for the application and bandwidth utilization is achieved, see also Annex A.6. The value of \"trr-int\" should be set to zero or not transmitted at all (in which case the default \"trr-int\" value of zero will be assumed) when Reduced-Size RTCP (see clause 7.3.6) is not used.\nFor speech sessions it is beneficial to keep the size of RTCP packets as small as possible in order to reduce the potential disruption of RTCP onto the RTP stream in bandwidth-limited channels. RTCP packet sizes can be minimized by using Reduced-Size RTCP packets or using the parts of RTCP compound packets (according to RFC 3550 [9]) which are required by the application. RTCP compound packet sizes should be at most as large as 1 time and, at the same time, shall be at most as large as 4 times the size of the RTP packets (including UDP/IP headers) corresponding to the highest bit rate of the speech codec modes used in the session. Reduced-Size RTCP and semi-compound RTCP packet sizes should be at most as large as 1 time and, at the same time, shall be at most as large as 2 times the size of the RTP packets (including UDP/IP headers) corresponding to the highest bit rate of the speech codec modes used in the session.\nAn MTSI client using ECN for speech in RTP sessions may support the RTCP AVPF ECN feedback message and the RTCP XR ECN summary report [84].  If the MTSI client supports the RTCP AVPF ECN feedback message then the MTSI client shall also support the RTCP XR ECN summary report.\nNOTE 1:\tThis can improve the interworking with non-MTSI ECN peers.\nWhen an MTSI client that has negotiated the use of ECN and then receives RTP packets with ECN-CE marks, the MTSI client shall send application specific adaptation requests (RTP CMR [28] or RTCP-APP CMR, as defined in Subclause 10.2.1.5) and shall not send RTCP AVPF ECN feedback messages, even if RTCP AVPF ECN feedback messages were negotiated.\nNOTE 2:\tRTP CMR is mandated to be supported by any AMR or AMR-WB implementation using the RTP profile [28].\nWhen an MTSI client in terminal that has negotiated the use of ECN for speech and RTCP AVPF ECN feedback messages receives both application specific requests and RTCP AVPF ECN feedback messages, the MTSI client should follow the application specific requests for perfoming media bit rate adaptation.\nWhen an MTSI client in terminal that has negotiated the use of ECN for speech and RTCP XR ECN summary reports receives an RTCP XR ECN summary report, the MTSI client should use the RTCP XR ECN summary report as specified in [84]. If the MTSI client received and acted upon a recent application specific adaptation request, then the MTSI client shall not perform any additional rate adaptation based on the received RTCP XR ECN summary report.\nIf ANBR (see clause 10.7) is available to the MTSI client in terminal, it should use this information when performing media bitrate adaptation. In addition, a media receiving MTSI client in terminal may send RTCP-APP or RTP CMR messages for speech rate adaptation based on adaptation decisions, including ANBR information.\nFor speech, RTCP APP packets are used for adaptation (see clause 10.2). If the MTSI client determines that RTCP APP cannot be used or does not work then the MTSI client may use CMR in the AMR RTP payload [28] inband CMR or other RTCP mechanisms for adaptation.\nAn MTSI client that requests mode adaptation shall use the CMR in the AMR/AMR-WB RTP payload [28] when using the AMR or the AMR-WB codec or in the EVS payload [125] when using the EVS codec, respectively, when:\n-\tthe RTCP bandwidth is set to zero,\n-\tthe MTSI client detected that the remote end-point does not respond to adaptation requests sent with RTCP APP during the session, or\n-\tthe support for RTCP APP was not negotiated for the session.\nIf RTCP-APP was negotiated, an MTSI client that requests mode adaptation for EVS shall use RTCP-APP when the CMR in the EVS RTP payload has been disabled for the session.\nNOTE 3:\tIt is not possible to send adaptation requests if both CMR in the EVS RTP payload has been disabled and if RTCP-APP is not negotiated for the session.\nAn MTSI client using AMR or AMR-WB that requests mode adaptation when no MTSI feature tag was received (see clause 5.2 of [57]) may use the CMR in the AMR/AMR-WB RTP payload, [28], when AMR or AMR-WB is used and may use the CMR in the EVS RTP payload, [125], when EVS is used, respectively. If ECN-triggered adaptation is used and an MTSI client requests mode adaptation when no MTSI feature tag was received it should use the CMR in the AMR RTP payload, [28].\nNOTE 4:\tOther procedures by which the MTSI client determines that RTCP APP cannot be used or does not work is implementation specific.\nIf ECN-triggered adaptation is used with AVP then the RTCP APP signalling could be too slow and CMR in the AMR RTP payload [28] should be used for faster feedback.\nAn MTSI client that requests mode adaptation in combination with other codec control requests (as defined in clause 10.2.1) shall use RTCP APP.\nAn MTSI client that requests rate adaptation for unidirectional streams shall use RTCP-based adaptation signaling (RTCP APP or RTCP SR/RR) since CMR in the AMR RTP payload, [28] is not usable for unidirectional streams.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.3.3\tVideo",
                            "text_content": "MTSI clients offering video shall support AVPF (RFC 4585 [40]). The behaviour can be controlled by allocating enough RTCP bandwidth using \"b=RR:\" and \"b=RS:\" (see clause 7.3.1) and setting the value of \"trr-int\".\nMTSI clients offering video shall support transmission and reception of AVPF NACK messages, as an indication of non-received media packets. MTSI terminals offering video shall also support transmission and reception of AVPF Picture Loss Indication (PLI). The actions of an MTSI client receiving NACK or PLI to improve the situation for the MTSI client that sent NACK or PLI is defined in clause 9.3. Note that by setting the bitmask of following lost packets (BLP) the frequency of transmitting NACK can be reduced, but the repairing action by the MTSI client receiving the message can be delayed correspondingly.\nThe Temporary Maximum Media Bit-rate Request (TMMBR) and Temporary Maximum Media Bit-rate Notification (TMMBN) messages of Codec-Control Messages (CCM) [43] shall be supported by MTSI clients in terminals supporting video. The TMMBR notification messages along with RTCP sender reports and receiver reports are used for dynamic video rate adaptation. See clause 10.3 for usage and Annexes B and C for examples of bitrate adaptation.\nMTSI clients supporting video shall support Full Intra Request (FIR) of CCM [43]. A sender should ignore FIR messages that arrive within Response Wait Time (RWT) duration after responding to a previous FIR message. Response Wait Time (RWT) is defined as RTP-level round-trip time, estimated by RTCP or some other means, plus twice the frame duration.\nMTSI clients in terminals shall not use SIP INFO message, as specified in [96], for video picture fast update.\nThe usage of the AVPF and CCM feedback messages is negotiated in SDP offer/answer, see Clause 6.2.3.2. Any AVPF or CCM feedback messages that have not been agreed in the SDP offer/answer negotiation shall not be used in the session, [40].\nAn MTSI client using ECN for video in RTP sessions may support the RTCP AVPF ECN feedback message and the RTCP XR ECN summary report [84]. If the MTSI client supports the RTCP AVPF ECN feedback message then the MTSI client shall also support the RTCP XR ECN summary report.\nNOTE:\tThis can improve the interworking with non-MTSI ECN-capable peers.\nWhen an MTSI client that has negotiated the use of ECN and TMMBR receives RTP packets with ECN-CE marks, the MTSI client shall send application specific adaptation requests (TMMBR) and shall not send RTCP AVPF ECN feedback messages, even if RTCP AVPF ECN feedback messages were negotiated in addition to TMMBR.\nWhen an MTSI client that has negotiated the use of ECN for video and RTCP AVPF ECN feedback messages receives both application specific requests and RTCP AVPF ECN feedback messages, the MTSI client should follow the application specific requests for perfoming media bit rate adaptation.\nWhen an MTSI client that has negotiated the use of ECN for video and RTCP XR ECN summary reports receives an RTCP XR ECN summary report, the MTSI client should use the RTCP XR ECN summary report as specified in [84]. If the MTSI client received and acted upon a recent application specific adaptation request, then the MTSI client shall not perform any additional rate adaptation based on the received RTCP XR ECN summary report.\nIf ANBR (see clause 10.7) information is available to the MTSI client in terminal, it should use this information when performing media bitrate adaptation. In addition, a media receiving MTSI client in terminal may send RTCP feedback messages (e.g., TMMBR, TMMBN messages of CCM, etc.) for video rate adaptation based on adaptation decisions, including ANBR information.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.3.4\tReal-time text",
                            "text_content": "For real-time text, RTCP reporting should be used according to general recommendations for RTCP.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.3.5\tVoid",
                            "text_content": "",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.3.6\tReduced-Size RTCP",
                            "text_content": "MTSI clients should support the use of Reduced-Size RTCP reports [87]. A Reduced-Size RTCP packet is an RTCP packet that does not follow the sending rules outlined in RFC 3550 [9] in the aspect that it does not necessarily contain the mandated RR/SR report blocks and SDES CNAME items.\nAs specified in RFC5506 [87], a client that support Reduced-Size RTCP shall also support AVPF, see clause 7.2 An SDP offer to use Reduced-Size RTCP shall also offer using AVPF.\nWhen Reduced-Size RTCP is used, the following requirements apply on the RTCP receiver:\n-\tThe RTCP receiver shall be capable of parsing and decoding report blocks of the RTCP packet correctly even though some of the items mandated by RFC3550 [9] are missing.\n-\tAn SDP attribute \"a=rtcp-rsize\" is used to enable Reduced-Size RTCP. A receiver that accepts the use of Reduced-Size RTCP shall include the attribute in the SDP answer. If this attribute is not set in offer/answer, then Reduced-Size RTCP shall not be used in any direction.\nWhen Reduced-Size RTCP is used, an RTCP sender transmitting Reduced-Size RTCP packets shall follow the requirements listed below:\n-\tAVPF early or immediate mode shall be used according to RFC4585 [40].\n-\tThe \"a=rtcp-rsize\" attribute shall be included in the SDP offer, see Annex A.9a.\n-\tReduced-Size RTCP packets should be used for transmission of adaptation feedback messages, for example APP packets as defined in Clause 10.2 and TMMBR as defined in Clause 10.3. When regular feedback packets are transmitted, the individual packets that would belong to a compound RTCP packet shall be transmitted in a serial fashion, although adaptation feedback packets shall take precedence.\n-\tTwo or more RTCP packets should be stacked together, within the limits allowed by the maximum size of Reduced-Size RTCP packets (see clause 7.3.2) (i.e., to form a semi-compound RTCP packet which is smaller than a compound RTCP packet). The RTCP sender should not send Reduced-Size RTCP packets that are larger than the regularly scheduled compound RTCP packets.\n-\tCompound RTCP packets with an SR/RR report block and CNAME SDES item should be transmitted on a regular basis as outlined in RFC 3550 [9] and RFC 4585 [40]. In order to control the allocation of bandwidth between Reduced-Size RTCP and compound RTCP, the AVPF \"trr-int\" parameter should be used to set the minimum report interval for compound RTCP packets.\n-\tThe first transmitted RTCP packet shall be a compound RTCP packet as defined in RFC3550 [9] without the size restrictions defined in clause 7.3.2.\nThe application should verify that the Reduced-Size RTCP packets are successfully received by the other end-point. Verification can be done by implicit means, for instance the RTCP sender that sends an adaptation feedback requests is expected to detect some kind of a response to the requests in the media stream. If verification fails then the RTCP sender shall switch to the use of compound RTCP packets according to the rules outlined in RFC3550 [9].\nExamples of SDP negotiation for Reduced-Size RTCP given in Clause A.9a.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.3.7\tVideo Region-of-Interest (ROI) Signaling",
                            "text_content": "Video Region-of-Interest (ROI) consists of signalling the currently requested region-of-interest (ROI) of the video on the receiver side to the sender for appropriate encoding and transmission.\nVideo ROI is composed of three modes of signalling from an MTSI receiver to an MTSI sender in order to request a desired region of interest, and an MTSI client supporting ROI shall support at least one of these modes:\n-\t‘FECC’ mode, in which the MTSI client uses the FECC protocol based on ITU-T H.281 over H.224 [135]-[138] to signal ROI information as a sequence of ‘Pan’, ‘Tilt’, ‘Zoom’ and ‘Focus’ (PTZF) commands.\n-\t‘Arbitrary ROI’ mode, in which the MTSI receiver determines a specific ROI and signals this ROI to the MTSI sender.\n-\t‘Pre-defined ROI’ mode, in which the MTSI receiver selects one of the ROIs pre-determined by the MTSI sender and signals this ROI to the MTSI sender. In this mode, the MTSI receiver obtains the set of pre-defined ROIs from the MTSI sender during the SDP capability negotiation.\nIn the FECC mode, the ROI information shall be signaled by the MTSI client via RTP packets that carry H.224 frames using the stack IP/UDP/RTP/H.224/H.281. FECC is internal to the H.224 frame and is identified by the client ID field of the H.224 packet. The zooming to a particular region of interest is enabled by the H.281 protocol that supports the 4 basic camera movements \"PTZF\" (Pan, Tilt, Zoom, and Focus). In case of a fixed camera without pan/tilt capabilities, the pan command should be mapped to left/right movements/translations and tilt command should be mapped to up/down movements/translations over the 2D image plane. As such, a combination of PTZ commands can still allow for zooming into an arbitrary ROI.\nThe signalling of ‘Arbitrary ROI’ and ‘Pre-defined ROI’ requests uses RTCP feedback messages as specified in IETF RFC 4585 [40]. The RTCP feedback message is identified by PT (payload type) = PSFB (206) which refers to payload-specific feedback message.  FMT (feedback message type) shall be set to the value ‘9’ for ROI feedback messages.  The IANA registration information for the FMT value for ROI is provided in Annex R.1. The RTCP feedback method may involve signaling of ROI information in both of the immediate feedback and early RTCP modes.\nThe FCI (feedback control information) format for ROI shall be as follows. The FCI shall contain exactly one ROI. The ROI information is composed of the following parameters:\n-\tPosition_X - specifies the x-coordinate for the upper left corner of the ROI area covered in the original content (i.e., uncompressed captured content) in units of pixels\n-\tPosition_Y - specifies the y-coordinate for the upper left corner of the ROI area covered in the original content in units of pixels\n-\tSize_X - specifies the horizontal size of the ROI area covered in the original content in units of pixels\n-\tSize_Y - specifies the vertical size of the ROI area covered in the original content in units of pixels\n-\tROI_ID – identifies the pre-defined ROI selected by the MTSI receiver\nFor ‘Arbitrary ROI’ requests, the RTCP feedback message for ROI shall contain the parameters Position_X, Position_Y, Size_X and Size_Y. The values for the each of the parameters Position_X, Position_Y, Size_X and Size_Y shall each be indicated using two bytes. The MTSI sender shall ignore ROI requests describing regions outside the original video. The FCI for the RTCP feedback message for ‘Arbitrary ROI’ shall follow the following format:\n0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n| Position_X (h)| Position_X (l)| Position_Y (h)|  Position_Y(l)|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|   Size_X (h)  |   Size_X (l)  |   Size_Y (h)  |    Size_Y(l)  |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\nFor each two-byte indication of the Position_X, Position_Y, Size_X and Size_Y parameters, the high byte (indicated by ‘(h)’ above) shall be followed by the low byte (indicated by ‘(l)’ above), where the low byte holds the least significant bits.\nFor ‘Pre-defined ROI’ requests, the RTCP feedback message for ROI shall contain the ROI_ID parameter. The value of ROI_ID shall be acquired from the \"a=predefined_ROI\" attributes that are indicated in the SDP offer-answer negotiation (see clause 6.2.3.4 for the related SDP-based procedures). The value for the ROI_ID parameter shall be indicated using one byte. The FCI for the RTCP feedback message for ‘Pre-defined ROI’ shall follow the following format:\n0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|           all ones                            |   ROI_ID      |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\nIf ‘Arbitrary ROI’ and ‘Pre-defined ROI’ are both successfully negotiated, then the RTCP feedback message from the MTSI receiver shall conform to one of the two message formats specified above for ‘Arbitary ROI’ or ‘Pre-defined ROI’, respectively. The MTSI sender should distinguish between the two RTCP feedback message formats by parsing the first 24 bits, which is uniquely set to all ones in case of ‘Pre-defined ROI’ requests.\nThe semantics of the ROI feedback messages is independent of the payload type.\n‘Sent ROI’ involves signalling from the MTSI sender to the MTSI receiver and this helps the MTSI receiver to know the actually sent ROI corresponding to the video transmitted by the MTSI sender, i.e., which may or may not agree with the ROI requested by the MTSI receiver, but shall contain it so that the end user is still able to see the desired ROI. When ‘Sent ROI’ is successfully negotiated, it shall be signalled by the MTSI sender.\nIf the sent ROI corresponds to an arbitrary ROI (indicated via the URN urn:3gpp:roi-sent in the SDP negotiaton, see clause 6.2.3.4), the signalling of the ROI shall use RTP header extensions as specified in IETF 5285 [95] and shall carry the Position_X, Position_Y, Size_X and Size_Y parameters corresponding to the actually sent ROI. The one-byte form of the header should be used. The values for the parameters Position_X, Position_Y, Size_X and Size_Y shall each be indicated using two bytes, with the following format:\n0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|   ID  | len=7 | Position_X (h)| Position_X (l)| Position_Y (h)|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n| Position_Y (l)|   Size_X (h)  |   Size_X (l)  |   Size_Y (h)  |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|  Size_Y (l)   |                 zero padding                  |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\nThe 4-bit ID is the local identifier as defined in [95]. The length field takes the value 7 to indicate that 8 bytes follow. For each two-byte indication of the Position_X, Position_Y, Size_X and Size_Y parameters, the high byte (indicated by ‘(h)’ above) shall be followed by the low byte (indicated by ‘(l)’ above), where the low byte holds the least significant bits.\nIf the sent ROI corresponds to one of the pre-defined ROIs (indicated via the URN urn:3gpp:predefined-roi-sent in the SDP negotiation, see clause 6.2.3.4), then the signalling of the ROI shall again use the RTP header extensions and shall carry the ROI_ID parameter corresponding to the actually sent pre-defined ROI.  The one-byte form of the header should be used. The value for the ROI_ID parameter shall be indicated using one byte, with the following format:\n0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|   ID  | len=0 |     ROI_ID    |      zero padding             |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\nIn this case, the length field takes the value 0 to indicate that only a single byte follows.\n‘Arbitrary ROI’ and ‘Pre-defined ROI’ may be supported bi-directionally or uni-directionally depending on how clients negotiate to support the feature during SDP capability negotiations. For terminals with asymmetric capability (e.g. the ability to process ROI information but not detect/signal ROI information), the sendonly and recvonly attributes may be used. Terminals should express their capability in each direction sufficiently clearly such that signals are only sent in each direction to the extent that they both express useful information and can be processed by the recipient.\n‘Arbitary ROI’ and ‘Pre-defined ROI’ support may be offered at the same time, or only one of them may be offered. When both capabilities are successfully negotiated by the MTSI sender and receiver, it is the MTSI receiver’s decision to request an arbitrary ROI or one of the pre-defined ROIs at a given time. When pre-defined ROIs are offered by the MTSI sender, it is also the responsibility of the MTSI sender to detect and track any movements of the ROI, e.g., the ROI could be a moving car, or moving person, etc. and refine the content encoding accordingly.\nThe presence of ROI signalling should not impact the negotiated resolutions (based on SDP imageattr attribute) between the sending and receiving terminals. The only difference is that the sending terminal should encode only the ROI with the negotiated resolution rather than the whole captured frame, and this would lead to a higher overall resolution and better user experience than having the receiving terminal zoom in on the ROI and crop out the rest of the frame.\nThe ROI information parameters exchanged via the RTP/RTCP signalling defined above are independent of the negotiated video resolution for the encoded content. Instead, the ROI information parameters defined above take as reference the original video content, i.e., uncompressed captured video content. Therefore, no modifications or remappings of ROI parameters are necessary during any transcoding that results in changes in video resolution or during potential dynamic adaptations of encoded video resolution at the sender.\nAn MTSI sender may have to handle multiple simultaneously received ROI requests. The encoder at the MTSI sender may consider the multiple ROI requests to determine a proximity ROI that is a larger area that contains all the requested ROIs, and encode the transmitted video stream according to the proximity ROI. The encoder may iteratively adjust the proximity ROI based on the interactive additional ROI requests received from the remote clients. These additional ROI requests can be in the form of PTZF commands (using the FECC protocol) corresponding to the desired translation of the proximity ROI each MTSI receiver wishes the MTSI sender to make. Alternatively, the MTSI sender may offer the set of candidate proximity ROIs to the MTSI receivers using the pre-defined ROI signalling framework, and collect responses from the MTSI receivers to determine their preferred proximity ROIs. By considering these additional ROI requests, the MTSI sender can make a better decision on the proximity ROI to fulfil the requests of as many MTSI receivers as possible.\nWhen the MTSI sender is not able to derive a proximity ROI from the received concurrent ROI requests, the MTSI sender should transmit the full-size view of the video to those users whose ROI requests cannot be satisfied. In case of ‘Pre-defined ROI’, this can be achieved by including the full-size view of the video in the list of pre-defined ROIs. Then, the MTSI sender can transmit the full-size view of the video and also signal the corresponding ROI_ID (via the RTP header extension using ‘Sent ROI’) if a specific pre-defined ROI request cannot be satisfied. In case of ‘Arbitrary ROI’, the MTSI sender can transmit the full-size view of the video and also signal the corresponding coordinates of the full-size view (via the RTP header extension using ‘Sent ROI’) during times when an ROI request cannot be satisfied.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.3.8\tDelay Budget Information (DBI) Signaling",
                            "text_content": "RAN delay budget reporting is specified in TS 36.331 [160] for E-UTRA and TS 38.331 [163] for NR while the use of RAN delay budget reporting is specified for coverage enhancements only in E-UTRA.. RAN delay budget reporting through the use of RRC signalling to eNB / gNB allows UEs to locally adjust air interface delay. Based on the reported delay budget information, a good coverage UE on the receiving end (i.e., the UE that contains the MTSI receiver) can reduce its air interface delay, e.g., by turning off CDRX or via other means. This additional delay budget can then be made available for the sending UE (i.e., the UE that contains the MTSI sender), and can be quite beneficial for the sending UE when it suffers from poor coverage. When the sending UE is in bad coverage, it would request the additional delay from its local eNB / gNB, and if granted, it would utilize the additional delay budget to improve the reliability of its uplink transmissions in order to reduce packet loss, e.g., via suitable repetition or retransmission mechanisms, and thereby improve end-to-end delay and quality performance.\nWhile RAN-level delay budget reporting as defined in TS 36.331 [160] and TS 38.331 [163] allows UEs (i.e., MTSI sender and MTSI receiver) to locally adjust air interface delay, such a mechanism does not provide coordination between the UEs on an end-to-end basis. To alleviate this issue, this clause defines RTCP signalling to realize the following capabilities on signalling of delay budget information (DBI) across UEs: (i) an MTSI receiver can indicate available delay budget to an MTSI sender, and (ii) an MTSI sender can explicitly request delay budget from an MTSI receiver.\nMore specifically, the RTCP-based signalling of DBI is composed of a dedicated RTCP feedback (FB) message type to carry available additional delay budget during the RTP streaming of media, signalled from the MTSI receiver to the MTSI sender. In addition, the defined RTCP feedback message type may also be used to carry requested additional delay budget during the RTP streaming of media, signalled from the MTSI sender to the MTSI receiver.\nA corresponding dedicated SDP parameter on the RTCP-based ability to signal available or requested additional delay budget during the IMS/SIP based capability negotiations is also defined, as described in sub-clause 6.2.8.\nSuch RTCP-based signaling of DBI can also be used by an MTSI receiver to indicate delay budget availability created via other means such as jitter buffer size adaptation as mentioned in clause 8.2.1.\nThe signalling of available or requested additional delay budget information (DBI) shall use RTCP feedback messages as specified in IETF RFC 4585 [40]. The RTCP feedback message is identified by PT (payload type) = RTPFB (205) which refers to RTP-specific feedback message. FMT (feedback message type) shall be set to the value '10' for delay budget information (DBI). The RTCP feedback method may involve signalling of available or requested additional delay budget in both of the immediate feedback and early RTCP modes.\nAs such, the RTCP feedback message shall be sent from the MTSI receiver to the MTSI sender to convey to the sender the available additional delay budget from the perspective of the receiver. The recipient UE of the RTCP feedback message (i.e., the UE containing the MTSI sender) may then use this information in determining how much delay budget it may request from its eNB / gNB over the RAN interface, e.g. by using RRC signalling based on UEAssistanceInformation as defined in TS 36.331 [160] and TS 38.331 [163].\nThe FCI (feedback control information) format shall be as follows. The FCI shall contain exactly one instance of the available additional delay budget information, composed of the following parameters:\n-\tAvailable additional delay budget delay - specified in milliseconds (16 bits)\n-\tSign 's' for the additional delay budget delay and whether this is positive or negative– specified as a Boolean (1 bit)\n-\tQuery 'q' for additional delay budget – specified as a Boolean (1 bit)\nThe sign value, 's' may be positive, indicated by ‘1’ or negative, indicated by ‘0’. Essentially, when the additional delay parameter takes on a positive value, the UE indicates that there is additional delay budget available. In case the additional delay parameter takes on a negative value, the UE indicates that the available delay budget has been reduced. A sequence of RTCP feedback messages may be sent by the UE to report on the additional delay budget availability in increments.\nWhen the MTSI receiver sends RTCP feedback messages indicating the available delay budget for the received RTP stream, the query parameter shall be to be set to '0'. When the MTSI sender sends RTCP feedback messages indicating the requested delay budget for the RTP stream sent from the MTSI sender to the MTSI receiver, the query parameter shall be set to '1'. In this case, the value of delay indicates the additional delay budget requested by the sender of the RTCP feedback message (i.e., the MTSI sender) for the RTP stream sent from the MTSI sender to the MTSI receiver.\nThe FCI for the proposed RTCP feedback message shall follow the following format where (i) 's' stands for the single-bit message on the sign of the additional delay parameter and (ii) 'q' stands for the single-bit message on query:\n0                1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|            delay              |s|q|     zero padding          |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\nThe high byte of delay shall be followed by the low byte, where the low byte holds the least significant bits.\nAnnex V presents example signalling flows on RAN delay budget reporting usage for voice in MTSI with and without DBI signalling.\nAn MTSI receiver shall not indicate available delay budget to an MTSI sender via DBI signalling more frequently than once every T_DBI seconds, provided that the necessary amount of RTCP bandwidth is available. If an MTSI receiver indicates available delay budget to an MTSI sender via DBI signalling, this shall mean that the indicated delay budget amount is available to the MTSI sender for at least the duration of T_DBI seconds. An MTSI sender shall not request delay budget from an MTSI receiver via DBI signalling more frequently than once every T_DBI seconds. T_DBI shall be set to a value between 1 – 3 seconds.\nNOTE:\tThe requirement on how to set the exact value of T_DBI is FFS.\nTiming-wise, it is possible that DBI signalling may happen concurrently or asynchronously between the MTSI sender and MTSI receiver, i.e., the MTSI receiver may indicate available delay budget to the MTSI sender, while the MTSI sender may request delay budget from an MTSI receiver.\nIf the MTSI sender receives available delay budget information from an MTSI receiver via DBI signaling, this delay budget is available for its uplink over the duration of at least T_DBI seconds.  Thus, if an MTSI receiver has already indicated available delay budget to the MTSI sender via DBI signalling, reception of a DBI request from the MTSI sender during any time within the time window of T_DBI seconds shall not trigger any further DBI signalling from the MTSI receiver to the MTSI sender on the available delay budget at any time sooner than T_DBI seconds following the last indication of the available delay budget.\nOnce the period of T_DBI seconds following the last indication of the available delay budget is over, if the available delay budget has changed, the MTSI receiver shall inform the MTSI sender on the new delay budget availability (as a relative value as explained above) using DBI signalling. If the MTSI sender does not receive any new DBI signalling on the available delay budget from the MTSI receiver after the T_DBI second period is over, it shall mean the continued availability of the same amount of delay budget indicated to the MTSI sender via the latest DBI signalling.\nLikewise, if the MTSI sender no longer needs the additional delay budget it has requested earlier or has a delay budget request that is different from what it had requested earlier, it shall inform the MTSI receiver about the new delay budget request (as a relative value as explained above) via DBI signalling. If the MTSI receiver does not receive any new DBI signalling on the requested delay budget from the MTSI sender after the T_DBI second period is over, this shall mean that the MTSI sender is still requesting the same amount of delay budget indicated to the MTSI receiver via the latest DBI signalling.\nIt should be noted that the delayBudgetReportingProhibitTimer parameter for RAN delay budget reporting as defined in TS 36.331 [160] for E-UTRA and TS 38.331 [163] for NR may take any of the values among 0, 0.4, 0.8, 1.6, 3, 6, 12 and 30 seconds, as set by the local eNB / gNB. Hence, if an MTSI receiver is to provide additional delay budget by locally adjusting air interface delay via RAN delay budget reporting (as supposed to adjusting its jitter buffer size, which can be set independently from the delayBudgetReportingProhibitTimer parameter), the frequency of its signalling to eNB / gNB is subject to the delayBudgetReportingProhibitTimer parameter. Likewise, when an MTSI sender requests delay budget from its local eNB / gNB via RAN delay budget reporting, the frequency of this signalling is subject to the delayBudgetReportingProhibitTimer parameter. Therefore, it should be observed that end-to-end delay adaptation through the use of RAN delay budget reporting and DBI signalling may be limited when the eNB / gNB sets the delayBudgetReportingProhibitTimer parameter to a large value. In particular, if delayBudgetReportingProhibitTimer is set to a value larger than T_DBI seconds, then DBI signaling cannot be used in conjunction with RAN delay budget reporting.\nProvided that the delayBudgetReportingProhibitTimer configurations over the uplink and downlink access networks of the respective MTSI sender and MTSI receiver both do not exceed 3 seconds, T_DBI should be set to a value greater than or equal to the maximum of the delayBudgetReportingProhibitTimer configurations over uplink and downlink access networks. In case an MTSI receiver adjusts its jitter buffer size and does not use RAN delay budget reporting, delayBudgetReportingProhibitTimer parameter for downlink may be considered to be set to zero as part of this recommendation. Typical delayBudgetReportingProhibitTimer configurations will be in the values of 0, 0.4, 0.8, 1.6 seconds, so setting T_DBI to 1.6 seconds is recommended to operate with typical delayBudgetReportingProhibitTimer configurations.\nWhen transcoding is present on the media path between the MTSI sender and MTSI receiver in the packet-switched domain, the end-to-end delay and quality performance enhancements realized by DBI signalling are still applicable as long as the media gateway in between passes the RTCP feedback messages carrying DBI. There may be a possible reduction however on the end-to-end performance gains, due to the additional delays incurred from transcoding.\nWhen transcoding is present on the media path between an MTSI sender in the packet-switched domain and a media receiver in the circuit-switched domain, the end-to-end delay and quality performance enhancements realized by DBI signalling may still be applicable if the media gateway is able to offer additional delay budget, e.g., by extending its jitter buffer size, while also considering the fixed delay over the circuit-switched domain. In this case, the media gateway may receive delay budget request from the MTSI sender via DBI signalling, and the media gateway may further inform the MTSI sender about available delay budget via DBI signalling (note that no DBI signalling happens in the circuit switched domain).\nIn case of multiparty conferencing, DBI signalling may also be useful to improve end-to-end delay and quality performance of the RTP streams exchanged between the clients and conferencing server. In particular, an MSMTSI client (as defined in Annex S) and an MSMTSI MRF (as defined in Annex S) may negotiate DBI signalling using the SDP based procedures described in sub-clause 6.2.8. An MSMTSI client may then use DBI signalling to indicate available additional delay budget for the RTP streams received from the MSMTSI MRF and also request additional delay budget for the RTP streams it sends to the MSMTSI MRF. Likewise, an MSMTSI MRF may then use DBI signalling to indicate available additional delay budget for the RTP streams received from the MSMTSI client and also request additional delay budget for the RTP streams it sends to the MSMTSI client.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "7.4\tRTP payload formats for MTSI clients",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "7.4.1\tGeneral",
                            "text_content": "This clause specifies RTP payload formats for MTSI clients, except for MTSI media gateways that is specified in clause 12.3.2, for all codecs supported by MTSI in clause 5.2. Note that each RTP payload format also specifies media type signalling for usage in SDP.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.4.2\tSpeech",
                            "text_content": "When the AMR codec is selected in the SDP offer-answer negotiation the AMR payload format [28] shall be used between RTP termination points.\nWhen the AMR-WB is selected in the SDP offer-answer negotiation the AMR-WB payload format [28] shall be used between RTP termination points.\nNOTE 1:\tIt may happen that EVS AMR-WB IO encoded speech is transported using the AMR-WB payload format between an EVS-capable MTSI client and a legacy (not EVS capable) MTSI client. This may also happen after SRVCC (see Clause 12.3.4) when an EVS-capable MTSI client sends EVS AMR-WB IO encoded speech in EVS payload format to the ATGW and the ATGW then re-packetizes the EVS AMR-WB IO packet into AMR-WB payload format without performing transcoding of the media.\nWhen the EVS codec is selected in the SDP offer-answer negotiation the EVS payload format [125] shall be used between RTP termination points.\nNOTE 2:\tAfter SRVCC when a CS UE (not EVS capable) sends AMR-WB encoded speech to the ATGW, it may happen that the ATGW then re-packetizes this AMR-WB packet into the EVS payload format without performing transcoding of the media, see clause 12.3.4.\nIn case of ambiguity the present specification shall take precedence over RFC 4867 [28].\nMTSI clients (except MTSI MGW) shall support both the bandwidth-efficient and the octet-aligned payload format of the AMR/AMR-WB payload format [28]. The bandwidth-efficient payload format shall be preferred over the octet-aligned payload format.\nWhen sending AMR or AMR-WB encoded media, the RTP Marker Bit shall be set according to Section 4.1 of the AMR/AMR-WB payload format [28]. When sending EVS encoded media, the RTP Marker Bit shall be set as described in the EVS payload format [125].\nThe MTSI clients (except MTSI MGW) should use the SDP parameters defined in table 7.1 for the session. For all access technologies, and for normal operating conditions, the MTSI client should encapsulate the number of non-redundant (a.k.a. primary) speech frames in the RTP packets that corresponds to the ptime value received in SDP from the other MTSI client, or if no ptime value has been received then according to \"Recommended encapsulation\" defined in table 7.1. The MTSI client may encapsulate more non-redundant speech frames in the RTP packet but shall not encapsulate more than 4 non-redundant speech frames in the RTP packets. The MTSI client may encapsulate any number of redundant speech frames in an RTP packet but the length of an RTP packet, measured in ms, shall never exceed the maxptime value.\nNOTE 3:\tThe terminology \"non-redundant speech frames\" refers to speech frames that have not been transmitted in any preceding packet.\nTable 7.1: Encapsulation parameters (to be used as defined above)\n\nNOTE 4:\tIt is possible to send only redundant speech frames in one RTP packet.\nWhen the radio access bearer technology is not known to the MTSI client, the default encapsulation parameters defined in Table 7.1 shall be used.\nWhen the AMR/AMR-WB payload formats are used, the bandwidth-efficient payload format should be used unless the session setup concludes that the octet-aligned payload format is the only payload format that all parties support. The SDP offer shall include an RTP payload type where octet-align=0 is defined or where octet-align is not specified and should include another RTP payload type with octet-align=1. MTSI client offering wide-band speech shall offer these parameters and parameter settings also for the RTP payload types used for wide-band speech.\nFor examples of SDP offers and answers, see annex A.\nThe RTP payload format for DTMF events ís described in Annex G.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 7.1: Encapsulation parameters (to be used as defined above)",
                                    "table number": 23,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "7.4.3\tVideo",
                            "text_content": "The following RTP payload formats shall be used:\n-\tH.264 () video codec RTP payload format according to RFC 6184 [25], where the interleaved packetization mode shall not be used. Receivers shall support both the single NAL unit packetization mode and the non-interleaved packetization mode of RFC 6184 [25], and transmitters may use either one of these packetization modes.\n-\tH.265 (HEVC) video codec RTP payload format according to [120].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.4.4\tReal-time text",
                            "text_content": "The following RTP payload format shall be used:\n-\tT.140 text conversation RTP payload format according to RFC 4103 [31] including the updates from RFC 9071 [185] when the negotiation for support of multiparty real-time text is successful.\nReal-time text shall be the only payload type in its RTP stream because the RTP sequence numbers are used for loss detection and recovery. The redundant transmission format shall be used for keeping the effect of packet loss low.\nMedia type signalling for usage in SDP is specified in section 10 of RFC 4103 [31], section 3 of RFC 4102 [49] and section 2.3 of RFC 9071 [185].\nNegotiation of support for mixing real-time text for multiparty-aware MTSI clients shall be done by using \"a=rtt-mixer\" to SDP attribute specified in RFC 9071. When the negotiation fails in a multiparty call, mixing for multiparty unaware endpoints shall be done by a mixer capable of handling multiparty mixing of real-time text as specified in RFC 9071 [185].\nNote: multiparty unaware endpoints is define in RFC9071[185].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.4.5\tCoordination of Video Orientation",
                            "text_content": "Coordination of Video Orientation consists in signalling of the current orientation of the image captured on the sender side to the receiver for appropriate rendering and displaying. When CVO is succesfully negotiated it shall be signalled by the MTSI client. The signalling of the CVO uses RTP Header Extensions as specified in IETF RFC 5285 [95]. The one-byte form of the header should be used. CVO information for a 2 bit granularity of Rotation (corresponding to urn:3gpp:video-orientation) is carried as a byte formatted as follows:\nBit#\t7\t6\t5\t4\t3\t2\t1\t0(LSB)\n\tDefinition\t0\t0\t0\t0\tC\tF\tR1\tR0\n\nWith the following definitions:\nC = Camera: indicates the direction of the camera used for this video stream. It can be used by the MTSI client in receiver to e.g. display the received video differently depending on the source camera.\n0: Front-facing camera, facing the user. If camera direction is unknown by the sending MTSI client in the terminal then this is the default value used.\n1: Back-facing camera, facing away from the user.\nF = Flip: indicates a horizontal (left-right flip) mirror operation on the video as sent on the link.\n0: No flip operation. If the sending MTSI client in terminal does not know if a horizontal mirror operation is necessary, then this is the default value used.\n1: Horizontal flip operation\nR1, R0 = Rotation: indicates the rotation of the video as transmitted on the link. The receiver should rotate the video to compensate that rotation. E.g. a 90° Counter Clockwise rotation should be compensated by the receiver with a 90° Clockwise rotation prior to displaying.\nTable 7.2: Rotation signalling for 2 bit granularity\n\nCVO information for a higher granularity of Rotation (corresponding to urn:3GPP:video-orientation:6) is carried as a byte  formatted as follows:\nBit#\t7\t6\t5\t4\t3\t2\t1\t0(LSB)\nDefinition\tR5\tR4\tR3\tR2\tC\tF\tR1\tR0\n\nwhere C and F are as defined above and the bits R5,R4,R3,R2,R1,R0 represent the Rotation, which indicates the rotation of the video as transmitted on the link. Table 7.3 describes the rotation to be applied by the receiver based on the rotation bits.\nTable 7.3: Rotation signalling for 6 bit granularity\n\nThe sending MTSI client in the terminal using a camera as source and equipped with appropriate orientation sensor(s) should compute the image orientation from the sensor(s) that indicate the rotation of the device with respect to the default camera orientation. It is recommended that appropriate filtering on the time and angular domain is applied onto the sensor’s indications to prevent a \"ping-pong\" effect between two quantization levels in the case where the measured value is fluctuating between two quantization levels. The sending MTSI client may choose to send any orientation information not necessarily based on orientation sensor(s).\nFor higher granularity CVO, a terminal shall send a report at least as frequently as it would have sent a 2-bit report. A report interval shorter than this requirement should only be used when the report contains a value that differs significantly from the previous report, i.e. after taking noise removal, sensor precision, and any other relevant factors into account.\nThe rotation is a quantized value of the angle between the earth vertical projected onto the plane of the image as sent on the link and the image vertical. The earth vertical is a radial line starting at the center of the earth and passing through the depicted scene while the image vertical is a line passing from the middle of the bottom to the middle of the top of the image. For the case where the camera is pointing vertical or nearly vertical, the last valid value used for rotation should be used. In case there is no previous valid value, a suitable default value should be chosen.\nWhen compensating for both rotation and flip at the receiving MTSI client, the operations shall be performed in the order of rotation compensation followed by flipping, because the order of flip and rotation operations matters when rotating 90° or 270°. The sending MTSI client shall correspondingly, when the transmitted image is both flipped and rotated, include information in the RTP Header Extension as if the transmitted image on the link was first flipped (mirrored) and then rotated, using an image perceived as upright (regardless if using portrait or landscape format) as starting point.\nThe MTSI client shall add the payload bytes as defined in this clause onto the last RTP packet in each group of packets which make up a key frame (I-frame or IDR frame in H.264 (AVC), or an IRAP picture in H.265 (HEVC)). The MTSI client may also add the payload bytes onto the last RTP packet in each group of packets which make up another type of frame (e.g. a P-Frame) only if the current value is different from the previous value sent.\nIf this is the only header extension present, a total of 8 bytes are appended to the RTP header, and the last packet in the sequence of RTP packets will be marked with both the marker bit and the Extension bit, as defined in RFC3550 [9].\nWhen CVO is not succesfully negotiated the MTSI clients are said to be in non-CVO operation. The sender in non-CVO operation should operate as follows to compensate for image rotation and potential misalignment.\nIf the receiver has explicitly indicated support for both [x,y] and [y,x] resolutions via the imageattr attribute during SDP negotiation (see clause 6.2.3.3 and an example in clause A.4.6), and when video is negotiated for the session, the sender should rotate the image prior to video encoding and compensate image rotation by changing the signaled Sequence Parameter Set in the video bitstream between [x,y] and [y,x] as applicable.\nIf the receiver has not explicitely indicated support for both [x,y] and [y,x] resolutions via the imageattr attribute during SDP negotiation, then the sender should apply rotation/padding/cropping/resizing prior to video encoding as the sender considers appropriate while keeping the resolution unchanged. As for CVO operation, the sending MTSI client in the terminal using a camera as source and equipped with appropriate orientation sensor(s) should compute the image orientation from the output of the sensor(s) that indicates the rotation of the device with respect to the default camera orientation. It is recommended that appropriate filtering on the time and angular domain is applied onto the sensor’s indications to prevent a \"ping-pong\" effect in the case where the measured value is fluctuating between two quantization levels. The decision of MTSI client transmitting video to change the image size needs not necessarily be based on input from orientation sensor(s).\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 7.2: Rotation signalling for 2 bit granularity",
                                    "table number": 24,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 7.3: Rotation signalling for 6 bit granularity",
                                    "table number": 25,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "7.4.6\tRTP Retransmission",
                            "text_content": "AVPF NACK messages are used by MTSI clients to indicate non-received RTP packets for video (see clause 7.3.3). The RTP Retransmission Payload Format RFC 4588 [140] supports retransmission of lost packets based on NACK feedback. Retransmission is useful if retransmitted packets arrive within the end to end delay requirements of the system. It is suitable for low RTT networks with relatively low observed packet loss [142]. If support for RTP retransmission payload format has been negotiated, the receivers shall support handling of RTP retransmission packets defined in RFC 4588 sent using SSRC multiplexing. Similarly, senders shall use RTP retransmission packets defined in RFC 4588 for packets it retransmits using SSRC multiplexing.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.4.7\tForward Error Correction (FEC)",
                            "text_content": "Forward Error Correction (FEC) can provide effective error resiliency under certain packet loss and network RTT conditions [142].  If support for FEC is negotiated, then use of a separate SSRC multiplexed FEC stream with the RTP payload defined in [141] shall be supported at both the receiver and the sender. The receiver can demultiplex the incoming stream by the SSRC field and map it to the source by using the ssrc-group mechanism defined in RFC 5956 [143]. The systematic FEC scheme defined in [141] is a flexible parity FEC scheme that supports various signalling of source packets used to generate the parity packets.\nOther types of FEC schemes may be supported. The use of a particular FEC sheme shall be negotiated before it is used.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.4.8\tStill Images",
                            "text_content": "The RTP payload format for HEVC as defined in [120] shall be used for the delivery of images and image sequences.\nNOTE 1: The time distance between RTP timestamps for HEVC encoded images/image sequence may be very varying and very long compared to typical HEVC encoded video, in the order of several seconds.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "7.5\tMedia flow",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "7.5.1\tGeneral",
                            "text_content": "This clause contains considerations on how to use media in RTP, packetization guidelines, and other transport considerations. The use of ECN for RTP sessions is also described for speech in this clause.\nThe general handling of bitrate variations is described in clause 7.5.5.1. Media specific handling is described in clause 7.5.5.2 for video.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.5.2\tMedia specific",
                            "text_content": "This clause describes how the speech media should be packetized during a session. It includes definitions both for the cases where the access type is known and one default operation for the case when the access type is not known.\nRequirements for transmission of DTMF events are described in Annex G.\n7.5.2.1.2.1\tGeneral\nWhen the radio access bearer technology is not known to the MTSI client, the default encapsulation parameters defined in Table 7.1 shall be used.\nThe codec modes and the other codec parameters (mode-change-capability, mode-change-period, mode-change-neighbor, etc), applicable for each session, are negotiated as described in clauses 6.2.2.2 and 6.2.2.3.\nWhen transmitting AMR or AMR-WB encoded media, codec mode changes should be aligned to every other frame border and should be performed to one of the neighbouring codec modes in the negotiated mode set, except for a MTSI media gateway, see clause 12.3.1.1. In the transmitted media, the highest codec mode of the negotiated mode-set (or of all modes, if no mode-set was included in the SDP answer) should be used, unless it is restricted by the most recently received CMR. In the received media, codec mode changes shall be accepted at any frame border and to any codec mode within the negotiated mode set.\nThe bandwidth-efficient payload format should be used for AMR and AMR-WB encoded media unless the session setup determines that the octet-aligned payload format must be used.\nThe adaptation of codec mode, aggregation and redundancy is defined in clause 10.2.\n7.5.2.1.2.2\tCodec Mode Requests\nFor AMR and AMR-WB, if the highest mode within the negotiated mode-set is acceptable for media reception, then the MTSI client in terminal shall either indicate that no codec mode request is present (i.e. value 15) or shall indicate the CMR value corresponding to the highest mode within the negotiated mode-set in the CMR bits in the AMR and/or AMR-WB payload format [28] in every outgoing RTP packet. Otherwise the highest acceptable mode within the negotiated mode-set shall be sent in CMR in each outgoing RTP packet.\nNOTE 1:\tThe MTSI client sending CMR values relies on that the remote media-sender will not send media with higher codec modes than requested by CMR, after some reaction time (round trip delay). However the remote party can send with lower modes within the negotiated mode-set, because there could be other mode limiting effects in the voice path.\nFor AMR and AMR-WB, the MTSI client shall accept that the remote party sends with lower modes within the negotiated mode-set than requested by the CMR. The MTSI client shall follow each received CMR and shall not use higher modes in media-encoding than indicated by the most recently received CMR, while lower modes within the negotiated mode-set are allowed any time.\nNOTE 2:\tThe codec modes in media-sending and media-receiving direction may differ in general. Received CMR values have no influence on or relation to received media-frames.\nThe MTSI client shall accept Codec Mode Requests signalled with the CMR bits in the AMR and/or AMR-WB payload format in every incoming RTP packet.\nFor EVS, the CMR related procedures in subclause A.2.2.1.1 of TS 26.445 [125] apply.\nIf the MTSI client supports RTCP-APP packets, it shall also accept CMR in every incoming RTCP-APP packet.\nThe MTSI client shall follow each received CMR as soon as possible.\nNOTE 3:\tThere is no upper limit defined for the reaction time; it is expected that typically the media-sender reacts within less than 40ms after the reception of a new CMR value.\n7.5.2.1.2.3\tFrame aggregation and redundancy\nThe MTSI client should send one speech frame encapsulated in each RTP packet unless the session setup or adaptation request defines that the other MTSI client wants to receive another encapsulation variant.\nThe MTSI client should request to receive one speech frame encapsulated in each RTP packet but shall accept any number of frames per RTP packet up to the maximum limit of 12 speech frames per RTP packet.\nFor application-layer redundancy, see clause 9.2.\nUse default operation as defined in clause 7.5.2.1.2.\nNOTE:\tThe RLC PDU sizes defined in TR 25.993 [33] have been optimized for the codec modes, payload formats and frame encapsulations defined in the default operation in clause 7.5.2.1.2.\nUse default operation as defined in clause 7.5.2.1.2, except that the MTSI client in terminal\n-\tshould send two speech frames encapsulated in each RTP packet unless the session setup or adaptation request defines that the other PS end-point want to receive another encapsulation variant;\n-\tshould request receiving two speech frames encapsulated in each RTP packet but shall accept any number of frames per RTP packet up to the maximum limit of 12 speech frames per RTP packet.\nUse default operation as defined in clause 7.5.2.1.2, except that the MTSI client in terminal:\n-\tshould send 0, 1, 2, 3 or 4 non-redundant speech frames encapsulated in each RTP packet unless the session setup or adaptation request defines that other PS end-point want to receive another encapsulation variant;\n-\tshould request receiving 1 to 4 speech frames in each RTP packet but shall accept any number of frames per RTP packet up to the maximum limit of 12 speech frames per RTP packet;\n-\tmay use application layer redundancy, in which case the MTSI client in terminal may encapsulate up to 12 speech frames in each RTP packet, with a maximum of four non-redundant speech frames.\nTo avoid congestion on the link and to improve inter-working with CS GERAN when AMR or AMR-WB is used and when more than one codec mode is allowed in the session, the MTSI client in terminal should limit the initial codec mode (ICM) to one of the lowest codec modes for an Initial Waiting Time from the beginning of the RTP stream, or until it receives one of the following:\n-\ta frame-block with rate control information; or:\n-\tan RTCP message with rate control information; or:\n-\treception quality feedback information, e.g. PLR or jitter in RTCP Sender Reports or Receiver Reports, indicating that the currently used codec mode is too high for the current operating condition.\nThe value for the Initial Waiting Time is 600 ms when ECN is not used and 500 ms when ECN is used, unless configured differently by the MTSI Media Adaptation Management as described in Clause 17.\nThe rate control information can either be: a CMR with a value other than ‘15’ in the RTP payload; or a CMR with a value other than ‘15’ in an RTCP_APP message (see Clause 10.2.1).\nNOTE 1:\tA CMR with a value of ‘15’ means that no mode request is present [28].\nIf no rate control information is received within the Initial Waiting Time, then the sending MTSI client in terminal should gradually increase the codec mode from the ICM towards the highest codec mode allowed in the session. While not detecting poor transmission performance or not receiving rate control information, the sending MTSI client in terminal should use step-wise up-switch to avoid introducing congestion during the upwards adaptation. The step-wise up-switch should be performed by switching to the next higher codec mode in the allowed mode set and then waiting for an Initial Up-switch Waiting Time before each subsequent up-switch until the first down-switch occurs.\nThe value for the Initial Up-switch Waiting Time is 600 ms when ECN is not used and 500 ms when ECN is used, unless configured differently by the MTSI Media Adaptation Management as described in Clause 17.\nThe following rules can be used for determining the ICM:\n-\tIf 1 codec mode is included in the mode-set then this should be the ICM.\n-\tIf 2 or 3 codec modes are included in the mode-set then the ICM should be the codec mode with the lowest rate.\n-\tIf 4 or more codec modes are included in the mode-set then the ICM should be the codec mode with the 2nd lowest rate.\nNOTE 2:\tWithout ECN, the Initial Waiting Time needs to be long enough to allow the receiver to collect relilable statistics for the adaptation, e.g. for PLR-triggered or jitter-triggered adaptation. With ECN, a congested network can immediately mark IP packets with ECN-CE, which allows the ECN-triggered adaptation react sooner. The Initial Waiting Time can therefore be shorter when ECN is used. The same applies for the Initial Up-switch Waiting Time.\nUse the default operation as defined in Clause 7.5.2.1.2.\nWhen the EVS AMR-WB IO mode is used from the start of the session, the Initial Codec Mode (ICM) should be selected as defined in Clause 7.5.2.1.6 for AMR-WB.\nWhen EVS Primary mode is used from the start of the session, the following principles apply for the selection of the Initial Codec Mode bit-rate (ICMbr):\n-\tIf GBR is known and if GBR is less than MBR, the ICMbr should be aligned with the GBR or should be lower than GBR.\nWhen EVS Primary mode is used from the start of the session, the Initial Codec Mode audio bandwidth (ICMab) should be the highest audio bandwidth negotiated for the Initial Codec Mode bit-rate (ICMbr).\nAn MTSI client may support dual-mono operation for EVS.\nThe packetization of dual-mono for EVS is described in [125]. When the EVS Primary mode is used for dual-mono encoding, the Header-full format must be used for all RTP packets.\nWhen offering dual-mono for an RTP payload type number, the number of channels is set to 2, see SDP example in Annex A.14.\nAn MTSI client should follow general strategies for error-resilient coding (segmentation) and packetization as specified by each codec [24][119] and RTP payload format [25][120] specification. Further guidelines on how the video media data should be packetized during a session are provided in this clause.\nCoded pictures should be encoded into individual segments:\n-\tFor H.264 (AVC), a slice corresponds to such a segment.\n-\tFor H.265 (HEVC), a slice segment corresponds to such a segment.\nEach individual segment should be encapsulated in one RTP packet. Each RTP packet should be smaller than the Maximum Transfer Unit (MTU) size.\nNOTE 1:\tUnnecessary video segmentation, e.g. within RTP packets, may reduce coding efficiency.\nNOTE 2:\tRTP packet fragmentation, e.g. across UDP boundaries, may decrease transport overhead and reduce error robustness. Hence, packet size granularity is a trade-off between error robustness and overhead that may be tuned according to bearer access characteristics if available.\nNOTE 3:\tIn most cases, the MTU-size has a direct relationship with the bearer of the radio network.\nReal-time text is intended for human conversation applications. Text shall not be transferred with higher rate than 30 characters per second (as defined for cps in section 6 of RFC 4103 [31]). A text-capable MTSI client shall be able to receive text with cps set up to 30 from an MTSI client in terminal. A text-capable MTSI client may be able to receive text with cps set up to 90 in order to be prepared to handle text received in a multiparty session, with multiple parties sending at a rate of 30 characters per second. This shall be indicated by the cps parameter in the sdp fmtp attribute for the \"t140\" format.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.5.3\tMedia synchronization",
                            "text_content": "RTCP SR shall be used for media synchronization by setting the NTP and RTP timestamps according to RFC 3550 [9]. To enable quick media synchronization when a new media component is added, or an MTSI session is initiated, the RTP sender should send RTCP Sender Reports for all newly started media components as early as possible.\nNOTE:\tAn MTSI sender can signal in SDP that no synchronization between media components is required. See clause 6.2.6 and clause A.7.\nThe media synchronization requirements for real-time text are relaxed. A synchronization error between text and other media of a maximum of 3 seconds is accepted. Since this is longer than the maximum accepted latency, no specific methods need to be applied to assure to meet the requirement\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.5.4\tECN usage in RTP sessions",
                            "text_content": "Once the ECN negotiation has been completed as defined in [84], then only ECT(0) shall be used when marking packets with ECT, [83]. When ECN is used for an RTP stream then the sending MTSI client shall mark every packet with ECT until the end of the session or until the session is re-negotiated to no longer use ECN. The leap-of-faith method is used for the ECN initiation.\nHandling of ECN Congestion Experience (ECN-CE) marked packets is described in clause 10.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "7.5.5\tHandling of bit-rate variations",
                            "text_content": "An MTSI client in terminal using variable bitrate encoding shall ensure for speech, and should ensure for video, that the transmitted bandwidth does not exceed the negotiated bandwidth (b=AS) nor the QoS bandwidth parameters (MBR, GBR) for the bearer, if defined and known. This can, in general, be done in two ways: either by controlling the bit-rate used for encoding each media frame or by controlling when the generated packets are transmitted.\nNOTE 1:\tThis bit-rate control is not to be confused with rate adaptation, which is described in clause 10. The main purpose of the bitrate control is to reduce the risk that policing functions in the network drop media packets since the bandwidth of packets is temporarily exceeding the allowed bandwidth, which is typically configured in a static fashion. Rate adaptation is instead used to ensure that the used bandwidth is sufficiently low to avoid packet losses and extended delays when operating conditions change.\nNOTE 2:\tControlling when packets are transmitted is called \"packet pacing\". The drawback with packet pacing is the increase of end-to-end delay. Excessive use of packet pacing can lead to not fulfilling the service requirements defined in TS 22.105 [34]. Packet pacing therefore needs to be used with care.\nThe method to control the encoding bitrate and/or the transmission of packets is left for the discretion of the implementation. However, the average bandwidth of transmitted packets shall be calculated over a sliding window that is no longer than T seconds. Different media types may use different window lengths. The default window length T is 2 seconds if nothing else is specified below.\nThe bitrate control ensures that the average bandwidth of transmitted media packets does not exceed the maximum allowed bandwidth in the sending direction.\nThe maximum allowed bandwidth for the sending direction is the smaller of:\n-\tThe b=AS bandwidth,\n-\tThe MBR for the bearer, after compensating for the RTCP bandwidth, if known.\nVideo encoders use variable bitrate encoding to ensure a sufficiently low average bit-rate, which allow temporarily encoding a few frames at high bit-rate to match the video content with high motion activity or complex scenes, or to send an Intra frame, e.g. , when a Full Intra Request (FIR) is received. The bitrate control should ensure that the average bandwidth of transmitted media packets does not exceed the maximum allowed bandwidth in the sending direction.\nThe bit-rate control requires managing the following properties:\n-\tThe size of large frame to transmit;\n-\tThe proportion of neighboring frames that can be reduced in size;\n-\tThe length of averaging window.\nWhen any two of the properties are known, it is possible to determine the third.\nTR 26.924 [144] Annex A describes a method for determining the length of the averaging window from the other two properties. The same method can also be used to determine the portion of the bit-rate for frames neighboring the large frame, which needs to be reduced depending on the size of the frame and the length of the averaging window.\nThe recommended procedure consists of reducing the encoding bit-rate of the frames neighboring the large frame in a balanced fashion, taking into account the spatio-temporal tradeoff of video quality when the encoding parameters such as quantization step or frame rate are adjusted. This may even require dropping some frames before they are encoded.\nWhen a FIR is received, the MTSI client in terminal may delay the generation and transmission of an Intra frame by up to a half of the averaging window.\nWhen speech is operated in a Source-Controlled Variable Bit Rate mode (e.g., EVS 5.9VBR), both the GBR and MBR need to be set at least as high as the highest rate used by the codec in this mode (e.g., 8.0kbps for EVS 5.9VBR).  These rates may be set higher for a session if, in addition to the VBR mode, a higher rate codec mode is also negotiated for the session.  Therefore, packet policing on the MBR or GBR will not prevent the transport of VBR media packets regardless of the averaging window used.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "8\tJitter buffer management in MTSI clients in terminals",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "8.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause specifies mechanisms to handle delay jitter in MTSI clients in terminals.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.2\tSpeech",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "8.2.1\tTerminology",
                            "text_content": "In the following paragraph(s), Jitter Buffer Management (JBM) denotes the actual buffer as well as any control, adaptation and media processing algorithm (excluding speech decoder) used in the management of the jitter induced in the transport channel. An illustration of an exemplary structure of an MTSI speech receiver with adaptive jitter buffer is shown in figure 8.1 to clarify the terminology and the relation between different functional components.\nFigure 8.1 illustrates the structure of an MTSI (Minimum Time-Synchronous Interframe Space) speech receiver, which is a type of speech codec used in telecommunication systems. The figure shows the various components involved in the receiver, including the modulator, demodulator, and error correction blocks. The modulator is responsible for converting the analog speech signal into a digital format, while the demodulator is used to extract the original speech signal from the digital data. Error correction blocks are included to ensure the integrity of the received signal, as errors can occur during transmission. The figure also shows the timing synchronization between the transmitter and receiver, which is crucial for accurate speech transmission. Overall, the MTSI speech receiver is designed to provide high-quality speech communication with minimal delay and error.\nFigure 8.1: Example structure of an MTSI speech receiver\nThe blocks \"network analyzer\" and \"adaptation control logic\" together with the information on buffer status form the actual buffer control functionality, whereas \"speech decoder\" and \"adaptation unit\" provide the media processing functionality. Note that the external playback device control driving the media processing is not shown in figure 8.1.\nThe grey dashed lines indicate the measurement points for the jitter buffer delay, i.e. the difference between the decoder consumption time and the arrival time of the speech frame to the JBM.\nThe functional processing blocks are as follows:\n-\tBuffer: The jitter buffer unpacks the incoming RTP payloads and stores the received speech frames. The buffer status may be used as input to the adaptation decision logic. Furthermore, the buffer is also linked to the speech decoder to provide frames for decoding when they are requested for decoding.\n-\tNetwork analyser: The network analysis functionality is used to monitor the incoming packet stream and to collect reception statistics (e.g. jitter, packet loss) that are needed for jitter buffer adaptation. Note that this block can also include e.g. the functionality needed to maintain statistics required by the RTCP if it is being used.\n-\tAdaptation control logic: The control logic adjusting playback delay and operating the adaptation functionality makes decisions on the buffering delay adjustments and required media adaptation actions based on the buffer status (e.g. average buffering delay, buffer occupancy, etc.) and input from the network analyser. Furthermore, external control input, including RTCP from the sender, can be used e.g. to enable inter-media synchronisation, to adapt the jitter buffer, or other external scaling requests. The control logic may utilize different adaptation strategies such as fixed jitter buffer (without adaptation and time scaling), simple adaptation during comfort noise periods or buffer adaptation also during active speech. The general operation is controlled with desired proportion of frames arriving late, adaptation strategy and adaptation rate.\n-\tSpeech decoder: The standard AMR, AMR-WB or EVS speech decoder. Note that the speech decoder is also assumed to include error concealment / bad frame handling functionality. Speech decoder may be used with or without the adaptation unit.\n-\tAdaptation unit: The adaptation unit shortens or extends the output signal length according to requests given by the adaptation control logic to enable buffer delay adjustment in a transparent manner. The adaptation is performed using the frame based or sample based time scaling on the decoder output signal during comfort noise periods only or during active speech and comfort noise. The buffer control logic should have a mechanism to limit the maximum scaling ratio. Providing a scaling window in which the targeted time scale modifications are performed improves the situation in certain scenarios - e.g. when reacting to the clock drift or to a request of inter-media (re)synchronization - by allowing flexibility in allocating the scaling request on several frames and performing the scaling on a content-aware manner. The adaptation unit may be implemented either in a separate entity from the speech decoder or embedded within the decoder.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "8.2.2\tFunctional requirements for jitter-buffer management",
                            "text_content": "The functional requirements for the speech JBM guarantee appropriate management of jitter which shall be the same for all speech JBM implementations used in MTSI clients in terminals. A JBM implementation used in MTSI shall support the following requirements, but is not limited in functionality to these requirements. They are to be seen as a minimum set of functional requirements supported by every speech JBM used in MTSI.\nSpeech JBM used in MTSI shall:\n-\tsupport source-controlled rate operation as well as non-source-controlled rate operation;\n-\tbe able to receive the de-packetized frames out of order and present them in order for decoder consumption;\n-\tbe able to receive duplicate speech frames and only present unique speech frames for decoder consumption;\n-\tbe able to handle clock drift between the encoding and decoding end-points.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "8.2.3\tMinimum performance requirements for jitter-buffer management",
                            "text_content": "An MTSI client in terminal supporting speech shall use a JBM fulfilling the minimum performance requirements defined in this clause. The JBM specified in [128] fulfils these minimum performance requirements and should be used for EVS. The EVS JBM may also be used for other codecs.\nThe jitter buffering time is the time spent by a speech frame in the JBM. It is measured as the difference between the decoding start time and the arrival time of the speech frame to the JBM. The frames that are discarded by the JBM are not counted in the measure.\nThe minimum performance requirements consist of objective criteria for delay and jitter-induced concealment operations. In order for a JBM implementation to pass the minimum performance requirements all objective criteria shall be met.\nA JBM implementation used in MTSI shall comply with the following design guidelines:\n1.\tThe overall design of the JBM shall be to minimize the buffering time at all times while still conforming to the minimum performance requirements of jitter induced concealment operations and the design guidelines for sample-based timescaling (as set in bullet point 3);\n2.\tIf the limit of jitter induced concealment operations cannot be met, it is always preferred to increase the buffering time in order to avoid growing jitter induced concealment operations going beyond the stated limit above. This guideline applies even if that means that end-to-end delay requirement given in TS 22.105 [34] can no longer be met;\n3.\tIf sample-based time scaling is used (after speech decoder), then artefacts caused by time scaling operation shall be kept to a minimum. Time scaling means the modification of the signal by stretching and/or compressing it over the time axis. The following guidelines on time scaling apply:\n-\tUse of a high-quality time scaling algorithm is recommended;\n-\tThe amount of scaling should be as low as possible;\n-\tScaling should be applied as infrequently as possible;\n-\tOscillating behaviour is not allowed.\nNOTE:\tIf the end-to-end delay for the ongoing session is known to the MTSI client in terminal and measured to be less than 150 ms (as defined in TS 22.105 [34]), the JBM may relax its buffering time minimization criteria in favour of reduced JBM adaptation artefacts if such a relaxation will improve the media quality. Note that a relaxation is not allowed when testing for compliance with the minimum performance requirements specified in clauses 8.2.3.2.2 and 8.2.3.2.3.\nThe objective performance requirements consist of criteria for delay, time scaling and jitter-induced concealment operations.\nThe objective minimum performance requirements are divided into three parts:\n1.\tLimiting the jitter buffering time to provide as low end-to-end delay as possible.\n2.\tLimiting the jitter induced concealment operations, i.e. setting limits on the allowed induced losses in the jitter buffer due to late losses, re-bufferings, and buffer overflows.\n3.\tLimiting the use of time scaling to adapt the buffering depth in order to avoid introducing time scaling artefacts on the speech media.\nIn order to fulfil the objective performance requirements, the JBM under test needs to pass the respective criteria using the six channels as defined in clause 8.2.3.3. Note that in order to pass the criteria for a specific channel, all three requirements must be fulfilled.\nThe reference delay computation algorithm in Annex D defines the performance requirements for the set of delay and error profiles described in clause 8.2.3.3. The JBM algorithm under test shall meet these performance requirements. The performance requirements shall be a threshold for the Cumulative Distribution Function (CDF) of the speech-frame delay introduced by the reference delay computation algorithm. A CDF threshold is set by shifting the reference delay computation algorithm CDF 60 ms. The speech-frame delay CDF is defined as:\nP(x) = Probability (delay_compensation_by_JBM ≤ x)\nThe relation between the reference delay computation algorithm and the CDF threshold is outlined in figure 8.2.\nFigure 8.2 illustrates the relationship between the reference delay algorithm and the cumulative distribution function (CDF) threshold, utilizing the delay and error profile 4 from table 8.1 as an example. The figure demonstrates how the CDF threshold is used to determine the optimal delay performance for a given communication system. The graph shows how the CDF curve is plotted against the reference delay, with the CDF threshold marking the point at which the system's performance drops below a certain level. This information is crucial for system designers and engineers to ensure that the communication system meets the required performance standards.\nFigure 8.2: Example showing the relation between the reference delay algorithm\nand the CDF threshold - the delay and error profile 4 in table 8.1 has been used\nThe JBM algorithm under test shall achieve lower or same delay than that set by the CDF threshold for at least 90 % of the speech frames. The values for the CDF shall be collected for the full length of each delay and error profile. The delay measure in the criteria is measured as the time each speech frame spends in the JBM; i.e. the difference between the decoder consumption time and the arrival time of the speech frame to the JBM.\nThe parameter settings for the reference delay computation algorithm are:\n-\tadaptation_lookback = 200;\n-\tdelay_delta_max = 20;\n-\ttarget_loss= 0.5.\nThe jitter induced concealment operations include:\n-\tJBM induced removal of a speech frame, i.e. buffer overflow or intentional frame dropping when reducing the buffer depth during adaptation.\n-\tDeletion of a speech frame because it arrived at the JBM too late.\n-\tModification of the output timeline due to link loss.\n-\tJitter-induced insertion of a speech frame controlled by the JBM (e.g. buffer underflow).\nLink losses handled as error concealment and not changing the output timeline shall not be counted in the jitter induced concealment operations.\nJitter loss rate = JBM triggered concealed frames / Number of transmitted frames\nThe jitter loss rate shall be calculated for active speech frames only.\nNOTE:\tSID_FIRST and SID_UPDATE frames belong to the non-active speech period, hence concealment for losses of such frames should not be included in the statistics.\nThe jitter loss rate shall be below 1% for every channel measured over the full length of the respective channel. The value of 1 % was chosen because such a loss rate will usually not significantly reduce the speech quality.\nSix different delay and error profiles are used to check the tested JBM for compliance with the minimum performance requirements. The profiles span a large range of operating conditions in which the JBM shall provide sufficient performance for the MTSI service. All profiles are 7500 IP packets long.\nTable 8.1: Delay and error profile overview - The channels are attached electronically\n\nThe attached profiles in the zip-archive \"delay_and_error_profiles.zip\" are formatted as raw text files with one delay entry per line. The delay entries are written in milliseconds and packet losses are entered as \"-1\". Note that when testing for compliance, the starting point in the delay and error profile shall be randomized.\nThe files described in table 8.2 and attached to the present document in the zip-archive \"JBM_evaluation_files.zip\" shall be used for evaluation of a JBM against the minimum performance requirements. The data is stored as RTP packets, formatted according to \"RTP dump\" format [41]. The input to these files is AMR or AMR-WB encoded frames, encapsulated into RTP packets using the octet-aligned mode of the AMR RTP payload format [28].\nTable 8.2: Input files for JBM performance evaluation - The files are attached electronically\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 8.1: Delay and error profile overview - The channels are attached electronically",
                                    "table number": 26,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 8.2: Input files for JBM performance evaluation - The files are attached electronically",
                                    "table number": 27,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "8.3\tVideo",
                    "description": "",
                    "summary": "",
                    "text_content": "Video receivers should implement an adaptive video de-jitter buffer. The overall design of the buffer should aim to minimize delay, maintain synchronization with speech, and minimize dropping of late packets. The exact implementation is left to the implementer.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.4\tText",
                    "description": "",
                    "summary": "",
                    "text_content": "Conversational quality of real-time text is experienced as being good, even with up to one second end-to-end text delay. Strict jitter buffer management is therefore not needed for text. Basic jitter buffer management for text is described in section 5 of RFC 4103 [31] where a calculation is described for the time allowed before an extra delayed text packet may be regarded to be lost.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "9\tPacket-loss handling",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "9.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause specifies some methods to handle conditions with packet losses. Packet losses in general will also trigger adaptation, which is specified in clause 10.\nThe ‘a=bw-info’ attribute defined in clause 19 allows for negotiating how much additional bandwidth (if any) may be used for application layer redundancy in the session. When application layer redundancy is used, the media bandwidth negotiated for the session may need to be increased, i.e. by increasing the value used for the b=AS bandwidth modifier. The b=AS bandwidth modifier is however only a single value, which also applies only to the receiving direction. When an MTSI client in terminal sends the SDP, it is therefore not possible for the networks and the other client to know if the intention is to use the entire media bandwidth all the time (both with and without redundancy); or if the intention is to use the b=AS bandwidth only when redundancy is needed and to use a lower bandwidth when redundancy is not needed. It is also not possible to know what the MTSI client in terminal can do in the sending direction. The ‘a=bw-info’ attribute (see clause 19) offers an improved negotiation mechanism to better know what the MTSI client in terminal can do and what it intends to do. This is further discussed in TR 26.924 [144].\nImproved error robustness can be enabled by packet-loss handling procedures of the codec or codec mode, via the adaptation procedures described in clause 10, or other mechanisms.  Annex X specifies the CHEM feature which enables the 3GPP system to exploit error robustness to avoid, delay, or reduce the need to handoff a terminal due to degradation in the media quality.  Annex Y provides example PLR threshold values that can be used for different codec configurations.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "9.2\tSpeech",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "9.2.1\tGeneral",
                            "text_content": "This clause provides a recommendation for a simple application layer redundancy scheme that is useful in order to handle operational conditions with severe packet loss rates. Simple application layer redundancy is generated by encapsulating one or more previously transmitted speech frames into the same RTP packet as the current previously not transmitted frame(s). An RTP packet may thus contain zero, one or several redundant speech frames and zero, one or several non-redundant speech frames.\nWhen transmitting redundancy, the MTSI client should switch to a lower codec mode, if possible. An MTSI client using AMR or AMR-WB shall utilize the codec mode rates within the negotiated codec mode set with the negotiated adaptation steps and limitations as defined by mode-change-neighbor and mode-change-period. It is recommended to not send redundant speech frames before the targeted codec mode is reached. Table 9.1 defines the recommended codec modes for different redundancy level combinations.\nWhen application layer redundancy is used for AMR or AMR-WB encoded speech media, the transmitting application may use up to 300 % redundancy, i.e. a speech frame transported in one RTP packet may be repeated in 3 other RTP packets.\nTable 9.1: Recommended codec modes and redundancy level combinations\nwhen redundancy is supported\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 9.1: Recommended codec modes and redundancy level combinations\nwhen redundancy is supported",
                                    "table number": 28,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "9.2.2\tTransmitting redundant frames",
                            "text_content": "When transmitting redundant frames, the redundant frames should be encapsulated together with non-redundant media data as shown in figure 9.1. The frames shall be consecutive with the oldest frame placed first in the packet and the most recent frame placed last in the packet. The RTP Timestamp shall represent the sampling time of the first sample in the oldest frame transmitted in the packet.\nNOTE 1:\tWhen switching from no redundancy to using redundancy, the RTP Timestamp may be the same for consecutive RTP packets.\nFigure 9.1 illustrates the difference between redundant and non-redundant frames in the context of 100% redundancy. The figure depicts two scenarios: one where the original packing is 1 frame per packet, and another where the original packing is 2 frames per packet. The visual representation clearly shows that in the case of 100% redundancy, the redundant frames are packed together, while in the non-redundant scenario, the frames are not packed together. This distinction is crucial for understanding the efficiency and effectiveness of redundancy in data transmission.\nFigure 9.1: Redundant and non-redundant frames in the case of 100 % redundancy,\nwhen the original packing is 1 frame per packet\nFigure 9.1 shows only one non-redundant frame encapsulated together with one redundant frame. It is allowed to encapsulate several non-redundant frames with one or several redundant frames. The following combinations of non-redundant frames and redundant frames can be used.\nTable 9.2: Example frame encapsulation with different redundancy levels and when maxptime is 240\n\nWith a maxptime value of 240, it is possible to encapsulate up to 12 frames per packet. It is therefore not allowed to use 300 % when the original encapsulation is 4 frames per packet, as shown in table 9.2. If the receiver's maxptime value is lower than 240 then even more combinations of original encapsulation and redundancy level will be prohibited.\nThe sender shall also ensure that the Maximum Transfer Unit (MTU) is not exceeded when sending the IP/UDP/RTP packet.\nFigure 9.2 shows an example where the frame aggregation is 2 frames per packet and when 100 % redundancy added.\nFigure 9.2 illustrates the difference between redundant and non-redundant frames in a network with 100% redundancy. The original packing is shown as 2 frames per packet. The diagram demonstrates how redundant frames are packed together to maximize efficiency, while non-redundant frames are not. This packing strategy is crucial for reducing network congestion and improving overall performance.\nFigure 9.2: Redundant and non-redundant frames in the case of 100 % redundancy,\nwhen the original packing is 2 frames per packet\nA redundant frame may be replaced by a NO_DATA frame. If the transmitter wants to encapsulate non-consecutive frames into one RTP packet, then NO_DATA frames shall be inserted for the frames that are not transmitted in order to create frames that are consecutive within the packet. This method is used when sending redundancy with an offset, see figure 9.3.\nFigure 9.3 illustrates the difference between redundant and non-redundant frames in a network with 100% redundancy. In the case of original packing, where each frame contains one packet, the redundancy is transmitted with an offset of 20 ms. The figure shows how the redundant frames are added to the non-redundant frames, ensuring that all packets are received correctly even in the event of a failure. The offset is crucial to maintain the timing synchronization between the original and redundant frames.\nFigure 9.3: Redundant and non-redundant frames in the case of 100 % redundancy, when the original \npacking is 1 frame per packet and when the redundancy is transmitted with an offset of 20 ms\nNote that with this scheme, the receiver may receive a frame 3 times: first the non-redundant encoding; then as a NO_DATA frame; and finally the redundant frame. Other combinations of redundancy and offset may result in receiving even more copies of a frame. The proper receiver behaviour is described in the AMR/AMR-WB payload format [28] and in the EVS payload format [125], respectively.\nFor any combinations of frame aggregation, redundancy and redundancy offset, the transmitter shall not exceed the frame encapsulation limit indicated by the receiver's maxptime value when constructing the RTP packet.\nWhen source controlled rate operation is used, it is allowed to send redundant media data without any non-redundant media, if no non-redundant media is available.\nNOTE 2:\tWhen going from active speech to DTX, there may be no non-redundant frames in the end of the talk spurt while there still are redundant frames that need to be transmitted.\nIn the end of a talk spurt, when there are no more non-redundant frames to transmit, it is allowed to drop the redundant frames that are in the queue for transmission.\nNOTE 3:\tThis ensures that it is possible to use redundancy without increasing the packet rate. The quality degradation by having less redundancy for the last frames should be negligible since these last frames typically contain only background noise.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 9.2: Example frame encapsulation with different redundancy levels and when maxptime is 240",
                                    "table number": 29,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "9.2.3\tReceiving redundant frames",
                            "text_content": "In order to receive and decode redundant media properly, the receiving application shall sort the received frames based on the RTP Timestamp and shall remove duplicated frames. If multiple versions of a frame are received, i.e. encoded with different bitrates, then the frame encoded with the highest bitrate should be used for decoding.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "9.3\tVideo",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "9.3.1\tGeneral",
                            "text_content": "MTSI clients can use the following mechanisms to recover from packet losses:\n-\tAVPF Generic NACK and Picture Loss Indication (PLI) feedback messages\n-\tRTP Retransmission\n-\tForward Error Correction (FEC)\nThese mechanisms offer different performance tradeoff according to channel conditions: end-to-end delay, bandwidth, rate and profile of packet losses.\nAVPF NACK messages are used by MTSI clients to indicate non-received RTP packets for video (see clause 7.3.3). An MTSI client transmitting video can use this information, as well as the AVPF Picture Loss Indication (PLI), to at its earliest opportunity take appropriate action to recover video from errors for the MTSI client that sent the NACK or PLI message. Recovery from error action is defined as sending a recovery picture that is equivalent to a good frame in clause 16.2.1, sending Gradual Decoder Refresh (GDR) that results in a good frame, or retransmitting missing packets.  Requirements and recommendations for packet loss handling are described below.\nRecommendation regarding usage under various channel conditions of error recovery mechanisms available for MTSI clients are provided in clause 9.3.4.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "9.3.2\tReceiver behaviour",
                            "text_content": "When NACK and PLI have been negotiated without retransmission support for the session then an MTSI client in terminal receiving media:\n-\tshall immediately queue a NACK message for RTCP scheduling upon detection of first error after decoding a good frame.\n-\tshould repeat queuing NACK messages for RTCP scheduling after an RWT duration if recovery picture does not arrive.\n-\tshall queue a PLI message for RTCP scheduling if a recovery picture does not arrive in two RWT duration, and shall then stop sending NACK messages that relate to the same data as that PLI.\n-\tshall repeat queuing PLI messages for RTCP scheduling after an RWT duration if the initially requested recovery picture does not arrive.\nReceiver may report more losses or repeat messages if it deems necessary. As a minimum requirement on the receiver side, it shall support the capability of picture level error detection or tracking in order to stop reporting of prior losses from the recovery point. If FEC is supported, NACK messages should signal irrecoverable lost packets after recovery by FEC instead of the detected lost packets before recovery. The receiver should wait \"repair-window\" duration before issuing a NACK message for the missing packets.\nWhen retransmission is supported, NACK messages correspond to requests for missing packets to be retransmitted instead of indication of error position for recovery without retransmission. The receiver should queue NACK messages for RTCP scheduling as necessary. The importance of lost packets along with possibility of timely arrival of requested packets should be considered before requesting retransmission.\nAnnex P.2 gives further description of receiver behaviour for error correction.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "9.3.3\tSender behaviour",
                            "text_content": "When NACK and PLI have been negotiated without retransmission support for the session then an MTSI client in terminal sending media:\n-\tshall send a recovery picture or Gradual Decoder Refresh (GDR) upon receiving NACK message if loss indicated by the message corresponds to error in a reference picture within 500 ms. If a recovery picture corresponding to the NACK message was sent prior to reception of the NACK message by less than RWT duration, the sender does not have to respond to this particular NACK message.\n-\tshall send an Instantaneous Decoder Refresh (IDR) or GDR picture upon receiving PLI message within 500 ms.\n-\tshould not respond to incoming NACK or PLI messages within RWT duration of the same message type indicating the same loss from the reception of the initial feedback message triggered by the onset of the loss.\nIDR picture is an intra picture where pictures following the IDR picture can be decoded without referring (inter prediction) to pictures decoded prior to IDR picture. This corresponds to IDR pictures in H.264 and HEVC. GDR is performing intra refresh by distributing intra picture data over N pictures. At the end of N pictures from the start of GDR all macroblock regions are intra coded (refreshed) generating a good frame. Similar to IDR case, if intra picture or GDR is used as a recovery mechanism, the pictures following the intra picture or the GDR pictures should not reference pictures decoded prior to these pictures.\nWhen retransmission is supported, sender should retransmit packets that it deems beneficial for timely recovery. Only source packets should be retransmitted. The minimum time the sender should keep an original RTP packet in its buffers available for retransmission, i.e. \"rtx-time\" value, should be RTT and the maximum time the sender should keep an original RTP packet should be 400 ms.\nWhen FEC is supported, the amount of time that spans the source and the corresponding repair packets, i.e. \"repair-window\", should not be less than the minimum required duration for the bitmask used for generation of the repair packets. The maximum time that spans the source and corresponding repair packets should not be more than 300 ms.\nAn MTSI client in terminal sending video shall obey the rate restrictions imposed by the video rate adaptation specified in clause 10.3.\nAnnex P.2 gives further description of sender behaviour for error correction. Annex P.3 gives further description of sender and receiver behaviour for RTP retransmission based recovery.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "9.3.4\tRecommendations for packet loss recovery mechanisms usage",
                            "text_content": "FEC should be used to provide robustness against moderate packet loss rates at high delay scenario. FEC can especially handle random losses and short burst losses and be beneficial in environments with high packet loss rates and/or high delay (RTT). The use of FEC may not be appropriate when packet losses are caused by insufficient throughput (over radio access or due to congestions in network) since it introduces some bit rate overhead. In order to compensate for bit rate overhead, FEC should be used with efficient rate adaptation mechanisms to reduce the source bit rate according to channel conditions and not increase the total RTP bitrate. When error cases cannot be recovered by FEC, other mechanisms are needed in combination with FEC.\n-\tRetransmission in combination with FEC should be used for the low RTT case with relatively high packet loss since retransmission can efficiently handle the FEC failure case.\n-\tGeneric NACK based recovery in combination with FEC should be used for high RTT, relatively high packet loss conditions since generic NACK based recovery does not introduce additional delay.\nSelective retransmission should be used under low delay (RTT) and low failure (loss) rate conditions. Retransmission needs to ensure that retransmitted packets arrive in time to meet delay requirements of the end-to-end system. Higher packet loss rates may cause loss of retransmitted packets, hence leading to larger end-to-end delay.\nGeneric NACK and PLI based error correction mechanism should be used in combination with FEC or selective retransmission or under low packet loss rates with high RTT conditions. Generic NACK message can be used for indication of packets to be retransmitted as well as informing the sender of loss of particular RTP packets for sender to take necessary actions to recover from errors.\nNOTE:\tUnder unknown and varying conditions the MTSI client should dynamically select & adapt the propoer mechanisms.\nAdditional information on the usage of these mechanisms is provided in [142].\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "9.4\tText",
                    "description": "",
                    "summary": "",
                    "text_content": "Redundant transmission provided by the RTP payload format as described in RFC 4103 [31] shall be supported. When the negotiation for support of multiparty real-time text is successful, redundant transmission provided by the RTP payload format as described in IETF RFC 9071 [185] shall also be supported. The transmitting application may use up to 200 % redundancy, i.e. a T140block transported in one RTP packet may be repeated once or twice in subsequent RTP packets. 200 % redundancy shall be used when the conditions along the call path are not known to be free of loss. However, the result of media negotiation shall be followed, and transmission without redundancy used if one of the parties does not show capability for redundancy.\nThe sampling time shall be 300 ms as a minimum (in order to keep the bandwidth down) and should not be longer than 500 ms. New text after an idle period shall be sent as soon as possible. The first packet after an idle-period shall have the M-bit set.\nThe procedure described in section 5 of RFC 4103 [31], or a procedure with equivalent or better performance, shall be used for packet-loss handling in the receiving MTSI client in terminal.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "10\tAdaptation",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "10.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "Adaptive mechanisms are used to optimize the session quality given the current transport characteristics. The mechanisms provided in MTSI are bit-rate, packet-rate and error resilience adaptation. These mechanisms can be used in different ways; however, they should only be used when the result of the adaptation is assumed to increase the session quality even if e.g. the source bit-rate is reduced.\nAdaptive mechanisms that act upon measured or signalled changes in the transport channel characteristics may be used in a conservative manner. Examples of measured changes in transport characteristics are variations in Packet Loss Rate (PLR) and delay jitter. Examples of signalled changes in transport characteristics are ANBR (see clause 10.7) and ECN Congestion Experienced (ECN-CE) marking in IP packet headers. A conservative use of adaptation is characterized by a fast response to degrading conditions, and a slower, careful upwards adaptation intended to return the session media settings to the original default state of the session. The long-term goal of any adaptive mechanism is assumed to be a restoration of the session quality to the originally negotiated quality. The short-term goal is to maximize the session quality given the current transport characteristics, even if that means that the adapted state of the session will give a lower session quality compared to the session default state if transported on an undisturbed channel.\nThe ‘a=bw-info’ attribute defined in Clause 19 may be used to align the adaptation with the bearer setup and the end-to-end resource allocation. A few recommendations are described in sub-clause 10.6.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "10.2\tSpeech",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "10.2.0\tGeneral",
                            "text_content": "To reduce the risk for confusion in the media-sender, it is beneficial if the signaling from media-receiver back to media-sender for the media adaptation is the same regardless of which triggers are used in the adaptation-decision in the media-receiver. The ANBR described in clause 10.7 should, if supported by both the access network and the MTSI client in terminal, be used as one such trigger.\nNOTE 1:\tThe media-receiver is aware that other nodes in the media path may also influence the media adaptation. A media-receiver sending a specific CMR value X can expect that (after some time) no media is received with a mode higher than X, but modes lower than X may be received any time.\nThe adaptation for AMR, AMR-WB and EVS includes adapting the media bit-rate, the frame aggregation, the redundancy level and the redundancy offset. The domain of adaptation for EVS furthermore includes adapting audio bandwidth, partial redundancy, switching between EVS primary mode and EVS AMR-WB IO mode.\nWhen the AMR codec or the AMR-WB codec is used, two signaling mechanisms are defined:\n-\tCMR in the AMR/AMR-WB RTP payload, [28].  \nCMR in RTP can be used by the media-receiver to restrict the codec mode in the remote media-sender to an upper limit (maximum mode).\n-\tRTCP-APP, see clause 10.2.1. \nIf the media-sender supports RTCP-APP, then the media-receiver can use it in the following way:\nCMR in RTCP-APP can be used by the media-receiver to restrict the codec mode in the remote media-sender to an upper limit (maximum mode), in addition to CMR in RTP. \nRTCP-APP can further be used by the media-receiver for the adaptation of frame aggregation, redundancy level and redundancy offset in the RTP packets to be sent by the remote media-sender.\nWhen the EVS codec is used, the following signaling mechanism is defined:\n-\tCMR in the EVS RTP payload, [125].\n-\tRTCP-APP, see clause 10.2.1.\nIn response to received DL ANBR, a speech media receiver should trigger sending CMR requesting bitrate adaptation in the corresponding media sender RTP stream. If RTCP-APP is supported, then a speech media receiver should trigger sending CMR or RTCP-APP requesting bitrate adaptation in the corresponding media sender RTP stream based on the received DL ANBR.\nWhen adapting frame aggregation and/or redundancy, the MTSI client must verify that the maximum packetization, defined by the maxptime SDP parameter, is not exceeded. The MTSI client must also verify that the IP packet sizes does not exceed the Maximum Transfer Unit (MTU).\nThe boundaries of the adaptation may be controlled by a set of parameters. These parameters may be configured into the MTSI client based on operator policy, for example using OMA-DM.\nTable 10.1 defines a mandatory set of parameters that are used by the ECN triggered adaptation for AMR and AMR-WB. The default values for the parameters are also specified. Alternate values for these parameters may be configured into the MTSI client based on operator policy, for example using OMA-DM.\nTable 10.1: Configuration parameters when ECN is used as a trigger\n\nThe configuration of adaptation parameters, and the actions taken during the adaptation, are specific to the particular triggers. For example, the adaptation may be configured to reduce the media bit-rate to AMR5.9 when ECN-CE is detected, while it may reduce the media bit-rate to AMR4.75 for bad radio conditions when high PLR is detected.\nMultiple ECN-CE markings within one RTP-level round-trip time is considered as the same congestion event. Each time an MTSI client detects a congestion event it shall send an adaptation request to reduce the media bit-rate unless already operating at the ECN_min_rate or below. An MTSI client detecting a congestion event shall not send an adaptation request to increase the media bit-rate for a time period ECN_congestion_wait after the end of the congestion event.\nMultiple adaptation trigger algorithms can be used in parallel, for example ECN-triggered adaptation, adaptation based on ANBR, and PLR-triggered adaptation. When multiple adaptation algorithms are used for the rate adaptation, the rate that the MTSI client is allowed to use should be no higher than any of the rates determined by each adaptation algorithm.\nNOTE 2:\tFor example, if the ECN-triggered adaptation indicates that AMR5.9 should be used and if the PLR-triggered adaptation indicates that AMR4.75 should be used then the rate that the MTSI client uses should be no higher than min(AMR5.9, AMR4.75) = AMR4.75.An example adaptation scheme is described in Annex C.\nWhen additional transport bandwidth information is provided using the ‘a=bw-info’ attribute defined in clause 19, the Minimum Desired Bandwidth should be aligned with the ECN_min_rate configuration parameter.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 10.1: Configuration parameters when ECN is used as a trigger",
                                    "table number": 30,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "10.2.1\tRTCP-APP with codec control requests",
                            "text_content": "When signalling adaptation requests for speech in MTSI, an RTCP-APP packet should be used. This application-specific packet format supports three different adaptation requests when the AMR or AMR-WB codec is used; bit-rate requests, frame aggregation requests and redundancy requests. The requests for frame aggregation and redundancy are also used when the EVS codec is used. The codec mode request used for AMR-WB is also used when the EVS AMR-WB IO mode is used. The application specific format supports additionally five requests that are used for the EVS codec. The RTCP-APP packet is put in a compound RTCP packets according to the rules outlined in RFC 3550 [9] and RFC 4585 [40]. In order to keep the size of the RTCP packets as small as possible it is strongly recommended that the RTCP packets are transmitted as minimal compound RTCP packets, meaning that they contain only the items:\n-\tSR or RR;\n-\tSDES CNAME item;\n-\tAPP (when applicable).\nThe recommended RTCP mode is RTCP-AVPF early mode since it will enable transmission of RTCP reports when needed and still comply with RTCP bandwidth rules. The RTCP-APP packets should not be transmitted in each RTCP packet, but rather as a result in the transport characteristics which require end-point adaptation.\nThe signalling allows for a request that the other endpoint modifies the packet stream to better fit the characteristics of the current transport link. The request in the received RTCP-APP is valid until a new request is received. Note that the media sender can, if having good reasons, choose to not comply with the request received from the media receiver. One such reason could be knowledge of that the local conditions do not allow the requested format.\nThe RTCP-APP packet defined to be used for adaptation signalling for speech in MTSI is constructed as shown in figure 10.1.\nFigure 10.1 illustrates the Real-Time Transport Control Protocol (RTCP) Application-Level Protocol (APP) formatting, which is used for the transmission of feedback information between media servers and renderers. The figure showcases the structure of RTCP-APP packets, detailing the various fields such as the session ID, timestamp, and counter values. The diagram highlights the importance of this protocol in maintaining the quality of experience (QoE) for users by enabling media servers to monitor and adjust their transmission rates in real-time.\nFigure 10.1: RTCP-APP formatting\nThe RTCP-APP specific fields are defined as follows:\n-\tSubtype - the subtype value shall be set to \"0\".\n-\tName - the name shall be set to \"3GM7\", meaning 3GPP MTSI Release 7.\nThe application-dependent data field contains the requests listed below. The length of the application-dependent data shall be a multiple of 32 bits. The unused bytes shall be set to zero.\nFigure 10.2 illustrates the basic syntax of the application-dependent data fields, showcasing various data types and their corresponding formats. The figure presents a structured layout, with rows representing different data fields and columns indicating the type of data. The visual representation aids in understanding the organization and arrangement of data within the application, highlighting the importance of data structure and format in programming.\nFigure 10.2: Basic syntax of the application-dependent data fields\nThe length of the messages is 1 or 2 bytes depending on request type.\nThe ID field identifies the request type. ID Code points [0000] ... [1000] are specified in the present document, whereas the other ID code points are reserved for future use.\nThe signalling for three different adaptation requests is defined below. For each request, the codecs that can use the request are also specified.\nThe requests that can be used in a session are negotiated with SDP, see clause 10.2.3.\nPADDING: This message contains no request but is identical to a padding byte with all zeroes and is therefore used as padding.\nFigure 10.2a illustrates the process of padding in a telecommunication system, focusing on the addition of redundant bits to a data stream to ensure error detection and correction. The figure depicts a data packet entering a network, where it undergoes a series of transformations, including error checking and correction. The key visual elements include the data packet, the network interface card (NIC), and the error detection and correction mechanisms. The padding process ensures that the data packet remains within the network's maximum transmission unit (MTU) size, preventing fragmentation and maintaining data integrity.\nFigure 10.2a: Padding\nCodecs: This request can be used for all codecs.\nThe DATA field is a 4-bit value field with all bits set to zero. When receiving a PADDING message, the whole octet shall be ignored, regardless of the bits in the DATA field.\nAn MTSI client uses this to pad the RTCP-APP to be 32 bit aligned when needed.\nRTCP_APP_REQ_RED: Request for redundancy level and offset of redundant data.\nFigure 10.3 illustrates the process of a redundancy request in a telecommunication network. The diagram depicts the interaction between the network nodes, specifically the source node and the destination node, as they initiate a redundancy request. The request is sent through the network, passing through various nodes such as the ingress switch, egress switch, and the core network. The figure highlights the importance of efficient network design and management, as well as the role of protocols in ensuring data redundancy and reliability.\nFigure 10.3: Redundancy request\nCodecs: This request can be used for all codecs.\nThe Bit field is a 12 bit bitmask that signals a request on how non-redundant payloads chunks are to be repeated in subsequent packets.\nThe position of the bit set indicates which earlier non-redundant payload chunks is requested to be added as redundant payload chunks to the current packet.\n-\tIf the LSB (rightmost bit) is set equal to 1 it indicates that the last previous payload chunk is requested to be repeated as redundant payload in the current packet.\n-\tIf the MSB (leftmost bit) is set equal to 1 it indicates that the payload chunk that was transmitted 12 packets ago is requested to be repeated as redundant payload chunk in the current packet. Note that it is not guaranteed that the sender has access to such old payload chunks.\nThe maximum amount of redundancy is 300 %, i.e., at maximum three bits can be set in the Bit field.\nSee clause 10.2.1 for example use cases.\nRTCP_APP_REQ_AGG: Request for a change of frame aggregation.\nFigure 10.4 illustrates the process of frame aggregation request in a telecommunication network. The figure depicts the interaction between the network nodes, including the sender, receiver, and intermediate nodes, as they exchange frames for aggregation. The sender initiates the process by sending a frame aggregation request to the receiver, which then responds with a confirmation. The intermediate nodes play a crucial role in forwarding the frames and ensuring the successful completion of the aggregation process. The figure highlights the importance of efficient frame aggregation in improving network performance and reducing congestion.\nFigure 10.4: Frame aggregation request\nCodecs: This request can be used for all codecs.\nThe DATA field is a 4 bit value field:\n-\t0000 - 1 frame / packet.\n-\t0001 - 2 frames / packet.\n-\t0010 - 3 frames / packet.\n-\t0011 - 4 frames / packet.\nThe values 0100…1111 are reserved for future use.\nThe maximum allowed frame aggregation is also limited by the maxptime parameter in the session SDP since the sender is not allowed to send more frames in an RTP packet than what the maxptime parameter defines.\nThe default aggregation is governed by the ptime parameter in the session SDP. It is allowed to send fewer frames in an RTP packet, for example if there are no more frames available at the end of a talk spurt. It is also allowed to send more frames in an RTP packet, but such behaviour is not recommended.\nSee clauses 7.4.2 and 12.3.2.1 for further information.\nRTCP_APP_CMR: Codec Mode Request\nFigure 10.5 illustrates the process of a codec mode request in a telecommunication system. The diagram depicts the interaction between the network elements, including the network element (NE), the network element manager (NEM), and the network control protocol (NCP). The NE sends a request to the NEM, which then forwards it to the NCP for processing. The NCP evaluates the request and sends a response back to the NE, indicating whether the request is accepted or denied. This process ensures that the network can efficiently allocate resources and maintain optimal performance.\nFigure 10.5: Codec mode request\nCodecs: This request can only be used for the AMR codec, the AMR-WB codecs and for the EVS codec when operating in AMR-WB IO mode.\nThe definition of the CMR bits in the RTCP_APP_CMR message is identical to the definition of the CMR bits defined in [28]. The CMR indicates the maximum codec mode (highest bit-rate) that the receiver wants to receive. The sender may very well use a lower codec mode (lower bit-rate) when sending.\nAn MTSI client in terminal that requests mode adaptation should transmit the CMR in an RTCP_APP_CMR, unless specified otherwise in Clause 7.3.2.\nWhen the MTSI MGW has an interworking session with a circuit-switched (CS) system using transcoding and requests mode adaptation, the MTSI MGW should transmit CMR in an RTCP_APP_CMR, unless specified otherwise in Clause 7.3.2, and should set the CMR in the AMR payload to 15 (no mode request present [28]).\nWhen the MTSI MGW has an interworking session with a circuit-switched (CS) system using TFO/TrFO, then the MTSI media gateway should translate the CMR bits (in GERAN case) or the Iu/Nb rate control messages (in UTRAN case) from the CS client into the CMR bits in the AMR payload. If the MTSI media gateway prefers to receive a lower codec mode rate from the MTSI client in terminal than what the CMR from the CS side indicates, then the MTSI media gateway may replace the CMR from the CS side with the CMR that the MTSI media gateway prefers. The value 15 (no mode request present [28]) shall be used in the CMR bits in the AMR payload towards the PS side if on the CS side no mode request has been received and if the MTSI media gateway has no preference on the used codec mode. The RTCP_APP_CMR should not be used in the direction from the MTSI media gateway towards the MTSI client when TFO/TrFO is used.\nIf an MTSI client receives CMR bits both in the AMR payload and in an RTCP_APP_CMR message, the mode with the lowest bit rate of the two indicated modes should be used. A codec mode request received in a RTCP_APP_CMR is valid until the next received RTCP_APP_CMR.\nFigure 10.6 below illustrates how the three requests are used by the transmitter. In this case, RTCP_APP_REQ_RED is equal to \"000000000101\".\n-\tThe speech encoder generates frames every 20 ms.\n-\tThe speech frames are buffered in the aggregation buffer until it is possible to generate a payload chunk with the number of frames requested by either ptime at session setup or by RTCP_APP_REQ_AGG during a session.\n-\tThe current payload chunk is used when constructing the current RTP packet.\n-\tThe history buffer contains previously transmitted payload chunks. The length of this buffer needs to be dimensioned to store the maximum number of payload chunks that are possible. This value is based on the max-red value, the maxptime values and from the minimum number of frames that the transmitter will encapsulate in the RTP packets. In this case, the buffer length is selected to 11 payload chunks since this corresponds to the worst case of max-red=220, maxptime=240 and one frame per payload chunk.\n-\tAfter transmitting the current RTP packet, the content of the history buffer is shifted, the current payload chunk is shifted in to the history buffer as P(n-1) and the oldest payload chunk P(n-11) is shifted out.\n-\tWhen constructing the (provisional) RTP payload, the selected preceding payload chunks are selected from the history buffer and added to the current payload chunk. In order to form a valid RTP payload, the transmitter needs to verify that the maxptime value is not exceeded. If the provisional RTP payload is longer than what maxptime allows, then the oldest speech frames shall be removed until the length (in time) of the payload no longer violates the maxptime value. NO_DATA frames in the beginning or at the end of the payload does not need to be transmitted and are therefore removed. The RTP Time Stamp needs to be incremented when a NO_DATA frames are removed from the beginning of the payload. A (provisional) RTP packet containing only NO_DATA frames does not need to be transmitted.\nNote also that the transmitter is not allowed to send frames that are older than the max-red value that the transmitter has indicated in the SDP.\nFigure 10.6 illustrates the impact of various adaptation requests on the encoding process and payload packetization. The figure showcases how different adaptation parameters influence the efficiency of data transmission, with varying levels of packetization and encoding techniques employed. Key visual elements include the adaptive coding and modulation (ACM) framework, the impact on packet loss, and the overall throughput optimization. The figure emphasizes the importance of fine-tuning these parameters to achieve optimal performance in real-world telecommunication networks.\nFigure 10.6: Visualization of how the different adaptation requests \naffect the encoding and the payload packetization\nIt should be noted that RTCP_APP_REQ_AGG and RTCP_APP_REQ_RED are independent. Furthermore, it should also be noted that different redundant payload chunks may contain different number of speech frames.\nRTCP_APP_REQ_EPRR: EVS Primary Rate Request\nFigure 10.6a illustrates the process of an Enhanced Video Services (EVS) primary rate request, which is a crucial step in the delivery of high-quality video content over IP networks. The figure depicts the interaction between the encoder, decoder, and network elements, such as the Session Description Protocol (SDP) and Real-time Transport Protocol (RTP) packets. The primary rate request is sent by the encoder to the network, initiating the process of video transmission. The figure highlights the importance of efficient communication between these components, ensuring smooth and uninterrupted video streaming experiences for end-users.\nFigure 10.6a: EVS primary rate request\nCodecs: This request can be used for the EVS codecs when operating in EVS Primary mode.\nThe DATA field a 4-bit field and is encoded as described in the table below. The rate request indicates the maximum codec mode (highest bit-rate) that the receiver wants to receive. The sender may use a lower codec mode (lower bit-rate) when sending. The rate request shall comply with the media type parameters that are negotiated in the session.\nTable 10.1a Encoding of the DATA field in the EVS Primary Rate Request.\n\nRTCP_APP_REQ_EBWR: EVS Bandwidth Request\nFigure 10.6b illustrates the process of an Enhanced Video Services (EVS) bandwidth request, showcasing the various stages of the request from the user equipment (UE) to the network elements. The figure depicts the UE sending a bandwidth request to the Evolved Packet Core (EPC), which then forwards the request to the Serving Gateway (SGW) and Packet Data Network Gateway (P-GW). The SGW and P-GW process the request and forward it to the Home Location Register (HLR) and the Evolved Packet Core Network Node (EPC-NN). The HLR and EPC-NN collaborate to allocate the necessary bandwidth, which is then relayed back to the SGW and P-GW. The figure emphasizes the importance of efficient bandwidth allocation in EVS services, ensuring a smooth and high-quality video experience for the user.\nFigure 10.6b: EVS bandwidth request\nCodecs: This request can be used for the EVS codecs when operating in Primary mode.\nThe DATA field is a 4-bit field b0…b3, corresponding to bit 4 to bit 7 in the octet:\n-\tb0 set to ‘1’ = request for narrowband.\n-\tb1 set to ‘1’ = request for wideband.\n-\tb2 set to ‘1’ = request for super-wideband.\n-\tb3 set to ‘1’ = request for fullband.\nEach bit in the DATA field indicates a bandwidth that the receiver wants to receive. One or several of these four bits can be set to ‘1’. For example, a request for ‘1110’ indicates that the receiver wants to receive narrowband, wideband or super-wideband speech but not fullband speech. The bandwidth request shall comply with the media type parameters that are negotiated in the session.\nRTCP_APP_REQ_EPRED: EVS Channel Aware Request\nFigure 10.6d illustrates the process of an Enhanced Video Services (EVS) partial redundancy request in a telecommunication network. The figure depicts the network nodes involved, including the source, intermediate nodes, and the destination. The EVS protocol is designed to ensure video quality and reliability by requesting partial redundancy from intermediate nodes, which helps in reducing packet loss and improving overall video quality. The figure highlights the importance of efficient network management and the role of EVS in maintaining high-quality video communication.\nFigure 10.6d: EVS partial redundancy request\nCodecs: This request can be used for the EVS codecs when operating in Primary mode.\nThe DATA field is a 4-bit field and is encoded as described in the table below.\nTable 1.b Encoding of the DATA field in the EVS Channel Aware Request.\n\nSince channel-aware mode is only defined for the EVS Primary 13.2 kbps mode then sending an EVS Channel Aware Request also implies changing to the EVS Primary mode and to the 13.2 kbps bit-rate and possibly also changing the audio bandwidth to either WB or SWB.\nRTCP_APP_REQ_EP2I: EVS Primary mode to EVS AMR-WB IO mode Switching Request\nFigure 10.6e illustrates the process of switching from the Enhanced Video Services (EVS) primary mode to the Enhanced Video Services (EVS) AMR-WB Input/Output (I/O) mode. The figure depicts the signaling request between the network elements involved in this transition, including the Media Independent Control (MIC) layer, the Media Independent Data (MIND) layer, and the Media Independent Control Protocol (MICP). The diagram highlights the importance of precise timing and synchronization in ensuring a smooth and error-free transition between these modes, which are crucial for maintaining high-quality video services in telecommunication networks.\nFigure 10.6e: EVS primary mode to EVS AMR-WB IO mode switching request\nCodecs: This request can be used for the EVS codecs when operating in Primary mode.\nThe DATA field is an 11-bit field where the first 9 bits (b4-b12) are used to indicate the AMR-WB codec modes that are allowed and the 2 last bits (b13 and b14) are flags to set mode-change-period and mode-change-neighbor as follows:\n-\tfirst 9 bits for mode-set:\n-\tb4 = ‘0’: AMR-WB 6.60 not allowed\nb4 = ‘1’: AMR-WB 6.60 allowed,\n-\tb5 = ‘0’: AMR-WB 8.85 not allowed\nb5 = ‘1’: AMR-WB 8.85 allowed,\n-\tb6 = ‘0’: AMR-WB 12.65 not allowed\nb6 = ‘1’: AMR-WB 12.65 allowed,\n-\tb7 = ‘0’: AMR-WB 14.25 not allowed\nb7 = ‘1’: AMR-WB 14.25 allowed,\n-\tb8 = ‘0’: AMR-WB 15.85 not allowed\nb8 = ‘1’: AMR-WB 15.85 allowed,\n-\tb9 = ‘0’: AMR-WB 18.25 not allowed\nb9 = ‘1’: AMR-WB 18.25 allowed,\n-\tb10 = ‘0’: AMR-WB 19.85 not allowed\nb10 = ‘1’: AMR-WB 19.85 allowed,\n-\tb11 = ‘0’: AMR-WB 23.05 not allowed\nb11 = ‘1’: AMR-WB 23.05 allowed,\n-\tb12 = ‘0’: AMR-WB 23.85 not allowed\nb12 = ‘1’: AMR-WB 23.85 allowed.\n-\tflags:\n-\tb13 = ‘0’: mode-change-period=1,\nb13 = ’1’: mode-change-period=2,\n-\tb14 = ‘0’: mode-change-neightbor=0,\nb14 = ‘1’: mode-change-neightbor=1.\nAn MTSI client sending this request shall set at least one of the mode-set bits to ‘1’. An MTSI client receiving a request with all zeroes shall ignore the request.\nThe mode-set indicated in the EVS Primary mode to EVS AMR-WB IO mode Switching Request can only allow codec modes that have been negotiated in SDP offer-answer. This request cannot be used to allow codec modes that have not been negotiated in SDP offer-answer.\nAn MTSI client sending this request should also send an RTCP_APP_CMR to indicate the codec mode that should be used after switching to EVS AMR-WB IO mode. An MTSI client receiving this request without a request for a codec mode should use the rules for Initial Codec Mode (ICM) defined in clause 7.5.2.1.6 to determine the codec mode that should be used after switching to EVS AMR-WB IO mode.\nThe last bit (b15) ‘R’ is reserved for future use. An MTSI client sending this request shall set it to ‘0’. An MTSI client receiving this request shall ignore this bit.\nRTCP_APP_REQ_EI2P: EVS AMR-WB IO mode to EVS Primary mode Switching Request\nFigure 10.6f illustrates the process of switching from Enhanced Voice Services (EVS) Adaptive Multi-Rate Wideband (AMR-WB) Input Output (IO) mode to EVS Primary mode. The figure depicts the signaling and control mechanisms involved in this transition, including the use of the Media Independent Control (MIC) protocol for synchronization and the Control Channel (CC) for signaling. The diagram highlights the role of the Radio Resource Control (RRC) protocol in managing the session and the importance of timing alignment for seamless service switching. The figure is essential for understanding the complex interworking of various protocols and their impact on the overall performance of the EVS system.\nFigure 10.6f: EVS AMR-WB IO mode to EVS Primary mode Switching request\nCodecs: This request can be used for the EVS codecs when operating in AMR-WB IO mode.\nThe DATA field is a 4-bit field which is reserved for future use. All four bits are set to ‘0’.\nThe bitrates and bandwidths that can be used after switching to EVS Primary mode are the same as negotiated at session setup or in a preceding session modification.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 10.1a Encoding of the DATA field in the EVS Primary Rate Request.",
                                    "table number": 31,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table 1.b Encoding of the DATA field in the EVS Channel Aware Request.",
                                    "table number": 32,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "10.2.2\tExample use cases",
                            "text_content": "The following examples demonstrate how requests for redundancy and frame aggregation are realised in the RTP stream.\nAll examples assume that the speech codec generates frames numbered N-10…N in a continuous flow.\nFigure 10.7 illustrates the flow of parameter sets for encoded frames, with each increment representing a time difference of 20 milliseconds. The figure showcases the transmission of data through various stages, including encoding, modulation, and decoding, emphasizing the synchronization and efficiency of the communication process. Key elements include the transmitter, receiver, and intermediate nodes, highlighting the interconnected nature of the network and the importance of timing synchronization for reliable data transmission.\nFigure 10.7: Flow of parameter sets for encoded frames\nEach increment corresponds to a time difference of 20 ms\nIn the examples below, P-1…P denote the sequence numbers of the packets.\nEXAMPLE 1:\nAn RTCP_APP_REQ_RED request with bit field 000000000000 (no redundancy) and RTCP_APP_REQ_AGG request with value = 0 (no frame aggregation) will yield packets as shown in figure 10.8.\nFigure 10.8 illustrates the default frame aggregation process in a network, where each frame is associated with a single packet. The figure depicts the frame aggregation process, starting with the source device sending a frame to the network. The frame is then passed through various network nodes, including switches and routers, before reaching its destination. The process involves packet reordering and reassembly, ensuring that the received frame is in the correct order and format. The figure highlights the importance of frame aggregation in improving network efficiency and reducing overhead.\nFigure 10.8: Default frame aggregation with one frame per packet\nEXAMPLE 2:\nAn RTCP_APP_REQ_RED request with bit field 000000000001 (100% redundancy and no offset) and an RTCP_APP_REQ_AGG request with value = 0 (no frame aggregation) will yield packets as shown in figure 10.9.\nFigure 10.9 illustrates the process of payload packetization with 100% redundancy and an offset of one packet. The figure shows a sequence of packets, each with a unique identifier, being transmitted over a network. The packets are divided into smaller units called frames, which are then further divided into segments. Each segment is assigned a unique identifier and is transmitted with a 100% redundancy check to ensure data integrity. Additionally, an offset of one packet is applied to the sequence, allowing for error correction and synchronization between the sender and receiver. The figure demonstrates the importance of efficient packetization techniques in maintaining data reliability and reducing network congestion.\nFigure 10.9: Payload packetization with 100 % redundancy and an offset of one packet\nEXAMPLE 3:\nAn RTCP_APP_REQ_RED request with bit field 000000000010 (100% redundancy with offset 1 extra packet) and an RTCP_APP_REQ_AGG request with value = 0 (no frame aggregation) will yield packets as shown in figure 10.10.\nFigure 10.10 illustrates the process of payload packetization with 100% redundancy and an additional offset of one packet. The figure shows a sequence of packets, each with a unique identifier, being transmitted over a network. The packets are divided into smaller units called frames, which are then further divided into segments. Each segment is assigned a unique identifier and is transmitted with a 100% redundancy check to ensure data integrity. Additionally, an extra offset of one packet is added to the sequence to prevent collisions and ensure the correct order of packets at the receiver. The figure highlights the importance of efficient packetization techniques in maintaining data integrity and preventing network congestion.\nFigure 10.10: Payload packetization with 100 % redundancy and an extra offset of one packet\nNO_DATA frames must be inserted to fill the gaps between two non-consecutive frames, e.g. between N-2 and N.\nEXAMPLE 4:\nAn RTCP_APP_REQ_RED request with bit field 000000000000 (no redundancy) and RTCP_APP_REQ_AGG request with value = 1 (frame aggregation 2 frames/packet) will yield packets as shown in figure 10.11.\nFigure 10.11 illustrates the process of payload packetization with 2 frames aggregated per packet, showcasing the division of data into smaller, more manageable units for efficient transmission. The figure depicts the initial raw data packet, which is then segmented into two smaller frames. These frames are then combined to form a single aggregated packet, as indicated by the merging of the two frames at the bottom of the figure. This process is crucial for managing network resources and improving overall data transmission efficiency.\nFigure 10.11: Payload packetization with 2 frames aggregated per packet\nEXAMPLE 5:\nAn RTCP_APP_REQ_RED request with bit field 000000000001 (100% redundancy) and an RTCP_APP_REQ_AGG request with value = 1 (frame aggregation 2 frames/packet) will yield packets as shown in figure 10.12.\nFigure 10.12 illustrates the process of payload packetization with 100% redundancy and two frames aggregated per packet. The figure shows a sequence of frames being combined to form a single packet, ensuring data integrity and reliability. This method is commonly used in high-speed communication systems to maximize throughput and minimize errors. The figure also highlights the importance of efficient packetization techniques in modern networking, where data rates are increasing and network congestion is a growing concern.\nFigure 10.12: Payload packetization with 100 % redundancy and 2 frames aggregated per packet\nEXAMPLE 6:\nAn RTCP_APP_REQ_RED request with bit field 000000000010 (100% redundancy with offset 1 extra packet) and an RTCP_APP_REQ_AGG request with value = 1 (frame aggregation 2 frames/packet) will yield packets as shown in figure 10.13.\nFigure 10.13 illustrates the process of payload packetization with 100% redundancy, one extra offset, and 2 frames aggregated per packet. The figure showcases the various stages of packetization, including the initial data frame, the addition of redundancy, and the final packetization with the extra offset. This process is crucial for ensuring data integrity and reliability in telecommunication networks.\nFigure 10.13: Payload packetization with 100 % redundancy, \none extra offset and 2 frames aggregated per packet\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.2.3\tSDP negotiation for RTCP-APP",
                            "text_content": "RTCP-APP request messages that can be used are negotiated with SDP using the ‘3gpp_mtsi_app_adapt’ attribute. The syntax for the 3GPP MTSI RTCP-APP adaptation attribute is:\na=3gpp_mtsi_app_adapt:<reqNames>\nwhere:\n<reqNames> is a comma-separated list identifying the different request messages (see below).\nThe ABNF for the RTCP-APP adaptation messages negotiation attribute is the following:\nadaptation attribute\t= \"a\" \"=\" \"3gpp_mtsi_app_adapt\" \":\" reqName *(\",\" reqName)\nreqName\t\t\t= \"RedReq\" / \"FrameAggReq\" / \"AmrCmr\" / \"EvsRateReq\" / \"EvsBandwidthReq\" / \"EvsParRedReq\" / \"EvsIoModeReq\" / \"EvsPrimaryModeReq\"\nThe name denotes the RTCP APP packet types the SDP sender supportes to receive. The meaning of the values is as follows:\nRedReq: Redundancy Request, clause 10.2.1.3\nFrameAggReq: Frame Aggregation Request, clause 10.2.1.4\nAmrCmr: Codec Mode Request for AMR and AMR-WB, clause 10.2.1.5\nEvsRateReq: EVS Primary Rate Request, clause 10.2.1.7\nEvsBandwidthReq: EVS Bandwidth Request, clause 10.2.1.8\nEvsParRedReq: EVS Partial Redundancy Request, clause 10.2.1.9\nEvsIoModeReq: EVS Primary mode to EVS AMR-WB IO mode Switching Request, clause 10.2.1.10\nEvsPrimaryModeReq: EVS AMR-WB IO mode to EVS Primary mode Switching Request, clause 10.2.1.11\nAn MTSI client supporting the reception of any RTCP APP packets defined in the present specification shall indicate the supported RTCP APP packet types in an initial SDP offer or answer it sends using the SDP \"a=3gpp_mtsi_app_adapt\" attribute. If the answerer receives an \"a=3gpp_mtsi_app_adapt\" attribute in the SDP offer, it may send the indicated RTCP APP packet types towards the offerer. The answerer shall indicate its capabilties with the \"a=3gpp_mtsi_app_adapt\" attribute irrespective if an \"a=3gpp_mtsi_app_adapt\" attribute was received and the capabilities within. If the offerer receives an \"a=3gpp_mtsi_app_adapt\" attribute in the SDP answer, it may send the indicated RTCP APP packet types towards the answerer.\nAn MTSI client supporting only AMR and AMR-WB therefore may for instance include the following in the SDP offer:\na=3gpp_mtsi_app_adapt: RedReq,FrameAggReq,AmrCmr\nAn MTSI client supporting only AMR, AMR-WB and EVS may for instance include the following in the SDP offer:\na=3gpp_mtsi_app_adapt: RedReq,FrameAggReq,AmrCmr,EvsRateReq,EvsBandwidthReq,EvsParRedReq,EvsIoModeReq,EvsPrimaryModeReq\nThe attribute shall only be used on media level.\nWhen interworking with pre-Rel-12 clients or non-MTSI clients, it may happen that they support the RTCP-APP signalling but not the SDP negotiation for AMR and AMR-WB. An MTSI client failing to negotiate RTCP-APP as described may still try to use the RTCP-APP signalling when requesting adaptation, but the MTSI client shall then also monitor the received media in order to determine if some or all of the adaptation requests included in the RTCP-APP were partially or fully followed or not followed at all. If none of the adaptation requests is followed, not even partially, then this is an indication that the remote client does not support the RTCP-APP signalling. The MTSI client should then try to use other means for triggering the adaptation, for example CMR in the AMR/AMR-WB payload or RTCP Sender Reports/Receiver Reports.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "10.3\tVideo",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "10.3.1\tGeneral",
                            "text_content": "MTSI clients receiving RTCP Receiver Reports (RR) indicating nonzero packet loss shall support adjusting their outgoing bitrate accordingly (see RFC 3550 [9]). Note that for IMS networks, which normally have nonzero packet loss and fairly long round-trip delay, the amount of bitrate reduction specified in RFC 3448 [56] is generally too restrictive for video and may, if used as specified, result in very low video bitrates already at (for IMS) moderate packet loss rates.\nA video sender shall support adapting its video output rate based on RTCP reports and TMMBR messages. This adaptation shall be used as described in clauses 10.3.2 to 10.3.6 unless the video sender is explicitly notified that no rate adaptation shall be performed, e.g.by setting the minimum quality bitrate equal to the negotiated bitrate. This adaptation should be performed while maintaining a balance between spatial quality and temporal resolution, which matches the bitrate and image size. Some examples are given in Annex B. For the handling of packet loss signaled through AVPF NACK and PLI, or for rate adaptation with RTCP reports and TMMBR messages, the video sender shall be able to dynamically adapt to the reported conditions, in particular to facilitate the operation of quality-recovery techniques pertinent to the situations. Quality-recovery techniques include, but may not be limited to, adapted intra frame periods, adaptation of random intra macroblock refresh ratios, FEC, and adaptation of the bit rates.\nThe rate adaptation can be controlled by using the video adaptation parameters defined in clause 17.2. By using the MIN_QUALITY/BIT_RATE/ABSOLUTE or the MIN_QUALITY/BIT_RATE/RELATIVE parameters it is possible to set the minimum bitrate for the adaptation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.3.2\tSignaling mechanisms",
                            "text_content": "The use of TMMBR and TMMBN depends on the outcome of the SDP offer/answer negotiation, see Clause 6.2.3.2.\nIf TMMBR and TMMBN are allowed to be used in the session and if the receiving MTSI client in terminal is made aware of a reduction in downlink bandwidth allocation through an explicit indication of the available bandwidth allocation from the network (e.g. due to QoS renegotiation or handoff to another radio access technology), or from measurements such as increased delay at the media receiver, it shall notify the media sender of the new current maximum bitrate using TMMBR. In this context the TMMBR message is used to quickly signal to the other party a reduction in available transport bitrate. If rate adaptation is allowed, the media sending MTSI client shall, after receiving TMMBR, adjust the sent media rate to the requested rate or lower and shall respond by sending TMMBN, as described in CCM [43]. When determining the encoder bitrate the MTSI client needs to compensate for the IP/UDP/RTP overhead since the bitrate indicated in the TMMBR message includes this overhead.  To determine TMMBR and TMMBN content, both media sending and media receiving MTSI clients in terminals shall use their best estimates of packet measured overhead size when measured overhead values are not available. If the TMMBR message was sent due to an explicit indication of available bandwidth allocation, the MTSI client in terminal that sent the TMMBR message shall, after receiving the TMMBN, send a SIP UPDATE to the other party to establish the new rate as specified in clause 6.2.7.\nIt is the media sender’s responsibility to estimate if, and by how much, queue build-up has occurred due to use of a sending rate that was higher than the available throughput, before being able to reduce the sending rate. It is therefore also the media sender’s responsibility to recover the buffering delay by sending with a rate that is lower than what the media receiver has requested in the TMMBR message for some period of time.\nIf TMMBR and TMMBN are not allowed to be used in the session and if the MTSI client in terminal is made aware of a reduction in downlink bandwidth allocation (e.g. due to QoS renegotiation or handoff to another radio access technology) it shall send a SIP UPDATE to the other party to establish the new rate as specified in clause 6.2.7.\nIf the receiving MTSI client in terminal is made aware of an increase in downlink bandwidth allocation (determined via separate negotiation) through an explicit indication from the network (e.g. due to QoS renegotiation or handoff to another radio access technology) then, if this has not yet occurred, it shall send a SIP UPDATE to the other party to establish the new rate as specified in clause 6.2.7.\nWhen an MTSI client in terminal receives available bandwidth information from ANBR (see 10.7), it shall not be considered an explicit indication of available bandwidth allocation that requires sending SIP UPDATE as described above. The conditions under which it is allowed to send SIP UPDATE based on ANBR are described in clause 6.2.5.1.\nThe media sender information in the RTCP Sender Reports (RTCP SR) contains information about how many packets and how much data the media sender has sent. A media receiving MTSI client in terminal may use this information to detect the difference between the sent bitrate (from the remote media sending client) and the received bitrate (in the local media receiving client).\nThe report blocks in the RTCP Receiver Reports (RTCP RR) or in the RTCP Sender Reports (RTCP SR), contain information about the highest received sequence number, the packet loss rate, the cumulative number of packet losses and interarrival jitter as experienced by the media receiver. A media sending MTSI client in terminal may use this information to detect the difference between the sent bitrate (from the local media sending client) and the received bitrate (in the remote media receiving client) and also to estimate the queue build-up that can happen when congestion occurs somewhere in the path.\nTo enable proper video rate adaptation, RTCP Reports must be sent frequently enough (e.g. at least twice per second) to allow MTSI clients to detect network congestion. An MTSI client in terminal shall set the RR and RS bandwidth modifiers in the SDP offer/answer to reserve an RTCP bandwidth that is no smaller than the bandwidth reserved by setting the RTCP bandwidth modifiers as follows (see Annex A.6):\n-\t0 bps for the RS field (at media level);\n-\t5000 bps for the RR field (at media level).\nNOTE 1:\tIn a point-to-point session the MTSI clients in terminals will be reserved, on average, 2500 bps of RTCP bandwidth in each direction when the RTCP bandwidth modifiers are negotiated as described above.\nFurthermore, unless there is a clear need to set the RTCP bandwidth higher than specified above, the RTCP bandwidth modifiers in the SDP offer should be set as specified above.\nNOTE 2:\tRFC 3550 recommends that the RTCP bandwidth default be 5% of the media bandwidth.  However, this default may be excessive in various scenarios, including 3GPP access networks, and should therefore be carefully evaluated when setting the RR and RS values differently than recommended in this clause.\nAnother way to estimate the transmitted bitrate is to analyse the size of the packets and the RTP time stamps.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.3.3\tAdaptation triggers",
                            "text_content": "An MTSI client in terminal sending or receiving media needs to know the currently allowed bitrate (The given telecommunication figure illustrates the process of media adaptation in a Real-Time Transport Protocol (RTCP) environment. The figure depicts an MTSI (Multiplex Transport Stream Interface) client in a terminal that is either sending or receiving media. The client must be aware of the current bitrate limitations, which are indicated by the allowed bitrate. The figure emphasizes the use of adaptation triggers, such as the Reception Report Blocks (RRBs) in the RTCP Receiver Reports or the Sender Report Blocks (SRBs) in the RTCP Sender Reports, to adjust the bitrate based on the feedback received from the server. Additionally, the figure highlights the use of the Adaptive Network Bitrate (ANBR) as another adaptation trigger. This ensures that the media is transmitted and received at an optimal bitrate, maintaining the quality of the media stream while adhering to the network's bitrate restrictions.). The currently allowed bitrate is the minimum of the bitrate negotiated in SDP offer/answer and the bitrate allowed after the latest preceeding adaptation (e.g. last previous TMMBR message) that increased or decreased the allowed bitrate for the encoder. When no bitrate reduction trigger is received, the value from SDP offer/answer shall be used. The currently allowed bitrate may therefore vary over time.\nAn MTSI client in terminal sending media shall use at least one adaptation trigger that is based on the reception report blocks in the received RTCP Receiver Reports or in the RTCP Sender Reports. An MTSI client in terminal sending media should also use ANBR as an adaptation trigger.\nNOTE:\tWhen interworking with non-MTSI clients then it may happen that the remote client only sends RTCP Receiver Reports (or Sender Reports) but does not use any adaptation triggers in its receiver. This may happen even if the remote client supports and uses TMMBR because it is possible that the remote client uses TMMBR only to signal bitrate changes due to handoff to another access and not for dynamic rate adaptation.\nAn MTSI client in terminal receiving media shall use at least one adaptation trigger that is not ECN. Examples of adaptation triggers are: ANBR, measurements of packet loss rate; measurements of jitter; difference between sending bitrate (e.g. from RTCP SR) and measured received bitrate; differences between sending packet rate (from RTCP SR) and received packet rate; and play-out delay margin (from packet arrival time until their scheduled play-out time).\nAn MTSI client in terminal sending or receiving media:\n-\tShould use one or more triggers that is capable to detect a needed reduction in throughput of 10% or more. If a trigger requires reception of an RTCP Sender or Receiver Report, the change should be detected within 3 frame durations of reception of the Sender or Receiver Report. If all triggers do not require Sender or Receiver Report reception, the change should be detected within 8 frame durations of the reduction in throughput.\n-\tShall use one or more triggers that is capable to detect a needed reduction in throughput of 25% or more. If a trigger requires reception of an RTCP Sender or Receiver Report, the change shall be detected within 6 frame durations of reception of the Sender or Receiver Report. If all triggers do not require Sender or Receiver Report reception, the change shall be detected within 15 frame durations of the reduction in throughput.\nIf an MTSI client in terminal receiving media uses DL ANBR to detect a needed reduction in throughput of 10% or more, it should send RTCP TMMBR to request the highest bitrate that is lower than ANBR and all other adaptation triggers.\nAn MTSI client in terminal sending media should take UL ANBR into account and adapt the sent bitrate to the highest bitrate that is still lower than or equal to the minimum of the adaptation triggers, and should then send RTCP TMMBN based on this bitrate.\nAn MTSI client in terminal receiving media shall use at least one method to estimate if and by how much the bitrate can be increased (). A method for how an MTSI client in terminal can estimate when and by how much the bitrate can be increased is described in Annex C.2.5.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.3.4\tSender behavior, downswitching",
                            "text_content": "The downswitching of the encoder bitrate in response to received adaptation requests or performance metrics is divided into two phases:\n-\tFirst a rate reduction phase, where the bitrate is reduced from the target bitrate currently used by the sender, which is too high for the current operating conditions, to the bitrate that is suitable for the current operating conditions.\n-\tThen a delay recovery phase, where the delay of any buffered data is recovered.\nThese phases are described in more detail below.\nAnnex C.2 gives a further description of the downswitching procedure.\nAn MTSI client in terminal sending media should be able to immediately change the sending bitrate to the bitrate requested in a received TMMBR message.\nDue to differences in client implementations (video encoder, cameras, etc), a sending MTSI client in terminal may or may not be able to immediately change the sending bitrate to the bitrate requested in a TMMBR message. The capability to immediately change the bitrate may also depend on whether the bitrate adaptation requires changing the frame rate and/or the video resolution.\nWhen a reduction of the bitrate is requested with TMMBR and the MTSI client in terminal cannot immediately adapt to the requested bitrate then this will introduce excessive bits () since the sending bitrate will be higher than the available bitrate. These excessive bits will cause buffering, packet delays and sometimes packet losses. In this case, the MTSI client in terminal shall calculate the amount of excessive bits that are created until the bitrate has been reduced to the requested bitrate. In this case, the sending MTSI client in terminal:\n-\tshould adapt the encoding bitrate such that:\n(10.3.4.2-1)\n-\tshall adapt the encoding bitrate such that:\n(10.3.4.2-2)\nwhere:\n(10.3.4.2-3)\nand:\tis the adaptation time required by the Worst-Case Adaptation Algorithm, see Annex C.2.4, in this case 1 second;\nis the bit-rate used before the adaptation starts;\nis the bit-rate requested in the TMMBR message.\nThe  is calculated over the , which is from the time when the TMMBR message is received until encoder has adapted down to the , see also Annex C.2.4. The bitrate used by the encoder is expected to vary from frame to frame. The bitrate should therefore be averaged using a sliding window over at least the last 5 frame durations before comparing it to the .\nAn MTSI client in terminal reducing the bitrate:\n-\tshould have adapted down to   after the TMMBR message was received,\n-\tshall have adapted down to   after the TMMBR message was received.\nThe above procedure applies only when a bitrate reduction is requested with a TMMBR message. When the bitrate is increased, after the congestion has been cleared, then the above procedure does not apply.\nAnnex C.2.4 gives a further description of the above requirements and recommendations and how the encoder should behave during the rate reducing phase.\nAfter adapting down to the requested bit-rate the sending MTSI client in terminal shall use a delay recovery phase where the bit-rate is (on average) lower than the requested bit-rate until the buffering delay caused by the excessive bits () described in clause 10.3.4.2 have been recovered, see also Annex C.2.4 and C.2.6.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.3.5\tSender behavior, up-switching",
                            "text_content": "An MTSI client in terminal sending media with a bitrate lower than currently allowed bitrate should try to increase the bitrate up to the currently allowed bitrate. The bitrate of the encoded media is increased slowly until the currently allowed bitrate is reached while monitoring that the quality is maintained, i.e. no packet losses and no delay should be introduced because of the up-switch.\nAn MTSI client in terminal sending media with a bitrate according to the currently allowed bitrate and receiving a TMMBR request for increasing the bitrate:\n-\tshould ramp up the bitrate to the currently allowed bitrate within 0.5 seconds,\n-\tshall ramp up the bitrate to the currently allowed bitrate within 1 second.\nIf during the up-switch procedure the MTSI client receives a TMMBR message for reducing the bitrate then the up-switch shall be aborted and the down-switch is started as described in clause 10.3.4.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.3.6\tReceiver behavior, down-switching",
                            "text_content": "An MTSI client in terminal receiving media and detecting that the throughput is reduced shall behave as follows:\n-\tWhen detecting that the throughput is reduced by more than 10% then it should send a TMMBR message requesting a bitrate that is at least 10% lower than the currently allowed bitrate,\n-\tWhen detecting that the throughput is reduced by more than 25% then it shall send a TMMBR message requesting a bitrate that is at least 25% lower than the currently allowed bitrate.\nTMMBR messages for down-switch are urgent feedback messages and shall be sent as soon as possibly. AVPF early mode or immediate mode, [40] shall be used whenever possible.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.3.7\tReceiver behavior, up-switch",
                            "text_content": "An MTSI client in terminal receiving media and detecting that the bitrate can be increase shall behave as follows:\n-\tIf the bitrate can be increased by at least 5% then the MTSI client in terminal should send a TMMBR message requesting a bitrate that is:\n(10.3.7-1)\n-\tIf the bitrate can be increased by at least 15% then the MTSI client in terminal shall send a TMMBR message requesting a bitrate that is:\n(10.3.7-2)\nTMMBR messages for up-switch shall be sent with the normal compound RTCP packets following the normal RTCP transmission rules defined for the RTP/AVP profile, [9]. This is to not unnecessarily prevent possible subsequent urgent feedback messages, e.g. for down-switch, to be sent using AVPF early mode or immediate mode.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.3.8\tECN triggered adaptation",
                            "text_content": "ECN triggered adaptation may be used in addition to other adaptation triggers. However, when ECN is used an MTSI client in terminal receiving media shall also use at least one other adaptation trigger, see clause 10.3.3. When ECN is used, an MTSI client in terminal sending media shall also monitor the received RTCP SR/RR. If ANBR described in clause 10.7 is used, the bitrate value used in that bitrate recommendation shall be seen as independent from ECN and thus not taking ECN-CE markings into account. It is therefore possible that ECN-CE and ANBR with a decreased bitrate value both report on the same detected restriction.\nNOTE 1:\tWhen ECN is negotiated, some networks in the path may allow ECN signalling to pass through even though the network does not actively use ECN to indicate congestion. For example, in a session between an LTE UE and a HSPA UE, the LTE access may allow and use ECN, but the backbone and the HSPA access may allow ECN to be used without marking packets with ECN-CE if congestion occurs in the backbone or in the HSPA access side.\n\nTable 10.2 defines a mandatory set of parameters that are used by the ECN triggered adaptation. The default values for the parameters are also specified. Alternate values for these parameters may be configured into the MTSI client based on operator policy, for example using OMA-DM.\nTable 10.2: Configuration parameters when ECN is used as a trigger\n\nThe ECN_min_rate parameter is set to the larger of the ECN_min_rate_relative and ECN_min_rate_absolute values. Since the ECN_min_rate_relative parameter is relative to the outcome of the offer-answer negotiation this means that the ECN_min_rate value may be different for different sessions. The ECN_min_rate_absolute parameter is used to prevent too low bit rates for video, which would result in too low quality.\nThe configuration of adaptation parameters, and the actions taken during the adaptation, are specific to the particular triggers. For example, the adaptation may be configured to reduce the media bit-rate to ECN_min_rate when ECN-CE is detected, while it may reduce the media bit-rate even further for bad radio conditions when high PLR is detected.\nMultiple ECN-CE markings within one RTP-level round-trip time is considered as the same congestion event. Each time an MTSI client detects a congestion event it shall send an adaptation request to reduce the media bit-rate unless already operating at the ECN_min_rate or below. An MTSI client detecting a congestion event shall not send an adaptation request to increase the media bit-rate for a time period ECN_congestion_wait after the end of the congestion event.\nMultiple adaptation algorithms can be used in parallel, for example ECN-triggered adaptation, ANBR, and Packet Loss Rate-triggered adaptation. When multiple adaptation trigger algorithms are used for the rate adaptation, the rate that the MTSI client is allowed to use should be no higher than any of the rates determined by each adaptation algorithm.\nNOTE 2:\tFor example, if the ECN-triggered adaptation indicates that 100kbps should be used and if the PLR-triggered adaptation indicates that 75kbps should be used then the rate that the MTSI client uses should be no higher than min(100, 75) = 75kbps.\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 10.2: Configuration parameters when ECN is used as a trigger",
                                    "table number": 33,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "10.4\tText",
                    "description": "",
                    "summary": "",
                    "text_content": "Rate adaptation (downgrade of used bandwidth) of text shall follow the recommendation in clause 9 of RFC 4103 [31]. RTCP reports are used as indicator of loss rate over the channel.\nWhen the transmission interval has been increased in order to handle a congestion situation, return to normal interval shall be done when RTCP reports low loss.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "10.5\tExplicit Congestion Notification",
                    "description": "",
                    "summary": "",
                    "text_content": "When the (e)NodeB experiences congestion it may set the ECN bits in the IP header to ‘11’ to indicate \"Congestion Experienced\" for packets that have been marked with ECN Capable Transport (ECT), [83], [84].\nAdaptation requests should be sent in response to ECN congestion events. Clauses 10.2 and 10.3 describe adaptation for speech and video when ECN-CE is detected.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "10.6\tUsing the a=bw-info attribute for adaptation",
                    "description": "",
                    "summary": "",
                    "text_content": "This sub-clause outlines a few generic recommendations for how the bandwidth properties signalled with the ‘a=bw-info’ may be used for the adaptation. Media specific usage may override these guidelines.\nDuring the session, when adaptation is needed:\n-\tThe bit rate range from the Minimum Desired Bandwidth up to the Maximum Desired Bandwidth (if different) defines the most commonly used adaptation range. The primary means for the adaptation in this range is adapting the source encoding while adapting the RTP packetization should remain unchanged. This includes adapting the frame range for video.\n-\tWhen adapting in this range, downwards rate adaptation should be fast while upwards rate adaptation should be relatively slow. This is because when these bandwidth properties are different then it is likely that an MBR>GBR bearer is used and the performance defined with the QoS parameters is only guaranteed when the bit rate does not exceed the GBR [90].\n-\tThe bit rate range above the Maximum Desired Bandwidth up to the Maximum Supported Bandwidth (if different) is mainly intended for sending application layer redundancy, in case additional bandwidth is needed for this purpose.\n-\tIt is preferable to first try to overcome the degraded operating conditions by reducing the bit rate, at least down to the Minimum Desired Bandwidth or even down to the Minimum Supported Bandwidth, before adding application layer redundancy.\n-\tThe bit rate range below the Minimum Desired Bandwidth down to the Minimum Supported Bandwidth (if different) is mainly intended to be used to keep the session alive during severely degraded operating conditions. For video, this can be achieved by e.g. reducing the resolution or the frame rate. For speech, this can be achieved by using frame aggregation or using a codec mode below the Minimum Desired Bandwidth. The end-to-end delay may be significantly increased and/or the quality may be significantly reduced. It may still be preferable to keep the media alive compared to e.g. video freezing, even if the quality is degraded.\n-\tThe Minimum Supported Bandwidth may be set larger than zero to limit the adaptation, e.g. to fulfil certain service requirements on end-to-end delay or minimum quality level. If the throughput is so low that not even the Minimum Supported Bandwidth can be fulfilled then there is likely no reason to continue using that media type in the session.\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "10.7\tAccess network bitrate recommendation",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "10.7.1\tGeneral",
                            "text_content": "Support and use of access network bitrate recommendations (ANBR) as described in this clause are optional for MTSI clients in terminal. Clause 10.7 does not apply to an MTSI client in terminal that does not support the ANBR message.\nSome access networks may provide the MTSI client in terminal with ANBR messages, separately per local access bearer and separately for the local uplink and downlink. It is expected that an ANBR message is sent to the MTSI client in terminal whenever the access network finds it reasonable to inform about a change in the recommended bitrate, such that the MTSI client in terminal is generally provided with up-to-date recommended bitrate information.\nIn general, a single access bearer can carry multiple RTP streams, in which case ANBR applies to the sum of the individual RTP stream bitrates on that bearer.\nAccess networks supporting ANBR may also support a corresponding ANBR Query (ANBRQ) message, which allows the MTSI client in terminal to query the network for updated ANBR information. ANBRQ shall only be used to query for an ANBR update when media bitrate is to be increased, not for media bitrate decrease.\nThe ANBR and ANBRQ messages, as used in this clause, are conceptual messages that allows generalization of the description between different accesses, e.g. LTE (see 10.7.4) and NR (see 10.7.5) and wireless LAN. There shall be a defined mapping between the conceptual ANBR/ANBRQ and actual messages for each access where ANBR/ANBRQ signaling is to be used. The format of such access-specific ANBR/ANBRQ messages may differ between different types of access networks, and there may not even exist a one-to-one mapping of messages. The recommended bitrate value in ANBR/ANBRQ is here defined to include IP and higher layer overhead, including bitrate used for RTCP signaling (as opposed to e.g. b=AS line in SDP, which does not include RTCP). Other definitions can be used by the individual access network mappings (for LTE and NR, the recommended physical layer bitrate is signalled by the access network, see clauses 10.7.4 and 10.7.5), e.g., including overhead below IP layer that is added by the access network, and the UE shall then perform appropriate value translation, e.g. adjusting for use of ROHC and removing the lower layer overhead.\nWhile the sizes of all other protocol overheads are static or change slightly during an MTSI session, the size of ROHC header is highly dynamic, and hence there is no deterministic and standardized way to map the recommended physical layer bitrate into the IP layer bitrate. The queried physical layer bitrate should be set considering all the L2 and above headers.\nNOTE 1:\tThe UE may determine the corresponding IP layer bitrate based on the long-term average of the IP packet sizes, L2 header sizes, and ROHC header sizes, but the translation methodologies and the estimation error levels required to implement accurate media bitrate adaptation have not been specified.\nNOTE 2:\tThe eNodeB may determine the corresponding IP layer bitrate based on the long-term average of the IP packet sizes, L2 header sizes, and ROHC header sizes, but the translation methodologies and the estimation error levels required to implement accurate media bitrate adaptation have not been specified.\nNOTE 3:\tThe recommended/queried bitrate as signalled over the LTE and NR access is defined to be in kbps at the physical layer. The uplink/downlink bitrate at the physical layer is , where is the bit-length of the k-th successfully transmitted/received TB by the UE within the window T. In TS 36.321 and 38.321, a window length of 2000 ms is applied.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.7.2\tRelation to session signaling bitrate information",
                            "text_content": "ANBR is only a recommendation and does not change any bitrate restrictions established by session signaling, described in clause 6.2.5.1. Such unaffected session signaling bitrate information includes:\n-\tSDP \"b=\" lines, including \"b=AS\", \"b=RS\", and \"b=RR\".\n-\tSDP \"a=bw-info\" lines, if present.\n-\tCodec-specific min/max bitrates, based on codec configuration and/or packetization parameters.\n-\tMBR and GBR QoS parameters.\nAn ANBR value with a bitrate above a maximum bitrate limit established by any of the above shall therefore instead be considered as a bitrate recommendation for the lowest of the above listed maximum bitrates (except for GBR that is not considered a maximum bitrate). When using a codec configuration with discrete bitrate steps, and if the ANBR value does not exactly match such discrete codec bitrate, it shall be considered as a bitrate recommendation for the next lower, signaled codec bitrate.\nIf a GBR bearer is used (GBR > 0), an ANBR value below GBR may be ignored, but the MTSI client in terminal should then be prepared to handle a higher than target packet loss and / or delay for the affected bearer. An ANBR value of 0 should be taken as a recommendation to temporarily stop sending RTP media on the affected bearer, without re-negotiating the session, with the exception for RTP media related to the first \"m=audio\" line in the SDP that shall never temporarily stop sending based on ANBR value 0. Corresponding RTCP transmission shall, when enabled, continue even when RTP media is stopped due to ANBR value 0.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.7.3\tUse with dynamic bitrate adaptation",
                            "text_content": "An MTSI client in terminal shall use the ANBR message as adaptation trigger, taking other available triggers into account. The same principle shall apply for both speech and video, adapting to the lowest bitrate resulting from any of the possibly multiple, available triggers. Clauses 10.2 and 10.3 describe adaptation details for speech and video. Use of ANBR in combination with ECN signaling is described in clause 10.3.8.\nA received ANBR message for a certain access bearer and media direction shall be considered valid for use as input to adaptation trigger evaluation until either another ANBR message is received for the same access bearer and media direction, until that access bearer is closed, or until the SIP session is either re-negotiated or closed.\nThis relates to adaptation of the media in RTP streams that the MTSI client in terminal sends in the uplink direction, controlling the local media encoder bitrate.\nThe below figures with signaling diagrams describe ANBR usage for a single media, regardless if that is voice or video. The \"Request max\" message in those figures is a generalized application level message that corresponds to RTCP TMMBR for video and CMR or RTCP-APP for voice. Similarily, the \"Notify max\" message is a generalized application level message that corresponds to RTCP TMMBN for video. \"Notify max\" has no counterpart for voice and is therefore not used for voice.\nAn MTSI client in terminal that rececives both ANBR with bitrate R0 and a \"Request max\" message with bitrate R1 for its media sending direction shall use min(R0, R1) as the combined bitrate for those two adaptation triggers.\nFigure 10.7-1 illustrates the relationship between uplink bitrate and ANBR (Average Network Bitrate) in a telecommunication system. The graph shows that as the ANBR increases, the uplink bitrate decreases, indicating a trade-off between the two parameters. This relationship is crucial for network operators to optimize their systems for both performance and efficiency. The figure also highlights the impact of various factors, such as user density and network congestion, on the uplink bitrate.\nFigure 10.7-1 Uplink bitrate decrease based on ANBR\n\nFigure 10.7-2 illustrates the uplink bitrate increase based on ANBR, showcasing how the data rate grows as the ANBR value increases. The figure depicts the relationship between the uplink bitrate and ANBR, with the x-axis representing the ANBR value and the y-axis representing the uplink bitrate in Mbps. The curve demonstrates a positive correlation between the two variables, indicating that as the ANBR value increases, the uplink bitrate also increases. This relationship is crucial for network operators to optimize their networks and ensure efficient data transmission.\nFigure 10.7-2 Uplink bitrate increase based on ANBR\nWhen an MTSI client in terminal receives an ANBR message for the local uplink that triggers an adaptation decision (step 4 of Figures 10.7-1 and 10.7-2):\n1.\tFor both video and voice, an adaptation resulting in a reduction of the media sender bitrate shall be initiated immediately without further signaling (step 6 of Figure 10.7-1).\n2.\tFor the case of video and if TMMBR / TMMBN are supported in the session:\na)\tIf the adaptation decision means that the MTSI client in terminal adapts bitrate below the most recently received TMMBR message (if any, step 4 of Figures 10.7-1 or 10.7-2), the media sender itself owns the uplink bitrate restriction and a corresponding TMMBN message shall be sent, notifying the remote media receiver of this changed local uplink restriction (step 7 of Figure 10.7-1 or step 5 of Figure 10.7-2). Such TMMBN message has the media sender’s own SSRC included in the bounding set [43]. Note that only the media sender or receiving TMMBR with a lower bitrate can then remove such own restriction, which means that TMMBR messages with a higher bitrate received from the remote media receiver will be ineffective and ignored. The media sender can repeat this procedure and either increase or decrease the used bitrate based on subsequent local uplink ANBR, sending corresponding TMMBN also for those changes, as long as the MTSI client in terminal does not receive a TMMBR from the remote MTSI client with a bitrate lower than the most recently sent TMMBN.\nb)\tAn adaptation resulting in an increase of the media sender bitrate in uplink (Figure 10.7-2) shall delay the media bitrate increase (step 6 of Figure 10.7-2) to allow sufficient time for the remote media receiver to receive and react to the TMMBN in bullet 2.a above, as described by section 3.5.4 of CCM [43] (steps 7-9 of Figure 10.7-2). After such delay, the media sender bitrate is increased (step 12 of Figure 10.7-2). The bitrate increase shall take all available adaptation triggers into account, which can cause the bitrate increase to be separated into several steps (see clause C.2.5).\nc)\tIt is recommended that the bitrate in a TMMBN from bullet 2.b) that is pre-announcing an increase in the media sender bitrate in uplink is set to correspond to the received ANBR message and not to the next bitrate step in a step-wise increase (see clause 10.3.5), to avoid unnecessary TMMBN, ANBRQ, and ANBR signaling (see also bullet 4) below).\n3.\tFor the case of voice, an adaptation resulting in an increase of the media sender bitrate in uplink shall result in an increase of media sender bitrate at the earliest opportunity (step 6 of Figure 10.7-2), taking other adaptation triggers into account, such as CMR.\n\nFigure 10.7-3 illustrates the downlink bitrate decrease based on ANBR through application signaling, showcasing the impact of ANBR on the network's performance. The figure depicts the relationship between ANBR and the downlink bitrate, with ANBR affecting the throughput of the network. Key elements include the ANBR threshold, the downlink bitrate, and the application signaling. The graph demonstrates how ANBR can optimize network resources and improve overall network performance.\nFigure 10.7-3 Downlink bitrate decrease based on ANBR through application signaling\n\nFigure 10.7-4 illustrates the downlink bitrate increase achieved through application signaling, as measured by the Automatic Network Binding (ANBR) protocol. The figure depicts the relationship between the ANBR value and the downlink bitrate, demonstrating how application signaling can optimize network performance. Key components include the ANBR metric, the downlink bitrate, and the application signaling process. The graph shows a positive correlation between the three variables, indicating that as the ANBR value increases, the downlink bitrate also increases. This relationship is crucial for network operators to understand and leverage in order to improve network efficiency and user experience.\nFigure 10.7-4 Downlink bitrate increase based on ANBR through application signaling\nWhen an MTSI client in terminal receives application signaling for bitrate adaptation of media, such as CMR (for speech) or TMMBR (for video), that triggers an adaptation decision (step 4 of Figure 10.7-3 or step 6 of Figure 10.7-4):\n4.\tFor video and if TMMBR is supported in the session, when receiving a TMMBR that would result in an increase of the media sender bitrate in uplink direction (step 6 of Figure 10.7-4), the media sender shall take all available adaptation triggers for the local uplink into account, e.g. any bitrate limit from the most recently received ANBR message. If the media sender has reason to believe that the most recently received ANBR for its uplink no longer applies, it may send an ANBRQ message for its uplink (step 7 of Figure 10.7-4), if supported, to trigger receiving an ANBR message with recent information (step 8 of Figure 10.7-4) before deciding on what bitrate value to send in a TMMBN (step 10 of Figure 10.7-4) and to use for media in the uplink direction (step 11 of Figure 10.7-4).\n5.\tFor voice, when receiving a CMR that would result in an increase of the media sender bitrate in uplink direction (step 6 of Figure 10.7-4), the media sender shall take all available adaptation triggers for the local uplink into account, e.g. any bitrate limit from the most recently received ANBR message. If the media sender has reason to believe that the most recently received ANBR for its uplink no longer applies, it may send an ANBRQ message for its uplink (step 7 of Figure 10.7-4), if supported, to trigger receiving an ANBR message with recent information (step 8 of Figure 10.7-4) before deciding on what voice mode to use in the uplink direction (step 11 of Figure 10.7-4).\nThis relates to adaptation of the media in RTP streams that the MTSI client in terminal receives in the downlink direction, which can require sending application-level messages to adapt the remote media encoder bitrate.\nWhen an MTSI client in terminal receives an ANBR message for the local downlink that triggers an adaptation decision (step 2 of Figure 10.7-3 or step 4 of Figure 10.7-4):\n1.\tFor the case of video and if TMMBR / TMMBN are supported in the session:\na)\tA corresponding TMMBR message requesting the remote media sender to change its rate to match the local downlink restriction shall be sent, as described in clause 10.3.2 (step 4 of Figure 10.7-3 or step 6 of Figure 10.7-4).\nNOTE:\tAdaptation is not triggered if the most recently received TMMBN from the remote media sender indicated a lower bitrate than would be included in a TMMBR message, because the remote media sender is then owning the bitrate limit itself (similar to bullet 2.a of the local uplink in clause 10.7.3.2 above).\nb)\tIt is recommended that the bitrate in a TMMBR from bullet 1.a) that is increasing the media sender bitrate is set to correspond to the most recently received ANBR message, to avoid unnecessary TMMBR, ANBRQ, and ANBR signaling caused by a possible step-wise increase (see also bullet 2.c in 10.7.3.2 above).\n2.\tFor the case of voice, adaptation signaling to match the local downlink restriction shall be initiated towards the remote media sender, as described in clause 10.2 (step 4 of Figure 10.7-3 or step 6 of Figure 10.7-4).\nWhen an MTSI client in terminal receives application signaling for bitrate adaptation related to received media, such as TMMBN (for video):\n3.\tA media receiver receiving a TMMBN with increased bitrate and where the remote media sender owns the restriction (see bullet 2.a of 10.7.3.2 and step 5 of Figure 10.7-2) shall re-evaluate its downlink adaptation triggers and, if an adaptation decision arrives at a lower bitrate value than in the received TMMBN (step 5 of Figure 10.7-2), send a TMMBR with that lower bitrate, as described by section 3.5.4 of CCM [43]. When deciding whether or not to send TMMBR, the media receiver shall take all available adaptation triggers into account, e.g. bitrate limit from the most recently received downlink ANBR message. If the media receiver has reason to believe the most recently received ANBR for its downlink no longer applies, it may send an ANBRQ message for its downlink (step 7 of Figure 10.7-2), if supported, to trigger receiving an ANBR message with recent information (step 8 of Figure 10.7-2).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.7.4\tMessage mapping for LTE access",
                            "text_content": "When using LTE access, ANBR is mapped to a MAC level message named \"Recommended bit rate MAC Control Element\" sent by the eNodeB and applicable to a specific dedicated bearer, as described by [85] and [157]. Similarly, when using LTE access, ANBRQ is mapped to a MAC level message named \"Recommended bit rate query MAC Control Element\" sent to the eNodeB and applicable to a specific, existing dedicated bearer, as described by [85] and [157]. An MTSI client in terminal using LTE access may support ANBR and ANBRQ signaling.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "10.7.5\tMessage mapping for NR access",
                            "text_content": "When using NR access, ANBR is mapped to a MAC level message named \"Recommended bit rate MAC Control Element\" sent by the gNB and applicable to a specific logical channel which is mapped to the single media flow (e.g., audio or video) to which the recommended bit rate applies.  Similarly, when using NR access, ANBRQ is mapped to a MAC level message named \"Recommended bit rate query MAC Control Element\" sent to the gNB and applicable to a specific, existing logical channel which is mapped to the single media flow to which the recommended bit rate applies.  An MTSI client in terminal using NR access may support ANBR and ANBRQ signaling.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "11\tFront-end handling",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "11.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "Terminals used for MTSI shall conform to the minimum performance requirements on the acoustic characteristics of 3G terminals specified in TS 26.131 [35]. The codec modes and source control rate operation (DTX) settings shall be as specified in TS 26.132 [36].\nFurthermore, the test point (Point-of-Interconnect (POI)) specified in [35] shall be a reference terminal capable of receiving digital speech data at the send side and producing a digital output of the received signal (see figure 11.1). During the testing, the radio conditions should be error free and the jitter and packet loss in the IP transport shall be kept to a minimum.\nFigure 11.1 illustrates the interface for testing the acoustic properties of a terminal used for Multiple Transmitter Single-Receiver (MTSI) communication. The figure shows the setup with a transmitter (Tx) and a receiver (Rx) connected through a cable, with a microphone and a speaker positioned at the interface. The purpose of this setup is to evaluate the acoustic performance of the terminal, ensuring that the transmitted signals are accurately received and interpreted by the receiver. The interface is crucial for maintaining clear communication channels in MTSI systems, which are commonly used in various industries for tasks such as monitoring and control.\nFigure 11.1: Interface for testing acoustic properties of a terminal used for MTSI\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "12\tInter-working",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "12.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "In order to support inter-working between different networks it is good if common codecs for the connection can be found. Requirements for different networks are described in this clause. In some cases functionality is also needed in the network to make the inter-working possible (e.g. MGCF and MGW).\nNOTE:\tThe term MTSI MGW (or MTSI Media gateway) is used in a broad sense, as it is outside the scope of the current specification to make the distinction whether certain functionality should be implemented in the MGW or in the MGCF.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "12.2\t3G-324M",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "12.2.1\tGeneral",
                            "text_content": "Inter-working functions are required between IMS and CS. There are separate functions, in e.g. a MGCF, for control-plane inter-working (see TS 29.163 [65]) and, in e.g. a IM-MGW, for user-plane inter-working. Control-plane inter-working includes for instance SIP  BICC and SIP  H.245 protocol translations, whereas user-plane inter-working requires transport protocol translations and possibly transcoding.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.2.2\tCodec usage",
                            "text_content": "An interoperable set of speech, video and real-time text codecs is specified for 3G-324M and MTSI. Both video codec level and maximum bitrate can be specified as part of the call setup negotiation (see clause 12.2.5). Thus, it may be possible that the MTSI client in terminal and a CS UE agree on a common codec end-to-end without the need for MGW transcoding.\nIf a common codec is not found and the MTSI MGW does not support transcoding between any of the supported codecs, then the controlling MGCF may drop the unsupported media component. If the speech part cannot be supported, then the connection should not be set up.\nA channel for real-time text is specified in ITU-T H.324. Presentation and coding is specified according to ITU-T Recommendation T.140, which is also used for MTSI clients (see clause 7.4.4). Inter-working is a matter of establishing the text transport channels and moving the text contents between the two transport levels.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.2.3\tPayload format",
                            "text_content": "See clause 7.4 of the present document.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.2.4\tMTSI media gateway trans-packetization",
                            "text_content": "The MTSI MGW shall offer conversion between H.223 as used in 3G-324M on the CS side and RTP as used in IMS. This clause contains a list inter-working functionalities that should be included.\nThe MTSI MGW should use a speech de-jitter buffer in the direction IMS to CS with sufficient performance to meet the 10 milliseconds maximum jitter requirement in clause 6.7.2 of ITU-T Recommendation H.324. H.324 specifies that transmission of each speech AL-SDU at the H.223 multiplex shall commence no later than 10 milliseconds after a whole multiple of the speech frame interval, measured from transmission of the first speech frame.\nTemporary video rate variations can occur on the IMS side for example due to congestion. The video rate on the CS side, in contrast, is under full control of the CS side UE and the MGCF.\nDuring session setup, the MGCF shall negotiate a video bitrate on the IMS side that allows all video bits to be conveyed to/from the CS link.\nA buffer shall be maintained at the IM-MGW in the direction from the IMS to the CS side. The size of the buffer should be kept small enough to allow for a low end-to-end delay, yet large enough to conceal most network jitter on the IMS side. Temporary uneven traffic on the IMS side, beyond the handling capability of the buffer, should be handled as follows: if the buffer overflows, RTP packets should be dropped and the resulting loss and observed jitter should be reported by the means of an RTCP RR at the earliest possible sending time. The drop strategy may preferably be implemented media aware (i.e. favouring dropping predicted information over non-predicted information and similar techniques), or may be drop-head. If the buffer runs empty, the CS side should insert appropriate flag stuffing.\nA buffer shall be maintained in the direction from the CS to the IMS side. The size of the buffer should be kept small enough to allow for a low end-to-end delay, but large enough to conceal most network jitter on the CS side. If the buffer overflows, then video bits must be dropped, preferably in a media-aware fashion, i.e. at GOB/slice/picture boundaries. IM-MGWs may also take into account the type of media data, i.e. coded with or without prediction. When the buffer runs empty, no activity is required on the IMS side.\nIf the CS video call is changed to a speech-only call [46], the video component on the IMS side shall be dropped.\nIf RTP packet loss is detected on input to the MTSI MGW at the IMS side, including losses caused by buffer-full condition as described above, corresponding H.223 AL-SDU sequence number increments should be made on the CS side to enable loss detection and proper concealment in the receiving CS UE.\nIf packet loss is detected on the CS side, e.g. through H.223 AL-SDU sequence numbers, those losses should be indicated towards the IMS side through corresponding RTP packet sequence number increments. The deliberate increments made for this reason will be visible in the RTCP RR from the MTSI client and the MTSI MGW should take that into account when acting on RTCP RR from the MTSI client, as the CS side losses are not related to the IMS network conditions.\nThis is mainly relevant in the direction from CS to IMS. The H.223 AL-SDUs include a CRC that forms an unreliable indication of data corruption. On the IMS side, no generic protocol mechanisms are available to convey this CRC and/or the result of a CRC check. The MTSI MGW shall discard any AL-SDUs which fail a CRC check and are not of a payload type that supports the indication of possible bit errors in the RTP payload header or data. If such payload type is in use, the MTSI MGW may forward corrupted packets, but in this case shall indicate the possible corruption by the means available in the payload header or data. One example is setting the Q bit of RFC 3267 [28] to 0 for AMR speech data that was carried in an H.223 AL-SDU with CRC indicating errors.  Another example is setting the F bit of RFC 6184 [25] for H.264 (AVC) NAL units or the F bit of [120] for H.265 (HEVC) NAL units that may contain bit errors.\nThe H.223 AL-SDU CRC is not fully fail-safe and it is therefore recommended that a MTSI client is designed to be robust and make concealment of corrupt media data, similar to the CS UE.\nThe same packet size and alignment requirements and considerations as defined in clause 7.5.2 of the present document and in TS 26.111 [45] apply to the MTSI MGW and controlling MGCF, as it in that sense acts both as a MTSI client towards the IMS and as a CS UE towards the CS side. Maximum available buffer size for packetization of media data may differ between IMS and CS UE. To avoid non-favourable segmentation of data (especially video) by the MTSI MGW, the controlling MGCF should indicate the SDP ‘a’ attribute \"3gpp_MaxRecvSDUSize\" to the MTSI client in terminal. This attribute indicates the maximum SDU size of the application data (excluding RTP/UDP/IP headers) that can be transmitted to the receiver without segmentation. The specific maximum SDU size limit is determined by the MGCF from the H.245 bearer capability exchange between the CS UE and the MGCF. For example, the MTSI MGW determines this through the maximumAl2SDUSize and maximumAl3SDUSize fields of the H223Capability member in H.245 TerminalCapabilitySet message.\nThe ABNF for the maximum receive SDU size attribute is described as follows:\nMax-receive-SDU-size-def\t= \"a\" \"=\" \"3gpp_MaxRecvSDUSize\" \":\" size-value CRLF\nsize-value\t= 1*5DIGIT; 0 to 65535 in octets\nThe value \"size-value\" indicates the maximum SDU size of application data, excluding RTP/UDP/IP headers, that can be transmitted to the other end point without segmentation.\nThe parameter \"3gpp_MaxRecvSDUSize\" should be included in the SDP at the session level and/or at the media level. Its usage is governed by the following rules:\n1.\tAt the session level, the \"3gpp_MaxRecvSDUSize\" attribute shall apply to the combination of the data from all the media streams in the session.\n2.\tAt the media level, the \"3gpp_MaxRecvSDUSize\" attribute indicates to the MTSI client in terminal that this particular media stream in the session has a specific maximum SDU size limit beyond which received  SDUs will be segmented before delivery to the CS UE.\n3.\tIf the \"3gpp_MaxRecvSDUSize\" attribute is included at the session and media levels, then the particular media streams have specific maximum SDU size limits for their own data while the session has an overall maximum SDU size limit for all the media data in the session.\nThe MGCF includes the \"3gpp_MaxRecvSDUSize\" attribute in the SDP offer or answer sent to the MTSI client in terminal after the MGCF determines the bearer capability of the CS UE (see Annex E of [65]). Upon reception of the SDP offer or answer that includes the \"3gpp_MaxRecvSDUSize\" attribute, the MTSI client in terminal need not include this attribute in its subsequent exchange of messages with the MTSI MGW.\nThere are no offer/answer implications on the \"3gpp_MaxRecvSDUSize\" attribute. The \"3gpp_MaxRecvSDUSize\" attribute in the SDP from the MTSI MGW is only an indication to the MTSI client in terminal of the maximum SDU size that avoids segmentation for the specified media streams and/or session.\nNOTE:\tDefault operation in the absence of the \"3gpp_MaxRecvSDUSize\" attribute in SDP is to not have any SDU size limits for any of the media streams or session.\nIn general, no explicit timestamps exist at the CS side. Even without transcoding functionality, the MTSI MGW may have to inspect and be able to interpret media data to set correct RTP timestamps.\nThe MTSI MGW shall terminate the H.223 protocol at the CS side. Similarly, the MTSI MGW shall terminate RTP and RTCP at the IMS side.\nThe IM-MGW and controlling MGCF should forward and translate the timing information between the IMS side (RTP timestamps, RTCP sender reports) and the CS side (H.245 message H223SkewIndication) to allow for media synchronization in the MTSI client in terminal and the CS UE. The MTSI MGW shall account for its own contribution to the skew in both directions. Note that transmission timing of H223SkewIndication and RTCP SR must be decoupled. H223SkewIndication has no timing restrictions, but is typically sent only once in the beginning of the session. RTCP SR timing is strictly regulated in RFC 3550 [9], RFC 4585[40], and clause 7.3. To decouple send timings, the time shift information conveyed in H223SkewIndication and RTCP SR must be kept as part of the MTSI MGW/MGCF session state. H223SkewIndication should be sent at least once, and may be sent again when RTCP SR indicates a synchronization change. A synchronization change of less than 50 ms (value to be confirmed) should be considered insignificant and need not be signalled.\nNOTE:\tThis procedure is not supported in the present Release in a decomposed MGCF and IM-MGW, as H.245 is treated on the MGCF and RTCP is sent at the IM-MGW, and no means are defined to forward information from the H223SkewIndication over the Mn interface.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.2.5\tSession control",
                            "text_content": "The MGCF shall offer translation between H.245 and SIP/SDP signalling according to TS 29.163 [65] to allow for end-to-end capability negotiation.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "12.3\tGERAN/UTRAN CS inter-working",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause defines requirements only for the PS side of the MGW, i.e. for the PS session in-between the MTSI client in a terminal and the MGW. The CS side of the MGW, i.e. in-between the MGW and the CS terminal, is out of scope of this clause.\nThis clause applies for MTSI MGWs supporting inter-working between a CS terminal using CS GERAN/UTRAN access or an MTSI client in terminal performing SRVCC to CS and:\n-\tan MTSI client in terminal using 3GPP access; or:\n-\tan MTSI client in terminal using fixed access; or:\n-\ta non-MTSI client.\nThe requirements and recommendations for these three cases are harmonized to enable using the same procedures regardless of the type of PS client and what access it uses, as long as it uses IP based access.\nThe target for this clause is to enable tandem-free operation when the same codec (AMR or AMR-WB) is used by both end-points.\nAn MTSI MGW may also support the other codecs listed in clause 18.2.2 for inter-working between an MTSI client in terminal using fixed access and a CS terminal using GERAN or UTRAN access. This means that tandem coding will be used and then the PS side and the CS side operate independently of each other. This further means that the requirements and recommendations for the PS side of the MGW are the same as for an MTSI client in terminal using fixed access, as described in clause 18, unless it is explicitly defined below.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "12.3.0\t3G-324M",
                            "text_content": "If 3G-324M is supported in the GERAN/UTRAN CS, then the inter-working can be made as specified in clause 12.2.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.3.1\tCodecs for MTSI media gateways",
                            "text_content": "This clause applies to MTSI MGWs used for interworking between an MTSI client in terminal using 3GPP access and a CS GERAN/UTRAN UE.\nMTSI media gateways supporting speech communication between an MTSI client in terminal using 3GPP access and terminals operating in the CS domain in GERAN and UTRAN should support Tandem-Free Operation (TFO) for AMR or AMR-WB according to TS 28.062 [37], and Transcoder-Free Operation (TrFO), see TS 23.153 [38].\nMTSI media gateways supporting speech communication and supporting TFO and/or TrFO shall support:\n-\tAMR speech codec modes 12.2, 7.4, 5.9 and 4.75 [11], [12], [13], [14] and source-controlled rate operation [15].\nMTSI media gateways should also support the other AMR codec types and configurations as defined in Clause 5.4 in [16].\nIn the receiving direction, from the MTSI client in the terminal, the MTSI media gateway shall be capable of restricting codec mode changes to be aligned to every other frame border and shall be capable of restricting codec mode changes to neighbouring codec modes within the negotiated codec mode set.\nNOTE 1:\tThis means that the MTSI client in a terminal will apply and accept mode changes according to UMTS AMR2 [16]. An example of an SDP offer for how the MTSI MGW can restrict AMR mode changes in the MTSI client in a terminal is shown in Table A.2.1. An example of an SDP answer from the MTSI MGW for restricting the mode changes in the MTSI client in a terminal is shown in Table A.3.4a.\nMTSI media gateways supporting wideband speech communication at 16 kHz sampling frequency and supporting TFO and/or TrFO for wideband speech shall support:\n-\tAMR wideband codec 12.65, 8.85 and 6.60 [17], ‎[18], ‎[19], [20] and source controlled rate operation ‎[21].\nMTSI media gateways supporting wideband speech communication at 16 kHz sampling frequency should also support the other AMR-WB codec types and configurations as defined in [16].\nIn the receiving direction, from the MTSI client in the terminal, the MTSI media gateway shall be capable of restricting codec mode changes to be aligned to every other frame border and shall be capable of restricting codec mode changes to neighbouring codec modes within the negotiated codec mode set.\nNOTE 2:\tThis means that the MTSI client in a terminal will apply and accept mode changes according to UMTS AMR-WB [16]. An example of an SDP offer for how the MTSI MGW can restrict AMR and AMR-WB mode changes in the MTSI client in a terminal is shown in Table A.2.4. An example of an SDP answer from the MTSI MGW for restricting the mode changes in the MTSI client in a terminal is shown in Table A.3.4.\nMTSI MGWs supporting wideband speech communication shall also support narrowband speech communications. When offering both wideband speech and narrowband speech communication, wideband shall be listed as the first payload type in the m line of the SDP offer (RFC 4566 [8]).\nRequirements applicable to MTSI media gateways for DTMF events are described in Annex G.\nThis clause applies to MTSI MGWs used for interworking between an MTSI client in terminal using fixed access and a CS GERAN/UTRAN UE.\nMedia codecs for MTSI MGWs for speech inter-working between fixed access and CS GERAN/UTRAN are specified in TS 181 005 [98] in clause 6.2 for narrow-band codecs and in clause 6.3 for wide-band codecs.\nMTSI MGWs for speech inter-working between fixed access and CS GERAN/UTRAN supporting AMR and AMR-WB shall follow clause 12.3.1.1 for the AMR and AMR-WB codecs. Tandem-free inter-working should be used whenever possible.\nFor the other codecs, the MTSI MGW shall follow the recommendations and requirements defined in clause 18 for the respective codec. For these codecs, tandem-free inter-working is not possible when interworking with CS GERAN/UTRAN.\nRequirements applicable to MTSI media gateways for DTMF events are described in Annex G.\nThe CTM coding format defined in TS 26.226 [52] is used for real time text in CS calls. In order to arrange inter-working, a transcoding function between CTM and RFC 4103 is required in the MTSI media gateway. A buffer shall be used for rate adaptation between receiving text from a real-time text transmitter according to the present document and transmitting to a CTM receiver. A gateway buffer of 2K characters is considered sufficient according to clause 13.2.4 in EG 202 320 [51].\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.3.2\tRTP payload formats for MTSI media gateways",
                            "text_content": "For RTP payload formats, see clause 18.4.3.\nMTSI media gateways supporting AMR or AMR-WB shall support the bandwidth-efficient payload format and should support the octet-aligned payload format. When offering both payload formats, the bandwidth-efficient payload format shall be listed before the octet-aligned payload format in the preference order defined in the SDP.\nThe MTSI media gateway should use the SDP parameters defined in table 12.1 for the session.\nFor all access technologies and for normal operating conditions, the MTSI media gateway should encapsulate the number of non-redundant speech frames in the RTP packets that corresponds to the ptime value received in SDP from the other MTSI client, or if no ptime value has been received then according to \"Recommended encapsulation\" defined in table 12.1. The MTSI media gateway may encapsulate more non-redundant speech frames in the RTP packet but shall not encapsulate more than 4 non-redundant speech frames in the RTP packets. The MTSI media gateway may encapsulate any number of redundant speech frames in an RTP packet but the length of an RTP packet, measured in ms, shall never exceed the maxptime value.\nTable 12.1: Recommended encapsulation parameters\n\nWhen the access technology is not known to the MTSI media gateway, the default encapsulation parameters defined in Table 12.1 shall be used.\nThe SDP offer shall include an RTP payload type where octet-align=0 is defined or where the octet-align parameter is not specified and should include another RTP payload type with octet-align=1. MTSI media gateways offering wide-band speech shall offer these parameters and parameter settings also for the RTP payload types used for wide-band speech.\nMTSI media gateways should support the RTCP-APP signalling defined in clause 10.2.1. The Codec Mode Request (RTCP_APP_CMR) is only relevant when AMR or AMR-WB is used but the Redundancy Request and the Frame Aggregation Request can be used for all codecs. When RTCP-APP is not supported or cannot be used in the session then adaptation can also be based on RTCP Receiver Reports/Sender Reports.\nMTSI media gateways should support redundancy according to clause 9.\nNOTE:\tSupport of transmitting redundancy may be especially useful in the case an MTSI media gateway is aware of the used access technology and knows that the Generic Access technology is used.\nBoth CTM according to TS 26.226 [52] and RFC 4103 make use of ITU-T Recommendation T.140 presentation and character coding. Therefore inter-working is a matter of payload packetization and CTM modulation/demodulation.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 12.1: Recommended encapsulation parameters",
                                    "table number": 34,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "12.3.3\tExplicit Congestion Notification",
                            "text_content": "An MTSI MGW can be used to enable ECN between the MTSI client in terminal and the MTSI MGW when inter-working with CS GERAN/UTRAN.\nIf ECN is supported in the MTSI MGW, then the MTSI MGW shall also:\n-\tsupport ECN as described in this specification for the MTSI client in terminal, except that the MTSI MGW does not determine whether ECN can be used based on the Radio Access Technology that is used towards the MTSI client in terminal;\n-\tsupport RTP/AVPF and SDPCapNeg if the MTSI MGW supports RTCP AVPF ECN feedback messages;\n-\tbe capable of enabling end-to-end rate adaptation between the MTSI client in terminal and the CS terminal by performing the following:\n-\tnegotiate the use of ECN with the MTSI client in terminal, if it can be confirmed that the network used towards the MTSI client in terminal properly handles ECN-marked packets;\n-\tinter-work adaptation requests between the MTSI client in terminal and the CS GERAN/UTRAN;\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.3.4\tCodec switching procedures with SRVCC",
                            "text_content": "An MTSI client in terminal (hereinafter \"local client\") using 3GPP PS access may be handed over to CS access. By that SRVCC procedure, the end-point of the IP connection moves from the local client to a CS MGW in the CS network, as described in TS 23.216 (SRVCC) [133].\nIn order to achieve this handover, the MSC server, controlling the CS MGW, sends a SIP INVITE message:\n-\teither to the remote client (in case of SRVCC handover without SRVCC enhancement);\n-\tor to the ATCF (in case of SRVCC handover with ATCF enhancement),\nto change the communication end from the MTSI client in terminal to the CS MGW as described in TS 23.237 [134].\nIf EVS is used between local and remote client before SRVCC and if AMR-WB is used after SRVCC by the local CS UE, an MTSI MGW (e.g. MSC/CS-MGW or ATCF/ATGW) can send the RTCP_APP_EP2I request message, (see clause 10.1.2.10), or a CMR in the RTP payload requesting an EVS AMR-WB IO mode, to the remote client to request that it switches from the EVS Primary mode to the EVS AMR-WB IO mode. The mode-set used in CS shall be included in the RTCP_APP_EP2I request message. Furthermore, the RTCP_APP_EP2I request message also supports signalling to restrict the timing and destination of codec mode changes. An SDP offer/answer negotiation between the MTSI MGW and the remote client can also be performed to align the mode-sets and to optimize the resource usage and also to request switching to the EVS AMR-WB IO mode.\nCorrespondingly, the RTCP_APP_EI2P request message can be used to switch from the EVS AMR-WB IO mode to the EVS Primary mode, e.g. in case an SRVCC handover to a CS access and a switch to the EVS AMR-WB IO mode is followed by a reverse SRVCC to perform handover back to the PS access. An SDP offer/answer negotiation can also be performed to restore the session, e.g. bitrates, bandwidths and other configuration parameters, to what was used before SRVCC.\nNOTE: \tThe DTX operation of EVS Primary and AMR-WB IO may be configured in sending direction with either a fixed SID update interval (from 3 to 100 frames) or an adaptive SID update interval – more details can be found in clauses 4.4.3 and 5.6.1.1 of TS 26.445 [125]. The DTX operation of AMR-WB is defined with a fixed interval of 8 frames for SID updates. Implementers of MTSI MGWs are advised to take into account the SID flexibility of EVS (with respect to AMR-WB) for the interworking between AMR-WB and EVS AMR-WB IO.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "12.4\tPSTN",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "12.4.1\t3G-324M",
                            "text_content": "If 3G-324M is supported in the PSTN, then the inter-working can be made as specified in clause 12.2.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.4.2\tText",
                            "text_content": "PSTN text telephony inter-working with PS environments is described in ITU-T Recommendation H.248.2 [50]and further elaborated in EG 202 320 [51].\nText telephony modem tones are sensitive to packet loss, jitter and echo canceller behaviour. Therefore, conversion of modem based transmission of real-time text is best done at the border of the PSTN. If PSTN text telephone tones need to be carried audio coded in a PS network, considerations must be taken to carry them reliably as for example specified in ITU-T Recommendations V.151 [54] and V.152 [55].\nWhen inter-working with PSTN text telephones, it must be considered that in PSTN most text telephone communication methods do not allow simultaneous speech and text transmission. An MTSI client in terminal indicating text capability shall not automatically initiate text connection efforts on the PSTN circuit. Instead, either a requirement for text support should be required from the MTSI client in terminal, active transmission of text from the MTSI client in terminal, or active transmission of text telephone tones from the PSTN terminal. See clause 13 of EG 202 320 [51].\nNote that the primary goal of real-time text support in MTSI is not to offer a replica of PSTN text telephony functionality. On the contrary, real-time text in MTSI is aiming at being a generally useful mainstream feature, complementing the general usability of the Multimedia Telephony Service for IMS.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "12.5\tGIP inter-working",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "12.5.1\tText",
                            "text_content": "RFC 4103 [31] and T.140 are specified as default real-time text codec in SIP telephony devices in RFC 4504 [53]. When GIP implements this codec, the media stream contents are identical for the two environments. Packetization will also in many cases be equal, while consideration must be taken to cope with different levels of redundancy and possible use of different media security and integrity measures.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.5.2\tSpeech",
                            "text_content": "See Clause 12.7.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "12.6\tVoid",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "12.6.1\tVoid",
                            "text_content": "",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.6.2\tVoid",
                            "text_content": "",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "12.7\tInter-working with other IMS and non-IMS IP networks",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "12.7.1\tGeneral",
                            "text_content": "IMS and MTSI services are required to support inter-working with similar services operating on other IP networks, both IMS based and non-IMS based, [2]. It is an operator option to provide transcoding when the end-to-end codec negotiation fails to agree on a codec to be used for the session. The requirements herein apply to MTSI MGWs when such transcoding is provided.\nThese requirements were designed for sessions carried with IP end-to-end, possibly inter-connected through one or more other IP networks.\nA main objective is to harmonize the requirements for this inter-working case with the requirements for GERAN/UTRAN CS inter-working defined in Clause 12.3. There is however one major difference as the MGW requirements in Clause 12.3 apply only to the PS side of the MTSI MGW, i.e. between the MTSI MGW and the MTSI client in the terminal, while here there are requirements for the MTSI MGW both towards the MTSI client in the terminal and towards the remote network.\nMost requirements included here apply only to the PS access towards the remote network but there are also requirements that target both the local MTSI client in terminal and the remote network or even only the local MTSI client.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.7.2\tSpeech",
                            "text_content": "This clause defines how speech media should be handled in MTSI MGWs in inter-working scenarios between an MTSI client in terminal using 3GPP access and a non-3GPP IP network and between an MTSI client in terminal using fixed access and a non-3GPP IP network. This clause therefore defines requirements for what the MTSI MGW needs to support and how it should behave during session setup and session modification. A few SDP examples are included in Annex A.10.\nThis clause applies to MTSI MGWs used for interworking between an MTSI client in terminal using 3GPP access and a client using another IMS or non-IMS IP network.\nMTSI MGWs offering speech communication between an MTSI client in a terminal and a client in another IP network through a Network-to-Network Interface (NNI) using AMR shall support:\n-\tAMR speech codec modes 12.2, 7.4, 5.9 and 4.75 [11], [12], [13], [14] and source-controlled rate operation [15], both towards the local MTSI client in terminal and towards the remote network;\n-\tG.711, both A-law and -law PCM, [77], towards the remote network.\nand should support:\n-\tlinear 16 bit PCM (L16) at 8 kHz sampling frequency, towards the remote network.\nWhen such MTSI MGWs also offer wideband speech communication using AMR-WB they shall support:\n-\tAMR wideband codec 12.65, 8.85 and 6.60 [17], ‎[18], ‎[19], [20] and source controlled rate operation ‎[21] , both towards the local MTSI client in terminal and towards the remote network;\nand should support:\n-\tG.722 (SB-ADPCM) at 64 kbps, [78], towards the remote network; and:\n-\tlinear 16 bit PCM (L16) at 16 kHz sampling frequency, towards the remote network.\nNOTE:\tA TrGW decomposed from an IBCF can also be media-unaware and forward any media transparentely without changing the encoding. Transcoding support is optional at the Ix interface.\nThis clause applies to MTSI MGWs used for interworking between an MTSI client in terminal using fixed access and a client using another IMS or non-IMS IP network.\nMedia codecs for MTSI MGWs for speech inter-working between fixed access and IP clients in other IMS or non-IMS IP networks are specified in TS 181 005 [98] in clause 6.2 for narrow-band codecs and in clause 6.3 for wide-band codecs. In addition, the MTSI MGW should support linear 16 bit PCM (L16) at 8 kHz sampling frequency for narrow-band speech. An MTSI MGW supporting wideband speech should also support linear 16 bit PCM (L16) at 16 kHz sampling frequency.\nMTSI MGWs for speech inter-working between access and CS GERAN/UTRAN supporting AMR and AMR-WB shall follow clause 12.7.2.2.2 for the AMR and AMR-WB codecs. Tandem-free inter-working should be used whenever possible.\nFor the other codecs, the MTSI MGW shall follow the recommendations and requirements defined in clause 18 for the respective codec.\nIf the remote network supports AMR for narrowband speech and/or AMR-WB for wideband speech, then transcoding shall be avoided whenever possible. In this case, the MTSI MGW should not be included in the RTP path unless it is required for non transcoding related purposes. If the MTSI MGW is included in the RTP path then it shall support forwarding the RTP payload regardless of codec mode and packetization.\nNOTE:\tAn example of where transcoding may be required when AMR and/or AMR-WB are supported by the remote network is when the remote terminal is limited to modes that are not supported by the local MTSI client in terminal due to operator configuration.\nIf the MTSI MGW is performing transcoding of AMR or AMR-WB then it shall be capable of restricting mode changes, both mode change period and mode changes to neighboring mode, if this is required by the remote network.\nRequirements applicable to MTSI MGW for DTMF events are described in Annex G.\nIt is important to optimize the quality-bandwidth compromise, even though the NNI uses a fixed IP network. For this reason, the following preference order should be used by MTSI MGWs unless another preference order is defined in bilateral agreements between the operators or configured otherwise by the operator:\n-\tThe best option is if a codec can be used end-to-end. For example, using AMR or AMR-WB end-to-end is preferable over transcoding through G.711 or G.722 respectively.\n-\tThe second best solution is to use G.711 or G.722 as inter-connection codecs, for narrow-band and wide-band speech respectively, since these codecs offer a good quality while keeping a reasonable bit rate.\n-\tThe linear 16 bit PCM format should only be used as the last resort, when none of the above solutions are possible.\nIf a wide-band speech session is possible, then fall-back to narrow-band speech should be avoided whenever possible, unless another preference order is indicated in the SDP.\nNOTE:\tThere may be circumstances, for example bit rate constraints, when a fall-back to narrow-band speech is acceptable since the alternative would be a session setup failure.\nMTSI MGWs offering speech communication over the NNI shall support the RTP/AVP profile and should support the RTP/AVPF profile, [40]. If the RTP/AVPF profile is supported then the SDP Capability Negotiation (SDPCapNeg) framework shall also be supported, [69].\nAn MTSI MGW supporting EVS should support the RTCP-APP signalling for speech adaptation defined in clause 10.2.1.\nThe payload format to be used for AMR and AMR-WB encoded media is defined in Clause 12.3.2.1. The payload format to be used for EVS encoded media is defined in [125]. The MTSI MGW shall support the following payload SDP parameters for AMR and AMR-WB: octet-align, mode-set, mode-change-period, mode-change-capability, mode-change-neighbor, maxptime, ptime, channels and max-red.\nThe payload format to be used for G.711 encoded media is defined in RFC 3551, [10], for both -law (PCMU) and -law (PCMA).\nThe payload format to be used for G.722 encoded media is defined in RFC 3551, [10].\nNOTE:\tThe sampling frequency for G.722 is 16 kHz but is set to 8000 Hz in SDP since it was (erroneously) defined this way in the original version of the RTP A/V profile, see [10].\nThe payload format to be used for linear 16 bit PCM is the L16 format defined in RFC 3551, [10]. When this format is used for narrow-band speech then the rate (sampling frequency) indicated on the a=rtpmap line shall be 8000. When this format is used for wide-band speech then the rate (sampling frequency) indicated on the a=rtpmap line shall be 16000.\nThe payload formats to be used for the other codecs are listed in Clause 18.4.3.\nFor the G.711, G.722 and linear 16 bit PCM formats, the frame length shall be 20 ms, i.e. 160 and 320 speech samples in each frame for narrow-band and wide-band speech respectively.\nMTSI MGWs offering speech communication over the NNI shall support encapsulating up to 4 non-redundant speech frames into the RTP packets.\nMTSI MGWs may support application layer redundancy. If redundancy is supported then the MTSI MGW should support encapsulating up to 8 redundant speech frames in the RTP packets. Thereby, an RTP packet may contain up to 12 frames, up to 4 non-redundant and up to 8 redundant frames.\nAn MTSI MGW setting up a speech session should align the ptime and maxptime between the networks so that the same packetization can be used end-to-end, even when transcoding is used.\nThe MGW should use the packetization schemes indicated by the ptime value in the SDP offer and answer. If no ptime value is present in the SDP then the MGW should encapsulate 1 frame per packet or the packetization used by the end-point clients.\nThe MTSI MGW should preserve the packetization used by the end-point clients to minimize the buffering times otherwise caused by jitter. For example, if one end-point adapts the packetization to use 2 frames per packet then the MTSI MGW should adapt the packetization to the other end-point to also use 2 frames per packet. This applies also when the MTSI MGW performs transcoding. The packet size can become quite large for some combinations of formats and packetization. If the packet size exceeds the Maximum Transfer Unit (MTU) of the network then the MTSI MGW should encapsulate fewer frames per packet.\nNOTE:\tIt is an implementation consideration to determine the MTU of the network. RFC 4821 [79] describes one method that can be used to discover the path MTU.\nWhen the MTSI MGW does not perform any transcoding then it shall be transparent to the packetization schemes used by the end-point clients.\nThe RTP implementation shall include an RTCP implementation.\nMTSI MGWs offering speech should support AVPF (RFC 4585 [40]) configured to operate in early mode. When allocating RTCP bandwidth, it is recommended to allocate RTCP bandwidth and set the values for the \"b=RR:\" and the \"b=RS:\" parameters such that a good compromise between the RTCP reporting needs for the application and bandwidth utilization is achieved, see also SDP examples in Annex A.10. When an MTSI MGW uses tandem-free inter-working between two PS networks then it should align the RTCP bandwidths such that RTCP packets can be sent with the same frequency in both networks. This is to allow for sending adaptation requests end-to-end without being forced to buffer the requests in the MTSI MGW. The value of \"trr-int\" should be set to zero or not transmitted at all (in which case the default \"trr-int\" value of zero will be assumed) when Reduced-Size RTCP (see clause 7.3.6) is not used.\nFor speech sessions, between the MTSI client in terminal and the MTSI MGW, it is beneficial to keep the size of RTCP packets as small as possible in order to reduce the potential disruption of RTCP onto the RTP stream in bandwidth-limited channels. RTCP packet sizes can be minimized by using Reduced-Size RTCP packets or using the parts of RTCP compound packets (according to RFC 3550 [9]) which are required by the application.\nThe MTSI MGW shall be capable of adapting the session to handle possible congestion. For AMR and AMR-WB encoded media, the MTSI MGW shall support the adaptation signalling method using RTCP APP packets as defined in clause 10.2, both towards the MTSI client in terminal and towards the remote network. As the IP client in the remote network may or may not support the RTCP APP signalling method, the MTSI MGW shall also be capable of using the inband CMR in the AMR payload. When receiving inband CMR in the payload from the remote network, the MTSI MGW does not need to move the adaptation signalling to RTCP APP packets before sending it to the MTSI client in terminal.\nFor PCM, G.722 and linear 16 bit PCM encoded media, the MTSI MGW shall support RFC 3550 for signalling the experienced quality using RTCP Sender Reports and Receiver Reports.\nFor a given RTP based media stream to/from the MTSI client in terminal, the MTSI MGW shall transmit RTCP packets from and receive RTCP packets to the same port number.\nFor a given RTP based media stream to/from the remote network, the MTSI MGW shall transmit RTCP packets from and receive RTCP packets on the same port number, not necessarily the same port number as used to/from the MTSI client in terminal.\nThis facilitates inter-working with fixed/broadband access. However, the MTSI MGW may, based on configuration or local policy, accept RTCP packets that are not received from the same remote port where RTCP packets are sent by either the MTSI client in terminal or the remote network.\nFor AMR and AMR-WB encoded media, the MTSI MGW shall follow the same requirements when inter-working with other IP network as when inter-working with GERAN/UTRAN CS, see clause 12.3.2.1.\nFor a given RTP based media stream to/from the MTSI client in terminal, the MTSI MGW shall transmit RTP packets from and receive RTP packets to the same port number.\nFor a given RTP based media stream to/from the remote network, the MTSI MGW shall transmit RTP packets from and receive RTP packets on the same port number, not necessarily the same port number as used to/from the MTSI client in terminal.\nThis facilitates inter-working with fixed/broadband access. However, the MTSI MGW may, based on configuration or local policy, accept RTP packets that are not received from the same remote port where RTP packets are sent by either the MTSI client in terminal or the remote network.\nThe MTSI MGW shall be capable of dynamically adding and dropping speech media during the session.\nThe MTSI MGW may use the original SDP offer received from the MTSI client in terminal when creating an SDP offer that is to be sent outbound to the remote network.\nIf the MTSI MGW adds codecs to the SDP offer then it shall follow the recommendations of Clause 12.7.2.3 when creating the outbound SDP offer and when selecting which codec to include in the outbound SDP answer.\nIf the MTSI MGW generates an SDP offer based on the offer received from the MTSI client in terminal, it should maintain the ptime and maxptime values as indicated by the MTSI client in terminal. If the MTSI MGW generates an SDP offer without using the SDP offer from the MTSI client in terminal then it should define the ptime and maxptime values in accordance in Clause 12.7.2.6, i.e. the preferred values for ptime and maxptime are 20 and 80 respectively.\nIf the MTSI MGW does not support AVPF (nor SDPCapNeg) then it shall not include the corresponding lines in the SDP offer that is sent to the remote network.\nIn case of interworking, the audio levels should be aligned to ensure suitable audio levels to the end users. This is especially important when codecs with different overload points are used on each side of the MTSI MGW as this can result in an asymmetrical loudness between the end points.\nNOTE 1:\tThe overload point of a given codec refers to the adjustment factor between the digital levels in input/output of this codec and the resulting acoustic levels. In practice the overload point value corresponds to the analog Root Mean Square (RMS) level of a full-scale sinusoidal signal.\nFor MTSI client in terminal using fixed access, clause 18.8 applies to ensure proper audio alignment.\nFor communications requiring interworking with other IMS or non-IMS IP networks, terminals connected to these networks may use different codecs, which have different overload points. In this case, it is recommended that the MTSI MGW doing transcoding ensure proper audio level alignment. This alignment shall be performed such that the nominal level is preserved (0 dBm0 shall be maintained to 0 dBm0). As an example, a fixed CAT-IQ DECT terminal implementing G.722 with a 9 dBm0 overload point as recommended in ITU-T Recommendation G.722 [78] might need some audio level alignment in case of wideband voice interworking with a 3GPP terminal using AMR-WB with a 3.14 dBm0 overload point.  The audio level alignment may use dynamic range control to prevent saturation or clipping.\nNOTE 2:\tThe definition of the dBm0 unit can be found in ITU-T P.10 [108].\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.7.3\tExplicit Congestion Notification",
                            "text_content": "An MTSI MGW can be used to enable ECN within the local network when the local ECN-capable MTSI client in terminal is in a network that properly handles ECN-marked packets, and either the remote network cannot be confirmed to properly handle ECN-marked packets or the remote terminal does not support or use ECN.\nIf ECN is supported in the MTSI MGW, then the MTSI MGW shall also:\n-\tsupport RTP/AVPF and SDPCapNeg if the MTSI MGW supports RTCP AVPF ECN feedback messages;\n-\tbe capable of enabling end-to-end rate adaptation between the local MTSI client in terminal and the remote client by performing the following towards the local MTSI client in terminal:\n-\tnegotiate the use of ECN;\n-\tsupport ECN as described in this specification for the MTSI client in terminal, except that the MTSI MGW does not determine whether ECN can be used based on the Radio Access Technology.\nNOTE:\tThe adaptation requests are transmitted between the local and the remote client without modification by the MTSI MGW.\nAn MTSI MGW can also be used to enable ECN end-to-end if the remote client uses ECN in a different way than what is described in this specification for the MTSI client in terminal, e.g. if the remote client only supports probing for the ECN initiation phase or it needs the RTCP AVPF ECN feedback messages.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.7.4\tText",
                            "text_content": "The codec and other considerations for real-time text described in the present document for MTSI clients in terminal using 3GPP access apply also to MTSI clients in terminal using fixed access. There are thus no inter-working considerations on the media level between these types of end-points.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "12.7.5\tInter-working IPv4 and IPv6 networks",
                            "text_content": "If different IP versions are used by the offerer and the answerer, information in the SDP offer or answer related to IP version and QoS negotiation should be modified appropriately by the MTSI MGW so that the offerer and the answerer agree with an identical or similar source bit-rates.\nFor video, b=AS in IPv6 should be assumed to be a product of b=AS in IPv4 and 1.04, rounded down to a nearest integer, when other information that can be used to re-compute b=AS in IPv6 from b=AS in IPv4 is not present. Likewise, b=AS in IPv4 should be assumed to be a product of b=AS in IPv6 and 0.96, rounded up to a nearest integer. These formulas meet the relationship of b=AS values for 176×144 and 320×240 in Table N.x. Depending on service policy or codec configuration, other formulas can be used.\nAn MTSI MGW for interworking between IPv4 and IPv6 networks supporting the ‘a=bw-info’ attribute (see clause 19) shall re-compute the bandwidth properties signalled with this attribute if only bandwidths for either IPv4 or IPv6 are present. If bandwidth properties are provided with values for both IPv4 and IPv6 then the MTSI MGW should not re-compute the bandwidths.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "12.8\tMGW handling for NO_REQ interworking",
                    "description": "",
                    "summary": "",
                    "text_content": "The meaning of \"none\" and \"NO_REQ\" for EVS (as specified in TS 26.445 [125] is not equivalent to code-point \"CMR=15\" for AMR and AMR-WB (as specified according to TS 26.114 and RFC 4867 with its errata):\n-\tFor AMR-WB, CMR=15 overrides the previously received CMR value (corresponding to a speech mode or CMR=15). In other words, when an MTSI client receives CMR15 it is no longer restricted for its outbound packets by the previously received CMR, however it still complies with the negotiated mode-set.\n-\tFor EVS, the 'NO_REQ' and 'none' CMR code points mean that there is no request and this CMR value shall be ignored. In other words, when an MTSI client receives NO_REQ or 'none' for EVS it is still restricted for its outbound packets by the previously received CMR (if any) and in addition it still complies within the negotiated codec operation modes.\nMGWs in the path, repacking between the RTP format according to RFC 4867 [28] and the EVS RTP format in TS 26.445 [125] shall translate between these code-points (in transcoder-free operation):\n-\tWhen translating a single frame per packet from AMR-WB to EVS (AMR-WB IO): CMR=15 shall be replaced by the highest possible of EVS AMR-WB IO allowed in the session.\n-\tWhen translating a single frame per packet from EVS (AMR-WB IO) to AMR-WB: NO_REQ and none shall be replaced by the previously sent CMR (or the highest possible of AMR-WB allowed in the session if no request has been sent since the beginning of the session).\n-\tWhen translating more than one frame per packet (e.g. from 1 frame per packet to 2 frames per packets or vice versa), the MGW may have to \"combine\" or \"repeat\" CMRs following same translation as for the single frame per packet when applicable.\nThe above translation rules apply except when MGW wants to change the CMR. An example is when a MGW detects problems at an early stage in uplink which may require the MGW to send a CMR to limit bitrate at a lower value than the incoming CMR from the remote media receiver.\nNOTE:\tWhen EVS AMR-WB IO is not used (transcoder-free operation is not possible), the speech path is split into two links (AMR-WB and EVS) and the adaptation on these two links are independent from each other. CMR translation between AMR-WB and EVS at the MGW is therefore not required.\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "13\tVoid",
            "description": "\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "13a\tMedia types, codecs and formats used for MSRP transport",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "13a.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "The IMS messaging service is described in TS 26.141 [59]. The description of IMS messaging in clauses 1-6 of TS 26.141 [59] is applicable for MSRP-transported media in MTSI. The MSRP transport itself is described in TS 24.247 [82].\nAll statements in TS 26.141 regarding IMS messaging are valid for MSRP transported media in MTSI including the status of the statement (shall, should, may).\nAny differences between IMS messaging in TS 26.141 [59] and MSRP transported media in MTSI are described in clause 13a.2.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "13a.2\tDifference relative to 3GPP TS 26.141",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "13a.2.1\tVideo",
                            "text_content": "For MSRP transported Media in MTSI, clause 5.2.2 of this specification applies.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "14\tSupplementary services",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "14.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "In this section media layer behaviour is specified for relevant supplementary services. The supplementary services included in MTSI are described in TS 24.173 [57]. The requirements on the codec support and the data transport are identical to those listed in clauses 5.2 and 7. These requirements are listed here due to the fact that there might be other media-influencing nodes in MTSI whose behaviour is not explicitly covered by other parts of the present document.\nThe recommended behaviour described in the following sections is valid for MTSI clients, i.e. all session IP end-points; terminals, MTSI media gateways and other 3GPP network nodes acting as IP endpoints in MTSI sessions.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "14.2\tMedia formats and transport",
                    "description": "",
                    "summary": "",
                    "text_content": "Any implementation of a supplementary service which affects media or media handling, e.g. such as media creation, media rendering and media manipulation, shall meet the same requirements as a MTSI client in terminal regarding codec support and codec usage. Where applicable,, speech codecs shall be supported according to clause 5.2.1, video according to clause 5.2.2 and text according to clause 5.2.3.\nSimilarly, the configuration and the transport of the media in any implementation of a supplementary service which affects media or media handling shall be done according to clause 7.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "14.3\tMedia handling in hold procedures",
                    "description": "",
                    "summary": "",
                    "text_content": "Whenever a supplementary service includes a hold procedure according to RFC 3264 [58], e.g. when using the HOLD supplementary service, the media flow is changed in terms of the session flow attribute (e.g. changing the session attribute \"sendrecv\" into \"sendonly\" or \"recvonly\" or \"inactive\" and then back again). When this occurs, any involved media-originating or media-terminating node should take measures to ensure that the transitions between the different media flow states in the session occur with minimal impact on the media quality.\nWhen a full-duplex session has put the media flow on hold (see section 8.4 in RFC 3264 [58]), the media flow has been changed into a unidirectional flow through changing the session attribute into either \"sendonly\" or \"recvonly\". When resuming the session, it is restored to full duplex by changing the flow attributes back into \"sendrecv\" from \"sendonly\" and \"recvonly\". In this case, the encoder and decoder states in the MTSI clients may not be aligned and a state mismatch could occur. This would result in media quality degradation. Therefore, the following actions are recommended whenever the media session is not being put on hold anymore and the session is restored to full duplex:\n-\tfor speech media, the speech decoders should be reset;\n-\tfor video media, the video encoders should start the updated session with a full infra refresh even if the previously allocated encoders are still active and no infra refresh is scheduled to be sent.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "15\tNetwork preference management object",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "15.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "The MTSI client in the terminal may use the OMA-DM solution specified in this clause for enhancing the SDP negotiation and resource reservation process. If a MTSI client in the terminal uses this feature, it is mandatory for the MTSI client in the terminal to implement the Management Object (MO) as described in this clause.\nThe 3GPP MTSINP (MTSI Network Preference) MO defined in this clause may be used to manage the QoS profile settings which express the network preference for the MTSI client in the terminal. The MO covers parameters that the MTSI client in the terminal could make use of in SDP negotiation and resource reservation process.  If a MTSI client in the terminal supports the feature, the usage of the MO includes:\n1.\tDuring SDP negotiation process, MTSI client in the terminal should start SDP negotiation based on the MO parameters.\n2.\tDuring resource reservation process, MTSI client in the terminal should start QoS negotiation based on the MO parameters.\nThe following parameters in MTSI should be included in the Management Object (MO):\nSpeech\tcodec (AMR, AMR-WB, EVS) and bearer QoS parameters\nVideo\tcodec (H.264 (AVC), H.265 (HEVC)) and bearer QoS parameters\nReal Time text\tbearer QoS parameters\nIndication of the priority when there are more than one alternative for a media type is included. Version numbering is included for possible extending of MO.\nThe Management Object Identifier shall be: urn:oma:mo:ext-3gpp-mtsinp:1.0.\nProtocol compatibility:  The MO is compatible with OMA Device Management protocol specifications, version 1.2 and upwards, and is defined using the OMA DM Device Description Framework as described in the Enabler Release Definition OMA-ERELD _DM-V1_2[67].\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "15.2\tNodes Definition",
                    "description": "",
                    "summary": "",
                    "text_content": "The following nodes and leaf objects in figure 15.1 shall be contained under the 3GPP_MTSINP node if a MTSI client in the terminal support the feature described in this clause (information of DDF for this MO is given in Annex H):\n\n\nFigure 15.1 illustrates the hierarchical structure of the MTSI network preference management object tree, which organizes various network parameters such as bandwidth allocation, priority levels, and service classes. The tree starts from the top with the network level, followed by service provider, transport service, and finally the application level. Each node represents a specific preference or configuration setting, and the connections between nodes define the hierarchy and dependencies. This structured approach allows for efficient management and control of network resources, ensuring optimal performance and service quality for different types of traffic.\nFigure 15.1: MTSI network preference management object tree\nNode: /<X>\nThis interior node specifies the unique object id of a MTSI network preferences management object. The purpose of this interior node is to group together the parameters of a single object.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\nThe following interior nodes shall be contained if the MTSI client in the terminal supports the \"MTSI network preferences Management Object\".\n/<X>/Speech\nThe Speech node is the starting point of the speech codec definitions (if any speech codec are available)\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>\nThis interior node is used to allow a reference to a list of speech codec objects.\n-\tOccurrence: OneOrMore\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ID\nThis leaf node represents the identification number of a set of parameters for speech session.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/TAG\nThis leaf node represents the identification tag of a set of parameters for speech session. It is recommended to have at least a node, for example, ID, TAG, or implementation-specific ones, for the identification purpose such that each set of parameters can be distinguished and accessed.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/Priority\nThis leaf represents the priority of a set of parameters for speech session. Lower value means higher priority and the value is used in the terminal for client initiated QoS handling. The priority uses a 16 bit unsigned integer.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n-\tValues: Zero or higher\n/<X>/Speech/<X>/IPver\nThis leaf represents the version of the Internet Protocol used in the session.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: \"IPv4\", \"IPv6\"\n/<X>/Speech/<X>/Codec\nThis leaf gives the MIME subtype name of speech codec. This leaf is preferably pre-configured by the device.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: MIME subtype name of speech codec, e.g., \"AMR\", \"AMR-WB\", \"EVS\".\nThe value \"AMR\" refers to the AMR speech codec as defined in 3GPP. The value \"AMR-WB\" refers to the AMR-WB speech codec as defined in 3GPP. The value \"EVS\" refers to the EVS speech codec as defined in 3GPP.\n/<X>/Speech/<X>/Bandwidth\nThis interior node is used to allow a reference to a list of parameters related to speech bandwidth assignment.\n-\tOccurrence: One\n-\tFormat: node\n-\tMinimum Access Types: Get\n-\tValues: positive integer\n/<X>/Speech/<X>/Bandwidth/AS\nThis leaf gives the preferred speech codec bandwidth by the network for the bearer set-up, including RTP/UDP/IP headers. It provides the value for \"b=AS\" line for speech part used in the end-to-end SDP negotiation process, which represents the bit rate in kbits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/Bandwidth/RS\nThis leaf provides the value for \"b=RS\" line for speech part used in the end-to-end SDP negotiation process, which represents the bit rate in bits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/Bandwidth/RR\nThis leaf provides the value for \"b=RR\" line for speech part used in the end-to-end SDP negotiation process, which represents the bit rate in bits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/RateSet\nThis leaf node represents a list of bit rates used by speech codec. Depending on the codec, each value can be understood as either the highest rate or the average rate. The entries in the list may either be generic, i.e., usable for any codec, but can also be codec-specific. The default usage is the generic list where the bit rates in bits/sec are included, e.g., \"5000, 6000, 7500, 12500\". A codec-specific list may indicate the desired modes. For example, in the case of AMR, the list could be \"0, 2, 4, 7\".\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/EVS\nThis interior node is used to allow a reference to a list of parameters related to the configuration of EVS speech codec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/EVS/Br\nThis leaf gives the value of br, a parameter representing the range or value of bit-rate for EVS speech codec defined in [125].\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/EVS/Bw\nThis leaf gives the value of bw, a parameter representing the range or value of bandwidth for EVS speech codec defined in [125].\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ConRef\nThis node specifies a reference to QoS parameters Management Object. The interior node’s leaf nodes specify the network preferred QoS parameters as defined in TS 24.008 and they should be used in the bearer request when client initiated QoS happen. Implementation specific MO may be referenced.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video\nThe Video node is the starting point of the video codec definitions (if any video codec are available)\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>\nThis interior node is used to allow a reference to a list of video codec objects.\n-\tOccurrence: OneOrMore\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ID\nThis leaf node represents the identification number of a set of parameters for video session.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/TAG\nThis leaf node represents the identification tag of a set of parameters for video session. It is recommended to have at least a node, for example, ID, TAG, or implementation-specific ones, for the identification purpose such that each set of parameters can be distinguished and accessed.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/Priority\nThis leaf represents the priority of a set of parameters for speech session. Lower value means higher priority and the value is used in the terminal for client initiated QoS handling. The priority uses a 16 bit unsigned integer.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n-\tValues: Zero or higher\n/<X>/Video/<X>/IPver\nThis leaf represents the version of the Internet Protocol used in the session.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: \"IPv4\", \"IPv6\"\n/<X>/Video/<X>/Codec\nThis leaf gives the MIME subtype name of video codec. This leaf is preferably pre-configured by the device.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: MIME subtype name of video codec, e.g., \"H264\", \"H265\".\nThe values \"H264\" and \"H265\" refer to the H.264 (AVC) and H.265 (HEVC) codecs as defined by MPEG and ITU respectively. The usage of H.264 (AVC) and H.265 (HEVC) codecs (profiles, levels etc) is described in the document TS 26.114 Chapter 5.5.2.\n/<X>/Video/<X>/Bandwidth\nThis interior node is used to allow a reference to a list of parameters related to video bandwidth assignment.\n-\tOccurrence: One\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/Bandwidth/AS\nThis leaf gives the preferred video codec bandwidth by the network for the bearer set-up, including RTP/UDP/IP headers. It provides the value for \"b=AS\" line for video part used in the end-to-end SDP negotiation process, which represents the bit rate in kbits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/Bandwidth/RS\nThis leaf provides the value for \"b=RS\" line for video part used in the end-to-end SDP negotiation process, which represents the bit rate in bits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/Bandwidth/RR\nThis leaf provides the value for \"b=RR\" line for video part used in the end-to-end SDP negotiation process, which represents the bit rate in bits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/Bandwidth/Source\nThis leaf gives the preferred video encoding bandwidth in kbits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/Bandwidth/PayloadSize\nThis leaf gives the preferred payload size for video, excluding payload header, which represents the amount of encoded video data in bytes transported over a RTP packet.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ProfileLevel\nThis interior node is used to allow a reference to a list of parameters related to the profile and level of video codec.\n-\tOccurrence: One\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ProfileLevel/H264\nThis leaf gives the profile-level-id of H.264 (AVC) video codec, which indicates the profile that the codec supports and the highest level supported for the signaled profile [24], [25].\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ProfileLevel/H265\nThis interior node is used to allow a reference to a list of parameters related to the profile and level of H.265 (HEVC) video codec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ProfileLevel/H265/Profile\nThis leaf gives the value of profile-id, a parameter representing the profile of H.265 (HEVC) video codec defined in [119], [120].\n-\tOccurrence: One\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ProfileLevel/H265/Level\nThis leaf gives the value of level-id, a parameter representing the level of H.265 (HEVC) video codec defined in [119], [120]. Level indicates the maximum computational complexity supported by the offerer in performing decoding for the given profile.\n-\tOccurrence: One\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ImageAttr\nThis interior node is used to allow a reference to a list of parameters related to the image sizes supported or preferred, specified with the \"imageattr\" attribute. (see clause A.4)\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ImageAttr/Send\nThis leaf gives the supported image sizes for the send direction. The value is a string such as \"176, 144, 224, 176, 272, 224, 320, 240\" which means four image sizes, 176x144, 224x176, 272x224, and 320x240 are supported for the send direction. The maximum image size in this leaf shall not exceed the maximum size limited by the offered codec level.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ImageAttr/Recv\nThis leaf gives the supported image sizes and their preferences for the receive direction. The value is a string such as \"176, 144, 0.5, 224, 176, 0.5, 272, 224, 0.6, 320, 240, 0.5\" which means four image sizes, 176x144, 224x176, 272x224, and 320x240 are supported for the receive direction but 272x224 is preferred since it might fit the available space on the display of the receiver better than the other image sizes. The maximum image size in this leaf shall not exceed the maximum size limited by the offered codec level. The value representing the level of preference by the offerer, defined in [76], is between 0 and 1 inclusive and 0.5 by default.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ConRef\nThis node specifies a reference to QoS parameters Management Object. The interior node’s leaf nodes specify the network preferred QoS parameters as defined in TS 24.008 and they should be used in the bearer request when client initiated QoS happen.  Implementation specific MO may be referenced.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Text\nThe Text node is the starting point of the real time text codec definitions (if the real time text codec is available).\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Text/<X>\nThis interior node is used to allow a reference to the real time text codec objects.\n-\tOccurrence: OneOrMore\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Text/<X>/ID\nThis leaf node represents the identification number of a set of parameters for text session.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Text/<X>/TAG\nThis leaf node represents the identification tag of a set of parameters for text session. It is recommended to have at least a node, for example, ID, TAG, or implementation-specific ones, for the identification purpose such that each set of parameters can be distinguished and accessed.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Text/<X>/Priority\nThis leaf represents the priority of a set of parameters for text session. Lower value means higher priority and the value is used in the terminal for client initiated QoS handling. The priority uses a 16 bit unsigned integer.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n-\tValues: Zero or higher\n/<X>/Text/<X>/IPver\nThis leaf represents the version of the Internet Protocol used in the session.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: \"IPv4\", \"IPv6\"\n/<X>/Text/<X>/TextFormat\nThis leaf node represents the MIME subtype name of text conversation protocol. The value \"t140\" refers to T.140 defined in ITU-T [26], [27].\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: MIME subtype name of the text conversation protocol, e.g., \"t140\"\n/<X>/Text/<X>/Bandwidth\nThis interior node is used to allow a reference to a list of parameters related to text bandwidth assignment.\n-\tOccurrence: One\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Text/<X>/Bandwidth/AS\nThis leaf provides the value for \"b=AS\" line for text part used in the end-to-end SDP negotiation process, which represents the bit rate in kbits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/Bandwidth/RS\nThis leaf provides the value for \"b=RS\" line for text part used in the end-to-end SDP negotiation process, which represents the bit rate in bits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/Bandwidth/RR\nThis leaf provides the value for \"b=RR\" line for text part used in the end-to-end SDP negotiation process, which represents the bit rate in bits/sec.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Text/<X>/RedundancyLevel\nThis leaf node represents the level of redundancy when redundancy is used with T.140 text.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n-\tValues: 0, 100, 200, 300\n/<X>/Text/<X>/SamplingTime\nThis leaf node, defined in clause 9.4, represents the period for which text may be buffered before transmission. Buffering time, defined in [31], has an identical meaning as this node, i.e., the shortest period between text transmissions. Default value is 300 ms.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Text/<X>/ConRef\nThis node specifies a reference to QoS parameters Management Object.  The interior node’s leaf nodes specify the network preferred QoS parameters as defined in TS 24.008 and they should be used in the bearer request when client initiated QoS happen.  Implementation specific MO may be referenced.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Text/<X>/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "15.3\tExample Configuration of 3GPP MTSINP MO",
                    "description": "",
                    "summary": "",
                    "text_content": "The examples below are configurations of 3GPP MTSINP MO for selected speech, text, and video sessions in Annex A. An example of SDP offer for speech session is shown in Table A.6.1, which includes two RTP payload types for AMR-NB. Parameter values in Table 15.1 may apply to both payload types and additional SDP parameters such as max-red may be included under the Ext node as vendor extensions. Depending on the implementation, two sets of session parameters may be defined for the two payload types respectively.\nTable 15.1: Example configuration of MTSINP for speech session\n\nAn example configuration of MTSINP for video session is shown in Table 15.3, which includes the RTP payload types for H.264. Although the \"b=AS\" value can also be computed with the Source and PayloadSize nodes, a different value with appropriate implementation margin can be directly assigned to the AS node. If the AS, Source, and PayloadSize nodes are defined together, the AS node value should be used for setting \"b=AS\". In Table 15.3, the \"b=AS\" values of 315, for H.264, are computed assuming IPv4 addressing. Note that the Priority node of H.264 is assigned values of 5, which shows that depending on service policy, parameters sets of lower priority may be preferred in the construction of SDP offer. If the ImageAttr node is to be defined, the maximum image size in either the Send or Recv node shall not exceed the maximum size limited by the offered codec level, which is 352x288 for Baseline profile at level 1.1.\nTable 15.2: Example configuration of MTSINP for text session\n\nAn example of SDP offer for video session is shown in Table A.4.4b, which includes a RTP payload type for H.264. Although the \"b=AS\" value can also be computed with the Source and PayloadSize nodes, a different value with appropriate implementation margin can be directly assigned to the AS node. If the AS, Source, and PayloadSize nodes are defined together, the AS node value should be used for setting \"b=AS\". In Table 15.3, the \"b=AS\" values of 315 and 57 kbps, for H.264 and H.263 respectively, are computed assuming IPv4 addressing. Note that the Priority nodes of H.264 and H.263 are assigned values of 5 and 3 respectively, which shows that depending on service policy, parameters sets of lower priority may be preferred in the construction of SDP offer. If the ImageAttr node is to be defined, as for H.264 in Table A.4.10a, the maximum image size in either the Send or Recv node shall not exceed the maximum size limited by the offered codec level, which is 352x288 for Baseline profile at level 1.1.\nTable 15.3: Example configuration of MTSINP for video session\n\n",
                    "tables": [
                        {
                            "description": "Table 15.1: Example configuration of MTSINP for speech session",
                            "table number": 35,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table 15.2: Example configuration of MTSINP for text session",
                            "table number": 36,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table 15.3: Example configuration of MTSINP for video session",
                            "table number": 37,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "16\tQuality of Experience",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "16.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "The MTSI Quality of Experience (QoE) metrics feature is optional for an MTSI client in a terminal and shall not disturb the MTSI service. Non-terminal MTSI clients (such as gateways) should not implement MTSI QoE reporting. An MTSI client that supports the QoE metrics feature shall support OMA-DM. The OMA-DM configuration server can configure the activation/deactivation and gathering of QoE metrics in the MTSI client (see clause 16.3). Configuration can also be done using the QMC functionality (see clause 16.5). An MTSI client supporting the QoE  metrics feature shall perform the quality measurements in accordance to the measurement definitions, aggregate them into client QoE metrics and report the metrics. The MTSI client may send QoE metrics reports during the session and at the end of the session. The way how the QoE metrics are processed and made available is out of the scope of this specification.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "16.2\tMetrics Definition",
                    "description": "",
                    "summary": "",
                    "text_content": "An MTSI client supporting the QoE metrics feature shall support the reporting of the metrics in this clause. The metrics are valid for speech, video and text media, and are calculated for each measurement resolution interval \"Measure-Resolution\" (sub-clause 16.3.2). They are reported to the server according to the measurement reporting interval \"Sending-Rate\" (sub-clause 16.3.2) and after the end of the session (sub-clause 16.4).\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "16.2.1\tCorruption duration metric",
                            "text_content": "Corruption duration, M, is the time period from the NPT time of the last good frame (since the NPT time for the first corrupted frame cannot always be determined) before the corruption, to the NPT time of the first subsequent good frame. A corrupted frame may either be an entirely lost frame, or a media frame that has quality degradation and the decoded frame is not the same as in error-free decoding.\nA good frame is a completely received frame:\n-\twhere all parts of the image are guaranteed to contain the correct content; or\n-\tthat is a refresh frame, that is, does not reference any previously decoded frames; or\n-\twhich only references previously decoded good frames\nCompletely received means that all the bits are received and no bit error has occurred.\nCorruption duration, M, in milliseconds can be calculated as below:\na)\tM can be derived by the client using the codec layer, in which case the codec layer signals the decoding of a good frame to the client. A good frame could also be derived by error tracking methods, but decoding quality evaluation methods shall not be used.\nb)\tAlternatively, the corruption is considered as ended after N milliseconds with consecutively completely received frames, or when a refresh frame has been completely received, whichever comes first..\n\nThe optional configuration parameter N can be set to define the average characteristics of the codec. If N has not been configured it shall default to the length of one measurement interval for video media, and to one frame duration for non-video media.\nThe syntax for the metrics \"Corruption_Duration\" is as defined in sub-clause 16.3.2.\nThe N parameter is specified in milliseconds and is used with the \"Corruption_Duration\" parameter in the \"3GPP-QoE-Metrics\" definition. The value of N may be set by the server. The syntax for N to be included in the \"att-measure-spec\" (sub-clause 16.3.2) is as follows:\n-\tN = \"N\" \"=\" 1*DIGIT\nAll the occurred corruption durations within each resolution period are summed and stored in the vector TotalCorruptionDuration. The unit of this metrics is expressed in milliseconds. Within each resolution period the number of individual corruption events are summed up and stored in the vector NumberOfCorruptionEvents. These two vectors are reported by the MTSI client as part of the reception report (sub-clause 16.4).\nThe parameter CorruptionAlternative indicates how the metric has been calculated, and shall be sent by the client via reception reporting (sub-clause 16.3.2) as \"a\", or \"b\".\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.2.2\tSuccessive loss of RTP packets",
                            "text_content": "The metric \"Successive_Loss\" indicates the number of RTP packets lost in succession per media channel.\nThe syntax for the metrics \"Successive_Loss\" is as defined in sub-clause 16.3.2.\nAll the number of successively lost RTP packets are summed up within each measurement resolution period of the stream and stored in the vector TotalNumberofSuccessivePacketLoss. The unit of this metric is expressed as an integer equal to or larger than 0. The number of individual successive packet loss events within each measurement resolution period are summed up and stored in the vector NumberOfSuccessiveLossEvents. The number of received packets are also summed up within each measurement resolution period and stored in the vector NumberOfReceivedPackets. These three vectors are reported by the MTSI client as part of the QoE report (sub-clause 16.4)\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.2.3\tFrame rate",
                            "text_content": "Frame rate indicates the playback frame rate. The playback frame rate is equal to the number of frames displayed during the measurement resolution period divided by the time duration, in seconds, of the measurement resolution period.\nThe syntax for the metric \"Frame_Rate\" is defined in sub-clause 16.3.2.\nFor the Metrics-Name \"Frame_Rate\", the value field indicates the frame rate value. This metric is expressed in frames per second, and can be a fractional value. The frame rates for each resolution period are stored in the vector FrameRate and reported by the MTSI client as part of the QoE report (sub-clause 16.4).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.2.4\tJitter duration",
                            "text_content": "Jitter happens when the absolute difference between the actual playback time and the expected playback time is larger than JitterThreshold milliseconds. The expected time of a frame is equal to the actual playback time of the last played frame plus the difference between the NPT time of the frame and the NPT time of the last played frame.\nThe syntax for the metric \"Jitter_Duration\" is defined in sub-clause 16.3.2.\nThe optional configuration parameter JT can be set to control the amount of allowed jitter. If the parameter has not been set, it defaults to 100 ms. The JT parameter is specified in ms and is used with the \"Jitter_Duration\" parameter in the \"3GPP-QoE-Metrics\" definition. The value of JT may be set by the server. The syntax for JT to be included in the \"att-measure-spec\" (sub-clause 16.3.2) is as follows:\n-\tJT = \"JT\" \"=\" 1*DIGIT\nAll the jitter durations are summed up within each measurement resolution period and stored in the vector TotalJitterDuration. The unit of this metric is expressed in seconds, and can be a fractional value. The number of individual events within the measurement resolution period are summed up and stored in the vector NumberOfJitterEvents. These two vectors are reported by the MTSI client as part of the QoE report (sub-clause 16.4).\nNote that the jitter duration metric is not measuring the incoming RTP or frame jitter, but instead the actual visible media playback jitter. Thus with a large enough jitter buffer the incoming RTP or frame jitter might be substantial, without any measurable jitter duration being reported (even if the JitterThreshold would have been set to zero).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.2.5\tSync loss duration",
                            "text_content": "Sync loss happens when the absolute difference between value A and value B is larger than SyncThreshold milliseconds. Value A represents the difference between the playback time of the last played frame of the video stream and the playback time of the last played frame of the speech/audio stream. Value B represents the difference between the expected playback time of the last played frame of the video stream and the expected playback time of the last played frame of the speech/audio stream.\nThe syntax for the metric \"SyncLoss_Duration\" is defined in sub-clause 16.3.2.\nThe optional configuration parameter ST can be set to control the amount of allowed sync mismatch. If the parameter has not been set, it defaults to 100 ms. The ST parameter is specified in ms and is used with the \"SyncLoss_Duration\" parameter in the \"3GPP-QoE-Metrics\" definition. The value of ST may be set by the server. The syntax for ST to be included in the \"att-measure-spec\" (sub-clause 16.3.2) is as follows:\n-\tST = \"ST\" \"=\" 1*DIGIT\nAll the sync loss durations are summed up within each measurement resolution period and stored in the vector TotalSyncLossDuration. The unit of this metric is expressed in seconds, and can be a fractional value. The number of individual events within the measurement resolution period are summed up and stored in the vector NumberOfSyncLossEvents. These two vectors are reported by the MTSI client as part of the QoE report (sub-clause 16.4).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.2.6\tRound-trip time",
                            "text_content": "The round-trip time (RTT) consists of the RTP-level round-trip time, plus the additional two-way delay (RTP level->loudspeaker->microphone->RTP level) due to buffering and other processing in each client.\n\nThe syntax for the metric \"Round_Trip_Time\" is defined in sub-clause 16.3.2.\nThe last RTCP round-trip time value estimated during each measurement resolution period shall be stored in the vector NetworkRTT. The unit of this metrics is expressed in milliseconds.\nThe two-way additional internal client delay valid at the end of each measurement resolution period shall be stored in the vector InternalRTT. The unit of this metrics is expressed in milliseconds.\nThe two vectors are reported by the MTSI client as part of the QoE report (sub-clause 16.4).\nNote that if the RTP and the RTCP packets for a media are not sent in the same RTP stream the estimated media round-trip time might be unreliable.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.2.7\tAverage codec bitrate",
                            "text_content": "The average codec bitrate is the bitrate used for coding \"active\" media information during the measurement resolution period.\nFor speech media \"active\" information is defined by frames containing speech, i.e. silence frames (SID-frames) and DTX periods are excluded from the calculation. If application-layer redundancy is used, any redundant frames should also be excluded. If partial redundancy is used within frames (e.g. EVS channel-aware mode), only the non-redundant bits in these frame should be counted as having \"active\" information.\nThe exact method for how the client identifies the active frames or bits is not specified here, and it is recognized that an implementation might not be able to fully exclude all non-active frames or bits from the calculation.\nThus for speech media the average codec bitrate can be calculated as the number of \"active\" speech bits received for \"active\" frames , divided by the total time, in seconds, covered by these frames. The total time covered is calculated as the number of \"active\" frames times the length of each speech frame.\nFor non-speech media the average codec bitrate is the total number of RTP payload bits received, divided by the length of the measurement resolution period.\nThe syntax for the metric \"Average_Codec_Bitrate\" is defined in sub-clause 16.3.2.\nThe average codec bitrate value for each measurement resolution period shall be stored in the vector AverageCodecBitrate. The unit of this metrics is expressed in kbit/s and can be a fractional value. The vector is reported by the MTSI client as part of the QoE report (sub-clause 16.4).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.2.8\tCodec information",
                            "text_content": "The codec information metrics contain details of the media codec settings used in the receiving direction during the measurement resolution period. If the codec information is changed during the measurement resolution period, the codec information valid when each measurement resolution period ends shall be reported. The unit of this metric is a string value. No \"white space\" characters are allowed in the string values, and shall be removed if necessary.\nFor speech media the semi-colon-separated codec information contains the used speech codec type (represented as in an SDP rtpmap offer) and the used codec settings for bandwidth and redundancy (represented as in an SDP fmtp offer). For instance \"EVS/16000/1;bw=swb;\", or \"EVS/16000/1;ch-aw-recv=3\".\nFor video media, the codec information contains the video codec type, represented as in an SDP offer, for instance \"H265/90000\". Furthermore, the semi-colon-separated video profile, level (and tier if applicable) used shall be reported, represented as in an SDP offer. For instance for H.265, \"profile-id=1;level-id=120;tier-flag=1\", or for H.264, \"profile-level-id=42e00a\". The actually used image size (not the maximum allowed) shall also be reported, represented as \"WxH\", for example \"320x240\".\nFor real-time text media, the codec information contains the text encoding, represented as in an SDP offer, for instance \"t140/1000/1\".\nThe syntax for the metric \"Codec_Info\", \"Codec_ProfileLevel\" and \"Codec_ImageSize\" are defined in sub-clause 16.3.2.\nThe codec info,  profile/level/tier and codec image size value for each measurement resolution period shall be stored in the vectors CodecInfo, CodecProfileLevel and CodecImageSize respectively. If the metric values in these vectors for a measurement resolution period are unchanged from the previous values in the respective vector, it is allowed to put the value \"=\" in the vector to indicate this. The CodecInfo, CodecProfileLevel and CodecImageSize vectors are reported by the MTSI client as part of the QoE report (sub-clause 16.4).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.2.9\tCall setup time",
                            "text_content": "The call setup time is measured on SIP level for originating calls (see ITU-T G-1028 [181] Table 3). It is defined as the time between the transmitted INVITE, and the reception of either \"200 OK\" or \"180 RINGING\" (whichever comes first).\n\nThe syntax for the metric \"Call_Setup_Time\" is defined in sub-clause 16.3.2.\nThe measured call setup time shall be stored in the variable CallSetupTime. The unit of this metrics is expressed in milliseconds. The variable is reported by the MTSI client as part of the QoE report (sub-clause 16.4).\nNOTE:\tThe reason for also using \"180 RINGING\" as an end-of-call-setup criteria is to compensate for the physical answering delay caused by the called user. Thus the metric measures the fastest possible call setup time, i.e. as if the called user had answered directly.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "16.3\tMetric Configuration",
                    "description": "",
                    "summary": "",
                    "text_content": "An MTSI client supporting the QoE metrics feature shall support the OMA-DM solution specified in this clause for configuration of QoE  metrics and their activation. The MTSI client shall also support the QMC functionality specified in clause 16.5 for configuration of QoE metrics.\nThe QoE configuration shall only be evaluated by the client at the start of a QoE measurement and reporting session (“QoE session”) associated with a MTSI session. This includes evaluation of any filtering criteria such as by geographical area. Client evaluation of all measurement and reporting criterias for an ongoing QoE session shall be unaffected by any QoE configuration changes received during that session – i.e., any changes to the QoE configuration shall only affect QoE sessions started after these configuration changes have been received.\nIf an MTSI client uses the OMA-DM configuration feature, it is mandatory for the MTSI client to implement the Management Object (MO) as described in this clause.\nThe 3GPP MTSIQOE (MTSI QoE metrics) MO defined in this clause may be used to configure the QoE metrics and reporting settings.\nThe metrics specified in the MO may be derived by the MTSI client. Version numbering is included for possible extension of the MO.\nThe Management Object Identifier shall be: urn:oma:mo:ext-3gpp-mtsiqoe:1.0.\nProtocol compatibility:  The MO is compatible with OMA Device Management protocol specifications, version 1.2 and upwards, and is defined using the OMA DM Device Description Framework as described in the Enabler Release Definition OMA-ERELD _DM-V1_2 [67].\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "16.3.1\tQoE metrics reporting management object",
                            "text_content": "The following nodes and leaf objects in figure 16.1 shall be contained under the 3GPP_MTSIQOE node if an MTSI client supports the feature described in this clause (information of DDF for this MO is given in Annex I):\nFigure 16.1 illustrates the MTSI QoE metrics management object tree, which outlines the hierarchical structure of quality of experience (QoE) metrics in a managed telecommunication system. The tree begins with the top-level management object, followed by various subordinate objects representing different aspects of QoE, such as network performance, user experience, and service availability. The figure demonstrates the interconnected relationships between these objects, highlighting the importance of a comprehensive approach to managing and optimizing QoE in a telecommunication network.\nFigure 16.1: MTSI QoE metrics management object tree\nNode: /<X>\nThis interior node specifies the unique object id of a MTSI QoE metrics management object. The purpose of this interior node is to group together the parameters of a single object.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\nThe following interior nodes shall be contained if the MTSI client supports the \"MTSI QoE metrics Management Object\".\n/<X>/Enabled\nThis leaf indicates if QoE reporting is requested by the provider.\n-\tOccurrence: One\n-\tFormat: bool\n-\tMinimum Access Types: Get\n/<X>/Servers\nThis leaf contains a space-separated list of URL of servers to which the QoE reports can be transmitted. It is URI addresses, e.g. . In case of multiple servers, the MTSI client randomly selects one of the servers from the list, with uniform distribution.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: URI of the servers to receive the QoE report.\n/<X>/APN\nThis leaf contains the Access Point Name that should be used for establishing the PDP context or EPS bearer on which the QoE metric reports will be transmitted. This may be used to ensure that no costs are charged for QoE metrics reporting.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: the Access Point Name\n/<X>/Format\nThis leaf specifies the format of the report and if compression (Gzip XML) [71] is used.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: \"XML\", \"GZIPXML\".\n/<X>/Rules\nThis leaf provides in textual format the rules used to decide whether metrics are to be reported to the QoE metrics report server. The syntax and semantics of this leaf are defined in clause 16.3.3.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: See clause 16.3.3.\n/<X>/Ext\nThe Ext node is an interior node where the vendor specific information can be placed (vendor includes application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech\nThe Speech node is the starting point of the speech media level QoE metrics definitions.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/Metrics\nThis leaf provides in textual format the QoE metrics that need to be reported, the measurement frequency, the reporting interval and the reporting range. The syntax and semantics of this leaf are defined in clause 16.3.2.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: see clause 16.3.2.\n/<X>/Speech/Ext\nThe Ext node is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video\nThe Video node is the starting point of the video media level QoE metrics definitions.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/Metrics\nThis leaf provides in textual format the QoE metrics that need to be reported, the measurement frequency, the reporting interval and the reporting range. The syntax and semantics of this leaf are defined in clause 16.3.2.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tAccess Types: Get\n-\tValues: see clause 16.3.2.\n/<X>/Video/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the Ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Text\nThe Text node is the starting point of the real-time text media level QoE metrics definitions.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n-\tValues: see clause 16.3.2.\n/<X>/Text/Metrics\nThis leaf provides in textual format the QoE metrics that need to be reported, the measurement frequency, the reporting interval and the reporting range. The syntax and semantics of this leaf are defined in clause 16.3.2.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: see clause 16.3.2.\n/<X>/Text/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/<LocationFilter>\nWhen present, this element indicates the geographic area(s) or location(s) where quality metric collection is requested. When not present, quality metric collection is requested regardless of the device’s location. The LocationFilter element comprises one or more instances of any combination of targeted cell-IDs, polygons and circular areas.Each cell-ID entry in LocationFilter is announced in cellList, and each polygon and circular area entry is announced in the polygonList or and circularAreaList elements, respectively.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/<LocationFilter>/CellList\nThis element specifies a list of cell identified by the CGI (i.e., NCGI, ECGI, CGI).\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: a list of CGI.\n/<X>/<LocationFilter>/PolygonList\nThis leaf specifies a list of shapes defined as ‘Polygon’ by OMA MLP [159].\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: a list of ‘Polygon’ defined by OMA MLP [159].\n/<X>/<LocationFilter>/Polygon_Conf_Level\nThis leaf indicates the probability in percent that the MTSI client is located in the corresponding polygon area specified by leaf ‘PolygonList’. It is defined as ‘lev_conf’ by OMA MLP [159]. If not present, it has default value of 60.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n-\tValues: ‘lev_conf’ defined by OMA MLP [159].\n/<X>/<LocationFilter>/CircularAreaList\nThis leaf specifies a list of shapes defined as ‘CircularArea’ by OMA MLP [159].\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: a list of ‘CircularArea’ defined by OMA MLP [159].\n/<X>/<LocationFilter>/Circular_Conf_Level\nThis leaf indicates the probability in percent that the MTSI client is located in the corresponding circular area specified by leaf ‘CircularAreaList’. It is defined as ‘lev_conf’ by OMA MLP [159]. If not present, it has default value of 60.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n-\tValues: ‘lev_conf’ defined by OMA MLP [159].\n/<X>/<LocationFilter>/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.3.2\tQoE metric reporting configuration",
                            "text_content": "The syntax of the text contained in the Metrics leaf is similar to the \"3GPP-QoE-Metrics\" attribute syntax specified in TS 26.234 [60] and TS 26.346 [74]:\n-\tQoE-Metrics\t= \"3GPP-QoE-Metrics:\" att-measure-spec *(\",\" att-measure-spec)) CRLF\n-\tatt-measure-spec\t= Metrics \";\" Sending-rate [\";\" Measure-Range] \n\t[\";\" Measure-Resolution] *([\";\" Parameter-Ext])\n-\tMetrics\t= \"metrics\" \"=\" \"{\"Metrics-Name *(\"|\" Metrics-Name) \" }\"\n-\tMetrics-Name\t= 1*((0x21..0x2b) / (0x2d..0x3a) / (0x3c..0x7a) / 0x7e) ;VCHAR except \";\", \",\", \"{\"\tor \"}\"\n-\tSending-Rate\t= \"rate\" \"=\" 1*DIGIT / \"End\"\n-\tMeasure-Resolution\t= \"resolution\" \"=\" 1*DIGIT ; in seconds\n-\tMeasure-Range\t= \"range\" \":\" Ranges-Specifier\n-\tParameter-Ext\t= (1*DIGIT [\".\" 1*DIGIT]) / (1*((0x21..0x2b) / (0x2d..0x3a) / (0x3c..0x7a) / 0x7c / 0x7e))\n-\tRanges-Specifier\t= as defined in RFC 2326 [72].\nThis attribute is used to indicate which QoE metrics are supported, the reporting interval, the measurement interval and reporting range.\nThe \"Metrics\" field contains the list of names that describes the metrics/measurements that are required to be reported in a MTSI call, provided that the MTSI client supports these measurements and the reporting rule conditions are met (see clause 16.3.3). The names that are not included in the \"Metrics\" field shall not be reported during the session.\nThe \"Sending-Rate\" shall be set, and it expresses the maximum time period in seconds between two successive QoE reports. If the \"Sending-Rate\" value is 0, then the client shall decide the sending time of the reports depending on the events occurred in the client. Values  1 indicate a precise reporting interval. The shortest interval is one second and the longest interval is undefined. The reporting interval can be different for different media, but it is recommended to maintain a degree of synchronization in order to avoid extra traffic in the uplink direction. The value \"End\" indicates that only one report is sent at the end of the session.\nThe optional \"Measure-Resolution\" field, if used, shall define a time over which each metrics value is calculated. The \"Measure-Resolution\" field splits the session duration into a number of equally sized periods where each period is of the length specified by the \"Measure-Resolution\" field. The \"Measure-Resolution\" field is thus defining the time before the calculation of a QoE parameter starts over. If the \"Measure-Resolution\" field is not present, the metrics resolution shall cover the period specified by the \"Measure-Range\" field. If the \"Measure-Range\" field is not present the metrics resolution shall be the whole session duration.\nThe optional \"Measure-Range\" field, if used, shall define the time range in the stream for which the QoE metrics will be reported. There shall be only one range per measurement specification. The range format shall be any of the formats allowed by the media. If the \"Measure-Range\" field is not present, the metrics range shall be the whole call duration.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.3.3\tQoE reporting rule definition",
                            "text_content": "This clause defines the syntax and semantics of a set of rules which are used to reduce the amount of reporting to the QoE metrics report server. The syntax of the metrics reporting rules is defined below:\n-\tQoE-Rule\t= \"3GPP-QoE-Rule\" \":\" rule-spec *(\",\" rule-spec)\n-\trule-spec\t= rule-name [\";\" parameters]\n-\trule-name\t= \"OnlyCallerReports\" / \"LimitSessionInterval\" / \"SamplePercentage\"\n-\tparameters\t= parameter *(\";\" parameter)\n-\tparameter\t= Param-Name [\"=\" Param-Value ]\n-\tParam-Name\t= 1*((0x21..0x2b) / (0x2d..0x3a) / (0x3c..0x7a) / 0x7e) ;VCHAR except \";\", \",\", \"{\"\tor \"}\"\n-\tParam-Value\t= (1*DIGIT [\".\" 1*DIGIT]) / (1*((0x21..0x2b) / (0x2d..0x3a) / (0x3c..0x7a) / 0x7c / 0x7e))\nThe semantics of the rules and the syntax of its parameters is defined below:\nThe OnlyCallerReports rule is used to determine the metrics reporting sources. When this rule is present, only the initiator of the call, i.e., caller, will report metrics to the QoE report server. When absent all parties report metrics.\nThe SamplePercentage rule can be used to set a percentage sample of calls which should report reception. This can be useful for statistical data analysis of large populations while increasing scalability due to reduced total uplink signalling. The sample_percentage parameter takes on a value between 0 and 100, including the use of decimals. It is recommended that no more than 3 digits follow a decimal point (e.g. 67.323 is sufficient precision).\nWhen the SamplePercentage rule is not present or its sample_percentage parameter value is 100 each MTSI client shall send metric report(s). If the sample_percentage value is less than 100, the UE generates a random number which is uniformly distributed in the range of 0 to 100. The UE sends the reception report when the generated random number is of a lower value than the sample_percentage value.\nThe LimitSessionInterval rule is used to limit the time interval between consecutive calls that report metrics. The min_interval parameter for this rule indicates the minimum time distance between the start of two calls that are allowed to report metrics. When this rule is absent there is no limitation on the minimum time interval.\nIn case multiple rules are defined in the Management Object, the MTSI client should only report metrics when all individual rules evaluate to true (i.e. the rules are logically ANDed). In case no rules are present the MTSI client should always report metrics (see also clause 16.4 for metrics reporting procedures).\nAn example for a QoE metric reporting rule is shown below:\n3GPP-QoE-Rule:OnlyCallerReports,SamplePercentage;sample_percentage=10.0,\n                                  LimitSessionInterval;min_interval=300,\nThis example rule defines that only the caller shall report, and only for 10% of the sessions, with the minimum time interval between the start times of two consecutive calls that report metrics to be 5 minutes.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "16.4\tMetrics Reporting",
                    "description": "",
                    "summary": "",
                    "text_content": "When a session is started, the MTSI client must determine whether QoE reporting is required for the session. If the parameter \"Enabled\" is set to false, no QoE reporting shall be done. If the \"Enabled\" parameter is set to true the optional \"Rules\" parameters are checked (sub-clause 16.3.3) to define if QoE reporting shall be done.\nOnce the need for QoE reporting has been established, the client shall continuously compute all specified metrics for each measurement interval period, according to the \"Measure-Resolution\" parameter (sub-clause 16.3.2). In order to bound the resources used by metrics reporting, the minimum values for the Measure-Resolution and Sending-Rate are specified to be 5 seconds and 30 seconds respectively. The computed metrics are represented in a vector format, adding an additional metric value to each metric vector after each new measurement interval period.\nNote that the calculated metrics shall only cover one measurement interval. For instance, if the corruption duration extends longer than to the end of the current measurement interval, only the portion which fits into the current measurement interval shall be reported. The remaining portion of the corruption duration shall be reported as belonging to the next measurement interval.\nThe end of the session will normally not correspond to the end of a measurement interval period, so the metrics for the last measurement interval period will typically be calculated over a time shorter than the configured measurement interval. Note, however, that these last metrics shall still be added to the metrics vectors and reported to the server.\nIt is possible for the server to use the start and stop timestamps, together with the knowledge of the configured measurement interval, to derive the actual length of the last measurement interval period, but any specific action or interpretation of these last shorter measurements is out of scope of this specification.\nThe MTSI client shall send QoE report messages to the server in accordance with the specified reporting interval \"Sending-Rate\" (sub-clause 16.3.2). All stored metrics data shall then be sent to the server, and then deleted from the metrics storage.\nNote that if the reporting interval is not an integer multiple of the measurement interval, only the measurement interval periods which have been fully passed shall be included in the report. The ongoing not-passed measurement interval period shall be included in the next report. The only exception is at the end of the session, where also the last ongoing measurement interval period shall be directly calculated and included in the report.\nIf QoE configuration has been done via the OMA MO, the client shall send QoE reports using the HTTP (RFC 2616 [73]) POST request carrying XML formatted metadata. If the optional \"APN\" parameter is defined in the OMA managed object, that APN shall be used for establishing the PDP context or EPS bearer on which the QoE metric reports will be transmitted. The MTSI client randomly selects one of the URIs from the MO \"Server\" parameter, with uniform distribution.\nIf QoE configuration has been done via the QMC functionality (see clause 16.5), the client shall also send the QoE reports as described in clause 16.5. Note that for QMC scheme, if the SliceScope is included in the QoE configuration and the slice associated with the MTSI service is within the SliceScope, the QoE collection shall be executed and the S-NSSAI and DNN that correspond to the report data shall be included for support of per-slice QoE reporting and evaluation in OAM. This information may be retrieved via the AT Command +CGDCONT [161]) or the specific traffic mapping with URSP rule[182].\nEach QoE report is formatted in XML according the following XML schema (sub-clause 16.4.1). An informative example of a single reception report XML object is also given (sub-clause 16.4.2). The reports should be compressed using GZIP only if the MO parameter \"Format\" specifies this.\nEach QoE Metrics element has a set of attributes and any number of media level QoE Metrics elements. All attributes are defined in sub-clause 16.4.1 and correspond to the QoE metrics listed in sub-clause 16.2. Individual metrics can be selected as described in sub-clause 16.3.2.\nExcept for the media level QoE metrics, the following parameters shall be reported for each report:\n-\tThe callId attribute identifies the call identity of the SIP session.\n-\tThe clientId attribute is unique identifier for the receiver, e.g. an MSISDN of the UE as defined in [80].\n-\tThe startTime and stopTime attributes identifies the client NTP time when the measurements included in the report were started and stopped. The time is based on the local real-time clock in the client, and might not be consistent with the true NTP time. However, assuming that the reporting is done without any extra delay the server can use the stopTime attribute to correct the timestamps if necessary.\n-\tThe mediaId attribute shall be reported for each media level QoE report, and identifies the port number for the media.\nIf the attribute qoeReferenceId was defined in the QMC configuration (see clause 16.5.2), the value shall be copied into each QoE report, to facilitate network-side correlation (see [178]). If this attribute was defined, the attribute recordingSessionId shall also be returned for each QoE report. The recordingSessionId is a two-byte octet defined by the client. It shall remain the same for all QoE reports belonging to the same session, and it should be different for QoE reports belonging to different sessions.\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "16.4.1\tXML schema for QoE report message",
                            "text_content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<xs:schema xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\ntargetNamespace=\"urn:3gpp:metadata:2008:MTSI:qoereport\"\nxmlns=\"urn:3gpp:metadata:2008:MTSI:qoereport\"\nelementFormDefault=\"qualified\">\n<xs:element name=\"QoeReport\" type=\"QoeReportType\"/>\n\n<xs:complexType name=\"QoeReportType\">\n<xs:sequence>\n<xs:element name=\"statisticalReport\" type=\"starType\" minOccurs=\"0\"\nmaxOccurs=\"unbounded\"/>\n<xs:any namespace=\"##other\" processContents=\"skip\" minOccurs=\"0\"\nmaxOccurs=\"unbounded\"/>\n</xs:sequence>\n<xs:anyAttribute processContents=\"skip\"/>\n</xs:complexType>\n\n<xs:complexType name=\"starType\">\n<xs:sequence>\n<xs:element name=\"mediaLevelQoeMetrics\" type=\"mediaLevelQoeMetricsType\" minOccurs=\"1\"\nmaxOccurs=\"unbounded\"/>\n</xs:sequence>\n<xs:attribute name=\"startTime\" type=\"xs:unsignedLong\" use=\"required\"/>\n<xs:attribute name=\"stopTime\" type=\"xs:unsignedLong\" use=\"required\"/>\n<xs:attribute name=\"callId\" type=\"xs:string\" use=\"required\"/>\n<xs:attribute name=\"clientId\" type=\"xs:string\" use=\"required\"/>\n<xs:attribute name=\"qoeReferenceId\" type=\"xs:hexBinary\" use=\"optional\"/>\n<xs:attribute name=\"recordingSessionId\" type=\"xs:hexBinary\" use=\"optional\"/>\n<xs:attribute name=\"dnn\" type=\"xs:string\" use=\"optional\"/>\n<xs:attribute name=\"snssai\" type=\"xs:unsignedLong\" use=”optional\"/>\n<xs:anyAttribute processContents=\"skip\"/>\n</xs:complexType>\n\n<xs:complexType name=\"mediaLevelQoeMetricsType\">\n<xs:sequence>\n<xs:any namespace=\"##other\" processContents=\"skip\" minOccurs=\"0\"\nmaxOccurs=\"unbounded\"/>\n</xs:sequence>\n<xs:attribute name=\"mediaId\" type=\"xs:integer\" use=\"required\"/>\n<xs:attribute name=\"totalCorruptionDuration\" type=\"unsignedLongVectorType\"\n       \tuse=\"optional\"/>\n<xs:attribute name=\"numberOfCorruptionEvents\" type=\"unsignedLongVectorType\"\n       \tuse=\"optional\"/>\n<xs:attribute name=\"corruptionAlternative\" type=\"xs:string\" use=\"optional\"/>\n<xs:attribute name=\"totalNumberofSuccessivePacketLoss\" type=\"unsignedLongVectorType\"\nuse=\"optional\"/>\n<xs:attribute name=\"numberOfSuccessiveLossEvents\" type=\"unsignedLongVectorType\" \n       \tuse=\"optional\"/>\n<xs:attribute name=\"numberOfReceivedPackets\" type=\"unsignedLongVectorType\" \n       \tuse=\"optional\"/>\n<xs:attribute name=\"framerate\" type=\"doubleVectorType\" use=\"optional\"/>\n<xs:attribute name=\"totalJitterDuration\" type=\"doubleVectorType\" use=\"optional\"/>\n<xs:attribute name=\"numberOfJitterEvents\" type=\"unsignedLongVectorType\"\nuse=\"optional\"/>\n<xs:attribute name=\"totalSyncLossDuration\" type=\"doubleVectorType\" use=\"optional\"/>\n<xs:attribute name=\"numberOfSyncLossEvents\" type=\"unsignedLongVectorType\"\nuse=\"optional\"/>\n<xs:attribute name=\"networkRTT\" type=\"unsignedLongVectorType\" use=\"optional\"/>\n<xs:attribute name=\"internalRTT\" type=\"unsignedLongVectorType\" use=\"optional\"/>\n<xs:attribute name=\"codecInfo\" type=\"stringVectorType\" use=\"optional\"/>\n<xs:attribute name=\"codecProfileLevel\" type=\"stringVectorType\" use=\"optional\"/>\n<xs:attribute name=\"codecImageSize\" type=\"stringVectorType\" use=\"optional\"/>\n<xs:attribute name=\"averageCodecBitrate\" type=\"doubleVectorType\" use=\"optional\"/>\n<xs:attribute name=\"callSetupTime\" type=\"xs:unsignedLong\" use=\"optional\"/>\n\n<xs:anyAttribute processContents=\"skip\"/>\n</xs:complexType>\n\n<xs:simpleType name=\"doubleVectorType\">\n<xs:list itemType=\"xs:double\"/>\n</xs:simpleType>\n\n<xs:simpleType name=\"stringVectorType\">\n<xs:list itemType=\"xs:string\"/>\n</xs:simpleType>\n\n<xs:simpleType name=\"unsignedLongVectorType\">\n<xs:list itemType=\"xs:unsignedLong\"/>\n</xs:simpleType>\n</xs:schema>\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.4.2\tExample XML for QoE report message",
                            "text_content": "Below is one example of QoE report message, in this example the measurement interval is 20 seconds, the reporting interval is 5 minutes, but the call ends after 55 seconds.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<QoeReport xmlns=\"urn:3gpp:metadata:2008:MTSI:qoereport\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:schemaLocation=\"urn:3gpp:metadata:2008:MTSI:qoereport qoereport.xsd\">\n<statisticalReport\nstartTime=\"1219322514\"\nstopTime=\"1219322569\"\nclientId=\"clientID\"\ncallId=\"callID\">\nqoeReferenceId=\"240F512A\"\nsnssai=\"01000FFF\"\ndnn=\"internet.mnc015.mcc234.gprs\"\nrecordingSessionId=\"0001\"\n<mediaLevelQoeMetrics\nmediaId=\"1234\"\ntotalCorruptionDuration=\"480 0 120\"\nnumberOfCorruptionEvents=\"5 0 2\"\ncorruptionAlternative=\"a\"\ntotalNumberofSuccessivePacketLoss=\"24 0 6\"\nnumberOfSuccessiveLossEvents=\"5 0 2\"\nnumberOfReceivedPackets=\"535 645 300\"\nframerate=\"50.0 49.2 50.0\"\nnumberOfJitterEvents=\"0 1 0\"\ntotalJitterDuration=\"0 0.346 0\"\nnetworkRTT=\"120 132 125\"\ninternalRTT=\"20 24 20\"\ncodecInfo=\"AMR-WB/16000/1 = =\"\naverageCodecBitRate=\"12.4 12.65 12.7\"/>\ncallSetupTime=\"345\"\n<mediaLevelQoeMetrics\nmediaId=\"1236\"\ntotalCorruptionDuration=\"83 0 0\"\nnumberOfCorruptionEvents=\"1 0 0\"\ncorruptionAlternative=\"b\"\ntotalNumberofSuccessivePacketLoss=\"3 0 0\"\nnumberOfSuccessiveLossEvents=\"2 0 0\"\nnumberOfReceivedPackets=\"297 300 225\"\nframerate=\"14.7 15.0 14.9\"\nnumberOfJitterEvents=\"0 0 0\"\ntotalJitterDuration=\"0 0 0\"\nnumberOfSyncLossEvents=\"0 1 0\"\ntotalSyncLossDuration=\"0 0.789 0\"\nnetworkRTT=\"220 232 215\"\ninternalRTT=\"27 20 25\"\ncodecInfo=\"H263-2000/90000 = =\"\ncodecProfileLevel=\"profile=0;level=45 = =\"\ncodecImageSize=\"176x144 = =\"\naverageCodecBitRate=\"124.5 128.0 115.1\"/>\ncallSetupTime=\"345\"/>\n</statisticalReport>\n</QoeReport>\n\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "16.5\tQoE Measurement Collection Functionalities",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "16.5.1\tConfiguration and reporting",
                            "text_content": "As an alternative to configuration via OMA-DM, the QoE configuration can optionally be specified by the QoE Measurement Collection (QMC) functionality. In this case the QoE configuration is received via specific RRC [158] messages for UMTS, RRC [160] messages for LTE, and RRC [163] messages for NR over the control plane, and the QoE reporting is also sent back via RRC messages over the control plane.\nIf QMC is supported, the UE shall support the following QMC functionalities:\n-\tQoE Configuration: The QoE configuration will be delivered via RRC to the UE as a container according to \"Application Layer Measurement Configuration\" (see [158]) for UMTS,  \"measConfigAppLayer\" (see [160]) for LTE and “AppLayerMeasConfig” for NR (see [163]). The container is an octet string with gzip-encoded data (see [71]) stored in network byte order. The maximum size of the container is 1000 bytes for UMTS (see [158]) and LTE  (see [160]), and 8000 bytes for NR (see [163]). When the container is uncompressed it is expected to conform to XML-formatted QoE configuration data according to clause 16.5.2 in the current specification. This uncompressed QoE Configuration shall be delivered to the MTSI client. The interface towards the RRC signalling is handled by the AT command +CAPPLEVMC for UMTS and LTE, and the AT command +CAPPLEVMCNR for NR [161].\n-\tQoE Metrics: QoE Metrics from the MTSI client shall be XML-formatted according to clause 16.4 in the current specification. The XML data shall be compressed with gzip (see [71]) and stored in network byte order into an octet string container. The maximum size is 8000 bytes for UMTS (see [158]) and LTE (see [160]). For NR (see [163]), the maximum size is 8000 bytes if RRC segmentation is not enabled, and 144000 bytes if enabled. The container shall be delivered via RRC to the RNC according to \"Application Layer Measurement Reporting\" (see [158]) for UMTS, to the eNB according to \"measReportAppLayer\" (see [160]) for LTE, and to the gNB according to “MeasurementReportAppLayer” for NR (see [163]). The behaviour if the compressed data is larger than the maximum container size is unspecified in this version of the specification. The interface towards the RRC signalling is handled by the AT command +CAPPLEVMR for UMTS and LTE, and the AT command +CAPPLEVMRNR for NR [161].\n-\tThe UE shall also set the QMC capability \"QoE Measurement Collection for MTSI services\" (see [158]) to TRUE for UMTS, include the QMC capability \"qoe-mtsi-MeasReport\" (see [160]) for LTE, and include the QMC capability “qoe-MTSI-MeasReport” (see [163]) for NR.\n-\tWhen a new session is started, the QoE reporting AT command +CAPPLEVMRNR [161] shall be used to send a Recording Session Indication. Such an indication does not contain any QoE report, but indicates that QoE recording has started for a session.\n-\tWhen the QoE configuration is to be released, an unsolicited result code associated with the AT command +CAPPLEVMC or AT command +CAPPLEVMCNR [161] and containing the parameter <start-stop_reporting> or <start-stop_measurement> set to \"1\", shall be sent to the MTSI client as notification of a discard request. Then the MTSI client shall stop collecting quality metrics and discard any already collected information [178].\nThe exact implementation is not specified here, but example signalling diagrams for UMTS, LTE and NR below show the QMC functionality with a hypothetical \"QMC Handler\" entity.\nFigure 16.5.1-1: Example signalling diagram for UMTS\n\n\nFigure 16.5.1-2 presents an example signalling diagram for Long Term Evolution (LTE) technology, illustrating the process of data transmission between a mobile device and a base station. The diagram showcases the various stages of signal processing, including modulation, channel coding, and demodulation, which are essential for maintaining high-speed and reliable communication. The figure also highlights the role of the Evolved Packet Core (EPC) in managing network resources and ensuring efficient data flow. The visual representation of the signalling process provides a clear understanding of how LTE technology enables seamless connectivity and supports advanced mobile services.\nFigure 16.5.1-2: Example signalling diagram for LTE\nFigure 16.5.1-3 illustrates an example signalling diagram for NR, showcasing the various stages of radio access network (RAN) signalling. The diagram begins with the eNB (evolved Node B) receiving a downlink control channel (DL-SCH) from the gNB (Gateway Node B). The eNB then processes the DL-SCH, sending a downlink physical random access procedure (DL-PRACH) to the UE (User Equipment). The UE responds with a downlink physical random access grant (DL-PRACH), which is acknowledged by the eNB. This signalling process is crucial for establishing a reliable connection between the eNB and the UE, enabling seamless communication and data transmission.\nFigure 16.5.1-3: Example signalling diagram for NR\nNOTE:\tThe QMC Handler is only shown here as one possible implementation, and it need not be implemented as such. The corresponding QMC functionality could be built into the MTSI client or into other UE entities. In this version of the specification the detailed implementation of the above functionalities is left to the UE vendor.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "16.5.2\tXML configuration",
                            "text_content": "When QoE reporting is configured via the QMC functionality, the configuration basically contains the same information as in the QoE metrics reporting managed object (see clause 16.3.1), but encapsulated according to the XML scheme below. Note that the managed object leaves \"Servers\", \"APN\" and \"Format\" are not needed for the QMC functionality, and thus not included.\nNote that if geographical filtering is handled on the network side (i.e. QoE reporting is turned on/off  by the network depending on the UE location), no LocationFilter should be specified in the QoE Configuration, as this would mean two consecutive filterings.\nAlso note that the optional attribute qoeReferenceId is a reference set by the network side (see [178]), which is not directly used by the client. However, if this attribute is defined, it shall be copied into each QoE report, to facilitate network-side correlation.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<xs:schema targetNamespace=\"urn:3gpp:metadata:2017:MTSI:qoeconfig\"\nelementFormDefault=\"qualified\"\nxmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\nxmlns:sv=\"urn:3gpp:metadata:2017:MTSI:schemaVersion\"\nxmlns=\"urn:3gpp:metadata:2017:MTSI:qoeconfig\">\n\n<xs:element name=\"MTSIQualityReporting\" type=\"QualityReportingType\"/>\n\n<xs:complexType name=\"QualityReportingType\">\n<xs:sequence>\n<xs:element name=\"LocationFilter\" type=\"LocationFilterType\" minOccurs=\"0\"/>\n<xs:any namespace=\"##other\" processContents=\"lax\" minOccurs=\"0\" maxOccurs=\"unbounded\"/>\n</xs:sequence>\n<xs:attribute name=\"enabled\" type=\"xs:boolean\" use=\"required\"/>\n<xs:attribute name=\"rules\" type=\"xs:string\" use=\"optional\"/>\n<xs:attribute name=\"speechMetrics\" type=\"xs:string\" use=\"optional\"/>\n<xs:attribute name=\"videoMetrics\" type=\"xs:string\" use=\"optional\"/>\n<xs:attribute name=\"textMetrics\" type=\"xs:string\" use=\"optional\"/>\n<xs:attribute name=\"qoeReferenceId\" type=\"xs:hexBinary\" use=\"optional\"/>\n<xs:attribute name=\"sliceScope\" type=\"UnsignedIntVectorType\" use=\"optional\"/>\n<xs:anyAttribute namespace=\"##other\" processContents=\"lax\"/>\n</xs:complexType>\n\n<xs:complexType name=\"LocationFilterType\">\n<xs:sequence>\n<xs:element name=\"cellID\" type=\"xs:unsignedLong\" minOccurs=\"0\" maxOccurs=\"unbounded\"/>\n<xs:element name=\"shape\" type=\"ShapeType\" minOccurs=\"0\"/>\n<xs:any namespace=\"##other\" processContents=\"lax\" minOccurs=\"0\" maxOccurs=\"unbounded\"/>\n</xs:sequence>\n<xs:anyAttribute namespace=\"##other\" processContents=\"lax\"/>\n</xs:complexType>\n\n<xs:complexType name=\"ShapeType\">\n<xs:sequence>\n<xs:element name=\"PolygonList\" type=\"PolygonListType\" minOccurs=\"0\"/>\n<xs:element name=\"CircularAreaList\" type=\"CircularAreaListType\" minOccurs=\"0\"/>\n<xs:any namespace=\"##other\" processContents=\"lax\" minOccurs=\"0\" maxOccurs=\"unbounded\"/>\n</xs:sequence>\n<xs:anyAttribute namespace=\"##other\" processContents=\"lax\"/>\n</xs:complexType>\n\n<xs:complexType name=\"PolygonListType\">\n<xs:annotation>\n<xs:documentation> see [OMA MLP] </xs:documentation>\n</xs:annotation>\n<xs:sequence>\n<xs:element name=\"Polygon\" minOccurs=\"0\" maxOccurs=\"unbounded\"/>\n<xs:any namespace=\"##other\" processContents=\"lax\" minOccurs=\"0\" maxOccurs=\"unbounded\"/>\n</xs:sequence>\n<xs:attribute name=\"ConfLevel\" type=\"xs:unsignedInt\" use=\"optional\"/>\n<xs:anyAttribute namespace=\"##other\" processContents=\"lax\"/>\n</xs:complexType>\n\n<xs:complexType name=\"CircularAreaListType\">\n<xs:annotation>\n<xs:documentation> see [OMA MLP] </xs:documentation>\n</xs:annotation>\n<xs:sequence>\n<xs:element name=\"CircularArea\" minOccurs=\"0\" maxOccurs=\"unbounded\"/>\n<xs:any namespace=\"##other\" processContents=\"lax\" minOccurs=\"0\" maxOccurs=\"unbounded\"/>\n</xs:sequence>\n<xs:attribute name=\"ConfLevel\" type=\"xs:unsignedInt\" use=\"optional\"/>\n<xs:anyAttribute namespace=\"##other\" processContents=\"lax\"/>\n</xs:complexType>\n<xs:simpleType name=\"UnsignedIntVectorType\">\n        <xs:list itemType=\"xs:unsignedInt\"/>\n    </xs:simpleType>\n</xs:schema>\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<xs:schema targetNamespace=\"urn:3gpp:metadata:2017:MTSI:schemaVersion\"\nxmlns=\"urn:3gpp:metadata:2017:MTSI:schemaVersion\"\n\nxmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\nelementFormDefault=\"qualified\">\n\n<xs:element name=\"schemaVersion\" type=\"xs:unsignedInt\"/>\n<xs:element name=\"delimiter\" type=\"xs:byte\"/>\n</xs:schema>\n\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "17\tManagement of Media Adaptation",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "17.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purpose of quality control or network management, it can be necessary to adjust the speech and video adaptation of the MTSI client in terminal. To effectively manage, i.e., initialize and update, the media adaptation of a large number of terminals, which can be implemented in different fashions, the 3GPP MTSIMA (MTSI Media Adaptation) MO defined in this clause may be used.\nThe MO, which exploits the information estimated or received from various entities such as ongoing multimedia packet stream, the far-end MTSI client in terminal, IMS, and network node such as eNodeB, provides two sets of parameters that can be used in the design of adaptation state machines for speech and video respectively. The parameters are contrived such that dependence on media codec or radio access bearer technology is avoided as much as possible, not to constrain the evolution of these elements. In addition, vendor specific parameters taking advantage of the implementation can be placed under Ext nodes.\nBy altering the parameters of the MO via OMA-DM protocol, media adaptation behavior of the MTSI client in terminal can be modified up to extent allowed by the implementation. Note that due to the underlying uncertainties and complexities, one should expect only to shape the expected bit rate trajectory of multimedia stream over time-varying transmission conditions, rather than to control the media flow in a timely and stringent manner. Detailed descriptions of the speech and video adaptation parameters can be found in table 17.1 and 17.2.\nThe Management Object Identifier shall be: urn:oma:mo:ext-3gpp-mtsima:1.0.\nProtocol compatibility: The MO is compatible with OMA Device Management protocol specifications, version 1.2 and upwards, and is defined using the OMA DM Device Description Framework as described in the Enabler Release Definition OMA-ERELD_DM-V1_2 [67].\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "17.2\tMedia adaptation management object",
                    "description": "",
                    "summary": "",
                    "text_content": "The following nodes and leaf objects in figure 17.1 shall be contained under the 3GPP_MTSIMA node if the MTSI client in terminal supports the feature described in this clause. Information of DDF for this MO is given in Annex J.\n\n\nFigure 17.1: MTSI media adaptation management object tree\nNode: /<X>\nThis interior node specifies the unique object id of a MTSI media adaptation management object. The purpose of this interior node is to group together the parameters of a single object.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\nThe following interior nodes shall be contained if the MTSI client in terminal supports the \"MTSI media adaptation management object\".\n/<X>/Speech\nThe Speech node is the starting point of parameters related to speech adaptation if any speech codec are available.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>\nThis interior node is used to allow a reference to a list of speech adaptation parameters.\n-\tOccurrence: OneOrMore\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ID\nThis leaf node represents the identification number of a set of parameters related to speech adaptation.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/TAG\nThis leaf node represents the identification tag of a set of parameters for speech adaptation. It is recommended to have at least a node, for example, ID, TAG, or implementation-specific ones, for the identification purpose such that each set of parameters can be distinguished and accessed.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/PLR\nThis interior node is used to allow a reference to a list of parameters related to packet loss rate (PLR).\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/PLR/MAX\nThis leaf node represents the maximum PLR tolerated when redundancy is not used, before the receiver signals the sender to attempt adaptation that reduces PLR or operate at modes more robust to packet loss.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Speech/<X>/PLR/LOW\nThis leaf node represents the minimum PLR tolerated, before the receiver signals the sender to probe for higher bit rate, increase the packet rate, reduce redundancy, or perform other procedures that could improve speech quality under such favorable conditions.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Speech/<X>/PLR/STATE_REVERSION\nThis leaf node represents the maximum PLR tolerated after adaptation state machine has taken actions, based on the measured PLR lower than LOW. Once PLR exceeds this threshold, the receiver decides that the actions taken to improve speech quality were not successful.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Speech/<X>/PLR/RED_INEFFECTIVE\nThis leaf node represents the maximum PLR tolerated, after adaptation state machine has taken actions to increase redundancy. Once PLR exceeds this threshold, the receiver decides that the situation was not improved but degraded.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Speech/<X>/PLR/DURATION_MAX\nThis leaf node represents the duration (ms) of sliding window over which PLR is observed and computed. The computed value is compared with the MAX threshold.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/PLR/DURATION_LOW\nThis leaf node represents the duration (ms) of sliding window over which PLR is observed and computed. The computed value is compared with the LOW threshold.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/PLR/DURATION_STATE_REVERSION\nThis leaf node represents the duration (ms) of sliding window over which PLR is observed and computed. The computed value is compared with the STATE_REVERSION threshold.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/PLR/DURATION_RED_INEFFECTIVE\nThis leaf node represents the duration (ms) of sliding window over which PLR is observed and computed. The computed value is compared with the RED_INEFFECTIVE threshold.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/PLR/DURATION\nThis leaf node represents the duration (ms) of sliding window over which PLR is observed and computed. The computed value is compared with the PLR thresholds.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/PLB\nThis interior node is used to allow a reference to a list of parameters related to an event, packet loss burst (PLB), in which a large number of packets are lost during a limited period.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/PLB/LOST_PACKET\nThis leaf node represents the number of packets lost during a period of PLB/DURATION.\n-\tOccurrence: One\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/PLB/DURATION\nThis leaf node represents the period (ms) for which LOST_PACKET is counted.\n-\tOccurrence: One\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ECN\nThis interior node is used to allow a reference to a list of parameters related to Explicit Congestion Notification (ECN) to IP.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ECN/USAGE\nThis leaf node represents a Boolean parameter that enables or disables ECN-based adaptation.\n-\tOccurrence: ZeroOrOne\n-\tFormat: bool\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ECN/MIN_RATE\nThis leaf node represents the minimum bit rate (bps, excluding IP, UDP, RTP and payload overhead) that speech encoder should use during ECN-based adaptation.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ECN/STEPWISE_DOWNSWITCH\nThis leaf node represents a Boolean parameter that selects which down-switch method to use, i.e., direct or step-wise, for ECN-triggered adaptation.\n-\tOccurrence: ZeroOrOne\n-\tFormat: bool\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ECN/RATE_LIST\nThis leaf node represents the list of bit rates to use during stepwise down-switch. This parameter is only applicable when stepwise down-switch is used.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ECN/INIT_WAIT\nThis leaf node represents the time (ms) that the sender should wait before an up-switch is attempted in the beginning of the session if no rate control information or reception quality feedback information is received.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ECN/INIT_UPSWITCH_WAIT\nThis leaf node represents the time (ms) that the sender should wait at each step during up-switch in the beginning of the session.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ECN/CONGESTION_WAIT\nThis leaf node represents the minimum interval (ms) between detection of ECN-CE and up-switch from the reduced rate.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ECN/CONGESTION_UPSWITCH_WAIT\nThis leaf node represents the waiting time (ms) at each step during up-switch after a congestion event, except for the initial up-switch which uses the ECN/CONGESTION_WAIT time.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ICM\nThis interior node is used to allow a reference to a list of parameters related to Initial Codec Mode (ICM).\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ICM/INITIAL_CODEC_RATE\nThis leaf node represents the bit rate (bps, excluding IP, UDP, RTP and payload overhead) that the speech encoder should use when starting the encoding in the beginning of the session.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ICM/INITIAL_CODEC_BANDWIDTH\nThis leaf node represents the audio bandwidth that the EVS speech encoder should use when starting the encoding in the beginning of the session, unless specified by bw, bw-send, or bw-recv parameter.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n-\tValues: nb, wb, swb, fb\n/<X>/Speech/<X>/ICM/INIT_WAIT\nThis leaf node represents the time (ms) that the sender should wait before an up-switch is attempted in the beginning of the session if no rate control information or reception quality feedback information is received.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ICM/INIT_UPSWITCH_WAIT\nThis leaf node represents the time (ms) that the sender should wait at each step during up-switch in the beginning of the session.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ ICM/INIT_PARTIAL_REDUNDANCY_OFFSET_SEND\nThis leaf node represents the initial partial redundancy offset (-1, 0, 2, 3, 5, or 7) that the EVS speech encoder should use when starting the encoding in the beginning of the session that uses channel aware mode, unless asked otherwise by the far-end MTSI client in terminal with the ch-aw-recv parameter .\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/ ICM/INIT_PARTIAL_REDUNDANCY_OFFSET_RECV\nThis leaf node represents the initial partial redundancy offset (-1, 0, 2, 3, 5, or 7) that the MTSI client in terminal should ask the far-end MTSI client in terminal with the ch-aw-recv parameter to use when starting the encoding in the beginning of the session that uses channel aware mode.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/MEDIA_ROBUSTNESS\nThis interior node is used to allow a reference to a list of parameters related to Media Robustness Adaptation that can be used for the CHEM feature.  Each unique codec type is identified by the CODEC_ID under a corresponding instance of the  MEDIA_ROBUSTNESS node which groups the parameters associated with the codec type/CODEC_ID.\n-\tOccurrence: ZeroOrMore\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/MEDIA_ROBUSTNESS/CODEC_ID\nThis leaf node represents the codec MIME type.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/MEDIA_ROBUSTNESS/TAG\nThis leaf node represents the identification tag of a set of parameters for speech robustness adaptation of a codec type identified by the CODEC_ID. It is recommended to have at least a node, for example, TAG, or implementation-specific ones, for the identification purpose such that each set of parameters can be distinguished and accessed.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/MEDIA_ROBUSTNESS/CFG_BIT_RATE_LIST\nThis interior node is used to provide a list of the bit rates of the configurations of the codec type (CODEC_ID) listed from the bit rate of the least robust configuration first to the bit rate of the most robust listed last.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/MEDIA_ROBUSTNESS/CFG_RED_LIST\nThis interior node is used to provide a list of the redundancy levels of the configurations of the codec type (CODEC_ID) listed from the redundancy level of the least robust configuration first to the redundancy level of the most robust listed last.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/MEDIA_ROBUSTNESS/HIGH_PLR_THRESH_LIST\nThis interior node is used to provide a list of the high PLR thresholds for each codec configuration except for the most robust configuration. A high PLR threshold for a given codec configuration is the highest tolerable PLR at that codec configuration before the MTSI client requests a more robust codec configuration that will yield lower PLR.\n\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/MEDIA_ROBUSTNESS/LOW_PLR_THRESH_LIST\nThis interior node is used to provide a list of the low PLR thresholds for each codec configuration except for the least robust configuration. A low PLR threshold for a given codec configuration is the lowest tolerable PLR at that codec configuration before the MTSI client requests a less robust codec configuration that will yield better quality.\n-\tOccurrence: One\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/MEDIA_ROBUSTNESS/DJB_PLR\nThis interior node indicates whether the estimated PLR is measured before or after de-jitter buffering.\n-\tOccurrence: One\n-\tFormat: boolean\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/MEDIA_ROBUSTNESS/PLR_AVG_WINDOW\nThis interior node indicates the duration of the sliding window used by the media receiver to estimate the received PLR.\n-\tOccurrence: One\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/N_INHIBIT\nThis leaf node represents the period (number of speech frames) for which adaptation is disabled to avoid the ping-pong effects, when adaptation state machine transitions from one state to another then back to the original state.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/N_HOLD\nThis leaf node represents the period (proportion of PLR/DURATION) that can substitute other periods such as DURATION_LOW or DURATION_RED_INEFFECTIVE, when they are not available.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/T_RESPONSE\nThis leaf node represents the expected response time (ms) for a request to be fulfilled. If a request transmitted to the far-end is not granted within a period of T_RESPONSE, the request can be considered lost during transmission or the far-end MTSI client in terminal might have decided not to grant it.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Speech/<X>/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video\nThe Video node is the starting point of parameters related to video adaptation if any video codec are available.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>\nThis interior node is used to allow a reference to a list of video adaptation parameters.\n-\tOccurrence: OneOrMore\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ID\nThis leaf node represents the identification number of a set of parameters related to video adaptation.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/TAG\nThis leaf node represents the identification tag of a set of parameters for video adaptation. It is recommended to have at least a node, for example, ID, TAG, or implementation-specific ones, for the identification purpose such that each set of parameters can be distinguished and accessed.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/PLR\nThis interior node is used to allow a reference to a list of parameters related to PLR.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/PLR/MAX\nThis leaf node represents the maximum PLR tolerated, before the receiver signals the sender to reduce the bit rate such that PLR is reduced.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Video/<X>/PLR/LOW\nThis leaf node represents the minimum PLR tolerated, before the receiver signals the sender to increase the bit rate.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Video/<X>/PLR/DURATION_MAX\nThis leaf node represents the duration (ms) of sliding window over which PLR is observed and computed. The computed value is compared with the MAX threshold.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/PLR/DURATION_LOW\nThis leaf node represents the duration (ms) of sliding window over which PLR is observed and computed. The computed value is compared with the LOW threshold.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/PLB\nThis interior node is used to allow a reference to a list of parameters related to PLB.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/PLB/LOST_PACKET\nThis leaf node represents the number of packets lost during a period of PLB/DURATION.\n-\tOccurrence: One\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/PLB/DURATION\nThis leaf node represents the period (ms) for which LOST_PACKET is counted.\n-\tOccurrence: One\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/MIN_QUALITY\nThis interior node is used to allow a reference to a list of parameters related to the minimum video quality.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/MIN_QUALITY/BIT_RATE\nThis interior node is used to allow a reference to a list of parameters related to the minimum bit rate.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/MIN_QUALITY/BIT_RATE/ABSOLUTE\nThis leaf node represents the minimum bit rate (kbps) that video encoder should use.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/MIN_QUALITY/BIT_RATE/RELATIVE\nThis leaf node represents the minimum bit rate (proportion of the bit rate negotiated for the video session) that video encoder should use.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Video/<X>/MIN_QUALITY/FRAME_RATE\nThis interior node is used to allow a reference to a list of parameters related to the minimum frame rate.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/MIN_QUALITY/FRAME_RATE/ABSOLUTE\nThis leaf node represents the minimum frame rate (fps, frames per second) that video encoder should use.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/MIN_QUALITY/FRAME_RATE/RELATIVE\nThis leaf node represents the minimum frame rate (proportion of the maximum frame rate limited by the codec profile/level negotiated for the video session) that video encoder should use.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Video/<X>/MIN_QUALITY/QP\nThis interior node is used to allow a reference to a list of parameters related to video quantisation.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/MIN_QUALITY/QP/H264\nThis leaf node represents the maximum value of luminance quantization parameter QPY that video encoder should use if H.264 is negotiated for the video session.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 51\n/<X>/Video/<X>/ECN\nThis interior node is used to allow a reference to a list of parameters related to Explicit Congestion Notification (ECN) to IP.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ECN/STEP_UP\nThis leaf node represents the proportion of current encoding rate estimated by video receiver, which is used to ask video sender to increase the rate by this value.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ECN/STEP_DOWN\nThis leaf node represents the decrease in the requested maximum encoding rate over current rate, when a down-switch is requested by the receiver.\n-\tOccurrence: ZeroOrOne\n-\tFormat: chr\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ECN/INIT_WAIT\nThis leaf node represents the minimum waiting time (ms) before up-switch is attempted in the initial phase of the session.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ECN/INIT_UPSWITCH_WAIT\nThis leaf node represents the waiting time (ms) at each step during up-switch in the beginning of the session.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ECN/CONGESTION_WAIT\nThis leaf node represents the minimum interval (ms) between detection of ECN-CE and up-switch from the reduced rate.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ECN/CONGESTION_UPSWITCH_WAIT\nThis leaf node represents the waiting time (ms) at each step during up-switch after a congestion event, except for the initial up-switch which uses the ECN/CONGESTION_WAIT time.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ECN/MIN_RATE\nThis interior node is used to allow a reference to a list of parameters related to the minimum bit rate during ECN-based adaptation.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ECN/MIN_RATE/ABSOLUTE\nThis leaf node represents the minimum bit rate (kbps, excluding IP, UDP, RTP and payload overhead) that video encoder should use during ECN-based adaptation.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/ECN/MIN_RATE/RELATIVE\nThis leaf node represents the minimum bit rate (proportion of the bit rate negotiated for the video session) that video encoder should use during ECN-based adaptation.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/RTP_GAP\nThis leaf node represents the maximum interval between packets (proportion of the estimated frame period) tolerated, before the receiver declares bursty packet loss or severe congestion condition.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n/<X>/Video/INC_FBACK_MIN_INTERVAL\nThis leaf node represents the minimum interval (ms) at which rate adaptation feedback such as TMMBR should be sent from the receiver to the sender, when the bit rate is being increased.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/DEC_FBACK_MIN_INTERVAL\nThis leaf node represents the minimum interval (ms) at which rate adaptation feedback such as TMMBR should be sent from the receiver to the sender, when the bit rate is being decreased.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/TP_DURATION_HI\nThis leaf node represents the duration (ms) of sliding window over which the interval between packet arrival and playout is observed. The computed value is compared with TARGET_PLAYOUT_MARGIN_HI.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/TP_DURATION_MIN\nThis leaf node represents the duration (ms) of sliding window over which the interval between packet arrival and playout is observed. The computed value is compared with TARGET_PLAYOUT_MARGIN_MIN.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/TARGET_PLAYOUT_MARGIN_HI\nThis leaf node represents the upper threshold of the interval (ms) between packet arrival and its properly scheduled playout.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/TARGET_PLAYOUT_MARGIN_MIN\nThis leaf node represents the lower threshold of the interval (ms) between packet arrival and its properly scheduled playout.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/RAMP_UP_RATE\nThis leaf node represents the rate (kbps/s) at which video encoder should increase its maximum bit rate from current value to the value indicated in the most recently received TMMBR message.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/RAMP_DOWN_RATE\nThis leaf node represents the rate (kbps/s) at which video encoder should decrease its maximum bit rate from current value to the value indicated in the most recently received TMMBR message.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/DECONGEST_TIME\nThis leaf node represents the time (ms) the receiver should command the sender to spend in decongesting the transmission path, before attempting to transmit at the sustainable rate of the path.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n/<X>/Video/<X>/HOLD_DROP_END\nThis leaf node represents a tri-valued parameter that controls how the sender should behave in case video quality cannot meet the requirements set in BIT_RATE, FRAME_RATE, or QP.\n-\tOccurrence: ZeroOrOne\n-\tFormat: int\n-\tMinimum Access Types: Get\n-\tValues: 0, 1, 2\n/<X>/Video/<X>/INITIAL_CODEC_RATE\nThis leaf node represents the initial bit rate (proportion of the bit rate negotiated for the video session) that the sender should begin encoding video at.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Video/<X>/X_PERCENTILE\nThis leaf node represents the percentile point of packet arrival distribution used with the TARGET_PLAYOUT_MARGIN parameters.\n-\tOccurrence: ZeroOrOne\n-\tFormat: float\n-\tMinimum Access Types: Get\n-\tValues: 0 ~ 100 %\n/<X>/Video/<X>/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\n/<X>/Ext\nThe Ext is an interior node where the vendor specific information can be placed (vendor meaning application vendor, device vendor etc.). Usually the vendor extension is identified by vendor specific name under the ext node. The tree structure under the vendor identified is not defined and can therefore include one or more un-standardized sub-trees.\n-\tOccurrence: ZeroOrOne\n-\tFormat: node\n-\tMinimum Access Types: Get\nTable 17.1: Speech adaptation parameters of 3GPP MTSIMA MO\n\nTable 17.2: Video adaptation parameters of 3GPP MTSIMA MO\n\n",
                    "tables": [
                        {
                            "description": "Table 17.1: Speech adaptation parameters of 3GPP MTSIMA MO",
                            "table number": 38,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table 17.2: Video adaptation parameters of 3GPP MTSIMA MO",
                            "table number": 39,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "17.3\tManagement procedures",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause explains how speech and video adaptation of the MTSI client in terminal can be managed using 3GPP MTSIMA MO and OMA-DM protocol. First, it is necessary to describe the expected behavior of media adaptation, i.e., reaction of the MTSI client in terminal to the received RTCP-APP and TMMBR messages, information on the transmission results such as RTCP RR and SR, signalled changes in transport characteristics such as ECN Congestion Experienced (ECN-CE) marking in IP packet headers, and analysis of packet reception status. Such descriptions, which include many parameters of different nature, can be made in the form of adaptation state machines or state transition tables, as in Annex C, based on the criteria for service quality or the policy for network management.\nSome parameters in the descriptions can be determined in session setup or measured during session, and therefore do not require to be managed from outside. For example, the maximum or minimum bit rate of speech and video codecs, and round-trip time (RTT) belong to this class of parameters. It is also possible that other parameters are implementation-specific, or related to detailed features of media codec or underlying radio access bearer technology. These classes of parameters are not provided by 3GPP MTSIMA MO but still can be included under Ext nodes as vendor extensions.\nThe next step will be to select the parameters to be included in 3GPP MTSIMA MO. It might not be practical or necessary to update all parameters in the descriptions and selecting a subset of key parameters might simplify the management. The set of parameters selected should enable the behavior of media adaptation to be controlled up to the necessary extent.\nThe results of session setup may influence the selection of media adaptation methods to apply. For example, the negotiated media codec and the bandwidth, or whether to use ECN or not may determine the necessary adaptation procedures. Selection of session parameters from 3GPP MTSINP MO falls outside the scope of the present document. Information available to the MTSI client in terminal that may assist such decisions includes, but may not be limited to, the radio access bearer technology, information on service provider broadcast by (e)NodeB, date and time, and service policy.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "17.3.1\tManagement of speech adaptation",
                            "text_content": "3GPP MTSIMA MO contains a set of parameters which can be used in the construction of adaptation state machines. If available, information on the expected behavior of the network, such as the scheduling strategy applied to eNodeB, can assist the design and calibration process. Basically the receiver estimates the encoding and payload packetization status of the sender, and transmits appropriate RTCP-APP messages when the state of adaptation state machine needs to be switched.\nEach PLR in table 17.1 is used to specify the conditions, usually as a threshold, to enter or exit a state. MAX, LOW, STATE_REVERSION, and RED_INEFFECTIVE correspond to PLR_1, PLR_2, PLR_3, and PLR_4 in Annex C respectively. Once the measured PLR exceeds or falls below the thresholds, while meeting certain conditions, adaptation state machine triggers the programmed transitions. A subset of PLRs can be used to construct adaptation state machines with fewer states. For example, the two-state adaptation state machine in Annex C can be built with MAX and LOW. DURATION_MAX, DURATION_LOW, DURATION_STATE_REVERSION, and DURATION_RED_INEFFECTIVE can be used to specify the duration of sliding window over which MAX, LOW, STATE_REVERSION, and RED_INEFFECTIVE PLR are observed and computed. DURATION is reserved for the case when it is not necessary to separately specify the durations. N_HOLD allows setting of the duration as an integer multiple of DURATION.\nWith each pair of a PLR and a DURATION, the observation period of each PLR can be controlled and the sensitivity of each transition path can be tailored to meet the requirements. For example, larger DURATION values are likely to smooth out the impact of bursty loss of packets and reduce the likelihood of frequent transitions between states, i.e., the ping-pong effects, but can delay the reaction to events that require immediate repairing actions. In general, transitions to states designed for better transmission conditions need to be taken more conservately than transitions to states for worse transmission conditions. Other requirements can be combined with PLR to refine the conditions for transitions.\nPacket loss burst (PLB) refers to a davastating event in which a large number of packets are lost during a limited period. Immediate measures, such as changing the bit rate or payload packetization are required to reduce the impact on the perceived speech quality. As PLR and PLR/DURATION enable detailed specification of PLR, PLB can be described efficiently with PLB/LOST_PACKET and PLB/DURATION.\nThe parameters ICM/INITIAL_CODEC_RATE, ICM/INIT_WAIT and ICM/INIT_UPSWITCH_WAIT can be used to control the rate adaptation during the beginning of the session. ICM/INITIAL_CODEC_RATE is used to define what codec mode should be used when starting the encoding for the RTP stream. In EVS Primary mode, ICM/INITIAL_CODEC_BANDWIDTH is used to define which audio bandwidth should be used when starting the encoding for the RTP stream. ICM/INIT_WAIT defines the period over which the sending MTSI client in terminal should use the Initial Codec Mode when ECN is not used. If no codec mode request or other feedback information is received within this period then the sender is allowed to adapt to a higher rate. Since it is unknown in the beginning of the RTP stream whether the transmission path can support higher rates, the adaptation to higher bit rates needs to be conservative. It is therefore recommended that when adapting to a higher rate the sender increases the rate only to the next higher rate in the list of codec modes allowed in the session. It is also recommended that the sender waits for a while in-between consecutive up-switches, to give the receiver a chance to evaluate whether the new rate can be sustained. This waiting period in-between consecutive up-switches can be controlled with the ICM/INIT_UPSWITCH_WAIT parameter when ECN is not used. For the channel aware mode of EVS Primary, ICM/INIT_PARTIAL_REDUNDANCY_OFFSET_SEND and INIT_PARTIAL_REDUNDANCY_OFFSET_RECV can be used to configure the initial redundancy offset for the send and the receive directions respectively.\nWhen ECN is used in the session, the ECN/INIT_WAIT and ECN/INIT_UPSWITCH_WAIT parameters are used instead of the ICM/INIT_WAIT and ICM/INIT_UPSWITCH_WAIT parameters, respectively.\nN_INHIBIT can be used to limit the earliest time for the next transition, after transition is temporarily disabled due to frequent transitions among a limited number of states. Use of N_INHIBIT is suggested as a measure to avoid unnecessary transtions during rapid fluctuations of transmission conditions. It is left as the discretion of the implementation to handle RTCP-APP messages received before the sender is allowed to transition again.\nT_RESPONSE refers to the maximum period the receiver can tolerate, before declaring that either the transmitted RTCP-APP message was lost or its execution was denied by the sender. After the timer expires, the receiver may retransmit the request or transmit a new request, or choose to be satisfied with current status.\nAdaptation state machines using above parameters collect the information on transmission path by analysing the packet reception process. Another, more direct source of information can be provided by network nodes, such as eNodeB, in the form of Explicit Congestion Notification (ECN) to IP. A key benefit of ECN is more refined initiation of adaptation in which the receiver can be aware of incoming deterioration of transmission conditions even before any packets are dropped by network node, i.e., as an early-warning scheme for congestion.\nSTEPWISE_DOWNSWITCH can be used to control the path of bit-rate reduction, i.e., whether to directly down-switch to ECN/MIN_RATE or to gradually down-switch via several intermediate bit-rates specified in ECN/RATE_LIST. The former path may be preferred when rapid reduction of the bit-rate is required while the latter path may be employed for more graceful degradation of speech quality.\nTo avoid premature up-switch before the congestion has been cleared, waiting periods during which the sender is not allowed to increase the bit-rate can be defined with ECN/CONGESTION_WAIT parameter. The ECN/CONGESTION_UPSWITCH_WAIT parameter is used to prevent congestion from re-occurring during the upswitch after the ECN/CONGESTION_WAIT period.\nTo align speech adaptation of the MTSI client in terminal with the purpose of quality control or network management, not only the terminals, which might be managed by different service providers, but also the behaviour, such as scheduling strategy or ECN-marking policy, of network nodes should be considered in the construction of adaptation state machines. It is also possible to program the terminals to adapt differently, as a means of differentiating the quality of service.\nWith 3GPP MTSIMA MO, it is possible to shape a rough trajectory of the bit rate over time-varying transmission conditions but the maximum and minimum bit rates of speech codec are determined during session setup with mode-set, which can be managed with RateSet leaf of 3GPP MTSINP MO (see clause 15).\nAdaptation state machines designed to recover the once reduced bit or packet rate at an earliest opportunity might be considered as an adaptation policy oriented to service quality. However, such an aggressive up-switch before the transmission conditions fully recover takes the risk of degrading the quality or even backward transitions, i.e., the ping-pong effects. Such an optimistic adaptation strategy might not necessarily result in higher quality but can influence the service quality of other terminals sharing the same link. On the other hand, adaptation state machines that increase the once reduced bit or packet rate more conservatively are likely to avoid such situations but might be late in the recovery of speech quality after the transmission conditions are restored.\nEven at similar total bit rates, bit stream consisting of a smaller number of larger packets can be at a disadvantage during transmission over packet networks or shared links, when the link quality deteriorates or the link becomes congested, than bit stream consisting of a larger number of smaller packets, since many types of schedulers installed in the network nodes base their decisions on the size of packets such that lower priorities are assigned to larger packets. RTCP_APP_REQ_RED, RTCP_APP_REQ_AGG, and RTCP_APP_CMR specify detailed request for the bit rate and packetization. Bit-fields of RTCP_APP_REQ_RED and RTCP_APP_REQ_AGG are restricted by parameters, such as max-red and maxptime, which are negotiated during session setup.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "17.3.2\tManagement of video adaptation",
                            "text_content": "Compared with speech adaptation where the number of allowed bit rates from speech encoder is limited and each encoded speech frame covers the same short period, e.g., 20 ms, or contains the same number of bits when voice activity is present, video adaptation should tolerate a higher level of uncertainty in the control of the bit rate. Moreover, due to the structural dependence between encoded video frames, from motion estimation and compensation, packetization is not likely to be used as an opportunity for adaptation. This dependence necessitates not only controling the bit rate but also putting an end to error propagation with AVPF NACK or PLI.\nOutput bit rate from video encoder depends also on the scene being encoded and even if maintaining a constant bit rate is intended, actual output bit rate is likely to fluctuate around a target value. In the design of adaptation state machines for video, this uncertainty needs to be compensated for, for example, with additional implementation margin.\nEncoded speech frames have a clear boundary in the bit stream and multiple speech frames can be transported over an RTP packet. In contrast, an encoded video frame, whose size depends on the bit rate, frame rate, and image size, is typically far larger than an encoded speech frame. Multiple packets are usually necessary to transport even a predicted frame, which is usually smaller than an intra frame.\nAs in speech adaptation, basic information on transmission path can be obtained from analyzing received packet stream. However, perceived video quality can be more sensitive to PLR since the compression ratio of video is typically higher than that of speech and even a minor level of packet loss can initiate error propagation to the following predicted frames, rendering them unrecognizable. For example, at comparable PLR values, speech quality can be acceptable but video quality can be significantly damaged such that dropping the media might be considered. Two parameters for PLR, MAX and LOW, and two additional parameters for their durations, DURATION_MAX and DURATION_LOW, are available for video adaptation.\nPLB/LOST_PACKET and PLB/DURATION are also available for video but the fundamental differences in the frame structure need to be taken into account when the event of packet loss burst is defined for video.\nINC_FBACK_MIN_INTERVAL and DEC_FBACK_MIN_INTERVAL can be used to control the rate of adaptation and also the amount of signalling overhead. These two minimum intervals are provided separately since the minimum interval between the feedback messages to decrease the bit rate typically needs to be shorter than the one to increase the bit rate. The urgency of rate-decreasing conditions generally requires shorter minimum feedback intervals.\nTarget bit rate for video is determined during session setup and can be considered as the maximum bit rate to be used during session, which can be configured with the Bandwidth leaf of 3GPP MTSINP MO. On the other hand, BIT_RATE can be used to set a lower threshold for the bit rate. Whether MIN_QUALITY/BIT_RATE/ABSOLUTE or MIN_QUALITY/BIT_RATE/RELATIVE is to be used is left as the discretion of the implementation or service provider. For example, capability of setting a fixed minimum bit rate can be necessary when the lowest quality of MTSI is required to be comparable to the quality of 3G-324M, whose bit rate for video is in general set to 47 ~ 49 kbps. If both MIN_QUALITY/BIT_RATE/ABSOLUTE and MIN_QUALITY/BIT_RATE/RELATIVE are set, the larger of these two shall be used as the minimum bit rate.\nIn the case of speech adaptation, the MTSI client in terminal limits the initial codec mode (ICM) to a lower mode than the maximum mode negotiated, until at least one frame block or an RTCP message is received with rate control information (see clause 7.5). This policy is recommended to avoid congestion during initial phase of session when the information on transmission path is known to neither the sender nor the receiver. INITIAL_CODEC_RATE can be used for video with similar objectives as that of ICM, i.e., a warming-up process in the beginning of session. Once the session starts and few packets are lost during delivery, the receiver will attempt to increase the bit rate by transmitting TMMBR messages requesting higher bit rates until the negotiated value is reached. However, low INITIAL_CODEC_RATE can reduce the video quality at session setup when the transmission path is free of congestion.\nThe maximum bit rate allowed for video communication in a session depends on the outcome of the SDP offer-answer negotiation. For inter-working with 3G-324M it is likely that the bit rate is limited to 47 ~ 49 kbps while for high-quality video communication it is foreseen that bit rates in the order of several hundred kbps might be used. This can be challenging when setting the ECN/MIN_RATE parameter since the configuration of the MTSI client in terminal parameters occurs rarely while the maximum allowed bit rate used for video may vary from session to session.\nTwo parameters, ECN/MIN_RATE/ABSOLUTE and ECN/MIN_RATE/RELATIVE, are therefore provided to enable better control of the video rate adaptation algorithm. The ECN/MIN_RATE/RELATIVE parameter is provided to limit the bit range variations during a session to avoid large quality variations. The ECN/MIN_RATE/ABSOLUTE parameter is provided to avoid reducing the bit rate to an unacceptably low quality level.\nFRAME_RATE can be used to set a lower threshold for the frame rate. As the bit rate is controlled during adaptation between two limits, the frame rate also needs to be controlled between the limits while maintaining a balance between spatial quality and temporal resolution (see clause 10.3). As the increase in codec profile/level can result in an abrupt increase of the maximum image size, e.g., from QCIF to CIF, so can quadruple the maximum frame rate, with a fixed image size. With \"imageattr\" attribute, it is possible that image sizes whose maximum frame rates are unspecified by codec profile/level, such as 272x224, can be negotiated (see clause A.4). In this case, the maximum frame rate is determined as the maximum value at the maximum image size supported by the profile/level negotiated. Whether MIN_QUALITY/FRAME_RATE/ABSOLUTE or MIN_QUALITY/FRAME_RATE/RELATIVE is used to specify the lower threshold of the frame rate is left as the discretion of the implementation or service provider. If both are set, the larger of these two shall be used as the minimum frame rate.\nRTP_GAP can be used to set the maximum interval between received packets before the receiver considers repairing actions. During periods of severe congestion or packet loss, the receiver may not receive packets for an unexpectedly long period. Observing such gaps in the reception of packets can be used by the receiver to request the sender to decrease the bit or packet rate. In the case of severe packet loss, this gap can be detected before any other observations are made and thus allows for faster reaction, while detection of packet loss requires reception of at least one packet after the loss.\nHowever, estimating such gaps in the arrival of packets can be challenging because video encoder may not always output packets at regular intervals and typical scheduling strategy of network node, especially in the downlink, can cause jitter in the delivery of video packets. Therefore, it is recommended that RTP_GAP is set conservatively and the measured gap is based on a moving average estimate of the frame period observed by the receiver. The timestamps of the received packets allow the receiver to estimate the frame period based on the past a few received video frames. Since typical video encoders are not likely to abruptly change their encoding frame rates, this estimate can serve as a fairly reliable basis for detecting the gaps in the transport of video packets.\nLeaf nodes for luminance quantization parameter, H263, MPEG4, and H264, can be used to set a lower threshold for the image clarity to be maintained. Target range of the quantization parameters depends on the video codec negotiated.\nIf the MTSI client in terminal cannot maintain the bit rate or the frame rate higher than the lower thresholds, or cannot maintain the quantization parameter lower than the higher threshold, the video stream might be put on hold, dropped, or the session might be ended, depending on the criteria for service quality or policy for network management, with HOLD_DROP_END.\nRAMP_UP_RATE and RAMP_DOWN_RATE can be used to control how fast the sender changes its target bit rate from its current target value to the value indicated in the most recently received TMMBR message, when the bit rate is being increased and decreased respectively. As with INC_FBACK_MIN_INTERVAL and DEC_FBACK_MIN_INTERVAL, rates for ramping up and down need to be different, as rapid ramping down is usually necessary whereas rapid ramping up is undesirable as it can cause sudden congestion in the transmission path.\nDECONGEST_TIME can be used to control the time spent in resolving the congestion of transmission path. Smaller values of this parameter can result in faster reduction of the bit rate while larger values can be used for slower decongestion. If the situation at the receiver does not improve at the end of initial decongesting, another round of decongestion can be attempted, or the video stream can be dropped or put on hold.\nFrom received packets, video frames are typically reconstructed to YUV format, converted to formats such as RGB, and stored in the frame buffer, before being fed to the display for visual presentation. TARGET_PLAYOUT_MARGIN_HI and TARGET_PLAYOUT_MARGIN_MIN can be used to maintain appropriate playout margin, defined as the interval between packet arrival and its properly scheduled playout. Duration of sliding window over which the interval is observed and computed can be controlled with TP_DURATION_HI and TP_DURATION_MIN.\nIn general, video should be encoded, packetized, transmitted, de-packetized, decoded, and, played out within a total delay target. In addition, processing of video should be appropriately synchronized to that of speech. If the estimated playout margin exceeds TARGET_PLAYOUT_MARGIN_HI, it is considered that video packets are arriving too early and there remains room for higher bit rate in the transmission path. Therefore the receiver may signal the sender to increase the bit rate with TMMBR messages. If the estimated playout margin falls below TARGET_PLAYOUT_MARGIN_MIN, it is considered that video packets are arriving too late and current transmission path cannot sustain the bit rate. Therefore the receiver should signal the sender to reduce the bit rate to enable earlier arrival of video packets.\nX_PERCENTILE can be used to control the target playout margin but the packet arrival distribution is left to the discretion of the implementation, which might be implemented as statistical models or empirical data.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "17.4\tManagement of media robustness adaptation",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "17.4.1\tGeneral",
                            "text_content": "The MEDIA_ROBUSTNESS node defined under the 3GPP MTSIMA MO may be used to manage media robustness adaptation across different vendor terminals in a network.  For each codec type, the MO node provides a list of codec configurations arranged from least robust to most robust.  For each of these configurations, with the exception the first and last, the MO node also provides two sets of PLR threshold levels (see Figure 17.2):\n-\tA set of high PLR thresholds that trigger the media receiver to request a more robust configuration from the media sender when the PLR is increasing in order to reduce the effects of the higher PLR on QoE, and\n-\tA set of low PLR thresholds that trigger the media receiver to request a less robust configuration from the media sender when the PLR is decreasing in order to take advantage of the improved media quality supported at the lower PLR.\nThe high PLR and low PLR thresholds between two codec configurations can be set independently to avoid ping-pong switching by introducing hysteresis. The least robust configuration does not have a low PLR threshold and the most robust configuration does not have a high PLR threshold.  The MO node does not describe the type of request message that shall be used for adapting the codec configuration as this is determined by the codec configuration being requested, i.e., in-band RTP CMR if requesting a speech codec mode change, RTCP-APP if it requesting speech application layer redundancy change, TMMBR for video.\nFigure 17.2 illustrates the relationship between the high and low PLR thresholds for media robustness adaptation, showcasing how these thresholds impact the overall system performance. The graph displays the adaptation curve, indicating the optimal threshold values that balance between minimizing packet loss rate (PLR) and maintaining system stability. Key visual elements include the x-axis representing the PLR threshold values and the y-axis representing the system performance metrics. The curve demonstrates how the system adapts to changes in the PLR threshold, highlighting the trade-off between packet loss and system robustness.\nFigure 17.2: High and Low PLR thresholds for media robustness adaptation\nThe MO node also provides a flag to indicate whether PLR measurements are to be made before or after the de-jitter buffer in the receiver.  Measuring before provides an estimate of the PLR over the transport link to the media receiver while measuring after provides a PLR estimate that is closer to the QoE after the media decoder.  The MO node also specifies the sliding averaging window over which PLR estimates are to be calculated.\nThe parameters are specified independent of the media codec or radio access bearer technology. In addition, vendor specific parameters of the implementation can be placed under Ext nodes.  Detailed descriptions of the speech robustness adaptation parameters can be found in table 17.1.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "18\tMTSI client in terminal using fixed access",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "18.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause 18 applies to an MTSI client in terminal using fixed access.\nThe functional components of an MTSI client in terminal using fixed access are the same as described in clause 4.2 except that another Layer 2 technology may be used instead of the 3GPP L2 data link.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "18.2\tMedia codecs",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "18.2.1\tGeneral",
                            "text_content": "Media codecs for speech and video are specified in TS 181 005 [98]. Additional requirements and recommendations are included below.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "18.2.2\tSpeech",
                            "text_content": "MTSI clients in terminal using fixed access supporting AMR, AMR-WB or EVS shall follow clause 5.2.1.\nAn MTSI client in terminal using fixed access supporting G.711 [77] shall support either A-law PCM or -law PCM and should support both.\nMTSI client in terminal using fixed access supporting G.722 shall use the mode operation 1 at 64 kbps as specified in ITU-T Recommendation G.722 [78] when G.722 is used. The bitstream ordering shall be in chronological order with Most Significant Bit (MSB) first.\nMTSI client in terminal using fixed access supporting EVRC, EVRC-B, and /or EVRC-WB shall follow 3GPP2 C.S0014-E v1.0 [99] when any of these codecs are used.\nEncoding of DTMF is described in Annex G.\nError concealment procedures shall be used to reduce the quality degradation of the reconstructed speech when one or more erroneous/lost speech or lost Silence Descriptor (SID) frames are received.\nFor G.722, it is recommended to use Appendix III or Appendix IV of ITU-T Recommendation G.722 [78].\nNOTE:\tAppendices III and IV meet the same quality requirements but with two different quality/complexity trade-offs:\n-\tAppendix III of ITU-T Recommendation G.722 [78] aims at maximizing the robustness at a price of additional complexity.\n-\tAppendix IV of ITU-T Recommendation G.722 [78] offers an optimized complexity/quality trade off with almost no additional complexity compared with G.722 normal decoding (+0.07 WMOPS).\nIf another error concealment procedure is used it shall have equivalent or better performance than Appendix III or Appendix IV.\nFor G.711, it is recommended to use Appendix I of ITU-T Recommendation G.711 [77]. If another error concealment procedure is used, it shall have equivalent or better performance than Appendix I of ITU-T Recommendation G.711.\nFor G.729, the error concealment procedure shall be used as specified in the Main Body of ITU-T Recommendation G.729 [100].\nFor G.729.1, the error concealment procedure shall be used as specified in the ITU-T Recommendation G.729.1 [101].\nAn MTSI client in terminal using fixed access supporting AMR, AMR-WB or EVS shall support source controlled rate operation in accordance with clause 5.2.1.\nFor an MTSI client in terminal using fixed access supporting other codecs than AMR, AMR-WB or EVS the following recommendations apply:\n-\tSource controlled rate operation for G.729 should be supported according to Annex B of ITU-T G.729 [100].\n-\tSource controlled rate operation for G.729.1 should be supported according to Annex C and Annex F of ITU-T G.729.1 [101]. Annex C specifies a discontinuous transmission (DTX) and comfort noise generation for G.729.1. Annex F specified the voice activity detector (VAD) to be used together with the DTX/CNG scheme of Annex C to provide the complete functionality of the discontinuous transmission system.\n-\tSource controlled rate operation for G.711 should be supported according to Appendix 2 of ITU-T G.711 [77].\n-\tNo source controlled rate operation has been standardized for G.722.\nNOTE 1:\tUse of source controlled rate operation is optional. Source controlled rate operation is known to degrade the speech quality, especially in noisy environments or with background music, and is not needed when both MTSI client in terminals are using fixed access and when the bandwidth is sufficient to ensure best possible voice quality.\nNOTE 2:\tApart from source controlled rate operation (VAD/DTX) specified in clause 4.19 of 3GPP2 C.S0014-E [99] and in 3GPP2 C.S0076 v1.0 [102], EVRC, EVRC-B, and EVRC-WB can dynamically vary the source coding bit-rate for active speech to achieve a targeted active speech average data rate as specified in 3GPP2 C.S0014-E.\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "18.2.3\tVideo",
                            "text_content": "MTSI clients in terminals using fixed access offering video communication shall support the video codecs as defined in clause 5.2.2.\nNOTE:\tThe video codecs recommended in TS 181 005 [98] are H.263 profile 0 and H.264 Baseline Profile without any constraint on the levels. For 3GPP MTSI clients in terminal using 3GPP access, only H.264 is specified in the present document but with a different profile: the Constrained Baseline Profile (CBP) for which the Level 1.2 is mandatory and Level 3.1 is recommended.\nThe Baseline Profile and the Constrained Baseline Profile are very close but not compatible. The Baseline Profile includes all features that are supported in the Constrained Baseline Profile but some limited features of the Baseline Profile are not supported in the Constrained Baseline Profile.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "18.2.4\tReal-time text",
                            "text_content": "An MTSI client in terminal using fixed access and offering real-time text shall support real-time text as defined in clause 5.2.3.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "18.3\tMedia configuration",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "18.3.1\tGeneral",
                            "text_content": "The general clause on media configuration (clause 6.1) applies to an MTSI client in terminal using fixed access.\nAn MTSI client in terminal using fixed access and supporting RTP/AVPF shall do RTP profile negotiation as defined in clause 6.2.1a.\nThe support for Explicit Congestion Notification (ECN) is optional for an MTSI client in terminal using fixed access. ECN may be used to perform rate adaptation for speech and video when at least one multi-rate or rate-adaptive codec is supported. If ECN is supported then this shall be done in accordance with the requirements and recommendations specified in clause 6 and in clause 7.3 for RTCP based adaptation.\nNOTE:\tIt is beneficial if the MTSI client in terminal using fixed access supports ECN, even if the fixed network is not expected to support or use ECN for RTP. This enables using ECN between fixed and mobile clients when the same codecs are supported end-to-end.\nAn MTSI client in terminal using fixed access and supporting ECN should negotiate ECN usage when the SDP offer includes at least one multi-rate or rate-adaptive codec, see clause 6.2.2 for speech and clause 6.2.3.2 for video. If only fixed-rate codecs are included in the SDP offer for a media type then ECN shall not be negotiated for that media type.\nAn MTSI client in terminal using fixed access and supporting ECN may accept using ECN when a multi-rate or rate-adaptive codec is accepted, see clause 6.2.2 for speech and clause 6.2.3.2 for video.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "18.3.2\tSession setup procedures",
                            "text_content": "The general clause on session set up procedures (clause 6.2.1) applies to the MTSI client in terminal using fixed access.\nIf an MTSI client in terminal using fixed access supports AVPF for a media type then it shall also support the complete SDPCapNeg framework, RFC 5939 [69], for that media type in order to negotiate the RTP profiles.\nIf an MTSI client in terminal using fixed access supports AMR and/or AMR-WB and/or EVS, then clause 6.2.2 applies for session set up.\nAn MTSI client in terminal using fixed access shall support RTP/AVP. When at least one multi-rate codec is supported (AMR, AMR-WB, EVS or G.729.1) then RTP/AVPF should be supported to allow for end-to-end rate adaptation.\nIf an MTSI client in terminal using fixed access supports AMR and/or AMR-WB, or EVS, then clause 6.2.2.2 applies for generating SDP offers for AMR-NB, AMR-WB and EVS.\nAn MTSI client in terminal using fixed access supporting both A-law PCM and -law PCM shall offer both variants when sending an SDP offer for G.711.\nWhen an MTSI client in terminal using fixed access supports EVRC-B or EVRC-WB, then clauses 14-18 of RFC 5188 [103] apply when generating SDP offers and answers for EVRC-B and EVRC-WB.\nIf an MTSI client in terminal using fixed access supports G.729.1 then it also supports G.729 and should offer both G.729.1 and G.729 when sending an SDP offer.\nAn MTSI client in terminal offering G.729 with source controlled rate operation shall use the parameter \"annexb\" according to RFC 4855 [107].\nThe following codec preference order applies for the SDP offer in the session negotiation:\n-\tIf AMR-WB is offered it shall be listed first in the codec list (in order of preference, the first codec being preferred).\n-\tIf both narrowband codecs and wideband codecs are offered, wideband codecs shall be listed first in the codec list.\nWhen sending the SDP answer, if a wide-band speech session is possible, then selection of narrow-band speech should be avoided whenever possible, unless another preference order is indicated in the SDP offer.\nSession setup for sessions including speech and DTMF events is described in Annex G.\nAn MTSI client in terminal using fixed access and supporting video shall support RTP/AVP and shall support RTP/AVPF.\nIf an MTSI client in terminal using fixed access supports video, then clause 6.2.3 applies for the video session set up.\nAn MTSI client in terminal using fixed access and offering text shall follow clause 6.2.4.\nThe general clause 6.2.5.1 related to the use of Application Specific (AS) bandwidth modifier applies also to the MTSI client in terminal using fixed access.\nIf an MTSI client in terminal using fixed access supports AMR and/or AMR-WB and/or EVS, then clause 6.2.5.2 applies for the bandwidth negotiation for these codecs.\nIf an MTSI client in terminal using fixed access supports video, then clause 6.2.5.3 applies for the bandwidth negotiation.\nWhen the SDP offer includes multiple codecs then the bandwidth indicated with b=AS shall be set based on the codec that requires the highest bandwidth.\nAn MTSI client in terminal using fixed access should include the ‘a=bw-info’ attribute (see clause 19) in the SDP offer for speech and video media types and should include the attribute for other media types, as described in clause 6.2.5.1. For AMR, AMR-WB or EVS, the setting of the bandwidth properties are defined in clause 6.2.5.2 and Annex K.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "18.3.3\tSession control procedures",
                            "text_content": "The clause 6.3 on session set up procedures applies also to an MTSI client in terminal that uses fixed access.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "18.4\tData transport",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "18.4.1\tGeneral",
                            "text_content": "The clauses data transport general (7.1) and RTCP usage (7.3.1) apply also to the MTSI client in terminal using fixed access.\nAn MTSI client in terminal using fixed access shall transport real-time media using RTP (RFC 3550 [9]) over UDP (RFC 0768 [39]). See clause 18.3.2.2, 18.3.2.3 and 18.3.2.4 for requirements on RTP/AVP and RTP/AVPF for speech, video and text, respectively.\nThe support of AVPF requires an MTSI client in terminal to implement the RTCP transmission rules, the signalling mechanism for SDP and the feedback messages explicitly mentioned in the present document.\nFor a given RTP based media stream, the MTSI client in terminal shall use the same port number for sending and receiving RTP packets. This facilitates interworking with fixed/broadband access. However, the MTSI client shall accept RTP packets that are not received from the same remote port where RTP packets are sent by the MTSI client.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "18.4.2\tPacketization",
                            "text_content": "For G.711 both 10 ms and 20 ms frame length shall be supported, and 20 ms frame length shall be used unless another packetization is negotiated. The terminal shall offer to receive 20 ms frame length packetization.\nFor G.722, 20 ms frame length shall be supported.\nThe default packetization time for the codecs used in the MTSI client in terminal using fixed access shall be 20 ms (1 non-redundant speech frame per RTP packet). The packetization could change as a result of adaptation by using frame aggregation when adapting to packet rate limited operating conditions, see also clause 18.7.\nPacketization time shall be indicated using the a=ptime SDP attribute.\nAn MTSI clients in terminal using fixed access shall support encapsulating up to 4 non-redundant speech frames into the RTP packets and 12 speech frames in total if redundancy is used (maxptime = 240).\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "18.4.3\tRTP payload format",
                            "text_content": "For each of the following codecs the payload formats are defined in:\n-\tFor AMR and/or AMR-WB, or EVS as specified in clause 7.4.2.\n-\tFor G.729.1 as specified in RFC 4749 [104], and as specified in RFC 5459 [105] when DTX is used.\n-\tFor EVRC and EVRC-B as specified in RFC 4788 [106].\n-\tFor EVRC-WB as specified in RFC 5188 [103].\n-\tFor DTMF events is described in Annex G.\nThe RTP payload types for G.711, G.729, G.722 shall be supported as specified in Section 6, Table 4 of RFC 3551 [10].\nThe following payload types should be used for G.711, G.729 and G.722:\nTable 18.4.3-1: Recommended payload type numbers\n\nFor other codecs, dynamic payload types shall be used.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 18.4.3-1: Recommended payload type numbers",
                                    "table number": 40,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "18.5\tJitter buffer management",
                    "description": "",
                    "summary": "",
                    "text_content": "An MTSI client in terminal using fixed access shall be able to handle delay jitter in order to minimize the speech quality degradation due to jitter (jitter induced frame losses) while limiting the additional end to end delay due to jitter buffering time.\nThe jitter buffer management (JBM) shall comply with the functional requirements defined in clause 8.2.2 and with the minimum performance requirements defined in clause 8.2.3.\nNOTE:\tThe delay and error profiles defined in clause 8.2.3.2.3 were derived for mobile access but they were selected to span the different jitter and packet loss conditions that may occur in different types of networks and in different combination of networks. For fixed-mobile interworking the jitter may be small and packet loss rate may be low in the fixed part of the path, but the jitter may be large and the packet loss rate may be fairly high in the mobile part of the path. This can give end-to-end jitter and packet loss characteristics that are similar to the characteristics found in these profiles. The JBM therefore needs to handle these profiles to support end-to-end fixed-mobile interworking.\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "18.6\tPacket-loss handling",
                    "description": "",
                    "summary": "",
                    "text_content": "An MTSI client in terminal using fixed access may use redundancy to handle operating conditions with high packet loss rates. When redundancy is supported then this shall be done in accordance with the requirements and recommendations defined in clause 9.\nWhen redundancy is used then the multi-rate or rate-adaptive capabilities of the codec should be used to avoid increasing the load in the network. Redundancy shall be used for fixed-rate codecs only when permitted by the allocated bandwidth.\nNOTE:\tIt is beneficial if the MTSI client in terminal using fixed access supports redundancy since this enables using such solutions end-to-end between fixed and mobile clients, at least when the same codecs are supported end-to-end.\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "18.7\tAdaptation",
                    "description": "",
                    "summary": "",
                    "text_content": "An MTSI client in terminal using fixed access supporting AMR and/or AMR-WB for speech or supporting video should support adaptation as described in clause 10 for speech and video, respectively.\nFrame aggregation and redundancy should be supported also for fixed-rate codecs.\nThe media bit rate adaptation for G.729.1 should use the same principles as described for AMR and AMR-WB in clause 10.2. For example, if G.729.1 is used at a bit rates up to 32 kbps, the adaptation may be configured to reduce the media bit-rate to 8 kbps when ECN-CE is detected.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "18.8\tFront-end handling",
                    "description": "",
                    "summary": "",
                    "text_content": "For terminals only supporting fixed access, performance requirements for terminal acoustics and test methods are specified in ETSI TS 103 737 [109], ETSI TS 103 738 [110], ETSI TS 103 739 [111], ETSI TS 103 740 [112], ETSI ES 202 737 [113], ETSI ES 202 738 [114], ETSI ES 202 739 [115], ETSI ES 202 740 [116] and for DECT terminals in ETSI specifications EN 300 175-8 [117] and EN 300 176-2 [118].\nOther terminals supporting fixed and 3GPP access shall meet or exceed the minimum performance requirements on the acoustic characteristics of 3G terminals specified in TS 26.131 [35] in order to harmonize the acoustic front-end.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "18.9\tSupplementary services",
                    "description": "",
                    "summary": "",
                    "text_content": "An MTSI client in terminal using fixed access shall support media handling for supplementary services as defined in clause 14, except that the codecs are defined in clause 18.2 and the data transport is defined in clause 18.4.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "19\tAdditional bandwidth information",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "19.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause describes additional bandwidth properties that can be used when the existing bandwidth modifiers (b=AS, etc) give insufficient information. The additional information can be used to, for example (but not limited to): align the resource allocation end-to-end; align the bearer setup in different networks; or to assist how the MTSI clients should adapt in case of degraded operating conditions. The bandwidth properties are defined in clause 19.2.\nA new SDP attribute ‘a=bw-info’ is defined in clause 19.3 and can be used to negotiate the additional bandwidth properties end-to-end. The SDP attribute allows for future extensions.\nThe IANA registration information on the new SDP attribute is provided in Annex M.6.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "19.2\tBandwidth properties",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "19.2.1\tGeneral description",
                            "text_content": "This clause defines in total seven bandwidth properties, which can be used both for sending and receiving direction. When the Maximum Supported Bandwidth property is defined for the receiving direction then this is semantically very similar to the b=AS parameter.\nFour bandwidth properties are defined to describe different transport bandwidths:\n-\tMaximum Supported Bandwidth\n-\tMaximum Desired Bandwidth\n-\tMinimum Desired Bandwidth\n-\tMinimum Supported Bandwidth\nThese bandwidth properties shall include the IP, UDP and RTP overhead.\nNOTE 1:\tCorresponding bandwidth parameters excluding IP, UDP and RTP overhead can be defined in the future but are not included here.\nSince the above bandwidth properties include the IP, UDP and RTP overhead, the following bandwidth properties are defined to assist the re-calculation of the above bandwidth properties, e.g. when a MGW does conversion between different IP versions and therefore need to re-calculate these values:\n-\tIP version\n-\tMaximum packet rate\n-\tMinimum packet rate\nDetailed descriptions for these bandwidth properties are given in the following sub-sections.\nThe motivations for defining these properties are:\n-\tThe best compromise between quality and network utilization is reached when the media uses bandwidths from the Minimum Desired Bandwidth up to the Maximum Desired Bandwidth, which is therefore the most preferred bandwidth range. The higher end of this range should preferably be used for most sessions. When bitrate adaptation is needed due to degraded operating conditions, it may require changing the bandwidth down towards the Minimum Desired Bandwidth.\n-\tBandwidths below the Minimum Desired Bandwidth, down to the Minimum Supported Bandwidth, may be used during poor operating conditions, although this should happen rarely. If the operating conditions are so poor that not even media using Minimum Supported Bandwidth can be maintained then the media may be stopped or the session may be closed.\n-\tBandwidths above the Maximum Desired Bandwidth, up to the Maximum Supported Bandwidth, can be used to provide room for redundancy so that the media may survive during very bad operating conditions and when bandwidth reduction alone is unable to provide sufficient quality. This range should be used rarely.\nNOTE 2:\tIncreasing the bandwidth during bad operating conditions is an exception. Normally, the end-points ought to reduce the bandwidth. However, there are cases when it is not possible to reduce the bandwidth. For example, when AMR 4.75 kbps is used then the encoding bitrate cannot be reduced any further. It is then possible to use frame aggregation to reduce the IP/UDP/RTP overhead. However, if the limitation is in the RAN, where ROHC is used, then this will have limited effect, possibly even no effect at all. In this case, the only remaining option to improve the probability that speech reaches the receiving end-point is to allow the end-points to use redundancy, even if this means using a higher bandwidth. Otherwise, it is likely that the session will be terminated prematurely. This specification therefore allows for using up to 300% redundancy, as described in clause 9.2.1.\nThis means that the following relationships apply:\n-\tMinimum Supported Bandwidth ≤ Minimum Desired Bandwidth\n-\tMinimum Desired Bandwidth ≤ Maximum Desired Bandwidth\n-\tMaximum Desired Bandwidth ≤ Maximum Supported Bandwidth\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.2.2\tMaximum Supported Bandwidth",
                            "text_content": "Definition:\nIdentifies the highest bandwidth that can be used in the session during any operating conditions (including redundancy).\nShould be used to set MBR.\nShould also be used to set GBR for MBR=GBR bearers.\nThe unit for this bandwidth property shall be kbps.\nUsage during the session:\nThe additional bandwidth for redundancy should only be used if adapting the bitrate to lower values, down to the Minimum Supported Bandwidth, fails to provide sufficient quality.\nQuality aspects:\nWhen additional bandwidth is allocated for redundancy, the resilience against losses should be improved. It should however be expected that the end-to-end delay will be longer than for the normal operating range.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.2.3\tMaximum Desired Bandwidth",
                            "text_content": "Definition:\nIdentifies the highest bandwidth that should be used in most cases during normal operating conditions. This normally corresponds to the maximum bitrate allowed for the encoding.\nThe unit for this bandwidth property shall be kbps.\nUsage during the session:\nThe adaptation should ensure that bandwidths up to the Maximum Desired Bandwidth are used whenever possible.\nQuality aspects:\nUsing bandwidths in the higher end of the Minimum Desired Bandwidth ~ Maximum Desired Bandwidth range should give the intended encoding quality and end-to-end delay.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.2.4\tMinimum Desired Bandwidth",
                            "text_content": "Definition:\nIdentifies the lowest bandwidth that should be used in the session during relatively normal or slightly degraded operating conditions.\nUsed for setting GBR for MBR>GBR bearers.\nThe unit for this bandwidth property shall be kbps.\nUsage during the session:\nBandwidths in the lower end of the Minimum Desired Bandwidth ~ Maximum Desired Bandwidth should be used less frequently, mainly during periods with high load and/or degraded operating conditions.\nThe bandwidth used by media can be lower than the Minimum Desired Bandwidth, for example during DTX periods or lower rate operation of Source-Controlled Variable Bit Rate modes, e.g. EVS 5.9 VBR, for speech or when DTMF is being transmitted instead of speech.\nQuality aspects:\nUsing bandwidths in the lower end of this range can give slightly reduced encoding quality but should not give increased end-to-end delay.\nFor video, this bandwidth should be selected such that the video is still relatively smooth.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.2.5\tMinimum Supported Bandwidth",
                            "text_content": "Definition:\nIdentifies the lowest bandwidth that may be used in the session during exceptional operating conditions.\nThe unit for this bandwidth property shall be kbps.\nUsage during the session:\nBandwidths below the Minimum Desired Bandwidth, down to the Minimum Supported Bandwidth, should be used quite rarely, mainly for severely degraded operating conditions.\nIf the operating conditions are so poor that not even Minimum Supported Bandwidth can be maintained then the session can be terminated.\nThe bandwidth used by media can deliberately be lower than the Minimum Supported Bandwidth, for example during DTX periods or lower rate operation of Source-Controlled Variable Bit Rate modes, e.g. EVS 5.9 VBR, for speech or when DTMF is being transmitted instead of speech. This is not to be considered a violation of the bandwidth parameter.\nQuality aspects:\nIt can be expected that the encoding quality is reduced for these bandwidths and also that the end-to-end delay is increased.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.2.6\tIP version",
                            "text_content": "Definition:\nIdentifies the IP version used for the calculation of the bandwidth properties.\nThis bandwidth property shall have the numerical values 4 or 6.\nUsage during the session:\nIt may happen that gateways performing IPv4-IPv6 conversion re-calculate the bandwidth modifiers, e.g. b=AS, while leaving the bandwidths indicated with the ‘a=bw-info’ attribute unchaged. It is therefore beneficial to indicate which IP version that was assumed when the bandwidth properties were calculated.\nThe bandwidth properties may be calculated either using IPv4 and/or IPv6. The SDP may include bandwidth properties for both IPv4 and IPv6 in which case different attribute lines are used for the different IP versions and the IP version needs to be indicated\nIf no IP version is included for any of the ‘a=bw-info’ lines related to a certain payload type and direction then IPv6 is assumed for all bandwidth properties related to the same direction and payload type, on all of the related ’a=bw-info’ lines.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.2.7\tMaximum Packet Rate",
                            "text_content": "Definition:\nIdentifies the maximum packet rate assumed when calculating the bandwidth properties.\nThe unit for this bandwidth property shall be packets per second.\nUsage during the session:\nThe overhead when transmitting media using IP/UDP/RTP depends on the packet rate, especially for media using a relatively low bit-rate media, e.g. speech. When IPv4-IPv6 conversion is performed and when the bandwidth properties are re-calculated for the ‘a=bw-info’ attribute, it is necessary to know which packet rate that was assumed when the bandwidth properties were originally calculated.\nThe maximum packet rate is used when re-calculating the Maximum Supported Bandwidth, Maximum Desired Bandwidth and Minimum Desired Bandwidth bandwidth properties.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.2.8\tMinimum Packet Rate",
                            "text_content": "Definition:\nIdentifies the minimum packet rate assumed when calculating the bandwidth properties.\nThe unit for this bandwidth property shall be packets per second.\nUsage during the session:\nThe overhead when transmitting media using IP/UDP/RTP depends on the packet rate, especially for media using a relatively low bit-rate media, e.g. speech. When IPv4-IPv6 conversion is performed and when the bandwidth properties are re-calculated for the ‘a=bw-info’ attribute, it is necessary to know which packet rate that was assumed when the bandwidth properties were originally calculated.\nThe minimum packet rate is used when re-calculating the Minimum Supported Bandwidth bandwidth property.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "19.3\tSDP attribute",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "19.3.1\tDefinition",
                            "text_content": "The syntax for the SDP attribute is:\na=bw-info:<pt-def> <direction> <bw-prop-1>=<bw-value-def-1>; ...; <bw-prop-N>=<bw-value-def-N>\n\nwhere:\n<pt-def> is the definition of the RTP payload type(s) that the bandwidth information applies to. This can be a single value, a comma-separated list of RTP payload type numbers, or a wild card (‘*’).\n<direction> is either ‘send’ or ‘recv’. The direction shall be defined for each ‘a=bw-info’ line.\n<bw-prop-X>=<bw-value-def-X> define the bandwidth property and the related bandwidth value(s).\nThe new attribute is designed to allow for future extensibility.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.3.2\tSDP grammar",
                            "text_content": "The ABNF RFC 5234 [153] for this attribute is the following:\nbw-attrib\t\t= \"a=bw-info:\" pt-def SP direction SP bw-def *(\";\" [SP] bw-def)\n\npt-def\t\t= \"*\" / pt-val *(\",\" pt-val)\npt-val\t\t= 1*3DIGIT\n\ndirection\t\t= \"send\" / \"recv\" / \"sendrecv\" / direction-ext\ndirection-ext\t= 1*VCHAR\n\nbw-def\t\t= bw-name \"=\" bw-val-def\nbw-name\t\t= 1*VCHAR\t\t\t; Label defining the bandwitdh property\nbw-val-def\t= zero-based-int-or-real / bw-val-def-ext\t; Bandwidth value for the bandwidth property\nbw-val-def-ext\t= zero-based-int-or-real *(\":\" zero-based-int-or-real)\n; Extension possibility\n\n\n; DIGIT as defined by IETF RFC 4566\n; zero-based-int-or-real as defined by IETF RFC 8866\n\nThe 'a=bw-info' attribute defines the following possible directionalities for the bandwidth. Three directionalities are defined here:\n-\tsend: In the send direction for SDP Offer/Answer agent providing the SDP or in case of declarative use in relation to the device that is being configured by the SDP.\n-\trecv: In the receiving direction for the SDP Offer/Answer agent providing the SDP or in case of declarative use in relation to the device that is being configured by the SDP.\n-\tsendrecv: In both the send and receiving directions for the SDP Offer/Answer agent providing the SDP or in case of declarative use in relation to the device that is being configured by the SDP.\nAdditional directionalities may be defined in the future, if needed. If an ‘a=bw-info’ line is received with an unknown directionality then the entire ‘a=bw-info’ line is ignored.\nThe directionality shall be specified when the ‘a=bw-info’ attribute is used. Only one directionality can be specified on each ‘a=bw-info’ line.\nIt is allowed to define different bandwidth properties on different attribute lines for the same payload type and direction. However, special care should be taken to avoid conflicting definitions. Therefore, a single bandwidth property shall not be included in several attribute lines applicable to the same payload type, direction and IP version. For example, if bandwidth property ‘MaxSupBw’ is defined for payload number 96 on one ‘a=bw-info’ line for direction ‘send’ and IPv6, then ‘MaxSupBw’ cannot be defined on another 'a=bw-info' line for the same payload type number, direction and IP version. However, for example, ‘MaxSupBw’ and ‘MinSupBw’ may be defined in different ‘a=bw-info’ lines, even for the same payload type, direction and IP version. This applies also when a wild card is used for the payload type number.\nThe ‘bw-name’ is a character string describing the name (or label) used for the bandwidth property that is defined. Four bandwidth property names are defined here for indicating bandwidth needs:\n-\tMaxSupBw: The Maximum Supported Bandwidth, see clause 19.2.2. The Maximum Supported Bandwidth may be a real value.\n-\tMaxDesBw: The Maximum Desired Bandwidth, see clause 19.2.3. The Maximum Desired Bandwidth may be a real value.\n-\tMinDesBw: The Minimum Desired Bandwidth, see clause 19.2.4. The Maximum Desired Bandwidth may be a real value.\n-\tMinSupBw: The Minimum Supported Bandwidth, see clause 19.2.5. The Maximum Supported Bandwidth may be a real value.\nThese bandwidth properties include IP/UDP/RTP overhead but not RTCP bandwidth, similar to b=AS. This means that the Maximum Supported Bandwidth for the receiving direction corresponds to the b=AS value used in an SDP offer-answer negotiation.\nThe following bandwidth property names are also defined:\n-\tIpVer: The IP version, see clause 19.2.6. Allowed values are 4 and 6 for IPv4 and IPv6, respectively. If the IP version is not indicated then IPv6 is assumed.\n-\tMaxPRate: The Maximum Packet Rate, see clause 19.2.7. The maximum packet rate may be a real value.\n-\tMinPRate: The Minimum Packet Rate, see clause 19.2.8. The minimum packet rate may be a real value.\nUnknown bandwidth property names shall be ignored, and shall not be included in an answer if received in an offer. A received SDP may include ‘a=bw-info’ lines containing both known and unknown bandwidth properties. Ignoring unknown bandwidth properties shall not cause known bandwidth properties to be ignored.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.3.3\tDeclarative use",
                            "text_content": "In declarative usage the SDP attribute is interpreted from the perspective of the end-point being configured by the particular SDP. An interpreter may ignore 'a=bw-info' attribute lines that contain only unknown payload numbers.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "19.3.4\tUsage in offer/answer",
                            "text_content": "The offer/answer negotiation is performed for each ‘a=bw-info’ attribute line, payload type, direction and bandwidth property individually.\nAn offerer may use the 'a=bw-info' attribute line for some or all of the offered payload types. The offerer may use the wild card to describe that a bandwidth property applies to all payload types included in the offer. Different bandwidth properties may be defined on different ‘a=bw-info’ attribute lines, even for the same payload type (including wild card) and directionality. However, the offerer shall ensure that there is no contradicting information. Therefore, a bandwidth property shall not occur on multiple ‘a=bw-info’ lines for the same payload type (including wild card), direction and IP version.\nAn answerer may remove the 'a=bw-info' attribute line(s) for the payload types where it was used in the SDP offer. If 'a=bw-info' is included in the SDP offer, the answerer may add additional 'a=bw-info' lines for payload types it has added in the SDP answer compared to the SDP offer. An answerer may also remove or add individual bandwidth properties.\nThe SDP may include an offer for some of the defined bandwidth properties without including an offer for other defined bandwidth properties, in which case the values of the omitted properties are undefined, but may still be implicitly limited by the general property equalities defined in clause 19.2.1.\nAn offer may include any defined directionality in the ‘a=bw-info’ attribute(e.g. ‘send’, ‘recv’ or ‘sendrecv’) regardless of the directional attribute defined for the media stream (‘a=sendrecv’, ‘a=sendonly’, ‘a=recvonly’ or ‘a=inactive’).\nAn agent understanding the 'a=bw-info' attribute and answering to an offer including the 'a=bw-info' attribute should include the attribute in the answer for all payload types for which it was offered.\nIf an answerer has received 'a=bw-info' in an SDP offer with a certain set of bandwidth properties, and would like to add additional bandwidth properties, possibly using other directionality, then it may do so by adding such definitions in the SDP answer.\nAn agent may also divide an 'a=bw-info' line into several 'a=bw-info' lines. One example is when the SDP offer included an 'a=bw-info' lines listing several different RTP payload types, or using a wild card. The agent may then divide the attribute line with the payload type list into several attribute lines with payload type lists consisting of fewer payload type numbers or even several attribute lines with only a single payload type number each. Another example is separating a list of bandwidth properties from a single ‘a=bw-info’ line onto multiple ‘a=bw-info’ lines.\nAn agent may also merge several ‘a=bw-info’ offers into fewer offers or even a single offer.\nAn agent responding to an 'a=bw-info' offer will need to consider the directionalities and reverse them in the answer when responding to media streams using unicast.\nIf the answerer removes one or several RTP Payload Types from the SDP when creating the SDP answer then the corresponding payload type numbers should be removed from the 'a=bw-info' lines as well.\nAn agent accepting an offer with the ‘a=bw-info’ attribute may modify the bandwidth properties in the following ways when including them in the answer:\n-\tThe Maximum Supported Bandwidth may be reduced.\n-\tThe Maximum Desired Bandwidth may be reduced.\n-\tThe Minimum Desired Bandwidth may be reduced.\n-\tThe Minimum Supported Bandwidth may be increased. If the reason for increasing the Minimum Supported Bandwidth is that the Minimum Packet Rate needs to be increased then the Minimum Packet Rate shall also be adjusted.\n-\tThe Maximum Packet Rate may be reduced.\n-\tThe Minimum Packet Rate may be increased.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "19.4\tModifications of the bandwidth information by intermediate network nodes",
                    "description": "",
                    "summary": "",
                    "text_content": "Networks nodes in the path, capable of understanding and modifying the SDP, may modify the new bandwidth information in the SDP offer for each codec and configuration in the following manner:\n-\tThe first node may decrease the maximum supported, maximum desired and minimum desired bandwidth according to network policies. However, the first node should not increase the maximum supported, maximum desired and minimum desired bandwidth except when required to correct undesired or erroneous UE behavior, or for IPv4/IPv6 transport interworking.\n-\tThe first node may increase the minimum supported bandwidth according to network policies. However, the first node should not decrease the minimum supported bandwidth except when required to correct UE misbehavior, or for IPv4/IPv6 transport interworking.\n-\tSubsequent nodes may decrease the maximum supported, maximum desired and minimum desired bandwidths and increase the minimum supported bandwidth, but shall not increase the maximum supported, maximum desired and minimum desired bandwidths, and shall also not decrease the minimum supported bandwidth except when required due to IPv4/IPv6 transport interworking.\n-\tNetworks nodes may remove an unwanted codec or configuration together with all related bandwidth information.\n-\tNetworks nodes may add codecs or configurations accessible via transcoding together with all related bandwidth information.\n-\tIf a network node desires to use a MBR=GBR bearer, it should decrease maximum supported bandwidth down to the maximum desired bandwidth in the SDP offer.\n-\tThe following relationships shall be maintained by any network node when modifying the bandwidth propertiess:\nMinimum Supported Bandwidth <= Minimum Desired Bandwidth\nMinimum Desired Bandwidth <= Maximum Desired Bandwidth\nMaximum Desired Bandwidth <= Maximum Supported Bandwidth\nNOTE:\tThese rules allow all both the originating and terminating operators in the call setup direction to implement certain policies, but avoid that subsequent operators in the call setup chain counteract the policies of the first operator, and guarantee that the used bandwidths remain in the supported range of the originating UE. For instance, the following policies are supported:\nAn operator desiring to set a lower limit to the acceptable QoS can increase the Minimum Supported Bandwidth.\nAn operator desiring to limit the GBR for MBR>GBR bearers can decrease the Minimum Desired Bandwidth.\nAn operator desiring to limit the GBR for MBR=GBR bearers can decrease the Maximum Supported Bandwidth.\nIn the SDP answer, the first node should not modify the bandwidth values except when required to correct UE misbehavior, when replacing the selected codec and configuration in the SDP answer due to transcoding, or due to IPv4/IPv6 transport interworking. Subsequent node also shall not modify the bandwidth values except when replacing the selected codec and configuration in the SDP answer due to transcoding, or due to IPv4/IPv6 transport interworking.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.1\tSDP offers for speech sessions initiated by MTSI client in terminal",
            "description": "This Annex includes several SDP examples for session setup for speech. SDP examples for sessions with speech and DTMF are shown in Annex G. These SDP offer and answer examples are designed to highlight the respective area that is being described and should therefore not be considered as complete SDP offers and answers. See TS 24.229 [7] for a complete description of the SDPs. Therefore mandated session parameters such as b=AS should be assumed as present in the media and session level, even if they are not included in the SDP examples.\nSome of the SDP examples contain a=fmtp lines that are too long to meet the column width constraints of this document and are therefore folded into several lines using the backslash (\"\\\") character. In a real SDP, long lines would appear as one single line and not as such folded lines.\nSome of the examples included in this Annex outline configurations that have been optimized for HSPA. These configurations are equally applicable to E-UTRAN and NR access since the packetization recommendations for HSPA and E-UTRAN and NR in Clauses 7.4.2 and 7.5.2.1 for MTSI clients and Clause 12.3.2 for MTSI media gateways are identical.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.1.1\tHSPA or unknown access technology",
                    "description": "",
                    "summary": "",
                    "text_content": "When the access technology is unknown to the MTSI client in terminal, the client uses the encapsulation parameters of default operation as defined in clause 7.5.2.1.2. The SDP examples below apply to HSPA as well as the default operation since the encapsulation parameters are the same.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.1.1.1\tOnly AMR-NB supported by MTSI client in terminal",
                            "text_content": "In this example one RTP Payload Type (97) is defined for the bandwidth-efficient payload format and another RTP payload type (98) for the octet-aligned payload format. In this case, the MTSI client in terminal supports mode changes at any time, mode changes to any mode and mode change restrictions.\nTable A.1.1: SDP example\n\nComments:\nThe UDP port number (49152) and the payload type numbers (97 and 98) are examples and the offerer is free to select other numbers within the restrictions of the UDP and RTP specifications. It is recommended to use the dynamic port numbers in the 49152 to 65535 range. RTP should use even numbers for RTP media and the next higher odd number for RTCP. It is however allowed to use any number within the registered port range 1 024 to 49 151. The receiver must be capable of using any combination of even and odd numbers for RTP and RTCP.\nThe SDP Capabilities Negotiation framework (SDPCapNeg) [69] is used to negotiate what RTP profile to use. The offer includes RTP/AVP in the conventional SDP part by including it in the media (m=) line, while RTP/AVPF is given as a transport capability using the SDPCapNeg framework \"a=tcap:1 RTP/AVPF\". A potential configuration gives RTP/AVPF as an alternative \"a=pcfg:1 t=1\". Given by the rules in SDPCapNeg, the RTP/AVPF profile has higher preference than RTP/AVP.\nIt is important that the MTSI client in terminal does not define any mode-set because then the answerer is free to respond with any mode-set that it can support. If the MTSI client in terminal would define mode-set to any value, then the answer only has the option to either accept it or reject it. The latter case might require several ping-pong between the MTSI clients before they can reach an agreement on what mode set to use in the session. This would increase the setup time significantly. This is also one important reason for why the MTSI clients in terminals must support the complete codec mode set of the AMR and AMR-WB codecs, because then a media gateway interfacing GERAN or UTRAN can immediately define the mode-set that it supports on the GERAN or UTRAN circuit switched access.\nSince the MTSI client in terminal is required to support mode changes at any frame border and also to any mode in the received media stream, it does not set the mode-change-period and mode-change-neighbor parameters.\nThe mode-change-capability and max-red parameter are new in the updated AMR payload format [28]. With mode-change-capability=2, the MTSI client in terminal shows that it does support aligning mode changes every other frame and the answerer then knows that requesting mode-change-period=2 in the SDP answer will work properly. The max-red parameter indicates the maximum interval between a non-redundant frame and a redundant frame. Note that the maxptime and max-red parameters do not need to be synchronized.\nThe payload type for the bandwidth-efficient payload format (97) is listed before the payload type for the octet-aligned payload format (98) because it is the preferred one.\nWith the combination of ptime:20 and maxptime:240, the MTSI client in terminal shows that it desires to receive one speech frame per packet but can handle up to 12 speech frames per packet. However, no more than 4 original speech frames can be encapsulated in one packet.\nA suitable SDP answer from another MTSI client in terminal is shown in Table A.3.0.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.1.1: SDP example",
                                    "table number": 41,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.1.1.2\tAMR and AMR-WB are supported by MTSI client in terminal",
                            "text_content": "The size of the SDP may become quite big, depending on how many configurations the MTSI client in terminal supports for different media. Therefore, the session setup may be divided into phases where the most desirable configurations are offered in the first phase. If the first phase fails, then the remaining configurations can be offered in a second phase.\nIn table A.1.2 an example is shown where a one-phase approach is used and where the SDP includes both AMR and AMR-WB and both the bandwidth-efficient and octet-aligned payload formats.\nTable A.1.2: SDP example: one-phase approach\n\nComments:\nIt is easy to imagine that the SDP offer can become quite large if the client supports many different configurations for one or several media. A solution to this problem is shown in Clause A.1.1.2.2.\nA few possible SDP answers are outlined in Tables A.3.1, A.3.1a, A.3.2, A.3.3 and A.3.4.\nTables A.1.3 and A.1.4 show the same configurations as in table A.1.2 but when the SDP has been divided into 2 phases.\nTable A.1.3: SDP example: 1st phase SDP offer\n\nTable A.1.4: SDP example: 2nd phase SDP offer\n\nComments:\nMany types of media and maybe even many different configurations for some or all media types, may give quite large SIP messages. When constructing the offer, the access type and the radio bearer(s) for the answerer are not yet known. To maintain a reasonable setup time, a 2-phase approach may be useful where the most desirable configurations are included in the 1st phase and the 2nd phase is entered only if all payload types for one media type are rejected.\nThere is however a drawback with the two-phase approach. If the 2nd phase is not entered, then a cell change that would require configurations from the 2nd phase SDP is likely to give long interruption times, several seconds, while the session parameters are re-negotiated.\nThe SDPCapNeg framework is only used in the 1st SDP offer because when generating the 2nd SDP offer the profile is already agreed. In this example, it is assumed that AVPF was accepted in the first round.\nIf the 1st SDP offer, shown in Table A.1.3, is accepted by the answerer then a few possible example SDP answers are shown in: Table A.3.1 if the answerer is an MTSI client in terminal and supports AMR-WB; Table A.3.2 if the answerer is an MTSI client in terminal but does not support AMR-WB; Table A.3.3 if the answerer is an MTSI client in terminal, supports AMR-WB and is using EGPRS access; Table A.3.4 if the answerer is a CS terminal, supports AMR-WB and an MTSI MGW is therefore needed.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.1.2: SDP example: one-phase approach",
                                    "table number": 42,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.1.3: SDP example: 1st phase SDP offer",
                                    "table number": 43,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.1.4: SDP example: 2nd phase SDP offer",
                                    "table number": 44,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "A.1.2\tEGPRS",
                    "description": "",
                    "summary": "",
                    "text_content": "In this example one RTP Payload Type (97) is defined for the bandwidth-efficient payload format and another RTP Payload Type (98) is defined for the octet-aligned payload format.\nTable A.1.5: SDP example\n\nComments:\nThe only difference compared with the SDP offer for HSPA is ptime: 40. This definition is used to optimize capacity by reducing the amount of overhead that lower layers introduce. Defining ptime:20 will also work, but will be less optimal. Thus, when performing a cell change from HSPA to EGPRS, it is not an absolute necessity to update the session parameters immediately. It can be done after a while, which would also reduce the amount of SIP signalling if a MTSI client in terminal is switching frequently between HSPA and EGPRS or some other access type.\nIt is recommended to set the max-red parameter to an integer multiple of the ptime.\nAn example of a suitable SDP answer to this SDP offer is shown in Table A.3.3a.\n",
                    "tables": [
                        {
                            "description": "Table A.1.5: SDP example",
                            "table number": 45,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.1.3\tGeneric Access",
                    "description": "",
                    "summary": "",
                    "text_content": "In this example one RTP Payload Type (97) is defined for the bandwidth-efficient payload format and another RTP Payload Type (98) is defined for the octet-aligned payload format.\nTable A.1.6: SDP example\n\nComments:\nIn this case the MTSI client in terminal has detected that the load on the WLAN network is quite high and therefore ptime is set to 80. For other operating conditions, it could set ptime to 20, 40 or 60. This parameter may be updated during the session if the load of the WLAN network changes.\nAn example of a suitable SDP answer to this SDP offer is shown in Table A.3.3b.\n",
                    "tables": [
                        {
                            "description": "Table A.1.6: SDP example",
                            "table number": 46,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.2\tSDP offers for speech sessions initiated by media gateway",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.2.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "These examples show only SDP offers when the MTSI media gateway does not support the same configurations as for the MTSI terminal in clause A.1. A media gateway supporting the same configurations as for the examples in clause A.1 should create the same SDP offers.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.2.2\tMGW between GERAN UE and MTSI",
                    "description": "",
                    "summary": "",
                    "text_content": "This example shows the SDP offer when the call is initiated from GSM CS using the AMR with the {12.2, 7.4, 5.9 and 4.75} codec mode set. In this example, it is also assumed that only the bandwidth-efficient payload format is supported and that it will not send any redundant speech frames.\nTable A.2.1: SDP example\n\nComments:\nSince the MGW only supports a subset of the AMR codec modes, it needs to indicate this in the SDP. The same applies for the mode change restrictions.\nAn example of a suitable SDP answer to this SDP offer is shown in Table A.3.5.\n",
                    "tables": [
                        {
                            "description": "Table A.2.1: SDP example",
                            "table number": 47,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.2.3\tMGW between legacy UTRAN UE and MTSI",
                    "description": "",
                    "summary": "",
                    "text_content": "This example shows the SDP offer when the call is initiated from legacy UTRAN CS mobile that only the AMR 12.2 mode. In this example, it is also assumed that only the bandwidth-efficient payload format is supported.\nTable A.2.2: SDP example\n\nComments:\nSince only one mode is supported, the mode-change-period, mode-change-neighbor and mode-change-capability parameters do not apply.\nIn this case it is advisable to not allow redundancy since the legacy UTRAN CS mobile does not support any lower rate codec modes and then redundancy would almost double the bitrate on the PS access side. Therefore, maxptime is set to 20 and max-red is set to 0.\nIf a mode-set with several codec modes was defined and if max-red and maxptime are set to larger values than what Table A.1.8 shows, then redundancy is possible on the PS access side but not together with TFO.\nAn example of a suitable SDP answer to this SDP offer is shown in Table A.3.6.\n",
                    "tables": [
                        {
                            "description": "Table A.2.2: SDP example",
                            "table number": 48,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.2.4\tMGW between CS UE and MTSI",
                    "description": "",
                    "summary": "",
                    "text_content": "This example shows the SDP offer when two mode sets are supported by the MGW.\nTable A.2.3: SDP example\n\nComments:\nRedundancy up to 100 % is supported in this case since max-red is set to 20.\nAn example of a suitable SDP answer to this SDP offer is shown in Table A.3.6.\n",
                    "tables": [
                        {
                            "description": "Table A.2.3: SDP example",
                            "table number": 49,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.2.5\tMGW between GERAN UE and MTSI when wideband speech is supported",
                    "description": "",
                    "summary": "",
                    "text_content": "This example shows the SDP offer when the call is initiated from GSM CS when AMR is supported with the {12.2, 7.4, 5.9 and 4.75} codec mode set and when AMR-WB is supported with the {12.65, 8.85 and 6.60} mode set. In this example, it is also assumed that only the bandwidth-efficient payload format is supported and that the MTSI MGW will not send any redundant speech frames.\nTable A.2.4: SDP example\n\nComments:\nSince the MGW only supports a subset of the AMR codec modes and of the AMR-WB codec modes, it needs to indicate this in the SDP. The same applies for the mode change restrictions.\n",
                    "tables": [
                        {
                            "description": "Table A.2.4: SDP example",
                            "table number": 50,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.3\tSDP answers to SDP speech session offers",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.3.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause gives a few examples of possible SDP answers. The likelihood that these SDP answers will be used may vary from case to case since the SDP answer depends on circumstances outside the scope of this specification for example: availability of resources, radio bearer assignment and policy control. It is impossible to cover all the possible variants and hence these examples should be regarded as just a few examples of many possible alternatives. They were however selected because they span the range of possible SDP answers quite well.\nThe SDP offers are included to clarify what is being answered.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.1a\tSDP answer from an MTSI client in terminal when only narrowband speech was offered",
                    "description": "",
                    "summary": "",
                    "text_content": "These SDP offers and answer are likely when the offering MTSI client in terminal (or other client) only supports narrowband speech (AMR).\nThe SDP offer included in this example is identical to the SDP offer shown in Table A.1.1.\nTable A.3.0: SDP example\n\nComments:\nThe SDP answer contains only one encoding format since TS 24.229 [7] requires that the answerer shall select exactly one codec for the answer. Since both MTSI clients in terminals support the same configurations for narrowband speech, it is likely that the selected configuration included in the answer is identical to the configuration in the offer and that no mode-set is defined by the terminating client.\nThe conclusion from this offer-answer procedure is that the offerer can only send AMR encoded speech to the answerer using the bandwidth-efficient payload type with RTP Payload Type 99, since this was the only configuration included in the answer. The answerer sends AMR encoded speech to the offerer using the bandwidth-efficient payload format, in this case RTP Payload Type 97.\nEven though both MTSI clients in terminals support all codec modes, it is desirable to mainly use the codec modes from the AMR {12.2, 7.4, 5.9 and 4.75} mode set because the set includes codec modes frequently used in GERAN and UTRAN, and enables to control quality and capacity with appropriate bit-rate granularity.\nUnless transmission conditions necessitate other encapsulation types it is also desirable to encapsulate only 1 speech frame per packet, even though both MTSI clients in terminals support receiving several frames per packet.\nIn the above example it is assumed that AVPF will be accepted since the MTSI client is required to support this RTP profile.\n",
                    "tables": [
                        {
                            "description": "Table A.3.0: SDP example",
                            "table number": 51,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.2\tSDP answer from an MTSI client in terminal",
                    "description": "",
                    "summary": "",
                    "text_content": "These SDP offers and answers are likely when both MTSI clients in terminals support AMR and AMR-WB and also both the bandwidth-efficient and the octet-aligned payload formats.\nThe SDP offer included in this example is identical to the SDP offer shown in Table A.1.2, with the exception that the number of channels is omitted for each of the codecs.  This implies that the terminal is offering one channel for each codec.\nTable A.3.1: SDP example\n\nComments:\nThe SDP answer contains only one encoding format since TS 24.229 [7] requires that the answerer shall select exactly one codec for the answer. Since both MTSI clients in terminals support the same configurations, it is likely that the selected configuration included in the answer is identical to the configuration in the offer and that no mode-set is defined by the terminating client. The conclusion from this offer-answer process is that AMR-WB will be used during the session with RTP Payload Type 97. The SDP answer does not include the number of audio channels, implying that one channel has been accepted.\nEven though both MTSI clients in terminals support all codec modes, it is desirable to mainly use the codec modes from the AMR-WB {12.65, 8.85 and 6.60} mode set because the set includes codec modes frequently used in GERAN and UTRAN, and enables to control quality and capacity with appropriate bit-rate granularity.\nUnless transmission conditions necessitate other encapsulation types it is also desirable to encapsulate only 1 speech frame per packet, even though both MTSI clients in terminals support receiving several frames per packet.\nIn the above example it is assumed that AVPF will be accepted since the MTSI client is required to support this RTP profile.\nThis SDP answer is also a possible answer to the SDP offer shown in Table A.1.3.\n",
                    "tables": [
                        {
                            "description": "Table A.3.1: SDP example",
                            "table number": 52,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.2a\tSDP answer from a non-MTSI UE with AVP",
                    "description": "",
                    "summary": "",
                    "text_content": "The MTSI client must be prepared to receive an SDP answer with AVP. This is likely to occur for legacy clients that do not support AVPF or SDPCapNeg. The example in Table A.3.1a shows a possible SDP answer with AVP to an SDP offer as shown in Table A.1.2.\nTable A.3.1a: SDP answer example with AVP\n\nComments:\nA client that does not support SDPCapNeg would not understand the attributes defined by the SDPCapNeg framework and would therefore ignore the lines with ‘a=tcap’ and ‘a=pcfg’.\n\n",
                    "tables": [
                        {
                            "description": "Table A.3.1a: SDP answer example with AVP",
                            "table number": 53,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.3\tSDP answer from an MTSI client in terminal supporting only AMR",
                    "description": "",
                    "summary": "",
                    "text_content": "These SDP offers and answers are likely when the answering MTSI client in terminal supports only AMR.\nThe SDP offer included in this example is identical to the SDP offer shown in Table A.1.2.\nTable A.3.2: SDP example\n\nComments:\nIn the answer, RTP Payload Types 97 and 98 have been removed since AMR-WB is not supported and RTP Payload Type 100 is removed since the answerer is required to answer with only one encoding format.\nEven though both MTSI clients in terminals support all codec modes, it is desirable to mainly use the codec modes from the AMR [12.2, 7.4 5.9 and 4.75] mode set because the set includes codec modes frequently used in GERAN and UTRAN, and enables to control quality and capacity with appropriate bit-rate granularity.\nThis SDP answer is also a possible answer to the SDP offer shown in Table A.1.3.\n",
                    "tables": [
                        {
                            "description": "Table A.3.2: SDP example",
                            "table number": 54,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.4\tSDP answer from an MTSI client in terminal using EGPRS access when both AMR and AMR-WB are supported",
                    "description": "",
                    "summary": "",
                    "text_content": "In this case the answering MTSI client in terminal is using EGPRS access and supports both narrowband and wideband speech, i.e. both AMR and AMR-WB.\nThe SDP offer is identical to the SDP offer shown in Table A.1.2.\nTable A.3.3: SDP example\n\nComments:\nThe answering MTSI client in terminal responds that it desires to receive 2 frames encapsulated in each packet. It will however send with 1 frame per packet since the offering MTSI client in terminal desires to receive this format. A future SIP UPDATE may change this so that 2 frames per packet are used in both directions.\nThe answering MTSI client in terminal also responds with max-red defined to 200 ms since this is the closes multiple of the desired frame aggregation. It should however be noted that it is not a requirement to define max-red  to be a multiple of ptime, but it is recommended to do so.\nThis SDP answer is also a possible answer to the SDP offer shown in Table A.1.3.\n",
                    "tables": [
                        {
                            "description": "Table A.3.3: SDP example",
                            "table number": 55,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.4a\tSDP answer from an MTSI client in terminal using EGPRS access when only AMR is supported",
                    "description": "",
                    "summary": "",
                    "text_content": "In this case the answering MTSI client in terminal is using EGPRS access but supports only narroband speech, i.e. only AMR.\nThe SDP offer is identical to the SDP offer shown in Table A.1.2 although the SDP answer here would also work nicely as a response to the SDP offer shown in Table A.1.5.\nTable A.3.3a: SDP example\n\nComments:\nThe answering MTSI client in terminal responds that it desires to receive 2 frames encapsulated in each packet. It will however send with 1 frame per packet since the offering MTSI client in terminal desires to receive this format. A future SIP UPDATE may change this so that 2 frames per packet are used in both directions.\nThe answering MTSI client in terminal also responds with max-red defined to 200 ms since this is the closes multiple of the desired frame aggregation. It should however be noted that it is not a requirement to define max-red  to be a multiple of ptime, but it is recommended to do so.\nThis SDP answer is also a suitable response to an SDP offer as shown in Table A.1.5, even if the answering MTSI client in a terminal is using HSPA access. This is because it is wise to harmonize the packetization, and the ptime in the SDP answer, with the ptime in the SDP offer so that 2 frames per packet will be used in both directions when one of the end-points is using EGPRS access.\n",
                    "tables": [
                        {
                            "description": "Table A.3.3a: SDP example",
                            "table number": 56,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.4b\tSDP answer from an MTSI client in terminal using WLAN",
                    "description": "",
                    "summary": "",
                    "text_content": "In this example, the MTSI client in terminal is using a WLAN network.\nThe SDP offer shown here is identical to the SDP offer shown in Table A.1.1.\nTable A.3.3b: SDP example\n\nComments:\nThis SDP answer, with ptime=80, is suitable if the MTSI client in terminal can measure the load in the WLAN network and has detected that the load is high. If, on the other hand, the load is low then the MTSI client in terminal may very well choose to use a lower value for the ptime attribute, for example 20 or 40.\nThis SDP answer is also suitable when the answering MTSI client in terminal is using HSPA access but when the offerer is using WLAN and indicates ptime=80, e.g. as shown in the SDP offer in Table A.1.6. In such a case, it is wise to harmonize the ptime values in both directions to increase the likelihood that several frames will be encapsulated in the RTP packets.\nThis SDP answer is also a possible answer to the SDP offer shown in Table A.1.3.\n",
                    "tables": [
                        {
                            "description": "Table A.3.3b: SDP example",
                            "table number": 57,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.5\tSDP answer from MTSI MGW supporting only one codec mode set for AMR and AMR-WB each",
                    "description": "",
                    "summary": "",
                    "text_content": "In this case the MTSI MGW supports only one codec mode set for AMR, {12.2, 7.4, 5.9 and 4.75}, and one codec mode set for AMR-WB, {12.65, 8.85 and 6.60}, since the CS terminal only supports these mode sets. The MTSI MGW also only supports the bandwidth-efficient payload format.\nThe SDP offer included in this example is identical to the SDP offer shown in Table A.1.2.\nTable A.3.4: SDP example\n\nComments:\nThe MTSI MGW is allowed to define the mode-set parameter since the MTSI client in terminal did not define it. Thereby, it is possible to avoid several SDP offers and answers.\nThe SDP answer contains only one encoding format since TS 24.229 [7] requires that the answerer shall select exactly one codec for the answer. In this case, the CS terminal supports wideband speech and the MTSI MGW therefore chooses to establish a wideband speech session.\nSince the MTSI client in terminal has defined that it does support restrictions in mode changes, the MTSI MGW can safely set the mode-change-period and mode-change-neighbor parameters.\nIn this example, the MTSI MGW also does not support redundancy so it sets max-red to zero.\nThis SDP answer is also a possible answer to the SDP offer shown in Table A.1.3.\n",
                    "tables": [
                        {
                            "description": "Table A.3.4: SDP example",
                            "table number": 58,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.5a\tSDP answer from MTSI MGW supporting only one codec mode set for AMR",
                    "description": "",
                    "summary": "",
                    "text_content": "In this case the MTSI MGW supports only one codec mode set for AMR, {12.2, 7.4, 5.9 and 4.75}, since the CS terminal supports only this mode set. The MTSI MGW also only supports the bandwidth-efficient payload format.\nTable A.3.4a: SDP example\n\nComments:\nThe MTSI MGW is allowed to define the mode-set parameter since the MTSI client in terminal did not define it. Thereby, it is possible to avoid several SDP offers and answers.\nThe SDP answer contains only one encoding format since TS 24.229 [7] requires that the answerer shall select exactly one codec for the answer. In this case, the CS terminal does not supports wideband speech and the MTSI MGW therefore selects to establish a narrowband speech session.\nSince the MTSI client in terminal has defined that it does support restrictions in mode changes, the MTSI MGW can safely set the mode-change-period and mode-change-neighbor parameters.\nIn this example, the MTSI MGW also does not support redundancy so it sets max-red to zero.\n",
                    "tables": [
                        {
                            "description": "Table A.3.4a: SDP example",
                            "table number": 59,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.6\tSDP answer from MTSI client in terminal on HSPA for session initiated from MTSI MGW interfacing UE on GERAN",
                    "description": "",
                    "summary": "",
                    "text_content": "This example shows the offers and answers for a session between a GERAN CS UE, through a MTSI media gateway, and a MTSI client in terminal.\nThe SDP offer shown here is very similar to the SDP offer shown in Table A.2.1. The only difference is that maxptime is set to 20.\nTable A.3.5: SDP example\n\nComments:\nThe MTSI media gateway offers only a restricted mode set sincethe CS terminal does not support anything else. The MTSI client in terminal has to accept this, if it wants to continue with the session setup.\nThis example also shows that the MTSI media gateway wants to receive only 1 frame per packet. The maxptime parameter is therefore set to 20. With max-red set to 0 the MTSI media gateway also shows that it will not send redundancy. The MTSI terminal can support receiving up to 12 frames per packet. It therefore set the maxptime parameter to 240.\nThe MTSI client in terminal detects that the MTSI media gateway does not want to receive redundancy and therefore sets max-red to 0.\nThe SDP answer shown in this example is also a suitable answer to the SDP offer shown in Table A.2.1. This SDP answer is also suitable for the SDP offer shown Table A.2.3.\n",
                    "tables": [
                        {
                            "description": "Table A.3.5: SDP example",
                            "table number": 60,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.3.7\tSDP answer from MTSI client in terminal on HSPA for session initiated from MTSI MGW interfacing legacy UE on UTRAN",
                    "description": "",
                    "summary": "",
                    "text_content": "This example shows the offers and answers for a session between a legacy UTRAN CS UE that only supports AMR 12.2, through a MTSI media gateway, and a MTSI client in terminal.\nThe SDP offer shown here is identical to the SDP offer shown in Table A.2.2.\nTable A.3.6: SDP example\n\nComments:\nThe MTSI media gateway offers only one codec mode set since the CS terminal does not support anything else. The MTSI client in terminal has to accept this, if it wants to continue with the session setup.\nThis example also shows that the MTSI media gateway want to receive only 1 frame per packet. The maxptime parameter is therefore set to 20. With max-red set to 0 the MTSI media gateway also shows that it will not send redundancy. The MTSI terminal can support receiving up to 12 frames per packet. It therefore set the maxptime parameter to 240.\nThe MTSI client in terminal detects that the MTSI media gateway does not want to receive redundancy and therefore sets max-red to 0.\n",
                    "tables": [
                        {
                            "description": "Table A.3.6: SDP example",
                            "table number": 61,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.4\tSDP offers and answers for video sessions",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.4.1\tVoid",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.2\tVoid",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.2a\tH.264/AVC",
                    "description": "",
                    "summary": "",
                    "text_content": "In this example the SDP offer includes H.264/AVC.\nTable A.4.2a1: Example SDP offer for H.264/AVC\n\nThe offered codec is H.264/AVC. The packetization-mode parameter indicates single NAL unit mode. This is the default mode and it is therefore not necessary to include this parameter (see RFC 6184 [25]). The profile-level-id parameter indicates Constrained Baseline profile at level 1.2, which supports bitrates up to 384 kbps. It also indicates, by using so-called constraint-set flags, that the bit stream can be decoded by any Baseline, Main or Extended profile decoder. The third parameter, sprop-parameter-sets, includes base-64 encoded sequence and picture parameter set NAL units that are referred by the video bit stream. The sequence parameter set used here includes syntax that specifies the number of re-ordered frames to be zero so that latency can be minimized. The bandwidth (including IP, UDP and RTP overhead) for video is restricted to 315 kbps.\nThe negotiation of AVPF features is also shown. By setting ‘trr-int’ to 5000 the MTSI client indicates that the minimum interval between two regular RTCP packets needs to be 5 seconds, [40]. The ‘nack’ and ‘nack pli’ parameters indicate that the MTSI client supports NACK (Generic NACK) and PLI (Picture Loss Indication) as defined by AVPF, [40]. The ‘ccm fir’ and ‘ccm tmmbr’ parameters indicate that the MTSI client supports the FIR (Full Intra Request) and TMMBR (Temporary Maximum Media Stream Bit Rate Request), [43]. The wildcard (‘*’) indicates that at it is possible to use these features for all RTP payload types for the video stream.\nThe negotiation of the video orientation header extension is made with the a=extmap attribute [95]. In this example, the local identifier (ID) is set to ‘4’. This number is only an example and other values may be used.\nAn example SDP answer to the offer is given below.\nTable A.4.2a2: Example SDP answer\n\nThe responding MTSI client is capable of using H.264/AVC. As the offer already indicated the lowest level (level 1.2) of H.264/AVC as well as the minimum constraint set, there is no room for further negotiation of profiles and levels. However, the bandwidth could be constrained further by reducing the bandwidth in b=AS.\n",
                    "tables": [
                        {
                            "description": "Table A.4.2a1: Example SDP offer for H.264/AVC",
                            "table number": 62,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2a2: Example SDP answer",
                            "table number": 63,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.2b\tHigh Granularity CVO example",
                    "description": "",
                    "summary": "",
                    "text_content": "This example is identical to A.4.2a with the exception of higher granularity CVO being offered.\nTable A.4.2b.1: Example SDP offer with High Granularity\n\nThe offer for higher granularity is indicated in the last SDP line above.\nTable A.4.2b.2: Example SDP answer with High Granularity\n\nThe answer indicates that higher granularity has been accepted as indicated by the last SDP line above.\n",
                    "tables": [
                        {
                            "description": "Table A.4.2b.1: Example SDP offer with High Granularity",
                            "table number": 64,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2b.2: Example SDP answer with High Granularity",
                            "table number": 65,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.2c\tRTP Retransmission",
                    "description": "",
                    "summary": "",
                    "text_content": "This example is identical to A.4.2a with the exception of retransmission being offered.\nTable A.4.2c.1: Example SDP offer with Retransmission\n\nThe offer for retransmission and associated parameters are listed after the line describing the format properties of the H.264 video.\nTable A.4.2c.2: Example SDP answer with Retransmission\n\nThe answer indicates that retransmission has been accepted as indicated.\n",
                    "tables": [
                        {
                            "description": "Table A.4.2c.1: Example SDP offer with Retransmission",
                            "table number": 66,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2c.2: Example SDP answer with Retransmission",
                            "table number": 67,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.2d\tRTP Forward Error Correction (FEC)",
                    "description": "",
                    "summary": "",
                    "text_content": "This example is identical to A.4.2a with the exception of FEC being offered.\nTable A.4.2d.1: Example SDP offer with FEC\n\nThe offer for FEC and associated parameters are listed after the line describing the format properties of the H.264 video.\nTable A.4.2d.2: Example SDP answer with FEC\n\nThe answer indicates that FEC has been accepted as indicated.\n",
                    "tables": [
                        {
                            "description": "Table A.4.2d.1: Example SDP offer with FEC",
                            "table number": 68,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2d.2: Example SDP answer with FEC",
                            "table number": 69,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.2e\tSDP Examples with ROI",
                    "description": "",
                    "summary": "",
                    "text_content": "This example is identical to A.4.2a with the exception of ‘Arbitrary ROI’ and ‘Sent ROI’ being offered.\nTable A.4.2e.1: Example SDP offer with ‘Arbitrary ROI’ and ‘Sent ROI’\n\nThe offer for ‘Arbitrary ROI’ and ‘Sent ROI’ are indicated in the last two lines.\nThe use of RTCP feedback messages carrying ‘Arbitrary ROI’ is negotiated with the ‘3gpp-roi-arbitrary’ parameter. The wildcard (‘*’) indicates that it is possible to use the ROI features for all RTP payload types including video.\nThe use of the ‘Sent ROI’ header extension carrying arbitrary ROI information is negotiated with the a=extmap attribute [95] based on the URN ‘urn:3gpp:roi-sent’. In this example, the local identifier (ID) is set to 7, which is only an example. Other values may be used as long as a distinct ID is assigned for each extmap attribute corresponding to different URNs.\n\nTable A.4.2e.2: Example SDP answer with ‘Arbitrary ROI’ and ‘Sent ROI’\n\nThe answer indicates that both ‘Arbitrary ROI’ and ‘Sent ROI’ have been accepted.\nThe following example is identical to A.4.2a with the exception of ‘Pre-defined ROI’ and ‘Sent ROI’ being offered.\nTable A.4.2e.3: Example SDP offer with ‘Pre-defined ROI’ and ‘Sent ROI’\n\nThe offer for ‘Pre-defined ROI’ and ‘Sent ROI’ are indicated in the last two lines.\nThe offered set of pre-defined ROIs is provided by the \"a=predefined_ROI\" attribute. The use of RTCP feedback messages carrying ‘Pre-defined ROI’ is negotiated with the ‘3gpp-roi-predefined’ parameter. The wildcard (‘*’) indicates that it is possible to use the ROI features for all RTP payload types including video.\nThe use of the ‘Sent ROI’ header extension carrying pre-defined ROI information is negotiated with the a=extmap attribute [95] based on the URN ‘urn:3gpp:predefined-roi-sent’. In this example, the local identifier (ID) is set to 7, which is only an example. Other values may be used as long as a distinct ID is assigned for each extmap attribute corresponding to different URNs.\nTable A.4.2e.4: Example SDP answer with ‘Pre-defined ROI’ and ‘Sent ROI’\n\nThe answer indicates that both ‘Pre-defined ROI’ and ‘Sent ROI’ have been accepted.\nThe following example is identical to A.4.2a with the exception of FECC, ‘Arbitrary ROI’ and ‘Sent ROI’ being offered.\nTable A.4.2e.5: Example SDP offer with FECC, ‘Arbitrary ROI’ and ‘Sent ROI’\n\nThe offer for FECC is made according to the procedures specified in [139]. In this example, the MTSI client offers a sendonly channel since it is unwilling to adjust the video ROI during encoding based on PTZF commands received from the far end and it does not intend to use H.224 to learn the capabilities of the far end. At the same time, if the far end is capable of FECC, it indicates that it can take advantage of this capability and send PTZF commands to adjust video ROI for the video stream in the receive direction.\n\nTable A.4.2e.6: Example SDP answer with FECC, ‘Arbitrary ROI’ and ‘Sent ROI’\n\nThe answer indicates that FECC, ‘Arbitrary ROI’ and ‘Sent ROI’ are all accepted. On FECC, the MTSI client answers with a recvonly confirming that it supports the FECC protocol and would be willing to adjust the video ROI during encoding based on PTZF commands received from the far end. As such, FECC can only be used for video in one direction.\nThe following example is identical to A.4.2a with the exception of FECC, ‘Pre-defined ROI’ and ‘Sent ROI’ being offered.\nTable A.4.2e.7: Example SDP offer with FECC, ‘Pre-defined ROI’ and ‘Sent ROI’\n\nIn this example, the MTSI client offers a sendrecv channel for FECC since it is willing to adjust the video ROI during encoding based on PTZF commands received from the far end and it intends to use H.224 to learn the capabilities of the far end.\n\nTable A.4.2e.8: Example SDP answer with FECC, ‘Pre-defined ROI’ and ‘Sent ROI’\n\nThe answer indicates that FECC, ‘Pre-defined ROI’ and ‘Sent ROI’ are all accepted. For FECC, the MTSI client answers with a sendonly since it is unwilling to adjust the video ROI during encoding based on PTZF commands received from the far end and it does not intend to use H.224 to learn the capabilities of the far end. At the same time, since the far end is capable of FECC, it indicates that it can take advantage of this capability and send PTZF commands to adjust video ROI for the video stream in the receive direction. As such, FECC can only be used for video in one direction.\n",
                    "tables": [
                        {
                            "description": "Table A.4.2e.1: Example SDP offer with ‘Arbitrary ROI’ and ‘Sent ROI’",
                            "table number": 70,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2e.2: Example SDP answer with ‘Arbitrary ROI’ and ‘Sent ROI’",
                            "table number": 71,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2e.3: Example SDP offer with ‘Pre-defined ROI’ and ‘Sent ROI’",
                            "table number": 72,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2e.4: Example SDP answer with ‘Pre-defined ROI’ and ‘Sent ROI’",
                            "table number": 73,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2e.5: Example SDP offer with FECC, ‘Arbitrary ROI’ and ‘Sent ROI’",
                            "table number": 74,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2e.6: Example SDP answer with FECC, ‘Arbitrary ROI’ and ‘Sent ROI’",
                            "table number": 75,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2e.7: Example SDP offer with FECC, ‘Pre-defined ROI’ and ‘Sent ROI’",
                            "table number": 76,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.2e.8: Example SDP answer with FECC, ‘Pre-defined ROI’ and ‘Sent ROI’",
                            "table number": 77,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.3\tVoid",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.4\tVoid",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.4a\tH.264/AVC with \"imageattr\" attribute",
                    "description": "",
                    "summary": "",
                    "text_content": "In this example the SDP offer includes H.264/AVC with negotiation of the image size using the \"imageattr\" attribute.\nTable A.4.10a: Example SDP offer for H.264/AVC with image size negotiation\n\nThe offered codec is H.264/AVC. The packetization-mode parameter indicates single NAL unit mode. This is the default mode and it is therefore not necessary to include this parameter (see RFC 6184 [25]). The profile-level-id parameter indicates Baseline profile at level 1.2, which supports bitrates up to 384 kbps. It also indicates, by using so-called constraint-set flags, that the bit stream can be decoded by any Baseline, Main or Extended profile decoder. The bandwidth (including IP, UDP and RTP overhead) for video is 315 kbps. The third parameter, sprop-parameter-sets, includes base-64 encoded sequence and picture parameter set NAL units that are referred by the video bit stream. The sequence parameter set used here includes syntax that specifies the number of re-ordered frames to be zero so that latency can be minimized. sprop-parameter-sets is constructed assuming the offered conditions and image size of 320x240, which is the largest of all offered sizes for send direction. The offering MTSI client offers four image sizes for both send and receive directions but prefers 272x224 for receive direction, which might fit the available space on its display better than the other image sizes.\nSince the support of a particular codec level does not imply that the video encoder has to produce a bitstream up to the maximum capability of the level, it may be useful for an MTSI client to indicate the image sizes it can encode video at for each codec it supports, using the \"imageattr\" SDP attribute [76]. Then on the receiving side, the MTSI client can indicate which of these image sizes it prefers to receive. This reduces the loss of quality from rescaling the decoded image to fit the available space on the receiver’s display.\nAn example SDP answer to the offer is given below.\nTable A.4.10b: Example SDP answer\n\nThe responding MTSI client is capable of using H.264/AVC. The responding MTSI client agreed to use a bandwidth of 315 kbps and to use the Baseline profile at level 1.2. From the four image sizes offered, the responding MTSI client included 320x240 for both send and receive directions. Although the offering MTSI client preferred 272x224 for receive direction, the responding MTSI client might not be able to offer 272x224 or not allow encoding and decoding of video of different image sizes simultaneously. The responding MTSI client sent new sprop-parameter-sets for the video decoder of the offering MTSI client, which was constructed assuming the agreed conditions and image size of 320x240.\nTable A.4.11: Example SDP answer\n\nIn this alternative answer, the responding MTSI client has restricted the video bandwidth to 107 kbps and restricted the H.264/AVC level to 1.1 which supports bitrates up to 192 kbps. The restricted H.264/AVC level should be high enough to enable the image sizes for both send and receive directions. From the four image sizes offered, the responding MTSI client included 272x224 for send direction, which was preferred by the offering MTSI client. For the receive direction, the responding MTSI client included 320x240 as preferred and 272x224 as fallback because the responding MTSI client was unsure  whether the offering MTSI client can encode and decode video of different image sizes simultaneously at the conditions. The responding MTSI client sent new sprop-parameter-sets for the video decoder of the offering MTSI client, which was constructed assuming the restricted conditions. Though not required in response to the SDP answer indicating more than one image size in the receive direction, the offering MTSI client may chose to send a second offer as shown in Table A.4.12 to confirm that it is able to encode and decode at different image sizes.\nTable A.4.12: Example Second SDP offer\n\nSince now the offering MTSI client knows that the responding MTSI client supports and prefers to use AVPF, AVPF is offered without SDPCapNeg and AVP.\n",
                    "tables": [
                        {
                            "description": "Table A.4.10a: Example SDP offer for H.264/AVC with image size negotiation",
                            "table number": 78,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.10b: Example SDP answer",
                            "table number": 79,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.11: Example SDP answer",
                            "table number": 80,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.12: Example Second SDP offer",
                            "table number": 81,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.4.4a.1\tH.264/AVC with \"imageattr\" attribute – different image sizes in SDP offer and answer",
                            "text_content": "In this example the SDP offer includes H.264/AVC with negotiation of the image size using the \"imageattr\" attribute.\nTable A.4.12ad: Example SDP offer for H.264/AVC with image size negotiation\n\nThe offer in Table A.4.12ad is identical to that in Table A.4.10a except that the MTSI client offers an image size of 320x240 for both directions.\nAn example SDP answer to the offer is given below.\nTable A.4.12ae: Example SDP answer\n\nIn this case, the offering MTSI client should proceed with the session setup without issuing another SDP offer to perform image size negotiation.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.4.12ad: Example SDP offer for H.264/AVC with image size negotiation",
                                    "table number": 82,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.4.12ae: Example SDP answer",
                                    "table number": 83,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.4.4a.2\tH.264/AVC with \"imageattr\" attribute – different payload type numbers in offer and answer",
                            "text_content": "In this example the SDP offer includes H.264/AVC with negotiation of the image size using the \"imageattr\" attribute.\nTable A.4.12af: Example SDP offer for H.264/AVC with image size negotiation\n\nThe offer in Table A.4.12af is identical to that in Table A.4.10a except that the MTSI client offers image sizes of 320x240 for the send direction and 272x224 for the receive direction.\nAn example SDP answer to the offer is given below.\nTable A.4.12ag: Example SDP answer\n\nIn this case, the responding MTSI client’s answer matches the image sizes in the offer. However, payload type number 99 is not available (e.g., already used for other media) and payload type number 101 is included instead for video media. After the session is established, the offering MTSI client sends the video with payload type number 101 with image size 320x240 towards the responding MTSI client. Similarly, the answering MTSI client sends the video with payload type number 99 with image size 272x224 towards the offering MTSI client.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.4.12af: Example SDP offer for H.264/AVC with image size negotiation",
                                    "table number": 84,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.4.12ag: Example SDP answer",
                                    "table number": 85,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "A.4.4b\tH.264/AVC with \"imageattr\" attribute with multiple rtpmaps",
                    "description": "",
                    "summary": "",
                    "text_content": "In this example the SDP offer includes H.264/AVC with negotiation of the image size using the \"imageattr\" attribute with multiple rtpmaps for different image sizes.\nTable A.4.12ac: Example SDP offer for H.264/AVC with image size negotiation and multiple rtpmaps\n\nThe offered codec is H.264/AVC. The packetization-mode parameter indicates single NAL unit mode. Two image sizes for send and receive directions are offered. The profile-level-id parameter of the first rtpmap indicates Constrained Baseline profile at level 2.2, which supports bitrates up to 4000 kbps. It also indicates, by using so-called constraint-set flags, that the bit stream can be decoded by any Baseline, Main or Extended profile decoder. The bandwidth (including IP, UDP and RTP overhead) for video is 900 kbps. The third parameter, sprop-parameter-sets, includes base-64 encoded sequence and picture parameter set NAL units that are referred by the video bit stream. The sequence parameter set used here includes syntax that specifies the number of re-ordered frames to be zero so that latency can be minimized. sprop-parameter-sets is constructed assuming the offered conditions and image size of 640x480. The profile-level-id parameter of the second rtpmap indicates Constrained Baseline profile at level 1.2, which supports bitrates up to 384kbps. It also indicates, by using so-called constraint-set flags, that the bit stream can be decoded by any Baseline, Main or Extended profile decoder. The third parameter, sprop-parameter-sets, includes base-64 encoded sequence and picture parameter set NAL units that are referred by the video bit stream. The sequence parameter set used here includes syntax that specifies the number of re-ordered frames to be zero so that latency can be minimized. sprop-parameter-sets is constructed assuming the offered conditions and image size of 320x240.\nAn example SDP answer to the offer is given below.\nTable A.4.12b: Example SDP answer\n\nThe responding MTSI client is capable of using H.264/AVC. The responding MTSI client agreed to use a bandwidth of 315 kbps and to use the Constrained Baseline profile at level 1.2. The responding MTSI client included 320x240 for both send and receive directions. Therefore, the final negotiated level is 1.2. The offering MTSI is expecting receiving H.264 RTP packets of resolution 320x240 with payload type number either 99 or 100, while the answering MTSI is expecting receving H.264 RTP packets of resolution 320x240 with payload type number 99.\n",
                    "tables": [
                        {
                            "description": "Table A.4.12ac: Example SDP offer for H.264/AVC with image size negotiation and multiple rtpmaps",
                            "table number": 86,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.12b: Example SDP answer",
                            "table number": 87,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.5\tH.264 with asymmetric video streams",
                    "description": "",
                    "summary": "",
                    "text_content": "As described in Clause 5.2.2 (Note 5), when a certain level of H.264 (AVC) is offered using the ‘profile-level-id’ parameter then the video codec is capable of receiving a bitstream up to the offered level and the bandwidth offered with b=AS. This however does not necessarily mean that the H.264 video codec will produce a bitstream up to the offere level when sending video. An MTSI client in terminal can use this method to set up asymmetric video streams. One drawback with using this method is that there is no information in the SDP that resource reservation functions in the network, e.g. RAN bearer allocation, could use to allocate transmission resources asymmetrically for the different directions.\nA better method to allocate asymmetric video for H.264 (AVC) is to use the ‘level-asymmetry-allowed’ and the ‘max-recv-level’ parameters defined in the H.264 payload format, [25]. The ‘profile-level-id’ parameter then defines the default level while the ‘max-recv-level’ parameter defines the maximum level for the receiving direction. With this method, there is codec-specific information in the SDP that could be used by resource reservation functions to allocate for example radio bearers in a more optimal way.\nThe SDP example below shows how a session with asymmetric video can be setup using these SDP parameters. The SDP offer sets the default level to 1.2 (max 384 kbps). The maximum receive level is set to 3.1 (max 14 Mbps) but is limited to 2 Mbps using the b=AS bandwidth modifier. The answerer also declares asymmetric video but using lower levels and bitrates. The default level is set to 1.1 (max 192 kbps) and receiving direction is limited to level 1.2 (max 384 kbps)\nTable A.4.13: Example SDP offer and answer for asymmetric video with H.264/AVC\n\nA resource reservation function that only uses the bandwidth information in the b=AS bandwidth modifiers will probably allocate 416 kbps in both directions. This means that an overallocation will occur but this does not present any other problems. The offering MTSI client offers two and three image sizes for both send and receive directions. A larger size, 1280x720, is offered only for the receive direction, which has a higher level.\nWith the ‘provile-level-id’, ‘level-asymmetry-allowed’ and the ‘max-recv-level’ in the SDP, a codec-aware resource allocation function can take advantage of this information and allocate transmission resources more efficiently, e.g. to allocate 192 kbps from the answerer to the offerer and 384 kbps from the offerer to the answerer. From the image sizes offered, the responding MTSI client included 640x480 for both send and receive directions.\n",
                    "tables": [
                        {
                            "description": "Table A.4.13: Example SDP offer and answer for asymmetric video with H.264/AVC",
                            "table number": 88,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.6\tH.264/AVC with \"imageattr\" attribute for non-CVO operation",
                    "description": "",
                    "summary": "",
                    "text_content": "In this example the SDP offer includes H.264/AVC with negotiation of the image size using the \"imageattr\" attribute allowing for orientation compensation in case of  non-CVO operation (see clause 6.2.3.3 and clause 7.4.5).\nTable A.4.14: Example SDP offer for H.264/AVC with image size negotiation\n\nThe offered codec is H.264/AVC. The packetization-mode parameter indicates single NAL unit mode. This is the default mode and it is therefore not necessary to include this parameter (see RFC 6184 [25]). The profile-level-id parameter indicates Constrained Baseline profile at level 1.2, which supports bitrates up to 384 kbps. It also indicates, by using so-called constraint-set flags, that the bit stream can be decoded by any Baseline, Main or Extended profile decoder. The bandwidth (including IP, UDP and RTP overhead) for video is 315 kbps. The third parameter, sprop-parameter-sets, includes base-64 encoded sequence and picture parameter set NAL units that are referred by the video bit stream. The sequence parameter set used here includes syntax that specifies the number of re-ordered frames to be zero so that latency can be minimized. sprop-parameter-sets is constructed assuming the offered conditions and image size of 320x240 and 240x320, and contains separate sequence and picture parameter sets with separate ID for both of the supported image resolutions in the send direction. In this example there are two Sequence Parameter Sets (SPS), numbered 0 and 1. SPS 0 has resolution 320x240. SPS 1 has resolution 240x320. There are two Picture Parameter Sets (PPS), numbered 0 and 1. PPS 0 refers to SPS 0. PPS 1 refers to SPS 1. There are four comma-separated and Base64 encoded NAL units as value for sprop-parameter-sets. The order in the example is SPS0,PPS0,SPS1,PPS1.\nWhile the offering MTSI client indicates support for CVO operation, it also offers a couple of image sizes following the format [x,y] and [y,x] for both send and receive directions which allows for signalling of image rotation by a change of resolution in the bitstream in case the receiving MTSI client does not support CVO operation.\nAn example SDP answer to the offer is given below.\nTable A.4.15: Example SDP answer\n\nThe responding MTSI client is capable of using H.264/AVC. The responding MTSI client agreed to use a bandwidth of 315 kbps and to use the Constrained Baseline profile at level 1.2. The responding MTSI client did not agree CVO operation (removed the extmap attribute) but agreed both offered images sizes 320x240 for both send and receive directions allowing for image rotation compensation in non-CVO operation. The responding MTSI client sent new sprop-parameter-sets for the video encoder of the offering MTSI client, which was constructed assuming the agreed conditions and image sizes.\n",
                    "tables": [
                        {
                            "description": "Table A.4.14: Example SDP offer for H.264/AVC with image size negotiation",
                            "table number": 89,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.4.15: Example SDP answer",
                            "table number": 90,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.4.7\tH.264 (AVC) and H.265 (HEVC)",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.4.7.1\tMTSI client with 848x480 resolution 5 inch display",
                            "text_content": "This example SDP offer is for an MTSI client with a 5 inch display that supports 848x480 video and a frame rate of 25 fps. The MTSI client supports H.264 (AVC) Constrained Baseline Profile (CBP) level 3.1. The MTSI client also supports H.265 (HEVC) Main Profile, Main tier level 3.1. When encoding video with H.264 (AVC), the required bandwidth is 690 kbps, including 36 kbps IPv6/UDP/RTP overhead (3 RTP packets per frame), but when H.265 (HEVC) is used, the required bandwidth is only 540 kbps, including 36 kbps overhead (3 RTP packets per frame).\nSince the SDP offer includes both codecs, then the b=AS bandwidth must be set to the higher of the bandwidths for those codecs.\nTable A.4.16: Example SDP offer for H.264 (AVC) and H.265 (HEVC)\n\nThe SDP offer includes the image sizes that are supported in sending and receiving directions. It is recommended to provide codec parameter sets for each image size in the SDP offer.\nTable A.4.17 shows an example SDP answer where the answerer receives the SDP offer described in Table A.4.16 and accepts using the H.265 (HEVC) codec. The answerer chooses to use the H.265 (HEVC) codec for increased quality and therefore sets the bandwidth to the same value as in the SDP offer.\nTable A.4.17: Example SDP answer when H.265 (HEVC) is used to increase the quality\n\nThe SDP offer in Table A.4.16 and the SDP answer in Table A.4.17 mean that symmetric bandwidths are requested with 690 kbps in both directions.\nTable A.4.18 shows another example SDP answer where the answerer receives the SDP offer described in Table A.4.16 and accepts using the H.265 (HEVC) codec. In this case, the answerer chooses to use the H.265 (HEVC) codec to save bandwidth and therefore sets the bit-rate to 540 kbps.\nTable A.4.18: Example SDP answer when H.265 (HEVC) is used to reduce the bit-rate\n\nThe SDP offer in Table A.4.16 and the SDP answer in Table A.4.18 mean that asymmetric bandwidths are requested. The offerer requested to receive 690 kbps while the answerer requested to receive 540 kbps. This discrepency however can be solved by sending a new SDP offer with only the selected codec.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.4.16: Example SDP offer for H.264 (AVC) and H.265 (HEVC)",
                                    "table number": 91,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.4.17: Example SDP answer when H.265 (HEVC) is used to increase the quality",
                                    "table number": 92,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.4.18: Example SDP answer when H.265 (HEVC) is used to reduce the bit-rate",
                                    "table number": 93,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.4.7.2\tMTSI client with 1280x720 resolution 5 inch display",
                            "text_content": "This example SDP offer is for an MTSI client with a 5 inch display that supports 1280x720 video and a frame rate of 25 fps. The MTSI client supports H.264 (AVC) Constrained Baseline Profile (CBP) level 3.1 and H.265 (HEVC) Main Profile, Main tier level 3.1. When encoding video with H.264 (AVC), the required bandwidth is 950 kbps, including 48 kbps IPv6/UDP/RTP overhead (4 RTP packets per frame), but when H.265 (HEVC) is used, the encoder uses only 640 kbps, including 36 kbps overhead (3 RTP packets per frame).\nThe answerer is also an MTSI client that supports H.264 (AVC) and H.265 (HEVC) in the same way as the offerer.\nTable A.4.19: Example SDP offer for H.264 (AVC) and H.265 (HEVC) and example SDP answer for H.265 (HEVC)\n\nThe SDP offer includes the image sizes that are supported in sending and receiving directions.\nThe answerer could also have chosen to use H.265 (HEVC) to improve the quality, similar to what is discussed for Table A.4.17. In this case, the answerer would set the bandwidth to the same value as in the SDP offer.\nAnother possibility is that the answerer wants to use H.265 (HEVC) partly to increase the quality and partly to reduce the bit-rate. In this case the answerer would select a bit-rate that is in-between the bit-rate in the SDP offer and the bit-rate in the SDP answer as shown in Table A.4.19.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.4.19: Example SDP offer for H.264 (AVC) and H.265 (HEVC) and example SDP answer for H.265 (HEVC)",
                                    "table number": 94,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.4.7.3\tMTSI client with 848x480 resolution 10 inch display",
                            "text_content": "This example SDP offer is for an MTSI client with 10 inch display that supports 848x480 video and a frame rate of 25 fps. The MTSI client supports H.264 (AVC) Constrained Baseline Profile (CBP) level 3.1 and H.265 (HEVC) Main Profile, Main tier level 3.1. When encoding video with H.264 (AVC), the required bandwidth is 900 kbps, including 48 kbps IPv6/UDP/RTP overhead (4 RTP packets per frame), but when H.265 (HEVC) is used, the encoder uses only 690 kbps, including 36 kbps of overhead (3 RTP packets per frame).\nThe answerer is also an MTSI client that supports H.264 (AVC) and H.265 (HEVC) in the same way as the offerer. The answerer chooses to use the H.265 (HEVC) codec to save bandwidth and therefore sets the bit-rate to 690 kbps.\nTable A.4.20: Example SDP offer for H.264 (AVC) and H.265 (HEVC) and example SDP answer for H.265 (HEVC)\n\nThe SDP offer includes the image sizes that are supported in sending and receiving directions.\nSimilar to the previous examples, the answerer could also have chosen to use H.265 (HEVC) to improve the quality or to use the codec partly to improve the quality and partly to reduce the bit-rate.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.4.20: Example SDP offer for H.264 (AVC) and H.265 (HEVC) and example SDP answer for H.265 (HEVC)",
                                    "table number": 95,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.4.7.4\tMTSI client with 1280x720 resolution 10 inch display",
                            "text_content": "This example SDP offer is for an MTSI client with a 10 inch display that supports 1280x720 video and a frame rate of 25 fps. The MTSI client supports H.264 (AVC) Constrained Baseline Profile (CBP) level 3.1 and H.265 (HEVC) Main Profile, Main tier level 3.1. When encoding video with H.264 (AVC), the required bandwidth is 1060 kbps, including 60 kbps IPv6/UDP/RTP overhead (5 RTP packets per frame), but when H.265 (HEVC) is used, the required bandwidth is only 800 kbps, including 48 kbps overhead (4 RTP packets per frame).\nThe answerer is also an MTSI client that supports H.264 (AVC) and H.265 (HEVC) in the same way as the offerer. The answerer chooses to use the H.265 (HEVC) codec to save bandwidth and therefore sets the bit-rate to 800 kbps.\nTable A.4.21: Example SDP offer for H.264 (AVC) and H.265 (HEVC) and example SDP answer for H.265 (HEVC)\n\nThe SDP offer includes the image sizes that are supported in sending and receiving directions.\nSimilar to the previous examples, the answerer could also have chosen to use H.265 (HEVC) to improve the quality or to use the codec partly to improve the quality and partly to reduce the bit-rate.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.4.21: Example SDP offer for H.264 (AVC) and H.265 (HEVC) and example SDP answer for H.265 (HEVC)",
                                    "table number": 96,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "A.4.8\tH.264 (AVC) and H.265 (HEVC) with asymmetric video streams",
                    "description": "",
                    "summary": "",
                    "text_content": "This example SDP offer shows how an asymmetric video session can be set up. The SDP offer is based on the example SDP offer shown in Annex A.4.7.4 (10 inch display, 1280x720 resolution) with modifications to allow for setting up an asymmetric session where the receive level is higher than the default level. The following video encoding and decoding capabilities apply:\n-\tFor H.264 (AVC):\n-\tThe Constrained Baseline Profile (CBP) is used.\n-\tThe default level is 1.2, max 384 kbps, as shown with ‘profile-level-id=42e00c’. This is then used for the maximum level in the sending direction if H.264 (AVC) is accepted by the answerer.\n-\tThe maximum level in the receiving direction is 3.1, as shown with‘max-recv-level=e01f’.\n-\tAsymmetric session is allowed as shown with ‘level-asymmetry-allowed=1’.\n-\tThe maximum bitrate in the receiving direction is limited to 1060 kbps with ‘b=AS:1060’.\n-\tFor H.265 (HEVC):\n-\tThe Main Profile is used.\n-\tThe default level is 1.0, max128 kbps, as shown with ‘level-id=30’. This is then used for the maximum level in the sending direction if H.265 (HEVC) is accepted by the answerer.\n-\tThe maximum level in the receiving direction is 3.1, as shown with ‘max-recv-level-id=93’.\n-\tAsymmetric session is allowed as shown by including the ‘max-recv-level-id’ parameter.\n-\tThe offerer would like to receive max 800 kbps if H.265 (HEVC) is accepted but there is no possibility to indicate this in the SDP offer.\n\nTable A.4.22: Example SDP offer and answer for asymmetric video with H.264 (AVC) and H.265 (HEVC)\n\nThe SDP offer includes the image sizes that are supported in sending and receiving directions. Different resolutions are offered by including two RTP payload types for H.264 (AVC) and H.265 (HEVC), respectively.\nFor PT=98, the MTSI client in terminal specifies max-recv-level-id=93 since this is needed for 1280x720 resolution. But for PT=97, it specifies max-recv-level-id=90 since this is sufficient for 640x480 resolution.\n",
                    "tables": [
                        {
                            "description": "Table A.4.22: Example SDP offer and answer for asymmetric video with H.264 (AVC) and H.265 (HEVC)",
                            "table number": 97,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.5\tSDP offers and answers for text",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.5.1\tT.140 with and without redundancy",
                    "description": "",
                    "summary": "",
                    "text_content": "An offer to use T.140 real-time text may be realized by using SDP according to the following example in session setup or for addition of real-time text during a session.\nTable A.5.1: Example SDP offer for T.140 real-time text\n\nThe example in table A.5.1 shows that RTP payload type 98 is used for sending text without redundancy, whereas RTP payload type 100 is used for sending text with 200 % redundancy. IPv4 addressing is assumed in the computation of bandwidth values. The \"a=rtt-mixer\" attribute indicates multiparty support.\nAn answer from a device supporting multiparty capability could provide the following SDP:\nTable A.5.2: Example SDP answer for T.140 real-time text with multiparty capability\n\nThe example in table A.5.2 shows an answer with RTP payload type 100 text with 200% redundancy, RTP payload type 98 is used for declaring the \"t140\" format to be carried with redundancy in the \"red\" format. Successful multiparty support negotiation is indicated by the \"a=rtt-mixer\" attribute. Note that the format can be used also for point-to-point sessions.\nAn answer from a device without multiparty capability could provide the following SDP:\nTable A.5.3: Example SDP answer for T.140 real-time text without multiparty capability\n\nThe example in table A.5.3 shows an answer with RTP payload type 100 included by a device for receiving text with 200% redundancy. RTP payload type 98 is used for declaring the \"t140\" format to be carried with redundancy in the \"red\" format. IPv4 addressing is assumed in the computation of bandwidth values. Note that a mixer may send multiparty text to a device without multiparty capability by formatting text for presentation for a multiparty view with some functional limitations.\n",
                    "tables": [
                        {
                            "description": "Table A.5.1: Example SDP offer for T.140 real-time text",
                            "table number": 98,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.5.2: Example SDP answer for T.140 real-time text with multiparty capability",
                            "table number": 99,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.5.3: Example SDP answer for T.140 real-time text without multiparty capability",
                            "table number": 100,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.6\tSDP example with bandwidth information",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.6.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause gives an example where the bandwidth modifiers have been included in the SDP offer. Clause A.6.2 gives some examples with the b=AS, b=RS and b=RR bandwidth modifiers. Clause A.6.3 gives some examples where the SDP are enhanced with the ‘a=bw-info’ attribute defined in clause 19.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.6.2\tSDP examples with bandwidth information declared with bandwidth modifiers",
                    "description": "",
                    "summary": "",
                    "text_content": "Table A.6.1: SDP example with bandwidth information\n\nThe b=AS value indicates the media bandwidth, excluding RTCP, see RFC 3550, section 6.2. On session level, the b=AS value indicates the sum of the media bandwidths, excluding RTCP.\nIn this example, the bandwidth for RTCP is allocated such that it allows for sending at least 2 compound RTCP packets per second when AVPF immediate mode is used. The size of a RTCP Sender Report is estimated to 110 bytes, given IPv4 and point-to-point sessions. The corresponding bandwidth then becomes 1760 bps which means that compound RTCP packets can be sent a little more frequently than twice per second.\nFor speech sessions, the total RTCP bandwidth is set to 4000 bps (2000 bps for each terminal) to give room for adaptation requests with APP packets according to clause 10.2 in at least some of the RTCP messages. This adds 16 bytes to the RTCP packet.\nThe b=AS of AMR, 30, is set in the media level as the larger of the b=AS for bandwidth-efficient payload format, 29, and the b=AS for octet-aligned payload format, 30, with IPv4.\nFor video, the total RTCP bandwidth is set to 5000 bps (2500 bps for each terminal) to give room for slightly more frequent reporting and also to give room for codec-control messages (CCM) [43].\nSetting the RS value to 0 does not mean that senders are not allowed to send RTCP packets. It instead means that sending clients are treated in the same way as receive-only clients, see also RFC 3556 [42].\nThe tcap attribute is in this example given on the session level to avoid repeating it for each media type.\n",
                    "tables": [
                        {
                            "description": "Table A.6.1: SDP example with bandwidth information",
                            "table number": 101,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.6.3\tSDP examples giving additional bandwidth information using the a=bw-info attribute",
                    "description": "",
                    "summary": "",
                    "text_content": "The SDP offer in Table A.6.2 below shows an SDP offer for speech where the MTSI client in terminal include the ‘a=bw-info’ attribute to signal some additional bandwidth properties. This example is based on the SDP offer in Table A.6.1 (only the audio part) with some changes, as described below.\nBoth AMR and AMR-WB are offered with all codec modes and also with both bandwidth-efficient and octet-aligned payload format. The MTSI client in terminal includes the ‘a=bw-info’ attribute both to show that this attribute is supported and to suggest suitable bandwidth properties. The assumptions used for the SDP offer follow the recommendations in clause 6.2.5.2, with the following description and a few changes:\n-\tBandwidth properties for both IPv4 and IPv6 are included. However, the b=AS bandwidth assumes IPv4.\n-\tThe Maximum Supported Bandwidth property suggests that 100% redundancy should be possible. The resource allocation in the networks may reduce this, if needed.\n-\tThe originating MTSI client must set the Maximum Supported Bandwidth and the Maximum Desired Bandwidth properties for AMR-WB to higher values than what is described in clause 6.2.5.2 Table 6.10-2 because it is required to offer all codec modes as described in clause 6.2.2.2 Tables 6.1 and 6.2. This also means that the b=AS bandwidth needs to be set to a higher value. A network in the path may however change the offered mode-sets, in which case it should also modify these bandwidth properties and the b=AS bandwidth.\n-\tThe originating MTSI client can also set the Maximum Supported Bandwidth and the Maximum Desired Bandwidth properties to the same value since offering the full mode sets means that redundancy can be used for both AMR and AMR-WB without allocating any additional bandwidth for this purpose. If a network changes the offset mode-sets, e.g. to AMR-WB {6.6, 8.85, 12.65} then it should modify these bandwidth properties correspondingly, and the Maximum Supported Bandwidth peroperty may then show a higher value than the Maximum Desired Bandwidth.\n-\tThe Maximum Desired Bandwidth property is based on the maximum codec rates without redundancy, i.e. AMR 12.2 and AMR 23.85, respectively.\n-\tIf a network changes the offered mode-sets then this bandwidth peroperty should be modified correspondingly.\n-\tThe Minimum Desired Bandwidth properties are based on AMR 5.9 and AMR-WB 6.6, respectively, without redundancy while still packetizing 1 frame per packet, as described in clause 6.2.5.2.\n-\tThe Minimum Supported Bandwidth properties are based on AMR 4.75 and AMR-WB 6.6, respectively, without redundancy while packing 4 frames per packet, as described in clause 6.2.5.2.\n\nTable A.6.2: SDP example for speech with AMR and AMR-WB with additional bandwidth information signalled with the ‘a=bw-info’ attribute\n\nComments:\nThe most relevant lines are highlighted with bold font.\nSince the SDP offer describes that the session should be symmetric, the ‘sendrecv’ directionality is used to reduce the size of the SDP. It would also have been possible to include separate ‘a=bw-info’ attribute lines with ‘send’ and ‘recv’, respectively.\nThe MinDesBw and MinSupBw bandwidths are the same for AMR with bandwidth-efficient and octet-aligned payload format, which allows for defining them on one ‘a=bw-info’ attribute line for both RTP payload types. However, since the MaxSupBw and MaxDesBw are different for bandwidth-efficient and octet-aligned payload format these bandwidth properties need to be defined on separate attribute lines.\nThe maximum packet rate and minimum packet rate are the same for all payload types and are therefore defined on separate attribute lines to allow for using a wildcard. It would also be possible to have one attribute line for each RTP payload type for these properties but this would in this case be just a waste of bytes.\nThe SDP offer in Table A.6.3 below shows an SDP offer for video where the MTSI client in terminal include the ‘a=bw-info’ attribute to signal some additional bandwidth peroperties. This example is based on the SDP offer in Table 6.1 (only the video part) with some changes, as described below. Bandwidth properties for both IPv4 and IPv6 are included. The conversion factor between IPv4 and IPv6 bandwidths defined in clause 12.7.5 for the b=AS parameter is used also for the additional bandwidth properties.\nThe MTSI client in terminal supports H.264 Constrained Baseline Profile (CBP) with level 3.1 but video is offered with asymmetric video streams, max 1 Mbps for the sending direction and max 2 Mbps for the receiving direction. The maximum bandwidth in the receiving direction can be limited to 2 Mbps with the b=AS bandwidth modifier. However, the b=AS bandwidth modifier cannot be used to describe the limitation for the sending direction. The MTSI client in terminal therefore includes the ‘a=bw-info’ attribute to able to describe the limitation also for the sending direction. Since the Maximum Supported Bandwidth and Maximum Desired Bandwidth properties are different for different the sending and receiving directions it is necessary to describe them using two \"a=bw-info\" attribute lines with directions ‘send’ and ‘recv’, respectively.\nThe MTSI client in terminal also proposes that the Minimum Desired Bandwidth and the Minimum Supported bandwidth based on the QoS examples in Annex E.21 for IPv4 (202 kbps) and in Annex E.22 for IPv6 (208 kbps). These bandwidth properties are the same for both sending and receiving directions, which means the number of lines can be reduced by using the ‘sendrecv’ directionality.\nIncluding the ‘a=bw-info’ also shows to the networks and the remote end-point that this attribute is supported and that other bandwidth modifiers may be added, if needed, even though they are not included in the SDP offer.\nTable A.6.3: SDP example for video with H.264 with additional bandwidth information signalled with the ‘a=bw-info’ attribute\n\nComments:\nThe most relevant lines are highlighted with bold font.\nThe MTSI client in terminal only describes the Maximum Supported Bandwidth and the Maximum Desired Bandwidth properties.\nThe Minimum Desired Bandwidth and the Minimum Supported Bandwidth are left undefined since the MTSI client in terminal can reduce the bitrate virtually down to zero by reducing the frame rate. Since the ‘a=bw-info’ attribute is included in the SDP, the network knows that this attribute is supported and it can then set these bandwidth properties based on the bearer allocation and/or operator policies.\nThe MTSI client in terminal also does not define the maximum and minimum packet rates. The network can still add these bandwidth properties if needed.\n\n",
                    "tables": [
                        {
                            "description": "Table A.6.2: SDP example for speech with AMR and AMR-WB with additional bandwidth information signalled with the ‘a=bw-info’ attribute",
                            "table number": 102,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.6.3: SDP example for video with H.264 with additional bandwidth information signalled with the ‘a=bw-info’ attribute",
                            "table number": 103,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.7\tSDP examples with \"3gpp_sync_info\" attribute",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.7.1\tSynchronized streams",
                    "description": "",
                    "summary": "",
                    "text_content": "In the example given below in table A.7.1, streams identified with \"mid\" attribute 1 and 2 are to be synchronized (default operation if the \"3gpp_sync_info\" attribute is absent).\nTable A.7.1: SDP example with requirement on synchronization\n\n",
                    "tables": [
                        {
                            "description": "Table A.7.1: SDP example with requirement on synchronization",
                            "table number": 104,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.7.2\tNonsynchronized streams",
                    "description": "",
                    "summary": "",
                    "text_content": "The SDP in table A.7.2 gives an example of the usage of \"3gpp_sync_info\" attribute at media level. In this example, there are two H.264 video streams where the first video stream, using port number 6000, should not be synchronized with any other media stream in the session.\nTable A.7.2: SDP example with no requirement on synchronization\n\n",
                    "tables": [
                        {
                            "description": "Table A.7.2: SDP example with no requirement on synchronization",
                            "table number": 105,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.8\tSDP example with QoS negotiation",
            "description": "This clause gives an example of an SDP interchange with negotiated QoS parameters.\nTable A.8.1: SDP example with QoS negotiation\n\nThe example in table A.8.1 shows an SDP exchange that reflects the signalling of negotiated QoS during initial session setup when there is only one PDP context or EPS bearer for the whole session. The first offer-answer procedure is initiated by the MTSI client in terminal A at session setup. The responding MTSI client chose the bandwidth-efficient payload format, by excluding the octet-align parameter, and reduced the bandwidth in b=AS to 29. The second offer-answer procedure is initiated by the MTSI client in terminal B when it receives a different negotiated QoS, only 30 kbps for video, than what was indicated in the first SDP offer from A. To notify A, B sends a new SDP offer, in this case embedded in an UPDATE message, to A indicating the lower negotiated QoS bit rate. The MTSI client in terminal A responds with its negotiated QoS value to B.\nNOTE:\tThe bit rate in the second SDP answer, 48 kbps, was deliberately chosen to show that this is a fully valid SDP answer even though the second SDP offer only defines 30 kbps. It is however recommended that the UEs choose the same bandwidths whenever possible.\nThe SDP offer in the SIP UPDATE message contains only one encoding format since the answerer has already removed all but one encoding format in the SDP answer to the initial SDP offer.\nIn this example it is assumed that the SDPCapNeg framework is not needed in the UPDATE since the RTP profile has already been chosen in the initial invitation.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.8.1: SDP example with QoS negotiation",
                    "table number": 106,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.9\tVoid",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.9a\tSDP offer/answer regarding the use of Reduced-Size RTCP",
            "description": "This example shows the offers and answers for a session between two MTSI clients controlling the use of Reduced-Size RTCP.\nTable A.9a.1: SDP example for Reduced-Size RTCP\n\nComments:\nThis example allows the use of Reduced-Size RTCP (attribute rtcp-rsize) for the adaptation feedback. Moreover the minimum interval between two regular compound RTCP packets is set to 5000 milliseconds.\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.9a.1: SDP example for Reduced-Size RTCP",
                    "table number": 107,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.10\tExamples of SDP offers and answers for inter-working with other IMS or non-IMS IP networks",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.10.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "The session between an MTSI client in a terminal and a client in a remote (IMS or non-IMS) network can be established in many ways, especially when the session is initiated by the remote network and when the remote network does not use the MTSI service.\nThe SDP will also depend on how and when the MTSI MGW chooses to add information about what formats (other than AMR and AMR-WB) that can be used for inter-working. There are, in general, two methods for MTSI MGWs to add information about the alternative formats. The first method is to add the alternative formats to the original SDP offer from the initiating client as a pre-emptive action. The second method is to leave the original SDP offer unchanged, forward it to the remote network and wait for the answerer to respond and only add the alternative formats if/when the SDP offer was rejected. A further complication is that there might be multiple MGWs in the path for this kind of inter-working and different MGWs might work differently.\nThe SDP examples included below should therefore be regarded as a few samples of possible SDPs and should not be regarded as a complete description of what might occur in a real implementation.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.10.2\tSession initiated by MTSI client in terminal",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.10.2.1\tSDP offers from an MTSI client in terminal",
                            "text_content": "The MTSI client in terminal could send an SDP offer as shown in Table A.10.1 (narrow-band speech only) or Table A.10.2 (wide-band and narrow-band speech).\nTable A.10.1: Original SDP offer from an MTSI client in terminal for narrow-band speech\n\nComments:\nThis SDP offer is identical to the SDP offer in Table A.1.1.\nTable A.10.2: Original SDP offer from an MTSI client in terminal for narrow-band and wide-band speech\n\nComments:\nThis SDP offer is identical to the SDP offer in Table A.1.2.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.10.1: Original SDP offer from an MTSI client in terminal for narrow-band speech",
                                    "table number": 108,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.10.2: Original SDP offer from an MTSI client in terminal for narrow-band and wide-band speech",
                                    "table number": 109,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.10.2.2\tSDP offers modified by MTSI MGW when pre-emptively adding inter-working formats",
                            "text_content": "In this example, the MTSI MGW intercepts the SIP INVITE with the original SDP offer from the MTSI client in terminal and adds the codecs and formats that are supported for inter-working before forwarding the SDP offer to the remote network.\nWhen an MTSI MGW pre-emptively adds codecs and formats for inter-working it will also remove lines that it does not support. These examples show an MTSI MGW that does not support AVPF nor SDPCapNeg and it will therefore remove the corresponding lines. The SDP offers could look like the examples included in Table A.10.3 (narrow-band speech only) and Table A.10.4 (wide-band and narrow-band speech).\nTable A.10.3: SDP offer for narrow-band speech which has been modified by the MTSI MGW before it is sent to the remote network\n\nComments:\nThe SDP offer from Table A.10.1 has been modified by adding RTP Payload Types 99 (A-law PCM), 100 (-law PCM) and 101 (linear 16 bit PCM with 8 kHz sampling frequency).\nThe lines \"a=tcap:1 RTP/AVPF\" and \"a=pcfg:1 t=1\" are removed because the MTSI MGW does not support AVPF nor SDPCapNeg in this example.\nTo allow for end-to-end adaptation for AMR and AMR-WB, the MTSI MGW keeps a=maxptime:240.\nIf the remote network supports AMR, then the received SDP answer should contain at least one RTP Payload Type for AMR but there may also be one or more RTP Payload types for non-AMR codecs. In this case, the MTSI MGW does not need to perform transcoding and may forward the SDP offer to the MTSI client in terminal unchanged.\nIf the SDP answer contains no AMR RTP Payload Type then the MTSI MGW needs to perform transcoding to and from the format indicated by the remote network. In this case, the MTSI MGW needs to add AMR to the SDP answer that is sent back to the MTSI client in terminal.\nTable A.10.4: SDP offer for wide-band and narrow-band speech which has been modified by the MTSI MGW before it is sent to the remote network\n\nComments:\nThe SDP offer from Table A.10.2 has been modified by adding RTP Payload Types 101 (G.722), 102 (linear 16 bit PCM with 16 kHz sampling frequency), 103 (A-law PCM), 104 (-law PCM) and 105 (linear 16 bit PCM with 8 kHz sampling frequency).\nNOTE:\tThe sampling frequency for G.722 is 16 kHz but has been set to 8 kHz in the SDP because G.722 was (erroneously) assigned this value in the original version of the RTP A/V profile. Hence, one need to use \"8000\" for backwards compatibility reasons, see also [10].\nThe lines \"a=tcap:1 RTP/AVPF\" and \"a=pcfg:1 t=1\" are removed because the MTSI MGW does not support SDPCapNeg (in this example).\nTo allow for end-to-end adaptation for AMR and AMR-WB, the MTSI MGW keeps a=maxptime:240.\nIf the remote network supports AMR-WB or AMR, then the received SDP answer should contain at least one RTP Payload Type for AMR-WB or AMR but there may also be one or more RTP Payload Types for non-AMR codecs. In this case, the MTSI MGW does not need to perform transcoding and can remove the non-AMR RTP Payload Types before forwarding the SDP answer to the MTSI client in terminal.\nIf the SDP answer contains no AMR-WB or AMR RTP Payload Type then the MTSI MGW needs to perform transcoding to and from the format indicated by the remote network.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.10.3: SDP offer for narrow-band speech which has been modified by the MTSI MGW before it is sent to the remote network",
                                    "table number": 110,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.10.4: SDP offer for wide-band and narrow-band speech which has been modified by the MTSI MGW before it is sent to the remote network",
                                    "table number": 111,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.10.2.3\tSDP modified by MGW when adding inter-working formats only when the original SDP offer was rejected",
                            "text_content": "In this example, the MTSI MGW either forwards the original SDP offer that was received from the MTSI client in terminal to the remote network or it is not involved in the session setup at all until it is concluded that the same codecs are not supported in the different networks. In this latter case, the MTSI MGW is invoked only if the remote network rejects the SDP offer.\nIn this case, when the MTSI MGW sends the (new) SDP offer to the remote network it knows that the AMR (and AMR-WB) codecs are not supported by the remote network because the original SDP offer was rejected. It is therefore unnecessary to include these codecs in the (new) SDP offer. The SDP offers could look like the examples included in Table A.10.5 (narrow-band speech only) and Table A.10.6 (wide-band and narrow-band speech).\nThe remote client may also suggest codecs and configurations when it rejects the SDP offer. Existence of such information can, of course, be used to increase the likelihood that the session setup will be successful. These SDP examples are however designed for the case when no such information is available from the remote network.\nTable A.10.5: New SDP offer for narrow-band speech sent by the MTSI MGW to the remote network\n\nComments:\nThe new SDP offer includes RTP Payload Types 99 (A-law PCM), 100 (-law PCM) and 101 (linear 16 bit PCM with 8 kHz sampling frequency).\nIn this case, the maxptime is set to 80, if the MTSI MGW does not support redundancy.\nTable A.10.6: New SDP offer for narrow-band and wide-band speech sent by the MTSI MGW to the remote network\n\nComments:\nThe new SDP offer includes RTP Payload Types 101 (G.722), 102 (linear 16 bit PCM with 16 kHz sampling frequency), 103 (A-law PCM), 104 (-law PCM) and 105 (linear 16 bit PCM with 8 kHz sampling frequency).\nNOTE:\tThe sampling frequency for G.722 is 16 kHz but has been set to 8 kHz in the SDP because G.722 was (erroneously) assigned this value in the original version of the RTP A/V profile. Hence, one need to use \"8000\" for backwards compatibility reasons, see also [10].\nIn this case, the maxptime is set to 80, if the MTSI MGW does not support redundancy.\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.10.5: New SDP offer for narrow-band speech sent by the MTSI MGW to the remote network",
                                    "table number": 112,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.10.6: New SDP offer for narrow-band and wide-band speech sent by the MTSI MGW to the remote network",
                                    "table number": 113,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "title": "A.11\tAdding or removing a video component to/from an on-going video call session",
            "description": "The MTSI client in a terminal can add, remove and modify the media components during an ongoing MTSI session. This clause describes the SDP offer in the initial SIP INVITE message, see Table A.11.1, and the SDP in the subsequent re-INVITE or UPDATE message for adding and removing a video stream to/from the ongoing MTSI video call session, see Table A.11.2 and Table A.11.3, respectively. Corresponding SDP answers in the SIP 200/OK responses are also described.\nThe initial video call session contains one video component and one speech component. During the session, the MTSI client in terminal A adds a uni-directional video component (such as one video clip) to the ongoing video call session. The SDP content attribute \"a=content:main\" and \"a=content:alt\" are used to label the main and alternative video components respectively [81].\nThis example does not show how to use the content attribute in combination with the grouping attribute, nor does it show how to use the content attribute in combination with the synchronization attribute defined in Clause 6.2.6.\nTable A.11.1: SDP offer/answer for setting up a video telephony session\n\nTable A.11.2: Second SDP offer/answer for adding one more video component\n\nTable A.11.3: Second SDP offer/answer for removing the video component\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.11.1: SDP offer/answer for setting up a video telephony session",
                    "table number": 114,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.11.2: Second SDP offer/answer for adding one more video component",
                    "table number": 115,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.11.3: Second SDP offer/answer for removing the video component",
                    "table number": 116,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.12\tSDP examples when using ECN",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.12.1\tSDP examples when using ECN for speech",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.12.1.1\tWith RTP/AVP and zero RTCP bandwidth",
                            "text_content": "The following SDP offer and SDP answer are likely when both MTSI clients in terminals use ECN for speech.\nThis SDP example is based on the SDP example found in Table A.3.0 except that bandwidth information for the media has been added, zero RTCP bandwidth has been negotiated, and AVPF is not offered.\nTable A.12.1.1: SDP example\n\nComments:\nThe SDP offer includes the SDP attribute ‘ecn-capable-rtp’ to indicate that ECN is supported. The SDP offer further includes the parameters: ‘leap’ to indicate that the leap-of-faith initiation method is to be used; and ‘ect=0’ to request that the other endpoint sets the ECN bits to ECT(0). The SDP offer does not include the \"rtcp-fb\" attribute for negotiating use of the RTCP AVPF ECN feedback messages [84]. This results in RTP CMR [28] being used as the application specific feedback for ECN-triggered adaptation. The SDP offer also proposes to not use RTCP for the session.\nThe SDP answer is configured in the same way as in the offer to indicate that the ECN usage and its configuration is agreeable to be used in the session.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.12.1.1: SDP example",
                                    "table number": 117,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.12.1.2\tWith RTP/AVPF and non-zero RTCP bandwidth",
                            "text_content": "This SDP example is based on the SDP example found in Table A.3.0 except that bandwidth information for the media has been added. The negotiation of Reduced-Size RTCP is added together with the ECN negotiation. Non-zero RTCP bandwidth and AVPF have also been negotiated.\nTable A.12.1.2: SDP example\n\nComments:\nThe SDP offer includes the SDP attribute ‘ecn-capable-rtp’ to indicate that ECN is supported. The SDP offer further includes the parameters: ‘leap’ to indicate that the leap-of-faith initiation method is to be used; and ‘ect=0’ to request that the other endpoint sets the ECN bits to ECT(0).  The SDP offer does not include the \"rtcp-fb\" attribute for negotiating use of the RTCP AVPF ECN feedback messages [84].  This results in RTCP-APP CMR and reduced-size RTCP being used as the application specific feedback for ECN-related adaptation.\nThe SDP answer is configured in the same way as in the offer to indicate that the ECN usage and its configuration is agreeable to be used in the session.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.12.1.2: SDP example",
                                    "table number": 118,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.12.1.3\tWith RTCP ECN feedback messages and RTCP XR ECN summary reports for inter-working with non-MTSI clients",
                            "text_content": "The following SDP offer and SDP answer are possible when an MTSI client is inter-working with non-MTSI clients and when the MTSI client supports RTCP AVPF ECN feedback messages and RTCP XR ECN summary reports.\nTable A.12.1.3: SDP example\n\nComments:\nThe SDP offer is similar to the offer in Table A.12.2. The line \"a=rtcp-fb:* nack ecn\" is included to indicate that the RTCP AVPF ECN feedback messages can be used by all payload types for speech. The line \"a=rtcp-xr:ecn-sum\" is included to indicate that the RTCP XR ECN summary reports can also be used.\nSince the offering MTSI client supports the RTCP AVPF ECN feedback messages and RTCP XR ECN summary reports there is no need to insert any media gateway in the path to solve inter-working.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.12.1.3: SDP example",
                                    "table number": 119,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "A.12.2\tSDP examples when using ECN for video in RTP",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.12.2.1\tWithout RTCP AVPF ECN feedback messages and RTCP XR ECN summary reports",
                            "text_content": "The following SDP offer and SDP answer are likely when both MTSI clients in terminals use ECN for video and TMMBR for rate adaptation.\nThis SDP example is the same as the SDP example found in Tables A.4.4b and A.4.4c, except that the negotiation for ECN has been added.\nTable A.12.2.1: Example SDP offer for H.264 video with ECN\n\nComments:\nThe SDP offer includes the SDP attribute ‘ecn-capable-rtp’ to indicate that ECN is supported. The SDP offer further includes the parameters: ‘leap’ to indicate that the leap-of-faith initiation method is to be used; and ‘ect=0’ to request that the other endpoint sets the ECN bits to ECT(0).\nThe SDP offer also includes an offer for AVPF to enable sending adaptation requests without following the normal rules for RTCP transmission intervals. TMMBR is also offered to indicate that this can be used for rate adaptation.\nThe SDP answer is configured in the same way as in the offer to indicate that the ECN usage and its configuration is agreeable to be used in the session.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.12.2.1: Example SDP offer for H.264 video with ECN",
                                    "table number": 120,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.12.2.2\tWith RTCP AVPF ECN feedback messages and RTCP XR ECN summary reports for inter-working with non-MTSI clients",
                            "text_content": "The following SDP offer and SDP answer are possible when an MTSI client is inter-working with non-MTSI clients not supporting TMMBR and when the MTSI client supports RTCP AVPF ECN feedback messages and RTCP XR ECN summary reports.\nThis SDP example is the same as the SDP example found in Tables A.4.4b and A.4.4c, except that the negotiation for ECN has been added.\nTable A.12.2.2: Example SDP offer for H.264 video with ECN\n\nComments:\nThe SDP offer is similar to the offer in Table A.12.2.1. The line \"a=rtcp-fb:* nack ecn\" is included to indicate that the RTCP AVPF ECN feedback messages can be used all payload types for video. The line \"a=rtcp-xr:ecn-sum\" is included to indicate that the RTCP XR ECN summary reports can also be used.\nThe answering client does not support TMMBR and full intra requests and therefore removes these attribute lines when creating the SDP answer.\nSince the offering MTSI client supports the RTCP AVPF ECN feedback messages and RTCP XR ECN summary reports there is no need to insert any media gateway in the path to provide inter-working.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.12.2.2: Example SDP offer for H.264 video with ECN",
                                    "table number": 121,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "title": "A.13\tSDP examples for MTSI client in terminal using fixed access",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.13.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause includes SDP examples that may be applicable to an MTSI client in terminal using fixed access. The SDP examples in Annex A.13.2 to A.13.6 show SDPs including PCM, G.729, G.722 and G.729.1. Examples of SDP offers for the AMR and AMR-WB codecs are described in Annex A.1 and the corresponding examples of SDP answers are found in Annex A.3. SDP examples for EVRC, EVRC-B and EVRC-WB are found in [97].\nExamples of SDP offer and answer for video are described in Annex A.4.\nAn example for an SDP offer for real-time text is described in Annex A.5.\nThese examples also include bandwidth information which is calculated assuming IPv6 and 20 ms packetization.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.13.2\tSDP examples for PCM",
                    "description": "",
                    "summary": "",
                    "text_content": "Table A.13.1 shows an example for the SDP offer and answer negotiation for PCM. The SDP offer uses the static payload type numbers that are defined in RFC 3551 [10] for PCM, i.e. payload type number 0 for -law PCM and payload type number 8 for A-law PCM, see also Clause 18.4.3. Since static payload type numbers are used, as shown on the m= line, then there is no need for adding any a=rtpmap attribute lines. The answerer chooses to accept A-law PCM and therefore sends an SDP answer with RTP payload type number 8 on the m= line.\nTable A.13.1: SDP example for PCM\n\nComments:\nThe SDPs further describe that the clients prefer to receive speech with 20 ms packetization (ptime is set to 20) but up to 240 ms packetization is allowed.\nTable A.13.2 shows an example for how the PCM codec can be negotiated using dynamic payload type numbers. In this case, payload type number 96 is used for -law PCM and payload type number 97 is used for A-law PCM. The answerer chooses to accept -law PCM.\nTable A.13.2: SDP example for PCM\n\nComments:\nThis example is included here to show that it is possible to use dynamic payload type numbers also for codecs for which static payload type numbers have been defined. It is however preferable to use static payload type numbers, see Clause 18.4.3.\n",
                    "tables": [
                        {
                            "description": "Table A.13.1: SDP example for PCM",
                            "table number": 122,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table A.13.2: SDP example for PCM",
                            "table number": 123,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.13.3\tSDP example for G.722",
                    "description": "",
                    "summary": "",
                    "text_content": "Table A.13.3 shows an example for how G.722 can be negotiated using the static payload type number (9) defined in RFC 3551 [10], see also Clause 18.4.3.\nTable A.13.3: SDP example for G.722\n\nComments:\nThe G.722 codec uses an RTP clock rate of 8 kHz even though G.722 is a wideband speech codec that uses a sampling frequency of 16 kHz. This means that the RTP Time Stamp is sampled with 8 kHz.\nThe SDPs further describe that the clients prefer to receive speech with 20 ms packetization (ptime is set to 20) but up to 240 ms packetization is allowed.\n",
                    "tables": [
                        {
                            "description": "Table A.13.3: SDP example for G.722",
                            "table number": 124,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "A.13.4\tSDP example for EVS, AMR-WB, G.722, AMR, PCM and DTMF",
                    "description": "",
                    "summary": "",
                    "text_content": "Table A.13.4 shows an example where an MTSI client in terminal using fixed access has been developed to support fixed-mobile interworking without the need for transcoding in a media gateway. It therefore supports the G.722 and PCM codecs that are normally used in fixed networks. In addition, it also supports the AMR-WB and AMR codecs in the same way as an MTSI client in terminal using mobile access would do. The SDP offer includes all these codecs as well as DTMF.\nTable A.13.4: SDP example for EVS, AMR-WB, G.722, AMR, PCM and DTMF\n\nComments:\nThe wideband codecs (AMR-WB and G.722) are listed as preferred over the narrowband codecs (AMR and PCM). This ensures that a wideband service will be set up whenever possible.\nThe AMR and AMR-WB codecs are listed here as preferred over the PCM and G.722 codecs, respectively, because of their lower bitrate and also because of their bitrate adaptation capabilities.\nThe SDP offer includes DTMF with both 8 kHz and 16 kHz RTP clock rate since there are codecs with both clock rates in the offer. An answerer is expected to accept the DTMF variant that has the same clock rate as for the accepted codec. This means that when G.722 is accepted then DTMF with 8 kHz clock rate should also be accepted, even though G.722 is a wideband speech codec. This is because G.722 uses 8 kHz clock rate, see RFC3551 [10].\nSince the clock rate of EVS is set to 16 kHz, regardless of the bandwidth in the session, DTMF with 16 kHz RTP clock rate should be accepted when EVS is accepted.\n",
                    "tables": [
                        {
                            "description": "Table A.13.4: SDP example for EVS, AMR-WB, G.722, AMR, PCM and DTMF",
                            "table number": 125,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "A.14\tSDP offers and answers for speech sessions with EVS",
            "description": "These examples show SDP offers and answers for speech sessions where EVS is negotiated. These SDP offer and answer examples are designed to highlight the respective area that is being described and should therefore not be considered as complete SDP offers and answers.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "A.14.1\tSDP offers initiated by MTSI client in terminal",
                    "description": "",
                    "summary": "",
                    "text_content": "The SDP offers below can be used by MTSI client in terminal, depending on the access technology or the number of audio channels.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.14.1.1\tUnknown access technology",
                            "text_content": "When the access technology is unknown to MTSI client in terminal, the SDP offer below can be used to initiate a speech session. In this example, RTP Payload Type 97 is defined for EVS, and two sets of RTP Payload Types, 98 and 99, and 100 and 101 are defined for AMR-WB and AMR respectively.\nTable A.14.1: SDP example\n\nComments:\nSince the MTSI client in terminal is not aware of the access technology it uses, all bit-rates of EVS are offered in the session.\nThe MTSI client in terminal supports all bandwidths, up to fullband.\nRegardless of the bandwidth used in the session, clock rate of EVS shall be set to 16 kHz.\nMedia level b=AS is computed for the highest bit-rate of EVS, 128 kbps, with IPv4 and Header-full payload format, which is greater than the b=AS values of other RTP Payload Types.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.1: SDP example",
                                    "table number": 126,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.1.2\tEGPRS",
                            "text_content": "When the access technology is EGPRS, the SDP offer below can be used to initiate a speech session. In this example, RTP Payload Type 97 is defined for EVS, and two sets of RTP Payload Types, 98 and 99, and 100 and 101 are defined for AMR-WB and AMR respectively.\nTable A.14.2: SDP example\n\nComments:\nIt is assumed that the modulation and coding scheme (MCS) of EGPRS used in this session is MCS-7 [132] or higher, which supports at least 44.8 kbps. The bit-rate available for data will be reduced further from the overhead for RLC and MAC headers.\nAll bit-rates of EVS from 5.9 (SC-VBR) to 24.4 kbps are offered in the session.\nThe MTSI client in terminal supports narrowband and wideband.\nMedia level b=AS is computed for 24.4 kbps of EVS with Header-full payload format, or for 23.85 which results in a b=AS value of 33 kbps. MCS lower than MCS-7 would necessitate the use of mode-set parameter for AMR-WB as MCS-6 supports only 29.6 kbps. However, higher MCS values would leave lower overhead for channel coding.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.2: SDP example",
                                    "table number": 127,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.1.3\tNR/E-UTRAN/HSPA",
                            "text_content": "When the access technology is E-UTRAN or HSPA, the SDP offer below can be used to initiate a speech session. In this example, RTP Payload Type 97 is defined for EVS, and two sets of RTP Payload Types, 98 and 99, and 100 and 101 are defined for AMR-WB and AMR respectively.\nTable A.14.3: SDP example\n\nComments:\nIt is assumed that 42 kbps is reserved for speech by the radio access technology.\nAll bit-rates of EVS from 5.9 (SC-VBR) to 24.4 kbps are offered in the session.\nThe MTSI client in terminal supports all bandwidths, up to super-wideband.\nMedia level b=AS is computed for 24.4 kbps of EVS with Header-full payload format.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.3: SDP example",
                                    "table number": 128,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.1.4\tDual-mono",
                            "text_content": "When dual-mono is offered, the SDP offer below can be used to initiate a speech session. In this example in Table A.14.4a, RTP Payload Types 97 and 98 are defined for EVS, and two sets of RTP Payload Types, 99 and 100, and 101 and 102 are defined for AMR-WB and AMR respectively.\nTable A.14.4a: SDP example\n\nComments:\nIt is assumed that 50 kbps is reserved for speech by the radio access technology.\nDual-mono session consisting of two 16.4 kbps SWB channels is offered for the send and the receive directions.\nIn addition, all bit-rates of EVS from 5.9 (SC-VBR) to 24.4 kbps are offered in the session. Channel-aware mode is disabled in the session for the receiving direction.\nMedia level b=AS is computed for a dual-mono session including 16.4 kbps of EVS with IPv4 and Header-full payload format which results in a b=AS value of  50 kbps.\n\nIn the example in Table A.14.4b, RTP Payload Types 97 and 98 are defined for EVS, and two sets of RTP Payload Types, 99 and 100, and 101 and 102 are defined for AMR-WB and AMR respectively.\nTable A.14.4b: SDP example\n\nComments:\nIt is assumed that 66 kbps is reserved for speech by the radio access technology.\nDual-mono session consisting of two NB-SWB channels is offered for the send and the receive directions. All bit-rates of EVS from 13.2 to 24.4 kbps are offered in the session. Partial redundancy (channel-aware mode) is used at the start of the session for the receive direction.\nMedia level b=AS is computed for a dual-mono session including 24.4 kbps of EVS with IPv4, Header-full payload format which results in a b=AS value of 66 kbps.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.4a: SDP example",
                                    "table number": 129,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table A.14.4b: SDP example",
                                    "table number": 130,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "A.14.2\tSDP offers initiated by media gateway",
                    "description": "",
                    "summary": "",
                    "text_content": "The SDP offer below can be used by media gateway.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.14.2.1\tNetwork between MTSI using fixed access and MTSI modifying SDP offer to configure EVS AMR-WB IO mode",
                            "text_content": "This example shows the SDP offer when the session is initiated from MTSI client in terminal using fixed access, which supports AMR (all modes) and AMR-WB (all modes). In addition, EVS, G.722, and PCM codecs are supported by the MTSI client in terminal.\nThe offers for AMR, AMR-WB and EVS codecs are changed by the network to include AMR {12.2, 7.4, 5.9, 4.75}, AMR-WB {12.65, 8.85, 6.60}, EVS AMR-WB IO {12.65, 8.85, 6.60}. For payload type 98, the network also changes the offer to start the session with EVS in EVS AMR-WB IO mode if it is agreed to use the codec.\nFor EVS, RTP Payload Types 97 and 98 are defined, for example, to initiate a speech session with another MTSI client in terminal using fixed access supporting a bit-rate of 64 kbps or radio access supporting all bit-rates from 5.9 to 24.4 kbps respectively.\nThe MTSI client in terminal does not include the evs-mode-switch parameter in the initial SDP offer, see Table 6.2a. The SDP is instead changed by the network.\nTable A.14.5: SDP example\n\nComments:\nFor EVS, narrowband and wideband are supported for Payload Type 98 while only wideband is supported for Payload Type 97.\nIf Payload Type 97 is negotiated, EVS Primary mode will be used at the start or update of the session, at 64 kbps wideband. EVS AMR-WB IO mode can be used in the middle of session, which can be switched by the sender, or the receiver with CMR.\nIf Payload Type 98 is negotiated, EVS AMR-WB IO mode will be used at the start or update of the session, at 6.60, 8.85, or 12.65 kbps.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.5: SDP example",
                                    "table number": 131,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "A.14.3\tSDP answers from MTSI client in terminal",
                    "description": "",
                    "summary": "",
                    "text_content": "The SDP answers below can be used by MTSI client in terminal, depending on access technology or service policy. It is assumed that SDP offers such as Tables A.14.1, A.14.2, A.14.3, A.14.4, or A.14.5 are received.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.14.3.1\tSDP answer from MTSI client in terminal when narrowband speech is negotiated",
                            "text_content": "In this example, the MTSI client in terminal includes only narrowband speech in the SDP answer.\nTable A.14.6: SDP example\n\nComments:\nThe SDP answer contains all bit-rates from 5.9 to 13.2 kbps, with IPv4 for the send and the receive directions.\nMedia level b=AS is computed for 13.2 kbps of EVS Primary mode, or 12.65 kbps of EVS AMR-WB IO mode, with Header-full payload format, either of which results in 30 kbps.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.6: SDP example",
                                    "table number": 132,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.3.2\tSDP answer from MTSI client in terminal when up to wideband speech is negotiated",
                            "text_content": "In this example, the MTSI client in terminal includes narrowband and wideband speech in the SDP answer.\nTable A.14.7: SDP example\n\nComments:\nThe SDP answer contains all bit-rates from 7.2 to 32 kbps, with IPv4 for the send and the receive directions.\nAs neither br-send nor br-recv of the SDP answer includes 5.9 kbps, source controlled variable bit-rate (SC-VBR) coding is not used for the session.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.7: SDP example",
                                    "table number": 133,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.3.3\tSDP answer from MTSI client in terminal when only wideband speech is negotiated",
                            "text_content": "In this example, the MTSI client in terminal includes only wideband speech in the SDP answer.\nTable A.14.8: SDP example\n\nComments:\nThe SDP answer contains all bit-rates from 9.6 to 32 kbps, with IPv4 for the send and the receive directions.\nIn EVS AMR-WB IO mode, only 6.60, 8.85, and 12.65 kbps are used.\nOnly Header-full format is used in the session.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.8: SDP example",
                                    "table number": 134,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.3.4\tSDP answer from MTSI client in terminal when up to super-wideband speech is negotiated",
                            "text_content": "In this example, the MTSI client in terminal includes narrowband, wideband, and super-wideband speech in the SDP answer.\nTable A.14.9: SDP example\n\nComments:\nThe SDP answer contains bit-rates from 8 to 48 kbps for the send direction, and bit-rates from 32 to 48 kbps for the receive direction, with IPv4.\nThe SDP answer contains bandwidths from narrowband to super-wideband for the sending direction, and only super-wideband for the receiving direction.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.9: SDP example",
                                    "table number": 135,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.3.5\tSDP answer from MTSI client in terminal when only super-wideband speech is negotiated",
                            "text_content": "In this example, the MTSI client in terminal includes only super-wideband speech in the SDP answer.\nTable A.14.10: SDP example\n\nComments:\nThe SDP answer contains bit-rates from 16.4 to 48 kbps, with IPv4 for the send and the receive directions.\nCMR is not used in this session.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.10: SDP example",
                                    "table number": 136,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.3.6\tSDP answer from MTSI client in terminal using WLAN",
                            "text_content": "This example shows the SDP answer when the MTSI client in terminal is using WLAN as the access technology.\nTable A.14.11: SDP example\n\nComments:\nThe SDP answer contains all bit-rates from 13.2 to 32 kbps, with IPv4 for the send and the receive directions. Channel-aware mode with offset 3 is enabled for the receiving direction.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.11: SDP example",
                                    "table number": 137,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.3.7\tSDP answer from MTSI client in terminal supporting dual-mono",
                            "text_content": "This example shows the SDP answer when the MTSI client in terminal supports dual-mono.\nTable A.14.12: SDP example\n\nComments:\nThe SDP answer contains a dual-mono session consisting of two 16.4 kbps SWB channels, for the send and the receive directions, with IPv4.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.12: SDP example",
                                    "table number": 138,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.3.8\tSDP answer from MTSI client in terminal supporting dual-mono for send direction",
                            "text_content": "This example shows the SDP answer when the MTSI client in terminal supports dual-mono only for the send direction.\nTable A.14.13: SDP example\n\nComments:\nThe SDP answer contains a dual-mono session consisting of two 16.4 kbps SWB channels for the send direction, and a mono session consisting of 24.4 kbps for the receive direction, with IPv4.\nIn the usage of the channels parameter, \"/n,\" n represents the number of audio channels, see [125].\n‘ch-send=2’ indicates that the answerer will include two audio channels (dual-mono) in the RTP packets in the sending direction, see Clause 7.5.2.1.9. ‘ch-recv=1’ indicates that the answerer expects that only one audio channel will be included in the RTP packets in the receiving direction.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.13: SDP example",
                                    "table number": 139,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.3.9\tSDP answer from MTSI client in terminal when SC-VBR is negotiated",
                            "text_content": "In this example, the MTSI client in terminal includes narrowband and wideband speech in the SDP answer. This SDP answer is used to negotiate the lowest possible bit-rate of EVS Primary, for example, due to limited network capacity.\nTable A.14.13a: SDP example\n\nComments:\nMedia level b=AS of SC-VBR is computed for the b=AS of its highest component bit-rate, 8 kbps. Therefore br=5.9, 5.9-7.2, and 5.9-8 result in the same b=AS value of 25, with IPv4.\nIf frame aggregation is not used, no codec mode of EVS AMR-WB IO other than 6.6 kbps can be used at this b=AS value, whether mode-set is included or not,\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.13a: SDP example",
                                    "table number": 140,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "A.14.4\tSDP answers from MTSI client in terminal using fixed access",
                    "description": "",
                    "summary": "",
                    "text_content": "These examples show the SDP answers when the MTSI client in terminal is using fixed access.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "A.14.4.1\tSDP answer from MTSI client in terminal using fixed access when narrowband speech is negotiated",
                            "text_content": "In this example, the MTSI client in terminal includes only narrowband speech in the SDP answer.\nTable A.14.14: SDP example\n\nComments:\nThe SDP answer contains only 13.2 kbps.\nDTX is disabled in the session.\nMedia level b=AS with IPv4 is computed for 13.2 kbps of EVS Primary mode, or 12.65 kbps of EVS AMR-WB IO mode, with Header-full payload format, either of which results in 30 kbps.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.14: SDP example",
                                    "table number": 141,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.4.2\tSDP answer from MTSI client in terminal using fixed access when only wideband speech is negotiated",
                            "text_content": "In this example, the MTSI client in terminal includes only wideband speech in the SDP answer.\nTable A.14.15: SDP example\n\nComments:\nThe SDP answer contains only 64 kbps.\nDTX is disabled in the session.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.15: SDP example",
                                    "table number": 142,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "A.14.4.3\tSDP answer from MTSI client in terminal using fixed access when only super-wideband speech is negotiated",
                            "text_content": "In this example, the MTSI client in terminal includes only super-wideband speech in the SDP answer.\nTable A.14.16: SDP example\n\nComments:\nThe SDP answer contains only 96 kbps.\nDTX is disabled in the session.\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table A.14.16: SDP example",
                                    "table number": 143,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "title": "A.15\tSDP offers and answers with ANBR capability signaling",
            "description": "Table A.15.1 demonstrates an example SDP offer with Access Network Bitrate Recommendation (ANBR) capability signalling defined in clause 6.2.9 for speech. The offer for ANBR capability signaling is indicated in the last line via the SDP attribute ‘anbr’.\nTable A.15.1: Example SDP offer with ANBR capability signalling for speech\n\nAn example SDP answer is shown in Table A.15.2, where the ANBR capability signalling is also supported by the answerer, as indicated by the last line.\nTable A.15.2: Example SDP answer with ANBR capability signalling for speech\n\nTable A.15.3 demonstrates another example SDP offer with ANBR capability signalling, this time for video.\nTable A.15.3: Example SDP offer with ANBR capability signalling for video\n\nThe corresponding example SDP answer is shown in Table A.15.4, where the ANBR capability signalling is also supported by the answerer, as indicated by the last line.\nTable A.15.4: Example SDP answer with ANBR capability signalling for video\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.15.1: Example SDP offer with ANBR capability signalling for speech",
                    "table number": 144,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.15.2: Example SDP answer with ANBR capability signalling for speech",
                    "table number": 145,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.15.3: Example SDP offer with ANBR capability signalling for video",
                    "table number": 146,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.15.4: Example SDP answer with ANBR capability signalling for video",
                    "table number": 147,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.16\tSDP offers and answers with QoS hint signalling",
            "description": "Table A.16.1 demonstrates an example SDP offer with QoS hint signalling defined in clause 6.2.7.4. The offer for QoS hint signalling is indicated in the last line via the SDP attribute ‘3gpp-qos-hint’.\nTable A.16.1: Example SDP offer with QoS hint signalling\n\nAn example SDP answer is shown in Table A.16.2, where the QoS hint signalling is also supported by the answerer, as indicated by the last line.\nTable A.16.2: Example SDP answer with QoS hint signalling\n\nTable A.16.3 demonstrates an example SDP offer with QoS hint signalling defined in clause 6.2.7.4, using explicit split of the end-to-end values. The offer suggests itself to use less than half of the end-to-end loss, but more than half of the end-to-end latency in the SDP attribute ‘3gpp-qos-hint’.\nTable A.16.3: Example SDP offer with QoS hint signalling and explicit split\n\nTable A.16.4 demonstrates another example SDP answer where the QoS hint signalling is also supported by the answerer, but where neither the desired QoS hint end-to-end values nor the QoS hint split values from the SDP offer can be supported and are changed in the SDP answer.\nTable A.16.4: Example SDP answer with QoS hint signalling changing QoS hint values and split\n\nThe resulting loss hint is 0.05% for both SDP offerer and SDP answerer (half of the provided end-to-end value), which is a significant relaxation in loss rate compared to the offer in Table A.16.3 that might not be sufficient to provide an acceptable user experience. The resulting latency hint is 400 ms (500-100) for the SDP offerer and 100 ms for the SDP answerer, which is stricter end-to-end than the offer in Table A.16.3, but the answerer takes on the stricter latency and leaves the offerer part of the split from the offer (400 ms) unmodified.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.16.1: Example SDP offer with QoS hint signalling",
                    "table number": 148,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.16.2: Example SDP answer with QoS hint signalling",
                    "table number": 149,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.16.3: Example SDP offer with QoS hint signalling and explicit split",
                    "table number": 150,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.16.4: Example SDP answer with QoS hint signalling changing QoS hint values and split",
                    "table number": 151,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.17\tSDP offers and answers with data channel capability signalling",
            "description": "The ellipsis (\"...\") in the examples in this clause is not part of the SDP but indicates possible presence of other media descriptions in addition to the ones shown in the examples.\nTable A.17.1 demonstrates an example SDP offer with data channel capability signalling for the \"bootstrap\" data channel defined in clause 6.2.10. The offering part is an ICE Lite agent, indicated by \"a=ice-lite\" on SDP session level (i.e., before first m= line), and thus only offers host candidates, in this example a single host candidate aligned with address information on the corresponding m= and c= lines.\nTable A.17.1: Example SDP offer with data channel capability signalling\n\nAn example SDP answer is shown in Table A.17.2, where the data channel capability signalling from Table A.17.1 is also supported and accepted by the answerer, as indicated by the non-zero port on the m= line. The answering part is an ICE Lite agent, indicated by \"a=ice-lite\" on SDP session level, and only supports ICE according to the predecessor ICE specification to [184] as indicated by no \"a=ice-options:ice2\" being included on SDP session level.\nTable A.17.2: Example SDP answer with data channel capability\n\nTable A.17.3 demonstrates an example SDP offer with multiple possible data channel application sources for the \"bootstrap\" data channel defined in Table 6.2.10.1-2. In this example, the offering part supports full ICE, indicated by no \"a=ice-lite\" on SDP session level.\nTable A.17.3: Example SDP offer with multiple data channel application sources\n\nAn example SDP answer is shown in Table A.17.4, where only one of the data channel application sources from the offer in Table A.17.3 is accepted by the answerer, removing the other a=dcmap lines.\nFigure 6.2.10.1-3 in clause 6.2.10.1 may be used as illustration to this example, in which case UE A in that Figure would send the offer in Table A.17.3, and UE B would send the answer in Table A.17.4.\nIn this SDP answer, the answerer (UE B) only accepts stream ID 110 to receive the data channel application from the offerer (UE A), but UE B has rejected to use any other data channel application provider.\nTable A.17.4: Example UE SDP answer choosing a single data channel application source\n\nFigure 6.2.10.1-3 in clause 6.2.10.1 may be used as illustration also to the example in Table A.17.5, in which case UE A in Figure 6.2.10.1-3 would send the offer in Table A.17.3, and the SDP answer sent back to UE A from the network would be the one in Table A.17.5.\nIn the SDP answer in Table A.17.5 sent from UE A’s (local) network, it is accepting stream ID 10 that would be used by UE A to receive its own, chosen data channel application, corresponding to the data channel application sent to UE B in stream ID 110 based on the SDP answer in Table A.17.4 such that both UEs can use the same application. That application is however received through different stream IDs for UE A and UE B, as shown in Figure 6.2.10.1-3.\nTable A.17.5: Example network SDP answer choosing a single data channel application source\n\nTable A.17.6 demonstrates an example SDP (re-)offer that adds two non-bootstrap data channel streams used by the data channel application in the bootstrap data channel in Table A.17.5. The data channel application streams (two in this example) desire specific loss and latency characteristics indicated by the \"a=3gpp-qos-hint\" line (see also Annex A.16). and are offered as a separate m= line due to having different QoS requirements and different destination (e.g. a peer UE) than the bootstrap data channel. The stream with ID 38754 has a strict latency requirement and data older than 150 ms will not be transmitted or re-transmitted. The stream with ID 7216 requires lower loss but can accept somewhat higher latency than stream ID 38754 and therefore allows at most 5 SCTP-level retransmissions.\nTable A.17.6: Example SDP offer with data channel application streams\n\nTable A.17.7 demonstrates an example SDP offer that is transferred from User A’s network (the originating network) to User B’s network (the terminating network). There are two bootstrap data channels with stream ID 100 in the SDP offer, one is marked by \"a=3gpp-bdc-used-by:sender\" line which means it is established between User A and User B’s network, the other is marked by \"a=3gpp-bdc-used-by:receiver\" line which means it is established between User A’s network and User B.\nTable A.17.7: Example SDP offer with two bootstrap data channels with stream ID 100\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.17.1: Example SDP offer with data channel capability signalling",
                    "table number": 152,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.17.2: Example SDP answer with data channel capability",
                    "table number": 153,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.17.3: Example SDP offer with multiple data channel application sources",
                    "table number": 154,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.17.4: Example UE SDP answer choosing a single data channel application source",
                    "table number": 155,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.17.5: Example network SDP answer choosing a single data channel application source",
                    "table number": 156,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.17.6: Example SDP offer with data channel application streams",
                    "table number": 157,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.17.7: Example SDP offer with two bootstrap data channels with stream ID 100",
                    "table number": 158,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.18\tSDP offers and answers for ITT4RT",
            "description": "Table A.18.1 shows an example of an SDP offer for an ITT4RT session with a 360 video, 2 overlay streams, and a scene description.\nTable A.18.1: Example SDP offer with scene description signalling\n\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.18.1: Example SDP offer with scene description signalling",
                    "table number": 159,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "AA.1\tIntroduction",
            "description": "This Annex provides the data channel sub-protocol registration information that is referenced from the WebSocket sub-protocol name registry by IANA at .\nNOTE: that data channels and WebSockets share the same sub-protocol definitions.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "AA.2\tHTTP",
            "description": "The subprotocol Identifier is:\nhttp\nThe subprotocol Common Name is:\nhttp\nThe subprotocol is defined in the specification:\n3GPP TS 26.114, IP Multimedia Subsystem (IMS); Multimedia telephony; Media handling and interaction\n\nA short phrase describing the function of the subprotocol:\nA UTF-8 encoded HTTP/1.1 compatible protocol over data channel.\nAssociated attributes:\nNone.\nContact information for the organization or person making the registration\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "AA.3\tMPEG Scene Description",
            "description": "The subprotocol Identifier is:\nmpeg-sd\nThe subprotocol Common Name is:\nmpeg-sd\nThe subprotocol is defined in the specification:\n3GPP TS 26.114, IP Multimedia Subsystem (IMS); Multimedia telephony; Media handling and interaction\n\nA short phrase describing the function of the subprotocol:\nA UTF-8 encoded JSON-formatted protocol for the exchange of MPEG-I scene description and scene description updates.\nAssociated attributes:\nNone.\nContact information for the organization or person making the registration\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "B.1\tVideo bitrate adaptation",
            "description": "It is recommended in clauses 7.3.3 and 10.3 that a video sender adapts its video output rate based on RTCP reports and TMMBR messages. The following examples illustrate the usage:\nEXAMPLE 1 – Handover to a different cell:\n1.\tA video session is established at 100kbps. 5kbps is allocated for RTCP and trr-int is set to 500 ms. This allows an MTSI client in terminal to send regular RTCP reports with an average 500 ms interval consuming less than 5 kbps for RTCP. At the same time it allows the MTSI client in terminal to send an early RTCP packet and then send the next one already after 800 ms instead of after 1 000 ms.\n2.\tThe receiver is now subject to a reduced bandwidth, e.g. 60 kbps, due to handover to a different cell. The network indicates the reduced bandwidth to the receiver. The receiver generates a TMMBR message to inform the sender of the new maximum bitrate, 60 kbps.\n3.\tThe sender receives the TMMBR message, adjusts its output bitrate and sends a TMMBN message back.\n4.\tThe receiver sends a SIP UPDATE message to the sender indicating 60 kbps\n5.\tThe receiver travels into an area with full radio coverage. A new bandwidth of 100 kbps is negotiated with the network. It sends a SIP UPDATE message for 100 kbps.\n6.\tThe sender receives the SIP UPDATE message, and adjusts its output bitrate.\nEXAMPLE 2 – Bad coverage or congestion:\n1.\tA video session is established at 100kbps. 5kbps is allocated for RTCP and trr-int is set to 500 ms. This allows an MTSI client in terminal to send regular RTCP reports with an average 500 ms interval consuming less than 5 kbps for RTCP. At the same time it allows the MTSI client in terminal to send an early RTCP packet and then send the next one already after 800 ms instead of after 1 000 ms.\n2.\tThe receiver detects congestion and estimates a preferred video transmission rate of e.g. 60 kbps. The receiver generates a TMMBR message to inform the sender of the new maximum bitrate, 60 kbps.\n3.\tThe sender receives the TMMBR message, adjusts its output bitrate and sends a TMMBN message back.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "C.1\tExample of feedback and adaptation for speech and video",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "C.1.1\tIntroduction",
                    "description": "",
                    "summary": "",
                    "text_content": "This annex gives the outline of possible example adaptation implementations that make use of adaptation signalling for speech as described in section 10.2. Several different adaptation implementations are possible and the examples shown in this section are not to be seen as a set of different adaptive schemes excluding other designs. Implementers are free to use these examples or to use any other adaptation algorithms. The examples are based on measuring the packet loss rate (PLR) but Annex C.1.3.1 describes how the measured frame loss rate (FLR) can be used instead of the PLR. A real implementation is free to use other adaptation triggers. The purpose of the section is to show a few different examples of how receiver state machines can be used both to control the signalling but also to control the signalling requests. Notice that the MTSI clients can have different implementations of the adaptation state machines.\nThe annex is divided into three sections:\n-\tSignalling considerations - Implementation considerations on the signalling mechanism; the signalling state machine.\n-\tAdaptation state machines - Three different examples of adaptation state machines either using the full set of adaptation dimensions or a subset thereof.\n-\tOther issues and solutions - Default actions and lower layer triggers.\nIn this annex, a media receiver is the receiving end of the media flow, hence the request sender of any adaptation request. A media sender is the sending entity of the media, hence the request receiver of the adaptation request. The three different adaptation mechanisms available; bit-rate, packet-rate and error resilience, represents different ways to adapt to current transport characteristics:\n-\tBit-rate adaptation. Reducing the bit-rate is in all examples shown in this section the first action done whenever a measurement indicating that action is needed to further optimize the session quality. A bit-rate reduction will reduce the utilization of the network resources to transmit the data. In the radio case, this would reduce the required transmission power and free resources either for more data or added channel coding. It is reasonable to assume, also consistent with a proper behaviour on IP networks, that a reduction of bit-rate is a valid first measure to take whenever the transport characteristics indicate that the current settings of the session do not provide an optimized session quality.\n-\tPacket-rate adaptation. In some of the examples, packet-rate adaptation is a second measure available to further adapt to the transport characteristics. A reduction of packet rate will in some cases improve the session quality, e.g. in transmission channels including WLAN. Further, a reduction of packet rate will also reduce the protocol overhead since more data is encapsulated into each RTP packet. Although robust header compression (RoHC) can reduce the protocol overhead over the wireless link, the core network will still see the full header and for speech data, it consists of a considerable part of the data transmitted. Hence, packet-rate adaptation serves as a second step in reducing the total bit-rate needed for the session.\n-\tError resilience. The last adaptive measure in these examples is the use of error resilience measures, or explicitly, application level redundancy. Application level redundancy does not reduce the amount of bits needed to be transmitted but instead transmit the data in a more robust way. Application level redundancy should only be seen as a last measure when no other adaptation action has succeeded in optimizing the session quality sufficiently well. For most normal use cases, application level redundancy is not foreseen to be used, rather it serves as the last resort when the session quality is severely jeopardized.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "C.1.2\tSignalling state considerations",
                    "description": "",
                    "summary": "",
                    "text_content": "The control of the adaptation signalling can by itself be characterized as a state machine. The implementation of the state machine is in the decoder and each MTSI client has its own implementation. The decoder sends requests as described in clause 10.2 to the encoder in the other end.\nThe requests that are transmitted can be queued up in a send buffer to be transmitted the next time an RTCP-APP packet is to be sent. Hence, a sender might receive one, two or all three receiver requests at the same time. It should not expect any specific order of the requests. A receiver shall not send multiple requests of the same type in the same RTCP-APP packet. Transmission of the requests should preferably be done immediately using the AVPF early mode but in some cases it may be justified to delay the transmission a limited time or until the next DTX period in order to minimize disturbance on the RTP stream, in the latter case monitoring of the RTP stream described below must take the additional delay into account.\nTo summarize:\n-\tA request can be sent immediately (alone in one RTCP-APP packet) but the subsequent RTCP-APP packet must follow the transmission rules for RTCP.\n-\tRTCP-APP packets may be delayed until the next DTX period.\nReception of the transmitted RTCP-APP packets is not guaranteed. Similar to the RTP packets, the RTCP packets might be lost due to link losses. Monitoring that the adaptation requests are followed can to be done by means of inspection of the received RTP stream.\nFor various reasons the requests might not be followed even though they received successfully by the other end. This behaviour can be seen in the following ways:\n-\tRequest completely ignored: An example is a request for 1 frame/packet which might be rejected as the MTSI client decides that the default mode of operation 2 frames/packet or more and a frame aggregation reduction compared to the default state is not allowed.\n-\tRequest partially followed: An example here is when no redundancy is received and a request for 100 % redundancy with 1 extra frame offset is made which may be realized by the media sender as 100 % redundancy with no extra offset. Another example is when a request for 5.9 kbps codec rate is sent and it is realized as e.g. 6.7 kbps codec rate. Table C.1 displays how the requests and realizations are grouped. E.g. it can be seen (if Ninit =1) that a request for 3 frames per packets realized as 2 frames per packet is considered to be fulfilled.\nTable C.1: Distinction of different settings for frame aggregation, \nredundancy and codec mode settings\n\nIn table C.1 above Ninit is 1 in most cases which corresponds to 1 frame per packet. In certain cases Ninit might have another value, one such example is E-GPRS access where Ninit may be 2. Ninit is given by the ptime SDP attribute.\nNOTE:\tSpecial care in the monitoring should be taken when DTX is used as DTX SID update packets are normally not aggregated or transmitted redundant. Important is also that it takes at least one roundtrip before the effect of a request is seen in the RTP flow, if transmission of RTCP is delayed due to e.g. bandwidth requirements this extra delay must also be taken into account in the monitoring.\nIf the requests are not followed as requested, the request should not be repeated infinitely as it will increase the total bit-rate without clear benefit. In order to avoid such behaviour the following recommendations apply:\n-\tPartially fulfilled requests should be considered as obeyed.\n-\tIf a new request is not fulfilled within T_RESPONSE ms, the request is repeated again with a delay between trials of 2*T_RESPONSE ms. If the three attempts have been made without sender action,  it should be assumed  that the request cannot be fulfilled. In this case, the adaptation state machine will stay in the previous state or in a state that matches the current properties (codec mode, redundancy, frame aggregation). Any potential mismatch between define states in the adaptation state machine and the current properties of the media stream should resolved by the request sender.\n-\tThe default mode of operation for a MTSI client if the RTCP bandwidth for the session is greater than zero is that the requests received should be followed. Ignoring requests should be avoided as much as possible. However, it is required that any signalling requests are aligned with the agreed session parameters in the SDP.\nIn some cases the adaptation state machine may go out-of-synch with the received RTP stream. Such cases may occur if e.g. the other MTSI client makes a reset. These special cases can be sensed, e.g. through a detection of a large gap in timestamp and/or sequence number. The state machine should then reset to the default state and start over again.\nThe signalling state machine has three states according to table C.2.\nTable C.2: Signalling state machine states\n\nFigure C.1 illustrates the signalling state machine implemented in order to ensure safe adaptation state transitions. The figure depicts a series of states, transitions, and actions that occur during the process of adapting a telecommunication system. The states represent different stages of the adaptation process, while the transitions indicate the flow between these stages. The actions associated with each state describe the specific steps taken to achieve the desired adaptation outcome. This state machine serves as a blueprint for the safe and efficient management of adaptation in telecommunication systems.\nFigure C.1: Signalling state machine, implemented in order\nto ensure safe adaptation state transitions\n",
                    "tables": [
                        {
                            "description": "Table C.1: Distinction of different settings for frame aggregation, \nredundancy and codec mode settings",
                            "table number": 160,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table C.2: Signalling state machine states",
                            "table number": 161,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "C.1.3\tAdaptation state machine implementations",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "C.1.3.1\tGeneral",
                            "text_content": "The example adaptation state machines shown in this section are different realizations of the control algorithm for the adaptation requests. Note that this does not include how the actual signalling should be done but how various triggers will result in the transmission of different requests.\nThe example adaptation state machines make use of the signalling state machine outlined in clause B.2. Common to all adaptation state machines is that it is possible to implement all versions in the same code and just exclude appropriate states depending on desired mode of operation. All examples can transit between a number of states (denoted S1…S4). In these examples, it is assumed that the codec is AMR-NB and that it uses two coding rates (AMR 12.2 and AMR 5.9). However, this is not a limitation of the adaptation mechanism by itself. It is only the scenario used in these examples.\nSince the purpose of the adaptation mechanism is to improve the quality of the session, any adaptation signalling is based upon some trigger; either a received indication or a measurement. In the case of a measurement trigger, it is important to gather reliable statistics. This requires a measurement period which is sufficiently long to give a reliable estimation of the channel quality but also sufficiently short to enable fast adaptation. For typical MTSI scenarios on 3GPP accesses, a measurement period in the order of 100 packets is recommended. Further, in order to have an adaptation control which is reliable and stable, a hangover period is needed after a new state has been entered (typically 100 to 200 packets). An even longer hangover period is suitable when transiting from an error resilient state or a reduced rate into the default, normal state. In the below examples, it is assumed that the metric used in the adaptation is the packet loss rate measured on the application layer. It is possible to use other metrics such as lower layer channel quality metrics.\nNOTE:\tMode change requests must follow the rules outlined in clause 5.2.1.\nThe example solution is designed based on the following assumptions:\n-\tWhen the packet loss rate increases, the adaptation should:\n-\tFirst try with a lower codec mode rate, i.e. bit-rate back off.\n-\tIf this does not improve the situation, then one should try with packet rate back-off by increasing the frame aggregation.\n-\tIf none of these methods help, then application layer redundancy should be added to save the session.\n-\tWhen the packet loss rate increases, one should try to increase the bit rate in a \"safe\" manner. This is done by probing for higher bit rates by adding redundancy.\n-\tThe downwards adaptation, towards lower rates and redundancy, should be fast while the upwards adaptation should be slow.\n-\tHysteresis should be used to avoid oscillating behaviour between two states.\nA description of the different states and what trigger the transition into the respective state is given in table C.3.\nTable C.3: Adaptation state machine states and their meaning\n\nThe parameters and other definitions controlling the behaviour of the adaptation state machine are described in table C.4. Example values are also shown, values which give good performance on a wide range of different channel conditions.\nTable C.4: State transition definitions, thresholds and temporal adaptation control parameters\n\nAs described in Annex C.1.1, the frame loss rate (FLR) can be used instead of the packet loss rate to trigger the adaptation. The benefit with using FLR is that this metric can (and should) include the late losses that occur if frames are received too late to be useful for decoding. Table C.4a shows thresholds that can be used for FLR if the FLR-triggered adaptation is used instead of the PLR-triggered adaptation.\nTable C.4a: FLR thresholds when using the frame loss rate to control the adaptation\n\nThe adaptation state machines shown in Annex C.1.3.2, C.1.3.3 and C.1.3.4 can be used also for FLR-triggered adaptation by applying the following modifications:\n-\tThe media receiver needs to measure the frame loss rate instead of the packet loss rate. The frame loss rate includes late losses.\n-\tThe PLR thresholds need to be replaced with the corresponding FLR thresholds, as shown in Table C.4a.\nThe state machines are otherwise the same.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table C.3: Adaptation state machine states and their meaning",
                                    "table number": 162,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table C.4: State transition definitions, thresholds and temporal adaptation control parameters",
                                    "table number": 163,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table C.4a: FLR thresholds when using the frame loss rate to control the adaptation",
                                    "table number": 164,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "C.1.3.2\tAdaptation state machine with four states",
                            "text_content": "The first example utilizes all adaptation possibilities, both in terms of possible states and transitions between the states. Figure C.2 shows the layout of the adaptation state machine and the signalling used in the transitions between the states.\nFigure C.2 illustrates the state diagram for a four-state adaptation state machine used in a telecommunication system. The diagram outlines the transitions between different states, including the initial state, idle state, busy state, and error state. Key components include the state transition logic, input/output buffers, and the state machine controller. The figure demonstrates how the system adapts to varying network conditions and ensures efficient resource allocation.\nFigure C.2: State diagram for four-state adaptation state machine\nState transitions:\nBelow are listed the possible state transitions and signalling that is involved. Note that the state can go from S1 to either S2 or state S4, this is explained below:\nTable C.5: State transitions for four-state adaptation state machine\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table C.5: State transitions for four-state adaptation state machine",
                                    "table number": 165,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "C.1.3.3\tAdaptation state machine with four states (simplified version without frame aggregation)",
                            "text_content": "This example is a simpler implementation with the frame aggregation removed.\nFigure C.3 illustrates a simplified four-state adaptation state machine, which outlines the process of state transitions in a telecommunication system. The state diagram consists of four states: INIT, IDLE, SEND, and RECEIVE, along with the corresponding actions and transitions between these states. The diagram demonstrates how the system adapts to different network conditions and optimizes resource allocation for improved performance. The state transitions are represented by arrows, indicating the direction of state changes, and the states are labeled for clarity. This state diagram serves as a visual guide for understanding the system's behavior and decision-making processes in real-time telecommunication scenarios.\nFigure C.3: State diagram for simplified four-state adaptation state machine\nState transitions:\nBelow are listed the possible state transitions and signalling that is involved.\nTable C.6: State transitions for simplified four-state adaptation state machine\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table C.6: State transitions for simplified four-state adaptation state machine",
                                    "table number": 166,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "C.1.3.4\tAdaptation state machine with two states",
                            "text_content": "This example is an implementation with the redundant states removed.\nFigure C.4 illustrates a two-state adaptation state machine, which is a fundamental component in the design of adaptive systems. The state diagram depicts the system's progression through different states based on the input signals and the system's internal logic. The states are represented by distinct symbols, and the transitions between states are indicated by arrows. This figure is essential for understanding the system's behavior and performance under various conditions.\nFigure C.4: State diagram for two-state adaptation state machine\nState transitions:\nBelow are listed the possible state transitions and signalling that is involved.\nTable C.7: State transitions for two-state adaptation state machine\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table C.7: State transitions for two-state adaptation state machine",
                                    "table number": 167,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "C.1.3.5\tAdaptation when using ECN",
                            "text_content": "This example shows how ECN may be used to trigger media bit-rate adaptation. ECN can be used in combination with other adaptation triggers, for example packet loss triggered adaptation schemes or frame loss rate triggered adaptation schemes, although this is not included in this example.\nIn this example, the ECN-triggered adaptation is configured using the set of parameters as described in Table C.8.\nTable C.8: Configuration parameters used for the ECN triggered adaptation in this example\n\nFigure C.5 shows how the codec rate changes over the session if there is no congestion and therefore no ECN-CE marking (and no packet losses). The codec modes that can be used during the session are negotiated at session setup. In this case it is assumed that the recommended four AMR {4.75, 5.9, 7.4 and 12.2 kbps} codec modes can be used in the session. It is further assumed that the highest codec mode allowed in the session is AMR 12.2 kbps and the ECN_min_rate corresponds to AMR 5.9 kbps, see Clause 10.2.0.\nNOTE:\tECN can also be used for AMR-WB in a corresponding way, with the difference that the highest codec mode and ECN_min_rate would be selected based on the AMR-WB codec mode rates.\nFigure C.5 illustrates the utilization of various codec modes within a session, showcasing the different processing techniques employed to optimize audio and video quality. The figure highlights the role of codecs such as G.711, G.729, and Opus in managing bandwidth and latency, while also demonstrating the impact of these choices on overall communication performance. The figure emphasizes the importance of selecting the appropriate codec mode for specific use cases, ensuring that the system can adapt to changing network conditions and deliver a seamless user experience.\nFigure C.5: Example of codec mode usage in a session\nThe session starts with the Initial Codec Mode (ICM), i.e. the AMR 5.9 kbps codec mode, see Clause 7.5.2.1.6. The receiving MTSI client evaluates the performance, for example by measuring the packet loss rate and detecting ECN-CE marked packets, and adapts the codec mode upwards (by sending adaptation requests backwards to the sender) in steps as long as no ECN-CE marked packets and no (or only marginal) performance problems are detected. In this case, this means that the MTSI client starts using the AMR 5.9 kbps mode, then switches to the AMR 7.4 kbps mode and then to the AMR 12.2 kbps mode.\nThe step-wise upswitching is used because the receiving MTSI client does not know whether the new and higher rate is sustainable or not. The transmission performance for each new rate needs to be verified over a time period before further upswitching can be attempted. If the new bit rate would prove to be not sustainable then the receiving MTSI client would switch back to the previously used rate or even a lower rate (not shown in these figures).\nFigure C.6 shows how ECN-CE marked packets may trigger codec adaptation.\nFigure C.6 illustrates an example of how ECN (Explicit Congestion Notification) may trigger codec adaptation in a telecommunication network. The figure depicts a network with multiple nodes, including a source, a router, and a destination. ECN is represented by the ECN bit in the IP header, which is used to indicate congestion in the network. When ECN is set, the source node adjusts the codec rate to reduce the likelihood of packet retransmissions, thus conserving network resources. The figure also shows how the codec rate is dynamically adjusted based on the ECN feedback, ensuring efficient data transmission and minimizing congestion.\nFigure C.6: Example of how ECN may trigger codec adaptation\nAgain, the session starts with ICM, i.e. the AMR 5.9 kbps codec mode. The MTSI client evaluates the performance, for example the packet loss rate and/or ECN-CE marked packets, and adapts the codec mode upwards if it is deemed possible to do so. During the upwards adaptation, the receiver detects in this example a congestion event since ECN-CE is set for at least one of the received IP packets. In this case a fast back-off strategy is used and the receiver therefore sends an adaptation request back to the sender using RTCP APP with a request to switch to a low codec mode, in this case to adapt to the AMR 5.9 kbps mode. The AVPF profile allows for sending an (one) RTCP packet without waiting for the normal RTCP transmission interval, even if a regular compound RTCP was recently transmitted. This gives a faster reaction to ECN-CE.\nAfter the down-switch, a waiting time is used to prevent upswitch too soon after the congestion event since too early upswitch is likely to trigger further congestion. The receiver uses RTCP APP also for the adaptation requests for upswitch. It is beneficial to use the normal RTCP transmission rules, defined for the AVP profile, for the upswitch adaptation signalling because this enables using the AVPF transmission rules in case congestion would occur immediately after the upswitch.\nThe response to the ECN-CE marking, the waiting time and the upswitching after a congestion event is the same regardless of when the congestion occurs, which is shown in Figure C.7. This is because the MTSI client is evaluating if the bit rate is sustainable also after switching up to the high bit rate.\nFigure C.7 illustrates the utilization of various codec modes within a session, showcasing the different processing techniques employed to optimize audio and video quality. The figure highlights the role of codecs such as G.711, G.729, and Opus in managing bandwidth and latency, while also demonstrating the impact of these choices on overall communication performance. The figure emphasizes the importance of selecting the appropriate codec mode for specific use cases, ensuring that the system can adapt to changing network conditions and deliver a seamless user experience.\nFigure C.7: Example of codec mode usage in a session\nFigure C.7 also shows how the fast down-switch gives a rapid codec mode switch from the AMR 12.2 kbps to the AMR 5.9 kbps mode. The codec mode request (CMR) sent from the receiver may suggest a direct switch from the AMR 12.2 kbps mode to the AMR 5.9 kbps mode. However, if the MTSI client is inter-working with a CS GERAN then mode changes will be limited in the session setup to every other frame border and also to neighboring modes. The MTSI client obviously has to follow such rules for mode changes, if they are defined in the session setup. The sender may therefore be prevented from following the CMR directly and it may take a few frames until the target codec mode is reached.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table C.8: Configuration parameters used for the ECN triggered adaptation in this example",
                                    "table number": 168,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "title": "C.2\tExample criteria for video bit rate feedback and adaptation",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "C.2.1\tIntroduction",
                    "description": "",
                    "summary": "",
                    "text_content": "This annex gives the outline of possible example adaptation criteria that make use of adaptation signalling for video as described in section 10.3. Several different adaptation implementations are possible and the example criteria shown in this section are not to be seen as an adaptive scheme excluding other designs. Implementers are free to use these example criteria or to use any other adaptation algorithm as long as the requirements and recommendations specified in clause 10.3 are fulfilled. The description of the example criteria is split into two parts, one for the media sender side and one for the media receiver side.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "C.2.2\tMedia sender side",
                    "description": "",
                    "summary": "",
                    "text_content": "The basic rate adaptation algorithm on the media sender side serves to combine the received RTCP TMMBR and RTCP Receiver Report or Sender Report in a way that makes adaptation possible in the presence of any or both of the aforementioned reports. One important aspect is that the TMMBR reports will serve as an upper limit on the permitted bitrate while RTCP Receiver or Sender Reports provide a means for temporary adjustments based on e.g. the packet loss rate in a given interval. Note that the actual bitrate limit will also depend on the bandwidth attribute in the SDP.  Typically adjustments of the permitted bitrate due to TMMBR reports are less frequent than adjustments due to RTCP Receiver or Sender Reports The media sender may use the following conditions to adjust its video transmission rate:\n1\tUpon receiving a TMMBR message the media sender sets its maximum transmission rate to the requested rate.\n2\tIf the requested rate in the TMMBR message is greater than the current video transmission rate the media sender (gradually) increases its transmission rate to the requested rate in the TMMBR message.\n3\tExamining the RTCP Receiver Report and Sender Report information to determine whether finer adaptations can be made to the video transmission rate.  For example, the media sender may reduce its video transmission rate in response to an increase in the packet loss rate.\n4\tReducing the video transmission rate if the media sender determines that the local radio uplink throughput is decreasing, e.g. detecting congestion in the uplink transmission buffers or examining other indicators of uplink quality.\n5\tOther conditions\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "C.2.3\tMedia receiver side",
                    "description": "",
                    "summary": "",
                    "text_content": "The basic rate adaptation algorithm on the media receiver side may consist of both the well-established RFC 3550 RTCP RR and SR reporting (which is not described further) and the estimation and sending of TMMBR to the sender. Transmission of TMMBR reports is typically less frequent than RTCP Receiver Reports or Sender Reports.\nThe media receiver may use the following conditions to send a TMMBR message requesting a reduction in video transmission rate\n1\tThe video packets are arriving too close to or too late for their scheduled playout\n2\tThe receiver detects an unacceptably high packet loss rate\n3\tThe receiver detects that the received bitrate has been reduced\n4\tOther conditions\nThe MTSI media receiver may use the following conditions to send a TMMBR requesting an increase in video transmission rate\n1\tThe video packets are arriving earlier than needed for their scheduled playout\n2\tOther conditions\nCare must be taken when sending consecutive TMMBR messages to accommodate the media sender’s reaction to previously sent TMMBR messages.  When doing this, the media receiver should account for delays in the transmission of TMMBR messages due to RTCP bandwidth requirements.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "C.2.4\tVideo encoder bitrate adaptation, down-switch",
                    "description": "",
                    "summary": "",
                    "text_content": "As described in clause 10.3.4.2, the video encoder may not be able to immediately change the sending bitrate to the requested bitrate, especially if this also requires changing the frame rate and/or the video resolution. During this period, the generated bitrate is higher than the channel capacity which means that excessive bits (excess_bits) are generated and the corresponding RTP packets will be queuing up at the node where the congestion occurs. Figure C.8 gives a simplified schematic description of the encoder bitrate adaptation. The encoder bitrate is here shown with straight lines. In reality, the amount of data generated by the encoder will vary from frame to frame and the bitrate will then vary around the bitrate shown in this figure. These bitrate variations are not considered in this description but needs to be considered in the real implementation.\nThe encoder uses the bitrate of the previous channel capacity (prev_rate) as long as the sender is unaware of the reduced channel capacity. When the TMMBR message is received, the encoder starts reducing the bitrate towards the new channel capacity (new_rate). Since the bitrate indicated in the TMMBR message includes the IP/UDP/RTP overhead then this needs to be removed. The encoder bitrate is then reduced even further for a while to gain back the delay caused by the queue build-up.\nFigure C.8 illustrates the process of bitrate reduction in a video encoder when the encoder is unable to immediately switch to the requested bitrate. The figure depicts the initial high bitrate, which is then gradually reduced as the encoder transitions to the desired lower bitrate. This process is crucial for maintaining video quality while optimizing for network conditions. The figure highlights the importance of adaptive bitrate streaming in ensuring a smooth viewing experience for users with varying network speeds.\nFigure C.8: Schematic figure of bitrate reduction in video encoder when the encoder cannot immediately switch to the requested bitrate\nThe upper limit requirement () for how many excessive bits that is allowed to be generated during the adaptation time is defined by the Worst-Case Adaptation Algorithm, which corresponds to the rectangle  while the recommendation () is defined by the triangle .\nThe amount of excessive bits that are generated corresponds to the area of the triangle . As can be seen in the figure, the measurement window () is here longer than the worst case adaptation time () which is used for defining the requirement limit and the recommendation limit for the excessive bits. In this example, the encoder bitrate is not reduced fast enough to fulfil the recommendation but the requirement is fulfilled. This shows that it is allowed to use an adaptation time that is longer than the time used for defining the requirement and recommendation, as long as the amount of excessive bits does not exceed the limit.\nAfter the encoder bitrate has been reduced to the new bitrate then the encoder needs to reduce the bitrate even further to form the beginning of the delay recovery period. The length of the delay recovery period depends on the amount of excessive bits that have been generated and how much lower the encoding bitrate is compared to the new channel capacity.\nIn reality, the queue starts to build up even before the sender has received the TMMBR message, which is here shown by the rectangle . The sender can estimate the excessive bits generated during this period from the RTCP Receiver Reports and can then compensate for this by extending the delay recovery period.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "C.2.5\tVideo encoder bitrate adaptation, receiver-driven up-switch",
                    "description": "",
                    "summary": "",
                    "text_content": "When the channel is being under-utilized by the sender, it is likely that the delivery of video packets will occur before they actually need to be played out at the receiver. Therefore, the sender rate could be increased and introduce some additional delay without negatively affecting the system or the user experience.\nThe excess bits () that can be introduced into the transmission path can be computed as follows in the case that the channel bandwidth is equal to the average receiving rate measured at the receiver, i.e., the worst case with no spare channel bandwidth available:\n(C.2.5-1)\nwhere:\t is the bitrate with which the sending rate is increased;\nis the Round-Trip Time;\nand:\t is the time needed to detect if congestion occurs, see Figure C.8.\nThe corresponding worst case excess delay () due to excess_bits equals:\n(C.2.5-2)\nwhere:\t is the average throughput as measured by the receiver.\nTherefore, if the receiver determines the amount of allowable excess delay () from the received video packets, it can calculate the amount of rate increase that would not congest the system as:\n(C.2.5-3)\nSince the one-way delay from sender to receiver is generally unknown to the receiver, it cannot use this to calculate the allowable excess delay. Instead the receiver measures the amount of time between when a packet arrives and when it is scheduled to be played out to determine how much additional delay is acceptable. This metric is actually more accurate from a user-experience perspective since this directly determines whether the video information in received packets can actually be displayed to the user without degradation.\nThe bitrate to request () in TMMBR is then:\n(C.2.5-4)\nBefore sending the TMMBR message with the requested rate, the receiver needs to verify that the requested rate does not exceed the bitrate that was negotiated in SDP offer/answer.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "C.2.6\tVideo encoder bitrate adaptation, recovery phase",
                    "description": "",
                    "summary": "",
                    "text_content": "The delay recovery rate () and delay recovery period () can be determined as follows. Let\n(C.2.6-1)\nwhere:\t () is the rate undershoot factor and may depend on the magnitude of the channel rate drop () is:\n(C.2.6-2)\nFor example, if  is large, then  may be proportionally large or if  is small, then  may be proportionally small, for example:\n(C.2.6-3)\nAssuming that the bits during time period  are queued up and are contributing to the delay, the delay recovery period can be computed as follows:\n(C.2.6-4)\nA minimum bit rate requirement for the encoder may exist that applies to  and, therefore, also to  as follows:\n(C.2.6-5)\nand therefore:\n(C.2.6-6)\nwith:\n(C.2.6-7)\nIf during the delay recovery period a TMMBR message is received that carries a new rate value (), and  is significantly larger than , for example , then the delay recovery period may be shortened. Conversely, if  then an extended delay recovery period can be computed.\nIn this annex, the reference jitter management algorithm is described. It is written in pseudo code and is non-causal; hence non-implementable. The purpose of this algorithm is to define an \"ideal\" behaviour which all jitter buffers used in MTSI should strive to mimic. This buffer operates based on three input parameters:\n-\tlookback factor to set the current target buffering depth;\n-\ttarget late loss rate;\n-\tmaximum allowed time scaling percentage.\nfunction ref_jb(channel,jb_adaptation_lookback,delay_delta_max,target_loss)\n% channel         = file name of the channel\n% lookback        = look back factor when estimating the max jitter\n%                   buffer level [number of frames]\n% delay_delta_max = max timescaling related modification (%) of the\n%                   delay\n% target_loss     = target late loss (%)\n% example syntax:\n% ref_jb('channel_1.dat',200,15,0.5);\n\nframelength = 20;\n% this value sets the speech data in each RTP packet to 20 ms. For 2 speech\n% frames/RTP packet the value would be 40 ms.\njitter_est_window=50;\n% Sets the jitter estimation window in number of frames\ndelay_delta_max_ms = framelength*delay_delta_max*0.01;\n% Sets the maximum allowed time scaling\ntscale = 1;\n% Scale factor of delay data\n% In this case the files are assumend to be ascii files with one delay\n% entry per line, the entries are in ms, a negative value denotes\n% a packet loss.\nx = load(channel);\nx =x';\n% remove packet losses\n% remove inital startup empty frames\nix = find(x > 0);\nx(1:ix(1)-1) = x(ix(1));\n% remove packet losses (replace with nearby delay values)\nix = find(x < 0);\npacket_loss = length(ix)/length(x)*100;\nfor n=1:length(ix)\nif (ix(n) > 1)\nx(ix(n)) = x(ix(n)-1);\nend;\nend;\n% convert timescale to ms\nx = x*tscale;\nL = length(x);\nT = 1:L;\n% estimate min and max TX delay, estimate a delta_delay\nfor n=1:L\nix = [max(1,n-jitter_est_window):n];\nmax_delay(n) = max(x(ix));\nmin_delay(n) = min(x(ix));\ndelta_delay(n) = max_delay(n)-min_delay(n);\nend\n% compute the target max jitter buffer level with some slow adaptation\n% downwards, just to mimick how a jitter buffer might behave\nfor n=1:L\nix = [max(1,n-jb_adaptation_lookback):n];\njb(n) = max(delta_delay(ix));\n% The timescaling is not allowed to adjust the jitterbuffer target max level\n% too fast.\nif n == 1\njb_ = jb(n);\nend\ndelta = abs(jb_-jb(n));\nif delta < delay_delta_max_ms;\njb_ = jb(n);\nelse\nif (jb(n) < jb_)\njb_ = jb_-delay_delta_max_ms;\nelse\njb_ = jb_+delay_delta_max_ms;\nend\njb(n) = jb_;\nend\n% jitter buffer target max level can only assume an integer number of frames\njbq(n) = ceil(jb(n)/framelength)*framelength;\n% compute estimated delay\ndel(n) = jbq(n)+min_delay(n);\nend\n\nif target_loss > 0\n% decrease the max jitter buffer leve until a target late loss has been\n% reached.\nlate_loss = length(find(del < x))/L*100.0;\njbq_save = jbq; % as the max level is increased until the late loss > target one\n% must be able to revert back to the previous data\nwhile late_loss < target_loss\njbq_save = jbq;\njbq = min(max(jbq)-framelength,jbq);\ndel = jbq+min_delay;\nlate_loss = length(find(del < x))/L*100.0;\nend\njbq = jbq_save;\ndel = jbq+min_delay;\nend\n\njdel = max(0,del-x);\n%Calculate and plot the CDF of the reference buffer.\nfigure(1);plot(T,jbq,T,del,T,x);\n[n,x] = hist(jdel,140); y = cumsum(n);y = y/max(y)*100;\nfigure(2);plot(x,y);axis([0 200 0 100]);ylabel('%');xlabel('ms');title('CDF of packet delay in JB');\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "E.1\tGeneral",
            "description": "This annex contains examples with mappings of SDP parameters to QoS parameters [64] for MTSI.\nThe bitrates used in these QoS examples for MBR and GBR for MBR=GBR bearers and for MBR for MBR>GBR bearers are based on the highest bitrates possible with the codecs, profiles and levels defined in Clause 5.2. The bitrates used for GBR for MBR>GBR bearers are chosen to still give usable quality levels.\nThe ‘a=bw-info’ attributed defined in Clause 19 can be used to provide additional bandwidth information for the setting of MBR and GBR and also to align the resource allocation end-to-end, see also Clauses 6.2.5 and 6.2.7.\nThe bearer setup also depends on the outcome of the SDP offer-answer negotiation. The QoS profiles shown below assume that both end-points agree on using the codecs and bitrates as described in each respective example.\nThe QoS Class Identifier (QCI) [90] and 5G QoS Indentifier (5QI) [176] are used to describe the packet forwarding treatment for different media types. The table below gives a few examples for how the QCI/5QI can be set for different media types.\nTable E.0: Example mapping between media type and QCI.\n\nThis mapping assumes that the QCIs are used as described in TS 23.203, Table 6.1.7, [90] for LTE access, and 5QIs as described in TS 23.501, Table 5.7.4-1 [176] for NR access.\n.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.0: Example mapping between media type and QCI.",
                    "table number": 169,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.2\tBi-directional speech (AMR12.2, IPv4, RTCP and MBR=GBR bearer)",
            "description": "The bitrate for AMR 12.2 including IP overhead (one AMR frame per RTP packet, using bandwidth efficient mode) is 28.8 kbps which is rounded up to 29 kbps. IPv4 is also assumed.\nTable E.1: QoS mapping for bi-directional speech (AMR 12.2, IPv4, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.1: QoS mapping for bi-directional speech (AMR 12.2, IPv4, RTCP and MBR=GBR bearer)",
                    "table number": 170,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.3\tVoid",
            "description": "\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.4\tBi-directional real-time text (3 kbps, IPv4 or IPv6, RTCP and MBR=GBR bearer)",
            "description": "Bi-directional text at 3 kbps all inclusive (text, IP overhead, RTCP).\nNote: For multiparty call scenarios, \"Guaranteed bitrate for downlink (kbps)\" and \"Maximum bitrate for downlink (kbps)\" should be a higher value than 3 kbps, e.g., 6kbps would be a suitable value.\nTable E.3: QoS mapping for bi-directional real-time text (3 kbps, IPv4, RTCP and MBR=GBR bearer) when using a conversational class bearer\n\nUsing a conversational class bearer means that resources are reserved throughout the session. Depending on the intended usage of real-time text, it might not be the most resource efficient choice to use a conversational class bearer, especially if it is foreseen that the sessions will be long-lived while the actual text conversations will be rare and bursty. Table E.4 therefore shows an example with QoS mapping for using an interactive class bearer. It is recommended to use QCI 6, 8, or 9 [90] for T.140 real-time text unless the service policy decides to assign different QCI types.\nTable E.4: QoS mapping for bi-directional real-time text (3 kbps, IPv4, RTCP) when using an interactive bearer\n\nTable E.5: QoS mapping for bi-directional real-time text (3 kbps, IPv6, RTCP and MBR=GBR bearer) when using a conversational class bearer\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.3: QoS mapping for bi-directional real-time text (3 kbps, IPv4, RTCP and MBR=GBR bearer) when using a conversational class bearer",
                    "table number": 171,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table E.4: QoS mapping for bi-directional real-time text (3 kbps, IPv4, RTCP) when using an interactive bearer",
                    "table number": 172,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table E.5: QoS mapping for bi-directional real-time text (3 kbps, IPv6, RTCP and MBR=GBR bearer) when using a conversational class bearer",
                    "table number": 173,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.5\tBi-directional speech (AMR-WB23.85, IPv4, RTCP and MBR=GBR bearer)",
            "description": "The bitrate for AMR-WB 23.85 including IP overhead (one AMR-WB frame per RTP packet, using bandwidth efficient mode) is 40.4 kbps which is rounded up to 41 kbps.\nTable E.6: QoS mapping for bi-directional speech (AMR-WB 23.85, IPv4, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.6: QoS mapping for bi-directional speech (AMR-WB 23.85, IPv4, RTCP and MBR=GBR bearer)",
                    "table number": 174,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.6\tBi-directional video (H.264 AVC level 1.1, 192 kbps, IPv4, RTCP and MBR=GBR bearer)",
            "description": "The video bandwidth is assumed to be 192 kbps and the IPv4 overhead 10 kbps (assuming 15fps and 2 IP packets per frame), resulting in 202 kbps. The transfer delay for video is different from other media. The applicable H.264 profile level can be derived from the \"profile-level-id\" MIME parameter signalled within the SDP \"a=fmtp\" attribute. H.264 receivers can request to receive only a lower bandwidth than depicted in this example via the SDP \"b:AS\" parameter.\nTable E.7: QoS mapping for bi-directional video (H.264 AVC level 1.1, 192 kbps, IPv4, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.7: QoS mapping for bi-directional video (H.264 AVC level 1.1, 192 kbps, IPv4, RTCP and MBR=GBR bearer)",
                    "table number": 175,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.7\tBi-directional speech (AMR12.2, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The bitrate for AMR 12.2 including IP overhead (one AMR frame per RTP packet, using bandwidth efficient mode) is 36.8 kbps which is rounded up to 37 kbps. IPv6 is also assumed.\nTable E.8: QoS mapping for bi-directional speech (AMR 12.2, IPv6, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.8: QoS mapping for bi-directional speech (AMR 12.2, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 176,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.8\tBi-directional speech (AMR-WB23.85, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The bitrate for AMR-WB 23.85 including IP overhead (one AMR-WB frame per RTP packet, using bandwidth efficient mode) is 48.4 kbps which is rounded up to 49 kbps. IPv6 is also assumed.\nTable E.9: QoS mapping for bi-directional speech (AMR-WB 23.85, IPv6, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.9: QoS mapping for bi-directional speech (AMR-WB 23.85, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 177,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.9\tVoid",
            "description": "\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.10\tBi-directional video (H.264 AVC level 1.1, 192 kbps, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The video bandwidth is assumed to be 192 kbps and the IPv6 overhead 16 kbps (assuming 15fps and 2 IP packets per frame), resulting in 208 kbps. The transfer delay for video is different from other media. IPv6 is also assumed. The applicable H.264 profile level can be derived from the \"profile-level-id\" MIME parameter signalled within the SDP \"a=fmtp\" attribute. H.264 receivers can request to receive only a lower bandwidth than depicted in this example via the SDP \"b:AS\" parameter.\nTable E.11: QoS mapping for bi-directional video (H.264 AVC level 1.1, 192 kbps, IPv6, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.11: QoS mapping for bi-directional video (H.264 AVC level 1.1, 192 kbps, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 178,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.11\tBi-directional speech (AMR, IPv4, RTCP and MBR>GBR bearer)",
            "description": "This QoS profile is defined for AMR (one AMR frame per RTP packet, bandwidth efficient mode) when AMR12.2 and AMR5.9 are used to define MBR and GBR for MBR>GBR bearers. IPv4 is also assumed.\nThe bitrate for AMR 12.2 including IP overhead is 28.8 kbps and the bitrate for AMR 5.9 including IP overhead is 22.4 kbps.\nTable E.12: QoS mapping for bi-directional speech (AMR, IPv4, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.12: QoS mapping for bi-directional speech (AMR, IPv4, RTCP and MBR>GBR bearer)",
                    "table number": 179,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.12\tBi-directional speech (AMR-WB, IPv4, RTCP and MBR>GBR bearer)",
            "description": "This QoS profile is defined for AMR-WB (one AMR-WB frame per RTP packet, bandwidth efficient mode) when AMR-WB23.85 and AMR-WB8.85 are used to define MBR and GBR for MBR>GBR bearers. IPv4 is also assumed.\nThe bitrate for AMR-WB23.85 including IP overhead is 40.4 kbps and the bitrate for AMR-WB8.85 including IP overhead is 25.6 kbps.\nTable E.13: QoS mapping for bi-directional speech (AMR-WB, IPv4, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.13: QoS mapping for bi-directional speech (AMR-WB, IPv4, RTCP and MBR>GBR bearer)",
                    "table number": 180,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.13\tVoid",
            "description": "\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.14\tBi-directional video (H.264 AVC level 1.1, IPv4, RTCP and MBR>GBR bearer)",
            "description": "The video bandwidths used for defining MBR and GBR are assumed to be 192 kbps and 64 kbps, respectively. The IPv4 overhead is 10 kbps (assuming 15fps and 2 IP packets per frame) for MBR and 5 kbps (assuming 15 fps and 1 IP packet per frame) for GBR, resulting in 202 kbps and 69 kbps, respectively. The transfer delay for video is different from other media. The applicable H.264 profile level can be derived from the \"profile-level-id\" MIME parameter signalled within the SDP \"a=fmtp\" attribute. H.264 receivers can request to receive only a lower bandwidth than depicted in this example via the SDP \"b:AS\" parameter.\n\nTable E.15: QoS mapping for bi-directional video (H.264 AVC level 1.1, IPv4, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.15: QoS mapping for bi-directional video (H.264 AVC level 1.1, IPv4, RTCP and MBR>GBR bearer)",
                    "table number": 181,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.15\tBi-directional speech (AMR, IPv6, RTCP and MBR>GBR bearer)",
            "description": "This QoS profile is defined for AMR (one AMR frame per RTP packet, bandwidth efficient mode) when AMR12.2 and AMR5.9 are used to define MBR and GBR for MBR>GBR bearers. IPv6 is also assumed.\nThe bitrate for AMR 12.2 including IP overhead is 36.8 kbps and the bitrate for AMR 5.9 including IP overhead is 30.4 kbps.\nTable E.16: QoS mapping for bi-directional speech (AMR, IPv6, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.16: QoS mapping for bi-directional speech (AMR, IPv6, RTCP and MBR>GBR bearer)",
                    "table number": 182,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.16\tBi-directional speech (AMR-WB, IPv6, RTCP and MBR>GBR bearer)",
            "description": "This QoS profile is defined for AMR-WB (one AMR-WB frame per RTP packet, bandwidth efficient mode) when AMR-WB23.85 and AMR-WB8.85 are used to define MBR and GBR for MBR>GBR bearers. IPv6 is also assumed.\nThe bitrate for AMR-WB 23.85 including IP overhead is 48.4 kbps and the bitrate for AMR-WB 8.85 including IP overhead is 33.6 kbps.\nTable E.17: QoS mapping for bi-directional speech (AMR-WB, IPv6, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.17: QoS mapping for bi-directional speech (AMR-WB, IPv6, RTCP and MBR>GBR bearer)",
                    "table number": 183,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.17\tVoid",
            "description": "\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.18\tBi-directional video (H.264 AVC level 1.1, IPv6, RTCP and MBR>GBR bearer)",
            "description": "The video bandwidths used for defining MBR and GBR are assumed to be 192 kbps and 64 kbps, respectively. The IPv6 overhead is 16 kbps (assuming 15fps and 2 IP packets per frame) for MBR and 8 kbps (assuming 15fps and 1 IP packets per rame) for GBR, resulting in 208 kbps and 72 kbps, respectively. The transfer delay for video is different from other media. The applicable H.264 profile level can be derived from the \"profile-level-id\" MIME parameter signalled within the SDP \"a=fmtp\" attribute. H.264 receivers can request to receive only a lower bandwidth than depicted in this example via the SDP \"b:AS\" parameter.\nTable E.19: QoS mapping for bi-directional video (H.264 AVC level 1.1, IPv6, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.19: QoS mapping for bi-directional video (H.264 AVC level 1.1, IPv6, RTCP and MBR>GBR bearer)",
                    "table number": 184,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.19\tBi-directional video (H.264 AVC level 1.2, 384 kbps, IPv4, RTCP and MBR=GBR bearer)",
            "description": "The video bandwidth is assumed to be 384 kbps and the IPv4 overhead 20 kbps (assuming 15fps and 4 IP packets per frame), resulting in 404 kbps. The transfer delay for video is different from other media. The applicable H.264 profile level can be derived from the \"profile-level-id\" MIME parameter signalled within the SDP \"a=fmtp\" attribute.\nTable E.20: QoS mapping for bi-directional video (H.264 AVC level 1.2, 384 kbps, IPv4, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.20: QoS mapping for bi-directional video (H.264 AVC level 1.2, 384 kbps, IPv4, RTCP and MBR=GBR bearer)",
                    "table number": 185,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.20\tBi-directional video (H.264 AVC level 1.2, 384 kbps, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The video bandwidth is assumed to be 384 kbps and the IPv6 overhead 32 kbps (assuming 15fps and 4 IP packets per frame), resulting in 416 kbps. The transfer delay for video is different from other media. IPv6 is also assumed. The applicable H.264 profile level can be derived from the \"profile-level-id\" MIME parameter signalled within the SDP \"a=fmtp\" attribute. H.264 receivers can request to receive only a lower bandwidth than depicted in this example via the SDP \"b:AS\" parameter.\nTable E.21: QoS mapping for bi-directional video (H.264 AVC level 1.2, 384 kbps, IPv6, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.21: QoS mapping for bi-directional video (H.264 AVC level 1.2, 384 kbps, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 186,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.21\tBi-directional video (H.264 AVC level 1.2, IPv4, RTCP and MBR>GBR bearer)",
            "description": "The video bandwidths used for defining MBR and GBR are assumed to be 384 kbps and 192 kbps, respectively. The IPv4 overhead is 20 kbps (assuming 15fps and 4 IP packets per frame) for MBR and 10 kbps (assuming 15 fps and 2 IP packets per frame) for GBR, resulting in 404 kbps and 202 kbps, respectively. The transfer delay for video is different from other media. The applicable H.264 profile level can be derived from the \"profile-level-id\" MIME parameter signalled within the SDP \"a=fmtp\" attribute. H.264 receivers can request to receive only a lower bandwidth than depicted in this example via the SDP \"b:AS\" parameter.\n\nTable E.22: QoS mapping for bi-directional video (H.264 AVC level 1.2, IPv4, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.22: QoS mapping for bi-directional video (H.264 AVC level 1.2, IPv4, RTCP and MBR>GBR bearer)",
                    "table number": 187,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.22\tBi-directional video (H.264 AVC level 1.2, IPv6, RTCP and MBR>GBR bearer)",
            "description": "The video bandwidths used for defining MBR and GBR are assumed to be 384 kbps and 192 kbps, respectively. The IPv6 overhead is 32 kbps (assuming 15fps and 4 IP packets per frame) for MBR and 16 kbps (assuming 15fps and 2 IP packets per frame) for GBR, resulting in 416 kbps and 208 kbps, respectively. The transfer delay for video is different from other media. The applicable H.264 profile level can be derived from the \"profile-level-id\" MIME parameter signalled within the SDP \"a=fmtp\" attribute. H.264 receivers can request to receive only a lower bandwidth than depicted in this example via the SDP \"b:AS\" parameter.\n\nTable E.23: QoS mapping for bi-directional video (H.264 AVC level 1.2, IPv6, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.23: QoS mapping for bi-directional video (H.264 AVC level 1.2, IPv6, RTCP and MBR>GBR bearer)",
                    "table number": 188,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.23\tBi-directional video (H.265 (HEVC) Main profile, Main tier, level 3.1, 500 kbps, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The video bandwidth is assumed to be 500 kbps and the IPv6 overhead 36 kbps (assuming 25 fps, 3 IP packets per frame and IPv6), resulting in 540 kbps. Adding 5% for RTCP increases the bandwidth by 27 kbps. However, the RTCP bandwidth is limited to max 14 kbps, see clause 7.3.1. Rounding up to the next higher integer multiple of 8 kbps gives 560 kbps.\nTable E.24: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 300 kbps, IPv6, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.24: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 300 kbps, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 189,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.24\tBi-directional video (H.265 (HEVC) Main profile, Main tier, level 3.1, 500/40 kbps, IPv6, RTCP and MBR>GBR bearer)",
            "description": "The video bandwidths used for defining MBR and GBR are assumed to be 500 kbps and 40 kbps, respectively. The IPv6 overhead is 36 kbps (assuming 25 fps and 3 IP packets per frame) for MBR and 2.4 kbps (assuming QCIF, 5 fps and 1 IP packets per frame) for GBR, resulting in 540 kbps and 45 kbps, respectively. Adding 5% for RTCP increases the bandwidth by 27 kbps for both MBR and GBR. However, the RTCP bandwidth is limited to max 14 kbps, see clause 7.3.1. Rounding up to the nearest higher integer multiple of 8 kbps gives 560 kbps and 64 kbps, respectively.\nTable E.25: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 500/40 kbps, IPv6, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.25: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 500/40 kbps, IPv6, RTCP and MBR>GBR bearer)",
                    "table number": 190,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.25\tBi-directional video (H.265 (HEVC) Main profile, Main tier, level 3.1, 600 kbps, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The video bandwidth is assumed to be 600 kbps and the IPv6 overhead 36 kbps (assuming 25 fps, 3 IP packets per frame and IPv6), resulting in 640 kbps. Adding 5% for RTCP increases the bandwidth by 32 kbps. However, the RTCP bandwidth is limited to max 14 kbps, see clause 7.3.1. Rounding up to the next higher integer multiple of 8 kbps gives 656 kbps.\nTable E.26: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 600 kbps, IPv6, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.26: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 600 kbps, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 191,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.26\tBi-directional video (H.265 (HEVC) Main profile, Main tier, level 3.1, 600/40 kbps, IPv6, RTCP and MBR>GBR bearer)",
            "description": "The video bandwidths used for defining MBR and GBR are assumed to be 600 kbps and 40 kbps, respectively. The IPv6 overhead is 36 kbps (assuming 25 fps and 3 IP packets per frame) for MBR and 2.4 kbps (assuming QCIF, 5 fps and 1 IP packets per frame) for GBR, resulting in 640 kbps and 45 kbps, respectively. Adding 5% for RTCP increases the bandwidth by 32 kbps for both MBR and GBR. However, the RTCP bandwidth is limited to max 14 kbps, see clause 7.3.1. Rounding up to the nearest higher integer multiple of 8 kbps gives 656 kbps and 64 kbps, respectively.\nTable E.27: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 600/40 kbps, IPv6, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.27: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 600/40 kbps, IPv6, RTCP and MBR>GBR bearer)",
                    "table number": 192,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.27\tBi-directional video (H.265 (HEVC) Main profile, Main tier, level 3.1, 650 kbps, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The video bandwidth is assumed to be 650 kbps and the IPv6 overhead 36 kbps (assuming 25 fps, 3 IP packets per frame and IPv6), resulting in 690 kbps. Adding 5% for RTCP increases the bandwidth by 34.5 kbps. However, the RTCP bandwidth is limited to max 14 kbps, see clause 7.3.1. Rounding up to the next higher integer multiple of 8 kbps gives 704 kbps.\nTable E.28: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 650 kbps, IPv6, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.28: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 650 kbps, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 193,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.28\tBi-directional video (H.265 (HEVC) Main profile, Main tier, level 3.1, 650/40 kbps, IPv6, RTCP and MBR>GBR bearer)",
            "description": "The video bandwidths used for defining MBR and GBR are assumed to be 650 kbps and 40 kbps, respectively. The IPv6 overhead is 36 kbps (assuming 25 fps and 3 IP packets per frame) for MBR and 2.4 kbps (assuming QCIF, 5 fps and 1 IP packets per frame) for GBR, resulting in 690 kbps and 45 kbps, respectively. Adding 5% for RTCP increases the bandwidth by 34.5 kbps for both MBR and GBR. However, the RTCP bandwidth is limited to max 14 kbps, see clause 7.3.1. Rounding up to the nearest higher integer multiple of 8 kbps gives 704 kbps and 72 kbps, respectively.\nTable E.29: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 650/40 kbps, IPv6, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.29: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 650/40 kbps, IPv6, RTCP and MBR>GBR bearer)",
                    "table number": 194,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.29\tBi-directional video (H.265 (HEVC) Main profile, Main tier, level 3.1, 750 kbps, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The video bandwidth is assumed to be 750 kbps and the IPv6 overhead 48 kbps (assuming 25 fps, 4 IP packets per frame and IPv6), resulting in 800 kbps. Adding 5% for RTCP increases the bandwidth by 40 kbps. However, the RTCP bandwidth is limited to max 14 kbps, see clause 7.3.1. Rounding up to the next higher integer multiple of 8 kbps gives 816 kbps.\nTable E.30: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 750 kbps, IPv6, RTCP and MBR=GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.30: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 750 kbps, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 195,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.30\tBi-directional video (H.265 (HEVC) Main profile, Main tier, level 3.1, 750/40 kbps, IPv6, RTCP and MBR>GBR bearer)",
            "description": "The video bandwidths used for defining MBR and GBR are assumed to be 750 kbps and 40 kbps, respectively. The IPv6 overhead is 48 kbps (assuming 25 fps and 4 IP packets per frame) for MBR and 2.4 kbps (assuming QCIF, 5 fps and 1 IP packets per frame) for GBR, resulting in 800 kbps and 45 kbps, respectively. Adding 5% for RTCP increases the bandwidth by 40 kbps for both MBR and GBR. However, the RTCP bandwidth is limited to max 14 kbps, see clause 7.3.1. Rounding up to the nearest higher integer multiple of 8 kbps gives 816 kbps and 72 kbps, respectively.\nTable E.31: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 750/40 kbps, IPv6, RTCP and MBR>GBR bearer)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.31: QoS mapping for bi-directional video (H.265 (HEVC) level 3.1, 750/40 kbps, IPv6, RTCP and MBR>GBR bearer)",
                    "table number": 196,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.31\tBi-directional speech (EVS 13.2, IPv4, RTCP and MBR=GBR bearer)",
            "description": "The bit-rate for EVS 13.2 including IP overhead (one EVS frame per RTP packet, using Header-Full format) is 30 kbps. IPv4 is assumed.\nTable E.32: QoS mapping for bi-directional speech (EVS 13.2, IPv4, RTCP and MBR=GBR bearer)\n\nNOTE:\tResidual BER and SDU error ratio of EVS are for further study.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.32: QoS mapping for bi-directional speech (EVS 13.2, IPv4, RTCP and MBR=GBR bearer)",
                    "table number": 197,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.32\tBi-directional speech (EVS 24.4, IPv4, RTCP and MBR=GBR bearer)",
            "description": "The bit-rate for EVS 24.4 including IP overhead (one EVS frame per RTP packet, using Header-Full format) is 41.2 kbps which is rounded up to 42 kbps. IPv4 is assumed.\nTable E.33: QoS mapping for bi-directional speech (EVS 24.4, IPv4, RTCP and MBR=GBR bearer)\n\nNOTE:\tResidual BER and SDU error ratio of EVS are for further study.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.33: QoS mapping for bi-directional speech (EVS 24.4, IPv4, RTCP and MBR=GBR bearer)",
                    "table number": 198,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.33\tBi-directional speech (EVS 13.2, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The bit-rate for EVS 13.2 including IP overhead (one EVS frame per RTP packet, using Header-Full format) is 38 kbps. IPv6 is assumed.\nTable E.34: QoS mapping for bi-directional speech (EVS 13.2, IPv6, RTCP and MBR=GBR bearer)\n\nNOTE:\tResidual BER and SDU error ratio of EVS are for further study.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.34: QoS mapping for bi-directional speech (EVS 13.2, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 199,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "E.34\tBi-directional speech (EVS 24.4, IPv6, RTCP and MBR=GBR bearer)",
            "description": "The bit-rate for EVS 24.4 including IP overhead (one EVS frame per RTP packet, using Header-Full format) is 49.2 kbps which is rounded up to 50 kbps. IPv6 is assumed.\nTable E.35: QoS mapping for bi-directional speech (EVS 24.4, IPv6, RTCP and MBR=GBR bearer)\n\nNOTE:\tResidual BER and SDU error ratio of EVS are for further study.\n\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table E.35: QoS mapping for bi-directional speech (EVS 24.4, IPv6, RTCP and MBR=GBR bearer)",
                    "table number": 200,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "G.1\tGeneral",
            "description": "Typically, \"DTMF events\" are triggered by an end-user (on either side of the speech call) by pressing some key of the user’s terminal, with the goal to control services in the network or in an application server. This may happen throughout the duration of the speech call on both ends of the call.\nIt might happen that DTMF events are forwarded as telephone events to the (remote) MTSI client in terminal. In such a case, the MTSI client in terminal may convert the telephone events into audible DTMF tone-pairs. There is, however, no requirement in 3GPP for handling downlink telephone events.\nThis annex describes a method for sending DTMF events as telephone events within the same RTP media stream as the speech, i.e. \"inband\", using the same IP address and UDP port as the RTP for speech, but using a different RTP Payload Type number.\n-\tMTSI clients in terminal offering speech communication shall support the below described method in the transmitting direction (uplink) and should support it in the receiving direction (downlink).\n-\tMTSI media gateways offering speech communication shall support the below described method in both directions with respect to the MTSI client in terminal, the transmitting direction (downlink) and in the receiving direction (uplink). For MTSI media gateways, the described method applies only to the PS session between the MTSI gateway and the MTSI client in terminal.\n-\tThe use of the telephone-event codec between MTSI media gateways is recommended. Typically, DTMF events are also transported between MTSI media gateways as telephone events in both directions.\n\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "G.2\tEncoding of DTMF events",
            "description": "DTMF events shall be encoded and transmitted in MTSI sessions as \"telephone events\" in RTP packets, using the selected \"telephone-event\" codec. DTMF events in this Annex refer to the DTMF Named Events described in Section 3.2, Table 3 in IETF RFC 4733 [61], i.e. events (0-9, *, # and A-D) which are encoded with event code values 0-9, 10, 11 and 12-15 respectively.\nDTMF events are carried as part of the audio stream which can either be narrowband, wideband, super-wideband or fullband audio, i.e. use 8 kHz or 16 kHz RTP clock rate respectively. MTSI clients that in addition to narrowband also support wideband, super-wideband or fullband speech shall support telephone-event RTP clock rates matching all supported codecs. When switching between speech and DTMF,   telephone events shall use the same RTP clock rate as the currently used codec for the speech signal in the same RTP stream.\nThe encoding of DTMF events includes specifying the duration time for the events, see IETF RFC 4733 [61]. Supporting long-lasting DTMF events, where the duration time exceeds the maximum duration time expressible by the duration field, is optional. If supported, long-lasting DTMF events shall be divided into segments, see IETF RFC 4733 [61]. To harmonize with legacy DTMF signalling, [62], [63], the tone duration of a DTMF event shall be at least 65 ms and the pause duration in-between two DTMF events shall be at least 65 ms. The duration of the DTMF event and the pause time to the next DTMF event, where applicable, should be selected such that it enables incrementing the RTP Time Stamp with an integer multiple of the number of timestamp units corresponding to the frame length of the speech codec used for the speech media before the DTMF event.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "G.3\tSession setup",
            "description": "The MTSI client(s) in terminal and the IMS network(s) shall support the telephone-event codec(s) for the transport of DTMF events during the whole MTSI session.\nNOTE:\tThey may in addition support the SIP INFO method (TS 24.229 [7]) for setup and modification of supplementary services, when no user plane is necessary. The SIP INFO method is, however, not to be used during MTSI sessions.\nWhen sending an SDP offer, an MTSI client should indicate support of all DTMF Named Events 0 to15 in the fmtp attribute. As defined by IETF RFC 4733 [61] section 7.1.1, if this fmtp parameter is not included, then the default applies: 0-15.\nIf the SDP offer includes a single audio codec then, this SDP offer shall also include the telephone-event codec with the same RTP clock rate as used for the offered audio codec, as described by Errata 3489 to IETF RFC 4733 [61]. If the SDP offer includes multiple audio codecs with different RTP clock rates, then this SDP offer  shall also include the telephone-event codecs with different payload type numbers for these different RTP clock rates.\nThe answerer, which determines the Selected (audio) Codec(s), shall, if telephone-event was included in the SDP offer, include in the SDP answer the corresponding telephone-event codec that matches the highest RTP clock rate from the Selected (audio) Codec(s).\nIf the SDP offer or answer contains multiple m=audio lines, then the telephone-event shall only be included for the first m=audio line.\nAn example of SDP offer and answer from MTSI clients in terminals using 3GPP access is provided in Table G.3.1 when narrowband speech codec with RTP clock rate 8000 is offered.\nTable G.3.1: SDP example for narrowband speech and DTMF\n\nAn example of SDP offer and answer from MTSI clients in terminals using 3GPP access is provided in Table G.3.2 when narrowband speech codecs with RTP clock rate 8000 and wideband and super-wideband speech codecs with RTP clock rate 16000 are offered.\nTable G.3.2: SDP example for narrowband,wideband and super-wideband for both speech and DTMF\n\nNOTE 1:\tWideband codec ITU-T G.722 uses an RTP clock rate of 8000, although its sampling frequency is 16000 Hz. An SDP offer or answer with G.722/8000 therefore must be combined with telephone-event/8000. The 3GPP EVS codec supports various sampling frequencies, up to 48000 Hz, but only one RTP clock rate of 16000 and the corresponding telephone-event/16000 is used.\n\nNOTE 2:\tThe a=sendrecv attribute applies to all RTP payload types within the same media stream. To comply with the transmission rules defined in clause G.4, SDP offers and SDP answers include audio codecs and telephone-event codec(s) for the same media stream in both directions. The consequence of this is that MTSI clients that want to send DTMF events in local uplink, also allow the remote MTSI client to send DTMF events in the reverse direction.\nFor MTSI clients in terminals, since support of DTMF events in the receiving direction is not mandatory, it is an implementation consideration to decide how to handle any received RTP packets containing telephone-event codec payload.\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table G.3.1: SDP example for narrowband speech and DTMF",
                    "table number": 201,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table G.3.2: SDP example for narrowband,wideband and super-wideband for both speech and DTMF",
                    "table number": 202,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "G.4\tData transport for DTMF events",
            "description": "For sending and receiving DTMF events via telephone events with RTP, the RTP payload format for \"DTMF Named Events\" of the telephone-event codec(s), IETF RFC 4733 [61], shall be supported by MTSI clients in terminal and MTSI media gateways.\nTelephone events shall use the same RTP media stream as for speech, i.e. the same IP address, UDP port, RTP SSRC and RTP clock rate as the Selected (Speech) Codec. Thereby, RTP Sequence Number and RTP Time Stamp shall be synchronized between RTP packets for speech and RTP packets for DTMF events. For example, by setting the initial random values the same and when switching from speech to DTMF, or vice versa, the RTP Sequence Number and RTP Time Stamp shall continue from the value that was used for the other audio media (speech or DTMF event).\nThe RTP Sequence Number for telephone events shall increment in the same way as for speech, i.e. by 1 for each transmitted RTP packet.\nThe RTP Time Stamp for telephone events should increment in the same way as for RTP speech packets or with an integer multiple. Example: if the RTP Time Stamp increments with 160 between RTP speech packets (Codec with RTP clock rate 8000 and 20 ms frame duration) then the RTP Time Stamp increment during DTMF events and when switching between speech and DTMF events should be 160 or an integer multiple of 160. The RTP Time Stamp should not increment with a smaller interval for DTMF events than for speech frames. The RTP Time Stamp shall use the same RTP clock rate as for the speech codec that is transmitted in the same RTP stream immediately before the start of the DTMF event(s).\nNOTE 1:\tA DTMF event may be transmitted in several RTP packets even if the DTMF event has a shorter duration time than what is expressible by the duration field. In this case all RTP packets containing the same DTMF event within the same segment shall have the same RTP Time Stamp value according to IETF RFC 4733 [61].\nSpeech packets shall not be transmitted such that the resulting decoded speech would overlap in time with the audible representation of DTMF events, when DTMF events are transmitted in the same RTP media stream.\nNOTE 2:\tMost DTMF events are not translated into DTMF tone-pairs, because they are used by the network or an application server (e.g. a voice mail box). For such cases, it would not matter, if DTMF events are overlapping with speech packets, but the non-overlap restriction is kept here for backward compatibility reasons. If an MTSI client receives speech and DTMF event packets, overlapping during a possible playout time, then the MTSI client optimally ignores the overlapping speech packets and plays out only the DTMF events correctly as DTMF tone-pairs, embedded into sufficient silence.\nNOTE 3:\tIf the RTP stream carrying the telephone events is paused on RTP level [156], the need to send telephone events may cause the MTSI client in terminal to leave the paused state.\n\nThis Device Description Framework (DDF) is the standardized minimal set. A vendor can define its own DDF for the complete device. This DDF can include more features than this minimal standardized version. This MO is included in the zip-archive \"3GPP MTSI MOs.zip\" attached to the present document.\n\nThis Device Description Framework (DDF) is the standardized minimal set. A vendor can define its own DDF for the complete device. This DDF can include more features than this minimal standardized version. This MO is included in the zip-archive \"3GPP MTSI MOs.zip\" attached to the present document.\n\nThis Device Description Framework (DDF) is the standardized minimal set. A vendor can define its own DDF for the complete device. This DDF can include more features than this minimal standardized version. This MO is included in the zip-archive \"3GPP MTSI MOs.zip\" attached to the present document.\n\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "K.1\tGeneral",
            "description": "This annex contains examples of computing b=AS for AMR and AMR-WB when ptime=20 and when ptime=40. In these examples, it is assumed that no extra bandwidth is allocated for redundancy.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "K.2\tProcedure for computing the bandwidth",
            "description": "The bandwidth is calculated using the following procedure when no extra bandwidth is allocated for redundancy:\n1)\tCalculate the size of the RTP payload, see below.\n2)\tCalculate the size of the IP packets by taking the RTP payload size (in bytes) and adding the IP/UDP/RTP overhead: 20 bytes for IPv4; 40 bytes for IPv6; 8 bytes for UDP; 12 bytes for RTP.\n3)\tConvert the IP packet size to bits.\n4)\tCalculate the required bit rate (bps) given the packet size and the packet rate: 50 packets per second for 1 frame per packet; 25 packets per second for 2 frames per packet.\n5)\tThe b=AS bandwidth is then calculated by converting the required bit rate to kbps and rounding to the nearest higher integer value.\nWhen redundancy is used then the RTP payload contains several frames, both non-redundant and redundant. For example, for 100% redundancy each RTP payload contains one non-redundant frame and one redundant frame, giving 2 frames per packet. The packet rate is however still 50 frames per packet.\nIf the SDP includes multiple codecs and/or configurations then the bandwidth is calculated for each configuration and the b=AS bandwidth is set to the highest of the bandwidths.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "K.3\tComputation of RTP payload size",
            "description": "When the b=AS bandwidth is computed it is assumed that the codec is using the highest allowed coded mode for each frame.\nThe RTP payload size for the bandwidth-efficient payload format mode and 1 frame/packet is calculated from the following components:\n-\t4 bits for the payload header (=CMR)\n-\t6 bits for the Table of Contents (ToC)\n-\tN bits for the speech frame (size depends on codec mode)\n-\tPadding bits at the end of the RTP payload to give an integer number of octets\nThe RTP payload size for the octet-aligned payload format mode and 1 frame/packet is calculated from the following components:\n-\t4 bits for the payload header (=CMR) + 4 bits padding\n-\t6 bits for the Table of Contents (ToC) + 2 bits padding\n-\tN bits for the speech frame (size depends on codec mode) + padding bits to give an integer number of octets\n-\tNo padding in the end of the RTP payload is needed since each item is already an integer number of octets\nThe RTP payload size for the bandwidth-efficient payload format mode and 2 frames per packet is calculated from the following components:\n-\t4 bits for the payload header (=CMR)\n-\t6 bits for the Table of Contents (ToC) for speech frame 1\n-\t6 bits for the Table of Contents (ToC) for speech frame 2\n-\tN1 bits for the speech frame 1 (size depends on codec mode)\n-\tN2 bits for the speech frame 2 (size depends on codec mode)\n-\tPadding bits at the end of the RTP payload to give an integer number of octets\nThe RTP payload size for the octet-aligned payload format mode and 2 frames per packet is calculated from the following components:\n-\t4 bits for the payload header (=CMR) + 4 bits padding\n-\t6 bits for the Table of Contents (ToC) for speech frame 1 + 2 bits padding\n-\t6 bits for the Table of Contents (ToC) for speech frame 2 + 2 bits padding\n-\tN1 bits for the speech frame 1 (size depends on codec mode) + padding bits to give an integer number of octets\n-\tN2 bits for the speech frame 2 (size depends on codec mode) + padding bits to give an integer number of octets\n-\tNo padding in the end of the RTP payload is needed since each item is already an integer number of octets\n\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "K.4\tDetailed computation",
            "description": "The tables below give a detailed description of the bandwidth computation. The b=AS bandwidth is not defined for SID. Since a SID is rarely encapsulated with a speech frame or another SID, Tables K.9-16 do not include the computation procedure for the comfort noise frame.\nTable K.1: Computation of b=AS for AMR (IPv4, ptime=20, bandwidth-efficient mode)\n\nTable K.2: Computation of b=AS for AMR (IPv6, ptime=20, bandwidth-efficient mode)\n\nTable K.3: Computation of b=AS for AMR (IPv4, ptime=20, octet-aligned mode)\n\nTable K.4: Computation of b=AS for AMR (IPv6, ptime=20, octet-aligned mode)\n\nTable K.5: Computation of b=AS for AMR-WB (IPv4, ptime=20, bandwidth-efficient mode)\n\nTable K.6: Computation of b=AS for AMR-WB (IPv6, ptime=20, bandwidth-efficient mode)\n\nTable K.7: Computation of b=AS for AMR-WB (IPv4, ptime=20, octet-aligned mode)\n\nTable K.8: Computation of b=AS for AMR-WB (IPv6, ptime=20, octet-aligned mode)\n\nTable K.9: Computation of b=AS for AMR (IPv4, ptime=40, bandwidth-efficient mode)\n\nTable K.10: Computation of b=AS for AMR (IPv6, ptime=40, bandwidth-efficient mode)\n\nTable K.11: Computation of b=AS for AMR (IPv4, ptime=40, octet-aligned mode)\n\nTable K.12: Computation of b=AS for AMR (IPv6, ptime=40, octet-aligned mode)\n\nTable K.13: Computation of b=AS for AMR-WB (IPv4, ptime=40, bandwidth-efficient mode)\n\nTable K.14: Computation of b=AS for AMR-WB (IPv6, ptime=40, bandwidth-efficient mode)\n\nTable K.15: Computation of b=AS for AMR-WB (IPv4, ptime=40, octet-aligned mode)\n\nTable K.16: Computation of b=AS for AMR-WB (IPv6, ptime=40, octet-aligned mode)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table K.1: Computation of b=AS for AMR (IPv4, ptime=20, bandwidth-efficient mode)",
                    "table number": 203,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.2: Computation of b=AS for AMR (IPv6, ptime=20, bandwidth-efficient mode)",
                    "table number": 204,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.3: Computation of b=AS for AMR (IPv4, ptime=20, octet-aligned mode)",
                    "table number": 205,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.4: Computation of b=AS for AMR (IPv6, ptime=20, octet-aligned mode)",
                    "table number": 206,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.5: Computation of b=AS for AMR-WB (IPv4, ptime=20, bandwidth-efficient mode)",
                    "table number": 207,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.6: Computation of b=AS for AMR-WB (IPv6, ptime=20, bandwidth-efficient mode)",
                    "table number": 208,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.7: Computation of b=AS for AMR-WB (IPv4, ptime=20, octet-aligned mode)",
                    "table number": 209,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.8: Computation of b=AS for AMR-WB (IPv6, ptime=20, octet-aligned mode)",
                    "table number": 210,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.9: Computation of b=AS for AMR (IPv4, ptime=40, bandwidth-efficient mode)",
                    "table number": 211,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.10: Computation of b=AS for AMR (IPv6, ptime=40, bandwidth-efficient mode)",
                    "table number": 212,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.11: Computation of b=AS for AMR (IPv4, ptime=40, octet-aligned mode)",
                    "table number": 213,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.12: Computation of b=AS for AMR (IPv6, ptime=40, octet-aligned mode)",
                    "table number": 214,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.13: Computation of b=AS for AMR-WB (IPv4, ptime=40, bandwidth-efficient mode)",
                    "table number": 215,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.14: Computation of b=AS for AMR-WB (IPv6, ptime=40, bandwidth-efficient mode)",
                    "table number": 216,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.15: Computation of b=AS for AMR-WB (IPv4, ptime=40, octet-aligned mode)",
                    "table number": 217,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table K.16: Computation of b=AS for AMR-WB (IPv6, ptime=40, octet-aligned mode)",
                    "table number": 218,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "L.1\tGeneral",
            "description": "This Annex describes Facsimile over IP (FoIP) transmission in MTSI using UDPTL-based transmission, see ITU-T Recommendation T.38, [93].\nFoIP is an optional capability for both MTSI client in terminals and MTSI MGWs. This Annex defines the minimum capabilities that need to be supported when FoIP is supported.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "L.2\tFoIP support in MTSI clients",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "L.2.1\tFoIP support in MTSI client in terminal",
                    "description": "",
                    "summary": "",
                    "text_content": "An MTSI client in terminal supporting FoIP is typically either a facsimile gateway or a facsimile end-point and does not need to support both cases.\nAn MTSI client in terminal may support FoIP where the MTSI client in terminal is used as a facsimile gateway between an external Group 3 facsimile equipment and the IMS network. In this case, the MTSI client in terminal acts as an Internet Facsimile Protocol (IFP) peer, either as an emitting gateway or as a receiving gateway depending on whether the MTSI client in terminal initiates the Internet Facsimile Transfer (IFT) or whether it accepts the IFT, [93].\nAn MTSI client in terminal may support FoIP where the MTSI client in terminal is the end-point for the facsimile transmission. In this case, the facsimile transmission originates or terminates in the MTSI client in terminal.\nAn MTSI client in terminal supporting FoIP and used as a facsimile gateway shall support:\n-\tinput/output to Group 3 facsimile devices, [91]\nNOTE:\tThe interface used to connect the external facsimile device to the MTSI client in terminal is outside the scope of this specification.\nAn MTSI client in terminal supporting FoIP and used either as a facsimile gateway or as a facsimile end-point should support the recommended configuration defined in Clause L2.3, Table L.1.\n-\tencapsulating and decapsulating T.30 to/from Internet Facsimile Protocol (IFP) packets, [93];\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "L.2.2\tFoIP support in MTSI MGW",
                    "description": "",
                    "summary": "",
                    "text_content": "An MTSI MGW may support FoIP where the MGW is used as a facsimile gateway between the IMS network and a Circuit Switched (CS) network, e.g. PSTN or CS GERAN, in order to connect to another Group 3 facsimile device.\nAn MTSI MGW supporting FoIP should support the recommended configuration defined in Clause L2.3, Table L.1.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "L.2.3\tRecommended configuration",
                    "description": "",
                    "summary": "",
                    "text_content": "The recommended configuration for T.38 UDPTL-based FoIP is defined in Table L.1.\nTable L.1: Recommended configuration for T.38 UDPTL-based FoIP\n\nIt is recommended that the MTSI client supports sending and receiving facsimile with 200% redundancy when UDP redundancy is used, even if the SDP attributes and parameters (‘T38FaxUdpECDepth’ with ‘minred’ and ‘'maxred’) are not supported. This allows for transmitting each IFP message three times, once as a primary message and twice as redundancy messages.\n",
                    "tables": [
                        {
                            "description": "Table L.1: Recommended configuration for T.38 UDPTL-based FoIP",
                            "table number": 219,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "L.3\tSession setup",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "L.3.1\tSession setup for any MTSI client supporting facsimile transmission",
                    "description": "",
                    "summary": "",
                    "text_content": "An MTSI client supporting facsimile transmission shall support facsimile transmission in stand-alone sessions without any other media types.\nNOTE:\tThis does not prevent supporting facsimile transmission also in other session types, for example in speech+facsimile sessions, but this is not described here.\nAn MTSI client supportings facsimile versions (T38FaxVersion) higher than 0 shall be capable of downgrading the session to any lower facsimile version, if indicated by a received SDP message.\nAn MTSI client sending an SDP for a facsimile session shall include the following in the SDP (offer or answer):\n-\tMIME media type and subtype names as defined in [94];\n-\tbandwidth information, both on media level and session level;\n-\tT38FaxVersion attribute, if the offered version is higher than 0;\n-\tT38FaxRateManagement attribute, with the value according to the offered method.\nAbsence of the T38FaxVersion attribute indicates that only version 0 is supported.\nSDP examples for facsimile calls can be found in clause L.7.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "L.3.2\tSession setup when the recommended profile is supported",
                    "description": "",
                    "summary": "",
                    "text_content": "When the MTSI client supports facsimile transmission according to the recommended profile in Annex L.2.3 and initiates a session for UDPTL-based facsimile transmission then:\n-\tthe following SDP lines shall be used in the SDP offer:\n-\tb=AS with the bandwidth set to at least 46 kbps for IPv4 or 48 kbps for IPv6;\n-\tT38FaxVersion attribute indicating at least version 2;\n-\tT38FaxRateManagement attribute with value ‘transferredTCF’;\n-\tthe following SDP attributes should be included in the SDP offer:\n-\tT38MaxBitRate, the value should be set to 14400;\n-\tT38FaxMaxBuffer with value 1800;\n-\tT38FaxMaxDatagram with value 150;\n-\tT38FaxUdpEC with value ‘t38UDPRedundancy’.\nOther SDP attributes defined in ITU-T T.38 Annex D may be included, if supported.\nWhen the MTSI client supports facsimile transmission according to the recommended profile in Annex L.2.3 and accepts an offer for a session initiation for facsimile transmission then:\n-\tthe following SDP lines shall be included in the SDP answer:\n-\tT38FaxVersion attribute indicating at least version 2;\n-\tT38FaxRateManagement, the value shall be the same as in the SDP offer;\n-\tT38FaxUdpEC, the value to include depends both on what error correction schemes the MTSI client supports and what error correction schemes that are declared in the SDP offer;\n-\tb=AS, the value indicates the bandwidth needed for facsimile transmission and should be aligned with T38MaxBitRate (if included);\n-\tand the following SDP attributes should be included:\n-\tT38MaxBitRate, the value should be set to 14400;\n-\tT38FaxMaxBuffer, the value indicates the receiver buffer size.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "L.4\tData transport using UDP/IP",
            "description": "An MTSI client in terminal supporting facsimile transmission using UDP/IP shall support:\n-\tencapsulating and decapsulating T.30 [92] into/from Internet Facsimile Protocol (IFP) packets [93];\n-\tUDPTL-based transport format in ITU-T Recommendation T.38 [93], and:\n-\tredundancy transmission of primary IFP packets, see ITU-T Recommendation T.38 Clause 9.1.4.1 [93].\nAn MTSI client in terminal supporting facsimile transmission using UDP/IP may support:\n-\tthe parity FEC scheme specified in ITU-T Recommendation T.38 Annex C [93].\nAn IFP packet may include either partial, single or multiple HDLC frames.\nA T.38 packet may include both one IFP packet and one or more redundancy/FEC information packets.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "L.5\tCS GERAN inter-working",
            "description": "An MTSI MGW for CS GERAN inter-working and supporting facsimile transmission should support the recommended profile in Annex L.2.3.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "L.6\tPSTN inter-working",
            "description": "An MTSI MGW for PSTN inter-working and supporting facsimile transmission should support the recommended profile in Annex L.2.3.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "L.7\tSDP examples",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "L.7.1\tFacsimile-only session",
                    "description": "",
                    "summary": "",
                    "text_content": "This example shows the media scope of the SDP offer and SDP answer for a facsimile-only session when the recommended configuration in Annex L.2.3 is offered by both end-points.\nTable L.2: Example SDP offer for facsimile-only session\n\nComments:\nThe session bandwidth is set to 46 kbps based on the following calculation:\n-\tthe maximum fax bitrate is 14.4 kbps;\n-\tit is recommended that the MTSI client supports 200% redundancy;\n-\t14.4 kbps and 150 bytes in each IP/UDP packet gives 12 packets per second;\n-\tIPv4 and UDP gives 28 bytes overhead for each IP/UDP packet (IPv6 and UDP gives 48 bytes overhead).\nThis gives 3*14400 +12*28*8 = 45888 bps, which is rounded up to 46 kbps for IPv4 (48 kbps for IPv6).\nITU-T Recommendation T.38 states that only ‘T38FaxRateManagement’ is mandatory to include in the SDP. There are however other reasons to include the other SDP lines:\n-\tb=AS is included both because this is useful information both for resource allocation in network nodes and the remote end-point, and because it is required by the current specification, see Clause 6.2.5.1;\n-\tthe ‘T38FaxVersion’ attribute needs to be included to declare that version 2 is supported, since the other end-point would otherwise assume that only version 0 is supported;\n-\tthe ‘T38MaxBitRate’, ‘T38FaxMaxBuffer’ and ‘T38FaxMaxDatagram’ attributes are very useful to ensure that the remote end-point sends fax media within the limitations of the local end-point;\n-\tThe ‘T38FaxUdpEc’ attribute is very useful information for the remote end-point in case of bad channel conditions.\nThe SDP attributes ‘T38FaxFillBitRemoval’, ‘T38FaxTranscodingMMR’ and ‘T38FaxTranscodingJBIG’ are not included since the MTSI client is not required to support these options.\nThe SDP attributes ‘T38FaxMaxIFP’, ‘T38FaxUdpECDepth’ and ‘T38FaxUdpFECMaxSpan’ are not included since these attributes are not defined for T.38 fax version 2.\n\n",
                    "tables": [
                        {
                            "description": "Table L.2: Example SDP offer for facsimile-only session",
                            "table number": 220,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "M.1\tIntroduction",
            "description": "This Annex provides the SDP attribute  registration information that is referenced from the IANA registry at /.\n\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.2\t3gpp_sync_info",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\n3gpp_sync_info\nLong-form Attribute Name in English:\n3GPP Synchronization Information attribute\nType of Attribute\nMedia level and Session Level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute specifies whether media streams should be synchronized or not.\nAppropriate Attribute Values for this Attribute:\nThe attribute is a value attribute. The defined values are \"Sync\" and \"No Sync\".\nMUX Category for this Attribute:\nNORMAL\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.3\t3gpp_MaxRecvSDUSize",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\n3gpp_MaxRecvSDUSize\nLong-form Attribute Name in English:\n3GPP Maximum Receive SDU Size attribute\nType of Attribute\nMedia level and Sesssion level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute indicates the maximum SDU size (in octets) of the application data (excluding RTP/UDP/IP headers) that can be transmitted to the receiver without segmentation.\nAppropriate Attribute Values for this Attribute:\nThe attribute is a value attribute. The defined values are 1*5DIGIT; 0 to 65535.\nMUX Category for this Attribute:\nNORMAL\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.4\t3gpp_mtsi_app_adapt",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\n3gpp_mtsi_app_adapt\nLong-form Attribute Name in English:\n3GPP MTSI RTCP-APP Adaptation attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to negotiate which RTCP-APP request messages that can be used in a session.\nAppropriate Attribute Values for this Attribute:\nThe attribute is a value attribute. The defined values are: \"RedReq\", \"FrameAggReq\", \"AmrCmr\", \"EvsRateReq\", \"EvsBandwidthReq\", \"EvsParRedReq\", \"EvsIoModeReq\", \"EvsPrimaryModeReq\".\nMUX Category for this Attribute:\nIDENTICAL-PER-PT\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.5\tpredefined_ROI",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\npredefined_ROI\nLong-form Attribute Name in English:\n3GPP predefined video region-of-interest (ROI) attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to negotiate which pre-defined regions of interest can be requested in a video telephony session.\nAppropriate Attribute Values for this Attribute:\nSee clause 6.2.3.4\nMUX Category for this Attribute:\nIDENTICAL-PER-PT\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.6\tbw-info",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\nbw-info\nLong-form Attribute Name in English:\nAdditional bandwidth information attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to negotiate additional bandwidth information for sessions where the \"b=\"-line bandwidth provides insufficient information or no information at all.\nAppropriate Attribute Values for this Attribute:\nSee clause 19.3.\nAdditional attribute values may be defined in the future.\nMUX Category for this Attribute:\nIDENTICAL-PER-PT\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.7\tccc_list",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\nccc_list\nLong-form Attribute Name in English:\n3GPP compact concurrent codec capabilities (CCC) attribute\nType of Attribute\nSession level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to indicate the concurrent codec capabilities of a terminal in a compact representation.\nAppropriate Attribute Values for this Attribute:\nSee clause S.5.7.2\nMUX Category for this Attribute:\nNORMAL\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.8\tanbr",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\nanbr\nLong-form Attribute Name in English:\n3GPP access network bitrate recommendation (ANBR) support attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to indicate the UE’s ability to use ANBR as an adaptation trigger and also its ability to receive ANBR information from the access network.\nAppropriate Attribute Values for this Attribute:\nNo values. See clause 6.2.9 for detailed usage.\nMUX Category for this Attribute:\nIDENTICAL\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.9\tPLR_adapt",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\nPLR_adapt\nLong-form Attribute Name in English:\nPacket Loss Rate Adaptation\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to describe the media receiver’s ability adapt codec configurations based on packet loss rate.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 clauses W.1, W.2, and W.3 for ABNF and detailed usage.\nMUX Category for this Attribute:\nIDENTICAL\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.10\tMAXimum-e2e-PLR",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\nMAXimum-e2e-PLR\nLong-form Attribute Name in English:\nMaximum end-to-end PLR of the media receiver\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to describe the maximum tolerable packet loss rate for the media receiver and a means to negotiate how this loss rate can be distributed across different links.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 clauses W.4.2 and W.4.3 for ABNF and detailed usage.\nMUX Category for this Attribute:\nIDENTICAL\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "M.11\t3gpp-qos-hint",
            "description": "Contact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\n3gpp-qos-hint\nLong-form Attribute Name in English:\n3GPP QoS hint attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to describe the UE’s desired QoS properties from the local access network.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 clause 6.2.7.4 for ABNF and detailed usage.\nMUX Category for this Attribute:\nIDENTICAL\nM.12\timageseq\nContact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\nimageseq\nLong-form Attribute Name in English:\n3GPP Image Sequence attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to negotiate the usage of still images in a session.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 clause 6.2.11 for ABNF and detailed usage.\nMUX Category for this Attribute:\nNORMAL\nM.13\t3gpp_360video\nContact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\n3gpp_360video\nLong-form Attribute Name in English:\n3GPP 360-degree Projected Video attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to negotiate the usage of a 360-degree projected video steam in a session .\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 Annex Y.6.2 for ABNF and detailed usage.\nMUX Category for this Attribute:\nNORMAL\nM.14\titt4rt_group\nContact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\nitt4rt_group\nLong-form Attribute Name in English:\n3GPP ITT4RT Group attribute\nType of Attribute\nSession level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to group 360-degree media and overlay media using the mid attribute\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 Annex Y.6.2.6 for ABNF and detailed usage.\nMUX Category for this Attribute:\nNORMAL\nM.15\t3gpp_overlay\nContact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\n3gpp_overlay\nLong-form Attribute Name in English:\n3GPP Overlay attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to indicate one or more parameters for configuring the rendering properties of an overlay.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 Annex Y.6.4.3 for ABNF and detailed usage.\nMUX Category for this Attribute:\nNORMAL\nM.16\t3gpp_360video_replacement\nContact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\n3gpp_360video_replacement\nLong-form Attribute Name in English:\n3GPP 360-degree Video Replacement attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to indicate that the content captured in the 360-degree video can be replaced.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 Annex Y.6.4.4 for ABNF and detailed usage.\nMUX Category for this Attribute:\nNORMAL\nM.17\t3gpp_fisheye\nContact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\n3gpp_fisheye\nLong-form Attribute Name in English:\n3GPP 360-degree Fisheye Video attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to indicate a 360-degree fisheye video stream.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 Annex Y.6.5.2 for ABNF and detailed usage.\nMUX Category for this Attribute:\nNORMAL\nM.18\t3gpp-camera-calibration\nContact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\n3gpp-camera-calibration\nLong-form Attribute Name in English:\n3GPP Camaera Calibration attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used for signaling of camera calibration parametres for network-based stitching.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 Annex Y.6.6 for ABNF and detailed usage.\nMUX Category for this Attribute:\nNORMAL\nM.19\tstitch_group\nContact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\nstitch_group\nLong-form Attribute Name in English:\n3GPP Stitch Group attribute\nType of Attribute\nSession level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to group the to-be-stitched 2D video captures using the mid attribute for network-based stitching.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 Annex Y.6.6 for ABNF and detailed usage.\nMUX Category for this Attribute:\nNORMAL\nM.20\tno_other_overlays\nContact name, email address, and telephone number:\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\nAttribute Name (as it will appear in SDP)\nno_other_overlays\nLong-form Attribute Name in English:\n3GPP No Other Overlays attribute\nType of Attribute\nMedia level\nIs Attribute Value subject to the Charset Attribute?\nThis Attribute is not dependent on charset.\nPurpose of the attribute:\nThis attribute is used to indicate that the MRF shall not group the 360-degree media stream from that ITT4RT-Tx client with overlay media streams from other ITT4RT clients.\nAppropriate Attribute Values for this Attribute:\nSee TS 26.114 Annex Y.6.8.2 for ABNF and detailed usage.\nMUX Category for this Attribute:\nNORMAL\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "N.1\tGeneral",
            "description": "If an MTSI client includes any video codecs in the SDP offer or answer, procedures to compute b=AS are left to the discretion of the implementation.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "N.2\tExamples",
            "description": "Table N.x shows example values of b=AS in IPv4 and IPv6 for each source bit-rate and image size pair of H.264/AVC. These values are determined from encoding a variety of content with the codec targeting a particular source bit-rate and then measuring the fluctuations of the encoded bit-rate in order to determine the recommended b=AS values. As the source bit-rate increases, the relative differences of b=AS values in IPv4 and IPv6 decrease as the proportion of RTP/UDP/IP headers in the packet decreases, but the required margin for the fluctuations increases. Different source bit-rates and b=AS values can be used for the same image size depending  on service policy, alternative codec configurations, and the amount of bit-rate variation introduced by the rate control algorithm implementation.\nTable N.1: Example of b=AS values for H.264/AVC\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table N.1: Example of b=AS values for H.264/AVC",
                    "table number": 221,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "O.1\tIntroduction",
            "description": "This Annex provides the RTP header extension  registration information that is referenced from the IANA registry at /.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "O.2\turn:3gpp:video-orientation",
            "description": "The desired extension naming URI:\nurn:3gpp:video-orientation\nA formal reference to the publicly available specification:\nTS 26.114\nA short phrase describing the function of the extension:\nCoordination of video orientation (CVO) feature, see clause 6.2.3.3\nContact information for the organization or person making the registration\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "O.3\turn:3gpp:video-orientation:6",
            "description": "The desired extension naming URI:\nurn:3gpp:video-orientation:6\nA formal reference to the publicly available specification:\nTS 26.114\nA short phrase describing the function of the extension:\nHigher granularity (6-bit) coordination of video orientation (CVO) feature, see clause 6.2.3.3\nContact information for the organization or person making the registration\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "O.4\turn:3gpp:roi-sent",
            "description": "The desired extension naming URI:\nurn:3gpp:roi-sent\nA formal reference to the publicly available specification:\nTS 26.114\nA short phrase describing the function of the extension:\nSignalling of the arbitrary region-of-interest (ROI) information for the sent video, see clause 6.2.3.4\nContact information for the organization or person making the registration\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "O.5\turn:3gpp:predefined-roi-sent",
            "description": "The desired extension naming URI:\nurn:3gpp:predefined-roi-sent\nA formal reference to the publicly available specification:\nTS 26.114\nA short phrase describing the function of the extension:\nSignalling of the predefined region-of-interest (ROI) information for the sent video, see clause 6.2.3.4\nContact information for the organization or person making the registration\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "O.6\turn:3gpp:audio-mixing-gain",
            "description": "The desired extension naming URI:\nurn:3gpp:audio-mixing-gain\nA formal reference to the publicly available specification:\nTS 26.114\nA short phrase describing the function of the extension:\nSignalling of the audio mixing gain header extension for the sent audio, see clause Y.X.1\nContact information for the organization or person making the registration\n3GPP Specifications Manager\n3gppContact@etsi.org\n+33 (0)492944200\n\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "P.1\tGeneral",
            "description": "This annex describes operation principles and provides examples to video packet loss handling scheme described in section 9.3. Several different video packet loss handling behaviours are possible at both sender and receiver ends for responding and reporting, respectively. Example criteria shown in this section are not to be seen as a scheme that excludes other designs. Implementers are free to use any packet loss algorithm as long as the requirements and recommendations specified in clause 9.3 are fulfilled.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "P.2\tVideo error recovery",
            "description": "Efficient video error recovery requires error tracking capabilities at both the sender and the receiver side. Error detection and tracking is necessary on the receiver side for detecting the occurrence of the error as well as detecting the recovery from the error. On the sender side it is necessary for producing a recovery picture that would address the reported packet loss. Basically a receiver should be able to detect errors and report them to the sender in timely fashion. In return sender responds by sending recovery pictures or performing gradual decoder refresh (GDR).\nAn example of video error recovery is illustrated in Figure P.1 below using a NACK message.\nFigure P.1 illustrates the process of video error recovery in a communication system, where a NACK (Negative Acknowledgment) feedback message is used to indicate the absence of a required signal. The figure depicts the sender, receiver, and the feedback loop, highlighting the role of the NACK in determining the retransmission of lost data packets. The sender sends a video frame, and upon receiving a NACK, it retransmits the frame. This process ensures that the receiver can recover from transmission errors and maintain the quality of the video stream. The figure also shows the synchronization between the sender and receiver, which is crucial for efficient error recovery.\nFigure P.1: Video error recovery using NACK feedback message.\nIn this example, the error correction is performed in the following steps:\n1)\tSender encodes a reference picture (blue) and transmits it. One or more of the packets belonging to this picture are lost.\n2)\tReceiver detects lost packets belonging to the blue picture upon receiving packets belonging to the picture following the blue picture or the last packet (if received) of the blue picture, after de-jittering.\n3)\tWhen the decoder tries to decode the picture following the blue picture and notices that a reference picture that it is referring to (i.e. the blue picture) is missing or has been partially received, and in response flags an error.\n4)\tUpon seeing the error report from the decoder, the receiver issues a NACK message. The duration of time that elapses from the first detection of missing packets to the issuance of the feedback message is denoted as the receiver reaction time.\n5)\tSender receives the NACK message, feeds this information to the encoder, which responds by encoding the next picture either as an intra or inter picture. Alternatively the encoder can generate GDR over next N frames. In the inter-picture case, the encoder refers to a reference picture (red) that it assumes can be correctly decoded at the receiver side. The duration of time that elapses from receipt of the feedback message and sending of the recovery picture is denoted as the sender reaction time.\n6)\tSender sends the recovery picture or the GDR to the receiver.\n7)\tReceiver’s decoder continues to decode incoming pictures looking for the arrival of the recovery picture or full refresh from GDR. The receiver may opt not to render any incoming corrupted pictures while waiting for the arrival of the recovery picture or full refresh.\nIf the recovery picture does not arrive in response wait time duration (RWT) then the receiver should issue another NACK message to request error recovery and wait for recovery. If the recovery still does not occur within another RWT, then it starts issuing PLI messages to request IDR or GDR recovery. This is illustrated in Figure P.2 below.\nFigure P.2 illustrates the process of video error recovery using a PLI (Predictive Low-delay Interpolation) feedback message. The figure depicts the flow of data from the source, through various processing stages, to the destination. Key components include the source, encoder, PLI feedback loop, and destination. The figure demonstrates how PLI feedback messages are used to predict and correct errors in the video stream, ensuring a high-quality viewing experience.\nFigure P.2: Video error recovery using PLI feedback message.\nPLI request becomes necessary when the likelihood of having a common reference frame for inter error recovery is diminished. In this example, the error correction is performed in the following steps:\n1)\tReceiver issues a PLI message after waiting for two RWT duration for a recovery picture requested by NACK messages to arrive from the onset of the error.\n2)\tSender upon reception of the PLI message, encodes the next picture as IDR picture or starts a GDR.\n3)\tReceiver receives the IDR picture or the GDR pictures resulting in full refresh.\nIn the above example, a second PLI is received by the sender within RWT interval. In this case, the sender ignores the second PLI since the receiver cannot detect the arrival of the first sent IDR/GDR within this time frame. The same principle applies to NACK messages as well. This would also apply to cases where the sender has sent a picture that could serve as a recovery picture (not triggered by a PLI/NACK message) prior to the reception of a PLI/NACK message within RWT duration. In this case the sender does not have to respond to the received PLI/NACK message as illustrated in Figure P.3 below.\nFigure P.3 illustrates a scenario where the sender is not required to respond to incoming NACK/PLI (Negative Acknowledgment/Prohibited Link Integrity) messages. This figure demonstrates the efficient handling of such situations, ensuring that resources are not wasted on unnecessary responses. The diagram highlights the communication flow between the sender and receiver, emphasizing the importance of proper message handling in telecommunication systems.\nFigure P.3: Example case where sender does not have to respond to incoming NACK/PLI messages.\nThis case would apply to schemes where the sender periodically performs some form of periodic intra refresh or inter recovery (periodically predict from long term reference (LTR) pictures) as long as the period is conforms to the timing restrictions defined in section 9.3.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "P.3\tRTP Retransmission",
            "description": "RTP retransmission offers retransmission of lost packets reported by NACK feedback. The receiver detects missing packets and requests retransmission of missing packets. The sender upon receiving the NACK message decides to take corrective action by retransmitting the reported missing packets to the receiver. If retransmitted packets arrive in time for rendering, then timely recovery is achieved.\nAn example of recovery from error is illustrated in Figure P.4 below using a NACK message.\nFigure P.4 illustrates the process of video error recovery in a communication system, where a NACK (Negative Acknowledgment) feedback message is used to indicate the need for retransmission. The figure depicts the sender, receiver, and feedback loop, highlighting the role of the NACK in determining the retransmission of corrupted data packets. The sender sends a video frame, which may contain errors. If the receiver detects an error, it sends a NACK signal back to the sender, prompting a retransmission of the affected frame. This process ensures that the video stream is transmitted without significant loss of quality due to errors.\nFigure P.4: Video error recovery using NACK feedback message and retransmission.\nIn this example, the error correction is performed in the following steps:\n1)\tSender encodes a reference picture (blue) and transmits it. Sender stores RTP packets corresponding to this frame in its buffers. One or more of the packets belonging to this picture are lost.\n2)\tReceiver detects lost packets belonging to the blue picture upon receiving packets belonging to the picture following the blue picture or the last packet (if received) of the blue picture, after de-jittering.\n3)\tThe receiver issues a NACK message and pauses decoding while caching incoming packets.\n4)\tSender receives the NACK message, checks whether the requested packets are available in its cache. If they are, it retransmits the requested packets.\n5)\tReceiver monitors the incoming packets to determine the arrival of the requested packets to resume decoding.\n6)\tIf packets arrive in time, rendering is not interrupted.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Q.1\tGeneral",
            "description": "This annex contains examples of computing b=AS for EVS Primary mode when ptime=20, and ptime=40. In these examples, it is assumed that no extra bandwidth is allocated for redundancy.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Q.2\tProcedure for computing the bandwidth",
            "description": "The bandwidth is calculated using the following procedure when no extra bandwidth is allocated for redundancy:\n1)\tCalculate the size of the RTP payload, see below.\n2)\tCalculate the size of the IP packets by taking the RTP payload size (in bytes) and adding the IP/UDP/RTP overhead: 20 bytes for IPv4; 40 bytes for IPv6; 8 bytes for UDP; 12 bytes for RTP.\n3)\tConvert the IP packet size to bits.\n4)\tCalculate the required bit-rate (bps) given the packet size and the packet rate: 50 packets per second for 1 frame per packet; 25 packets per second for 2 frames per packet.\n5)\tThe b=AS bandwidth is then calculated by converting the required bit-rate to kbps and rounding to the nearest higher integer value.\nIf the SDP includes multiple codecs and/or configurations, the bandwidth is calculated for each configuration and the b=AS bandwidth is set to the highest of the bandwidths.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Q.3\tComputation of RTP payload size",
            "description": "When the b=AS bandwidth is computed, it is assumed that the codec is using the highest allowed bit-rate for each frame.\nThe RTP payload size for the 2 bytes header-full payload format and 1 frame/packet is calculated from the following components:\n-\t8 bits for the codec mode request (CMR)\n-\t8 bits for the table of content (ToC)\n-\tN bits for the speech frame (size depends on bit-rate)\n-\tNo padding in the end of the RTP payload is needed since each item is already an integer number of octets\nThe RTP payload size for the 2 bytes header-full payload format and 2 frames/packet is calculated from the following components:\n-\t8 bits for the codec mode request (CMR)\n-\t16 bits for the table of content (ToC)\n-\tN bits for the speech frame (size depends on bit-rate)\n-\tNo padding in the end of the RTP payload is needed since each item is already an integer number of octets\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Q.4\tDetailed computation",
            "description": "The tables below give a detailed description of the bandwidth computation. The b=AS bandwidth is not defined for SID.\nNOTE 1:\tThe tables below apply for both the header-full format and the compact format of EVS Primary mode, as switching between the modes can occur during the session.\nFor each codec mode, b=AS value of EVS AMR-WB IO mode is the same as the b=AS value of AMR-WB in octet-aligned mode. See clause K.4.\nNOTE 2:\tThe tables in clause K.4 also apply for the compact format of EVS AMR-WB IO mode, as switching between the modes can occur during the session.\nNOTE 3:\tIn tables Q.1 and Q.2, the speech frame of 7.2 kbps in EVS Primary mode at ptime=20 is zero-padded by one byte to avoid the protected payload size of 8.0 kbps, but zero-padding by additional byte(s) is also allowed.\n\nTable Q.1: Computation of b=AS for EVS Primary mode (IPv4, ptime=20)\n\nTable Q.2: Computation of b=AS for EVS Primary mode (IPv6, ptime=20)\n\nTable Q.3: Computation of b=AS for EVS Primary mode (IPv4, ptime=40)\n\nTable Q.4: Computation of b=AS for EVS Primary mode (IPv6, ptime=40)\n\nTable Q.5: Computation of b=AS for EVS Primary mode (IPv4, ptime=20, dual-mono)\n\nTable Q.6: Computation of b=AS for EVS Primary mode (IPv6, ptime=20, dual-mono)\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table Q.1: Computation of b=AS for EVS Primary mode (IPv4, ptime=20)",
                    "table number": 222,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table Q.2: Computation of b=AS for EVS Primary mode (IPv6, ptime=20)",
                    "table number": 223,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table Q.3: Computation of b=AS for EVS Primary mode (IPv4, ptime=40)",
                    "table number": 224,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table Q.4: Computation of b=AS for EVS Primary mode (IPv6, ptime=40)",
                    "table number": 225,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table Q.5: Computation of b=AS for EVS Primary mode (IPv4, ptime=20, dual-mono)",
                    "table number": 226,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table Q.6: Computation of b=AS for EVS Primary mode (IPv6, ptime=20, dual-mono)",
                    "table number": 227,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "R.1\tVideo Region-of-Interest (ROI)",
            "description": "The RTCP feedback types for ‘Arbitrary ROI’ and ‘Pre-defined ROI’ is registered with IANA as follows:\nValue name: 3gpp-roi-arbitrary\nLong name: Video region-of-interest (ROI) arbitrarily selected by the endpoint\nMux-Category: IDENTICAL-PER-PT\nReference: TS 26.114.\nValue name: 3gpp-roi-predefined\nLong name: Video region-of-interest (ROI) pre-defined by the sender and selected by the endpoint\nMux-Category: IDENTICAL-PER-PT\nReference: TS 26.114.\nThe following value can be registered as one FMT value in the \"FMT Values for PSFB Payload Types\" registry http://www.iana.org/assignments/rtp-parameters:\nName: ROI\nLong name: Video region-of-interest (ROI)\nValue: 9\nReference: TS 26.114.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "R.2\tDelay Budget Information (DBI)",
            "description": "The RTCP feedback types for Delay Budget Information (DBI) is registered with IANA as follows:\nValue name: 3gpp-delay-budget\nLong name: Available or requested delay budget specified in milliseconds\nMux-Category: IDENTICAL-PER-PT\nReference: TS 26.114.\nThe following value can be registered as one FMT value in the \"FMT Values for RTPFB Payload Types\" registry http://www.iana.org/assignments/rtp-parameters:\nName: DBI\nLong name: Delay Budget Information (DBI)\nValue: 10\nReference: TS 26.114.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "R.3\tViewport (VP)",
            "description": "The RTCP feedback types for ‘Viewport’ is  registered with IANA as follows:\nValue name: 3gpp-viewport\nLong name: Viewport feedback for viewport-dependent 360-degree video\nMux-Category: IDENTICAL-PER-PT\nReference: 3GPP TS 26.114.\nThe following value is registered as one FMT value in the \"FMT Values for PSFB Payload Types\" registry http://www.iana.org/assignments/rtp-parameters:\nName: VP\nLong name: Viewport (VP)\nValue: To be assigned by IANA\nReference: 3GPP TS 26.114.\nEditor’s Note: A new FMT Value for PSFB Payload Types shall be assigned by IANA for the “Viewport” RTCP feedback type”\n\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "S.1\tGeneral",
            "description": "This annex describes an extension to MTSI, which is optional to implement for an MTSI client. It contains descriptions of both mandatory and optional functionalities for the particular type of MTSI client that is called MSMTSI client, which is better suited for group audio/video communication than a regular MTSI client. The specifications in this Annex apply in addition to the rest of this specification, except when it is explicitly stated that the text here replaces other parts of this specification.\nThe intention with this extension is to avoid transcoding as far as possible in multiparty calls. For example, without this extension, video conferencing would need transcoding in the MRF to compose the different videos received from different senders into a single video, containing a main video and a number of thumbnails, which is then sent to each receiver. It may happen that the MRF needs to compose different video compositions to different receivers, which multiplies the need for transcoding and thus scales poorly with the size of the group. With this extension, the MRF can forward the necessary streams, without transcoding, to each MSMTSI client in terminal, which then composes the final image that is presented to the user.\nAvoiding transcoding reduces the complexity in the MRF and reduces the end-to-end delay. Quality degradations caused by the transcoding can often also be avoided. The benefits with this extension are further described in TR 26.980 [152].\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "S.2\tVideo",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "S.2.1\tConversational video",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI client in the terminal shall be capable of receiving and locally composing at least one main video and one or more video thumbnails. A \"thumbnail\" video is in this context defined as a receive-only video \"m=\"-line that is not the first video \"m=\"-line in the SDP, and that is also not identified with any \"a=content:main\" or \"a=content:slides\".\nAn MSMTSI client in terminal shall support receiving at least one thumbnail and may also support receiving any number of additional thumbnails, subject to MSMTSI client capability. An MSMTSI MRF shall support sending at least two thumbnails and may support sending any number of additional thumbnails, subject to MSMTSI MRF capability.\nAn MSMTSI client in terminal shall support sending at least one thumbnail-sized simulcast format of the main video, and may support sending also other simulcast formats. An MSMTSI MRF shall support receiving at least one thumbnail-sized simulcast format of the main video, and may support receiving also other simulcast formats.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.2.2\tNon-conversational (screenshare) video",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI client may support sending and receiving screenshare video. The first picture of the screen sharing video an MSMTSI client sends after being granted the screenshare BFCP floor (see clause S.5.6) shall be random accessible, i.e., as if a FIR would have been received.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "S.3\tAudio",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "S.3.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI client in terminal shall be capable of receiving and may be capable of sending multiple simultaneous audio RTP streams. The number of multiple audio streams received at the MSMTSI client may be different than the number of multiple audio streams sent from the same MSMTSI client.\nSupport for multiple audio streams in the direction from an MSMTSI MRF to an MSMTSI client in the terminal shall be interpreted as originating from different group call participants.\nAn MSMTSI client in terminal shall support local mixing of received audio streams, and may support use of spatial rendering tools, such as local Head-Related Transfer Function (HRTF), to perform audio panning and mixing of the multiple audio streams. Audio panning may enable the rendering device to choose to vary the audio levels of participants by adjusting the mixing gains.\nMulti-stream audio is not to be confused with multichannel audio where multi-stream audio may include one or more of mono, stereo, or multichannel audio RTP streams originating from different group call participants.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.3.2\tDe-jitter buffer",
                    "description": "",
                    "summary": "",
                    "text_content": "The functional requirements for jitter-buffer management of MSMTSI client in terminal shall meet the same minimum performance requirements per audio stream that are set for MTSI clients (Clause 8).\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "S.4\tSIP",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "S.4.1\tMSMTSI client in terminal",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI client in terminal shall, when connecting to a remote party that included the \"isFocus\" tag in any of its SIP headers, subscribe to SIP conference events, as described in [147]. The MSMTSI client in terminal shall be able to receive and handle conference event notifications, resulting from the subscription. The MSMTSI client in terminal shall be capable of parsing all conference event information elements, shall be capable of receiving partial conference event information, and shall be capable of presenting conference event information to the user of the MSMTSI client in terminal, either automatically or on explicit user request. The MSMTSI client in terminal shall be capable of presenting at least the values of the conference event information elements indicated in bold below to the user of the MSMTSI client in the terminal, and shall be capable to use the conference event information elements indicated in italics below for endpoint and media identification, as defined by [147] and [148] (here also indicating relevant parts of the XML document hierarchy, for information):\n-\t<conference-info>\n-\t<conference-description>\n-\t<display-text>\n-\t<subject>\n-\t<users>\n-\t<user>\n-\t<display-text>\n-\t<associated-aors>\n-\t<entry>\n-\t<uri>\n-\t<endpoint>\n-\t<media>\n-\t<src-id>\nValues for other conference event information elements may optionally be made available to the user of the MSMTSI client in the terminal.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.4.2\tMSMTSI MRF",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI MRF shall include the \"isFocus\" tag in all of its outgoing SIP headers that support inserting that tag. It shall be capable of handling subscriptions and unsubscriptions for conference event information, as specified in [147].\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "S.5\tMedia configuration",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "S.5.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI client that receives an SDP offer with \"m=\"-lines that it cannot handle or does not understand shall use regular SDP offer/answer procedures [8] to individually reject those unsupported \"m=\"-lines. An MSMTSI client shall not send RTP or RTCP for rejected \"m=\"-lines.\nAn MSMTSI client shall support controlling its maximum sending rate per \"m=\"-line for media related to that \"m=\"-line, as described by clause 6.2.5.\nA \"common codec\" is a codec (typically a legacy/older generation codec) that is supported by all the participants in the conference and enables transcoder-free MSMTSI conferencing. If all participants share support for more than a single codec for a certain media type, the codec providing the best media quality for a given bitrate should be chosen by the MSMTSI MRF as the \"common codec\".\nA \"preferred codec\" is a codec (typically a better compression performance, newer generation codec) that is supported by some but not all participants in the conference and enables better media quality.\nThe common codec and preferred codec(s) may be determined by:\n1)\tthe codecs that were offered or pre-selected by the conference participant that initiated the conference (ad hoc or pre-scheduled)\n2)\tthe codecs supported by other conference participants, e.g., by use of SIP OPTIONS (see clause S.5.7.3).\nWhen setting up individual sessions with the conference participants, the MSMTSI MRF:\n1)\tshall include the common codec in the SDP offer/answer negotiation, and\n2)\tmay additionally include the preferred codecs in the SDP offer/answer negotiation to improve conference quality or performance.\nTo avoid transcoding when multiple codecs of a media type are used in an MSMTSI session,\n1)\tsimulcast [154] shall be negotiated;\n2)\tusage of both preferred and common codecs in the SDP shall be supported;\n3)\tthe MSMTSI MRF shall include the preferred codecs in the SDP as being simulcast with a corresponding common codec stream for the same media type; and\n4)\ta participant sending media using a preferred codec shall also simulcast a representation of the same media using the common codec for that media type.\nWhen constructing \"a=rid\" [155] line identification of simulcast formats, MSMTSI clients in terminal and MSMTSI MRF shall use a 1:1 mapping per direction between each rid-id and the corresponding RTP payload type number in the \"pt=\" parameter on the \"a=rid\" line. It is optional for MSMTSI clients in terminal and MSMTSI MRF to support constraints parameters for the \"a=rid\" lines. An MSMTSI client in terminal and MSMTSI MRF shall be capable to ignore any \"a=rid\" constraints parameters it does not understand and shall correctly negotiate them away in the SDP answer, as specified in [155].\nNOTE 1: The only, currently defined \"a=rid\" constraint applicable to 3GPP audio codecs is bitrate (\"max-br\").\nThe recommended approach by which the common and preferred codec information is exchanged between the MSMTSI MRF and the MSMTSI terminals is to use the order in which the codecs are listed in the SDP a=simulcast line, which lists simulcast streams in order of decreasing priority. The common codec should be listed first, assuming that the common codec simulcast stream is to be used as far as possible, to avoid transcoding. The preferred codec may instead be listed first if a limited amount of transcoding is considered an acceptable cost for keeping good media quality.\nNOTE 2:\tAn MSMTSI MRF needs to make a trade-off between minimizing transcoding by use of a common codec and maximizing media quality by use of a preferred codec in the conference, which is described in more detail in clauses 6.17 and 6.13.4 in [152]. The common codec being listed with highest priority means that it will be kept, even if some other simulcast streams need to be rejected or dropped (e.g. due to network resource limitations, see clause S.8). The preferred codec being listed with highest priority similarly means that it will be kept, even if common codec simulcast streams need to be rejected or dropped, which can in turn require transcoding to some conference participants. This applies both across different simulcast streams (\";\" separator) and for alternatives (\",\" separator) within a single simulcast stream in the \"a=simulcast\" line. This choice between prioritizing common or preferred codecs does not impact interoperability and is therefore left for individual MSMTSI MRF implementation.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.5.2\tMain video",
                    "description": "",
                    "summary": "",
                    "text_content": "The main video SDP \"m=\"-line shall be the first video \"m=\"-line in an SDP offer from an MSMTSI client, to increase the probability that it is accepted by a non-MSMTSI client. The main video SDP \"m=\"-line shall be identified by an \"a=content:main\" SDP attribute [81] under that \"m=\"-line. The MSMTSI client shall be capable of identifying the main video when the video \"m=\"-line contains \"a=content:main\", even if this is not the first video \"m=\"-line in the SDP. An MSMTSI client shall be capable of receiving an SDP without any \"a=content:main\" SDP video attribute, and should then choose main video to be the first suitable video \"m=\"-line that cannot be clearly identified for another purpose (such as for example \"a=content:slides\", see below).\nIn case of video, where the main video and thumbnail video are being sent from the MSMTSI client to the MSMTSI MRF, use of simulcast shall be indicated in SDP according to [154] and [155] in an SDP offer. SDP simulcast negotiation decides which simulcast formats, if any, that are sent between the MSMTSI clients in terminal and the MSMTSI MRF. An MSMTSI client in terminal shall use send direction simulcast in the SDP when negotiating use of simulcast to send main video thumbnail. An MSMTSI MRF shall use receive direction simulcast in the SDP when negotiating use of simulcast towards an MSMTSI client in terminal to receive main video thumbnail.\nAn MSMTSI client in terminal that receives an SDP offer using simulcast from a remote party that is not a conference focus (indicated by the SIP isFocus tag not being present in SIP headers), should disable use of simulcast in the corresponding SDP answer.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.5.3\tThumbnail video",
                    "description": "",
                    "summary": "",
                    "text_content": "Each thumbnail video that the MSMTSI client supports shall be negotiated as a separate SDP video \"m=\"-line, different from the main video \"m=\"-line (\"a=content:main\") and any screenshare video \"m=\"-line (\"a=content:slides\").\nAn MSMTSI client in the terminal shall use receive-only direction for all thumbnail videos in the SDP. An MSMTSI MRF shall use send-only direction for all thumbnail videos in the SDP that are sent towards an MSMTSI client in the terminal. As a specific case of the general SDP \"m=\"-line handling specified by S.5, an MSMTSI client that receives an SDP offer with more thumbnail video \"m=\"-lines than it can support, shall disable the \"m=\"-lines it cannot support (by setting port to 0) in the SDP answer. Which thumbnail \"m=\"-lines to keep and which to reject, in case all cannot be supported, is left for MSMTSI client implementation preference.\nA thumbnail \"m=\"-line is generally not dedicated to a certain conference participant and the number of \"m=\"-lines for thumbnails therefore need not match the number of conference participants. If RTP stream selective forwarding (see clause S.6) is used for thumbnails by the MSMTSI MRF, though the forwarded participant may change at any point in time, a single thumbnail \"m=\"-line can map to an RTP stream from any one of the participants. The number of thumbnail \"m=\"-lines actually used between an individual MSMTSI client in terminal and an MSMTSI MRF is thus decided by the minimum number of thumbnail \"m=\"-lines in any of their SDPs, irrespective of the MSMTSI client in terminal or the MSMTSI MRF being the entity supporting the fewest thumbnail \"m=\"-lines. Therefore, the number of thumbnail \"m=\"-lines supported by an individual MSMTSI client in terminal does not limit the number of thumbnail \"m=\"-lines used between the MSMTSI MRF and other MSMTSI clients in terminals participating in the same conference.\nAn MSMTSI client in terminal that receives an SDP offer using thumbnails from a remote party that is not a conference focus (indicated by the SIP isFocus tag not being present in SIP headers), should disable thumbnail \"m=\"-lines in the corresponding SDP answer.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.5.4\tScreenshare video",
                    "description": "",
                    "summary": "",
                    "text_content": "When screenshare video is supported, it shall be indicated as a separate SDP video \"m=\"-line, identified by \"a=content:slides\" [81] under that \"m=\"-line. There is no restriction in how the screenshare video \"m=\"-line is ordered in relation to other \"m=\"-lines in the SDP, except that it shall be listed after the main video \"m=\"-line.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.5.5\tAudio",
                    "description": "",
                    "summary": "",
                    "text_content": "The main audio SDP \"m=\"-line shall be the first \"m=\"-line in an SDP offer from an MSMTSI client, to increase the probability that it is accepted by a non-MSMTSI client.\nSupport for multiple, simultaneous audio streams shall be indicated in SDP as separate audio \"m=\"-lines. The number of supported channels in multi-channel audio shall be indicated per audio stream through the SDP \"m=\"-line <encoding parameters>, with the default being a single channel when <encoding parameters> is omitted. There is no restriction in how additional audio \"m=\"-lines are ordered in relation to other \"m=\"-lines in the SDP, except that they shall be listed after the main audio \"m=\"-line.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.5.6\tBFCP",
                    "description": "",
                    "summary": "",
                    "text_content": "Use of BFCP (see also clause S.7) is defined in TS 24.147 [147]. BFCP is negotiated with a single \"m=\"-line for BFCP in SDP as specified in [150]. If both screenshare video and main video are negotiated, they shall be negotiated to use separate BFCP floor identifications. An MSMTSI client shall be capable of correctly associating SDP \"m=\"-lines with BFCP floors through the SDP answer, as described in [150].\nAn MSMTSI MRF shall support at least the BFCP floor control server role in SDP offer/answer.\nAn MSMTSI client in terminal shall support the BFCP floor control client role in SDP offer/answer, but may in addition support also the BFCP floor control server role. Which role is taken by which part is decided by BFCP SDP offer/answer.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.5.7\tCompact Concurrent Codec Negotiation and Capabilities",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "S.5.7.1\tGeneral",
                            "text_content": "To establish MMCMH sessions that make the most of all the participating terminals’ codec capabilities without exceeding the concurrent codec capabilities of each participating terminal, the MMCMH session intiator needs to know the concurrent codec capabilities of all the other terminals.  MSMTSI terminals can use the concurrent codec capabilities exchange procedures specified in this clause to obtain this information in a compact format.  Furthermore, the specified procedures can be used to negotiate, in a compact manner, which concurrent codecs to use for the MMCMH session.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "S.5.7.2\tThe Compact CCC SDP Attribute",
                            "text_content": "The Compact CCC SDP attribute enables MSMTSI terminals to communicate the CCC information in a more compact format.  The ABNF definition is as follows:\nccc-list\t= \"a=ccc_list:\" codeclist 1*63( \"|\" ccc-prof )\ncodeclist\t= codec [SP config] *63( \";\" codec [SP config] )\nccc-prof \t= \"ENC:\" num *63( rule num ) \":DEC:\" num *63( rule num )\ncodec\t= byte-string\n; byte-string defined in RFC 4566\nlevel\t= 1*3DIGIT\nprofile\t= 1*3DIGIT\nconfig\t= ( profile SP level ) / level\nrule\t= \";\" / \",\"\nnum\t= 1*2DIGIT\n\ncodec is the media subtype name of a codec as defined in the RTP payload format for that codec, e.g. \"H264\" for H.264 as defined in [25] and \"H265\" for H.265 as defined in [120], respectively.\ncodeclist is an ordered list of the different codecs that are supported by the terminal.  The codecs should be listed in order of decreasing complexity from left to right for the \",\" rule to indicate the ability to substitute an instance of a more complex codec with a simpler one.\nlevel, which is optional, specifies the level of the codec, converted and expressed in hexadecimal format, i.e., for H.264 and H.265 the value is equal to level_idc as defined in [25] and level-id as defined in [120], respectively.\nprofile, which is optional, specifies the profile of the codec, e.g. for H.264 and H.265 the value is equal to profile_idc as defined in [25] and profile-id as defined in [120], both expressed in hexadecimal fomat, respectively. If the profile is included then the level is also included. However, it is allowed to have the level to be present without the profile being present.\nrule specifies in a particular CCC profile (ccc-prof) whether the resources used for a concurrent instance of the codec may be used instead by a concurrent instance of the codec listed afterwards, e.g., the next listed codec is less computationally complex and runs on the same processor as the previously listed codec.  When the value is \",\" then an instance of the subsequent codec can used in place of an instance of the previously listed codec.  When the value is \";\"' an instance of the subsequent codec cannot be used instead.\nnum specifies the maximum number of supported concurrent encoders (when the combination follows \"ENC\") or decoders (when the combination follows \"DEC\") of the specified codec at the specified level and profile (when present).  num specifies the maximum number of instances of the particular codec that can operate concurrently when all the other codecs in the same ccc-prof have their corresponding num of instances operating. The number of instances of num that immediately follows \"ENC\" and the number of instances of num that immediately follows \"DEC\" are both the same as the number of instances of codec, and an instance of num is mapped to an instance of codec with the same order in the ordered codeclist.\nThere can be multiple ccc-prof‘s to indicate support of different configurations of concurrent encoders and decoders, e.g., to indicate that supporting less concurrent encoders enables the terminal to support more concurrent decoders. ccc-prof‘s should not be in conflict with each other, i.e., indicate a different maximum number of instances (num) of a particular codec when the maximum number of instances of all the other codecs in the ccc-prof‘s are the same.  If a conflict is detected between ccc-prof‘s, the information from the first ccc-prof among the conflicting ccc-prof‘s is used and all the other conflicting ccc-prof‘s are ignored.\nIf the terminal has the ability to trim the number of received media streams it actually decodes, it can advertise a num value that is larger than it actually has the concurrent decoding capabilities for.\nAs the \"a=ccc_list\" attribute is a compact representation of the media capabilities that are expressed in SDP, using it is not expected to introduce any additional security conditions beyond those identified for SDP.  Therefore the security considerations for the attribute are covered by the security considerations for SDP as specified in RFC 4566 [8].  There are no identified interoperability concerns for this atttibute as it is a new attribute and the values used for the codec field are well defined to use values managed by IANA.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "S.5.7.3\tUsing the Compact CCC SDP Attribute for CCC Exchange",
                            "text_content": "The SIP OPTIONS method specified in RFC 3261 is used to query the capabilities of another terminal by asking the conference participant to send a copy of the SDP it would offer.\nFor example, the SIP OPTIONS request may be made in-advance of a conference call and the SIP OPTIONS response be stored for the queried terminal. Alternatively, immediately before setting up a conference, the conference initiator may query the capabilities of all the terminals it plans to invite for which it does not have the information pre-stored.\nIn single source multi-unicast (SSMU) topology [152], the MRF sends the SIP OPTIONS request to each of the terminals before setting up the conference. The terminals send the SIP OPTIONS response to the MRF. The MRF can then use this response information to pre-configure and send the SDP Offers to the terminals using simulcast and multiple m- lines for the MSMTSI session. Alternatively, for the case where MSMTSI terminals call in and sends SDP Offers to MRF (instead of MRF calling out), the MRF can still use knowledge from SIP OPTIONS response to adjust its SDP Answer.\nIn multi-unicast topology, the conference initiator sends the SIP OPTIONS request to each of the conference participants well in-advance of the conference call. Upon receiving the SIP OPTIONS response from the participants, the conference initiator may store the encoding/decoding preferences of the conference participants for setting up the MSMTSI session.\nA new content type cccex, is used to request the ccc_list attribute (see S.5.7.4).  The SIP OPTIONS response shall contain the text that follows \"a=ccc_list:\" when using the ccc_list attribute.\nSIP OPTIONS SDP examples are given in Clause T.3.4.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "S.5.7.4\tUsing the Compact CCC SDP Attribute for Session Initiation",
                            "text_content": "MSMTSI terminals shall be able to interpret and respond to the ccc_list attribute included in an SDP answer.  MSMTSI terminals should include the ccc_list attribute in an SDP offer to reduce the size of the offer when multiple media configurations of concurrent codecs are being offered.\nWhen an MSMTSI terminal generates an offer that includes the ccc_list attribute, it shall include only a single instance of the ccc_list attribute, and one or more media configurations which together cover all the possible concurrent codec configurations that the offerer can support. If the included media configuration(s) offer more concurrent codec configurations than the offerer can support, the offering MSMTSI terminal shall use the ccc_list attribute to indicate to the answerer additional restrictions to the media configurations included in the offer. This allows the MSMTSI offerer to include a single media configuration without using MediaCapNeg and requiring much fewer lines of SDP.\nWhen an MSMTSI terminal includes the ccc_list attribute in an SDP offer it shall check whether the ccc_list attribute is included in the SDP answer it receives.  If the attribute is included, the offering MSMTSI terminal may store this CCC information about the other terminal for use in future sessions.  If multiple instances of the attribute are included in the SDP answer, the offering MSMTSI terminal shall ignore all but the first instance.  If the attribute is not included, the offering MSMTSI terminal shall check that it can support the media configuration selected in the SDP answer in the MMCMH session.  If the offering MSMTSI can not support the selected media configuration, it shall send a re-INVITE to the answering terminal without including the ccc_list attribute in the new SDP offer.\nWhen an answering MSMTSI terminal receives an offer that includes the ccc_list attribute, it shall include exactly one instance of the ccc_list attribute in the SDP answer.  If multiple instances of the attribute are received in the offer, the answering MSMTSI terminal shall ignore all but the first instance.  The answering MSMTSI terminal may store this CCC information about the offering terminal for use in future sessions.\nWhen an answering MSMTSI terminal includes the ccc_list attribute in an SDP answer, it shall set the attribute to describe the complete concurrent codec capabilities of the answering MSMTSI terminal, independent of what was received in the SDP offer.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "S.6\tMedia transport",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "S.6.1\tRTP",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI client shall be capable of receiving multiple, separate RTP streams [9] related to a single SIP dialog and route them to the correct decoder based on RTP SSRC, RTP Payload Type, and any \"a=content\" information in the SDP. The number of RTP streams used in each direction and for each media type is limited to what is negotiated by SDP offer/answer for that SIP dialog, allowing the involved MSMTSI clients to express a limit to the number of streams they can handle simultaneously.\nAn MSMTSI client in terminal shall be capable of relating received RTP SSRC and CSRC with information from the conference event information (clause S.4), to enable indicating the identity of the RTP stream source. If a received RTP SSRC has no match in the conference event information, and if RTP CSRC is present, CSRC shall also be matched against conference event information. It is left up to MSMTSI client implementation what RTP stream source identification to use if neither SSRC nor CSRC can be matched against conference event information.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.6.2\tRTCP",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI client in the terminal shall, as an MTSI client in the terminal, be capable to receive RTCP feedback (FIR, PLI, TMMBR, etc) [40][43] and respond accordingly, but shall also be capable to identify which sent RTP stream (SSRC) the RTCP feedback targets and direct it to the appropriate encoder.\nAn MSMTSI client shall support RTP-level pause and resume functionality according to [156] for all of its RTP streams, with the exception of the main audio stream from an MSMTSI client in terminal towards an MSMTSI MRF, which is not required to (but may) support RTP-level pause and resume functionality. An MSMTSI client shall be capable of restricting its use of RTP-level pause and resume functionality according to received pause/resume config parameter information in SDP, including not using it at all if that is the negotiation outcome.\nAn MSMTSI client in terminal shall support RTP-level pause and resume functionality at least corresponding to config=3, and should support full RTP-level pause and resume functionality corresponding to config=1.\nAn MSMTSI MRF shall support RTP-level pause and resume functionality at least corresponding to config=2, and should support full RTP-level pause and resume functionality corresponding to config=1.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.6.3\tRTP Stream Selective Forwarding",
                    "description": "",
                    "summary": "",
                    "text_content": "When a conference includes a large number of terminals or participants, the size of the SDP Offer listing the concurrent codec capabilities (CCC) using multiple m= lines can increase considerably. To reduce the size of the SDP offer when a conference includes a large number of participants, RTP-level selective forwarding by the MSMTSI MRF shall support RTP pause/suspend, reuse, replace, and resume actions. This RTP-level \"suspend, resuse, replace, and resume\" action is described using an example in Clause 6.13.4.2, TR 26.980 [152].\nIn the SDP Offer the MSMTSI MRF may use fewer downlink m= lines, corresponding to dynamically selected streams even though there are large number of participants or terminals in the MSMTSI session.\nTo support RTP stream selective forwarding when some participants in a conference supports both the \"common\" and one or more \"preferred\" codecs while other participants support only the \"common\" codec, certain conditions need to be fulfilled for MSMTSI clients both in the terminal and in MSMTSI MRF. This is described below.\nThe MSMTSI MRF should construct the SDP Offer such that the downlink RTP stream from one participant fits sufficiently well with the capabilities of another participant such that the same downlink m= line can be used for RTP stream selective forwarding. For this, the MSMTSI MRF should pre-anlayze the CCCEx (e.g., based on SIP OPTIONS) and construct sub-groups of participants that can share a given m= line with a given set of \"preferred\" and \"common\" codecs in the simulcast.\nAn MSMTSI client in terminal that supports both \"common\" and \"preferred\" codecs for a media type shall support concurrent encoding, sending simulcast [155], and concurrent decoding, with more than a single one codec for every sending media source (\"m=\" line) of that media type. An MSMTSI MRF that supports both \"common\" and \"preferred\" codecs for a media type shall support receving simulcast with more than a single codec for every received media source (\"m=\" line) of that media type.\nAn MSMTSI client in terminal that supports both \"common\" and \"preferred\" codecs for a media type shall be capable to receive media using any one of those codecs, even if the used codec (RTP payload type) is changing from one RTP packet to the next, for all received media sources (\"m=\" lines) of that media type. This capability to receive RTP payload type changing from one RTP packet to the next is indicated by accepting payload types with both \"common\" and \"preferred\" codecs from the SDP offer in the SDP answer. This way, no SDP re-negotiation is needed to change codec between the ones included in the answer. This ability to support RTP payload type changes every RTP packet is an essential part of the receiving end of a codec simulcast scenario, and shall be explicitly indicated in SDP by including \"a=simulcast\" with the supported codecs as simulcast format alternatives, even if it means that only a single simulcast stream with alternatives is listed in simulcast receive direction.\nAn MSMTSI client in the terminal that negotiated receiving simulcast with different codecs and that receives a set of such simulcast streams, can dynamically choose which simulcast stream to decode and should use the best quality simulcast stream that is available.\nAn MSMTSI MRF that negotiated sending simulcast with a set of different codecs and that needs to forward streams using those codecs, may change RTP payload type within that set in its sent stream at any point in time, as needed to support the communication scenario and forwarding strategy used by the MSMTSI MRF.\nThe MSMTSI MRF should take action to allow decoder memories to clear when replacing one RTP stream with another RTP stream during switching, to avoid media distortion in the receiving MSMTSI client in the terminal. To enable this, it is currently necessary for the MSMTSI MRF to know the RTP payload format of the used codecs, even if no transcoding is needed. The MSMTSI MRF should therefore, before suspending forwarding of RTP stream A and replacing it by instead forwarding RTP stream B:\n-\tFor speech\n-\tReplace the content of a few RTP packet payloads from RTP stream A with a few silence indication (SID) or discontinuous transmission (DTX) frames for the used codec\n-\tFor video\n-\tTake assistance from the sender of RTP stream B, asking for a decoder refresh point by sending RTCP FIR to that RTP stream B sender\n-\tContinue forwarding RTP stream A while monitoring RTP stream B for decoder refresh points\n-\tFrom the point where a decoder refresh point is received in RTP stream A, suspend forwarding of RTP stream A and replace it by forwarding RTP stream B\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "S.7\tBFCP",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "S.7.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "BFCP with TCP transport according to [149][150] shall be supported. An MSMTSI client in terminal shall be capable of indicating to the user when it is granted a floor, when a floor request is rejected, and when a floor grant is revoked. The details of such indication are left for MSMTSI client implementation. If the MSMTSI client in terminal supports floor control of more than a single video, it shall be able to make such indications separately for each supported floor.\nAn MSMTSI client may support functionality for moderated BFCP floor handling, involving a floor chair.\nAn MSMTSI MRF should silently ignore and discard any received video that is currently under active floor control, but where another MSMTSI or MTSI client than the one sending such received stream currently owns the floor.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.7.2\tFloor controlled main video",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI client shall support BFCP [147][149] to control the main video.\nWhen BFCP is used to control the MSMTSI client main video, all MSMTSI clients are allowed to send video as long as no one owns that BFCP floor. Whenever any MSMTSI client owns the main video floor, only that MSMTSI client is allowed to send main video in the group video call, and the MSMTSI MRF forwards that video to all other participants. The MSMTSI MRF should continue to use any previously used video forwarding strategy towards the MSMTSI client in the terminal that owns the main video floor.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.7.3\tFloor controlled screenshare video",
                    "description": "",
                    "summary": "",
                    "text_content": "If screeenshare video is supported by an MSMTSI client, BFCP [147][149] to control the screenshare video shall also be supported.\nIf BFCP is not available to control the screenshare video, and considering that the MSMTSI client supports screenshare video as a separate video \"m=\"-line, implicit screenshare floor control of that \"m=\"-line shall be assumed. Such implicit floor control shall here be taken to mean that the MSMTSI client is allowed to start sending screenshare video at any point in time, whenever initiated by the user of the MSMTSI client. No explicit screenshare floor grant indication to the sending MSMTSI client is possible in this case. An MSMTSI client in the terminal using implicitly floor controlled screenshare video that begins receiving screenshare video after itself started sending, shall immediately stop sending screenshare video, since this shall be interpreted as the implicit screenshare floor grant being revoked.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.7.4\tImplicit floor control for audio",
                    "description": "",
                    "summary": "",
                    "text_content": "An MSMTSI client in terminal is allowed to receive more audio streams than it is capable of decoding concurrently at a given time. In such case, the MSMTSI client in terminal shall have means for choosing which streams to prioritize and which ones to ignore. This selection can be made based on which streams are not in DTX mode. Media streams may also be prioritized based on the active level or volume of the audio stream. However, this requires decoding of the media from each stream to determine the loudest stream. The prioritized streams may further be spatially mixed for rendering.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "S.7.5\tFloor control interworking with DTMF-capable MTSI clients",
                    "description": "",
                    "summary": "",
                    "text_content": "If MTSI clients participate in the group video call, not supporting BFCP for the main video but having successfully negotiated use of DTMF with the MSMTSI MRF according to Annex G, the MSMTSI MRF may act as a signalling gateway between DTMF and BFCP main video floor control. It is then assumed that the MSMTSI MRF is configured with a DTMF sequence that can be used to request and release that BFCP floor, and that this DTMF sequence is somehow communicated to the MTSI client, but the details of that are out of scope for this specification.\nIf such MTSI client uses the designated DTMF sequence to request the main video floor, it shall be treated in the MSMTSI MRF as equivalent to receiving a BFCP request for the main video floor.\nLacking other possibilities to indicate main video floor grant status back to such DTMF-requesting MTSI client, the MSMTSI MRF should send its main video back to it as long as it owns the main video floor.\nWhen the MTSI client owning the main video floor uses the DTMF sequence to release the main video floor, it shall be treated in the MSMTSI MRF as equivalent to receiving a BFCP release for the main video floor.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "S.8\tRate Adaptation",
            "description": "An MSMTSI client in the terminal should know which RTP streams that share a common channel resource (such as a radio bearer), and shall take this into account when performing per-stream rate adaptation. Per-stream adaptation is specified in clause 10. An MSMTSI MRF should, unless explicitly configured otherwise, assume during rate adaptation that all media streams of the same SDP media type (audio, video, etc) from a single MSMTSI client share a common channel resource. The sum of bitrates used for streams sharing a common channel resource shall be controlled such that they jointly do not exceed the estimated available channel resource. This applies to all MSMTSI clients both in the send direction and in the receive direction, providing rate adaptation information feedback (e.g. TMMBR or any rate control mechanism natively available to the used codec) to the sending party.\nIn situations where a MSMTSI client or MRF media sender that has the ability to send multiple media streams is faced with scarce network resources, insufficient to support maximum bitrate for all streams the sender is capable to send, it can be necessary for the sender to choose which streams to either entirely omit, temporarily stop, or degrade more than others. Degrading all streams evenly may not be the best approach, but consistently degrading one stream at a time may also not be preferable. The individual media receiver of those multiple streams is likely the one best equipped to decide which streams are most interesting to receive in a specific communication scenario, but some general guidance can be given. It is recommended that the main audio stream is considered most important, except for special use cases that do not require use of audio. Screenshare video is likely next most important, after which comes main video and BFCP. When using simulcast, main video simulcast using different codecs is likely more important than video thumbnail simulcast. Video thumbnails are likely least important in most use cases.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "T.1\tGeneral",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "T.1.1\tIntroduction",
                    "description": "",
                    "summary": "",
                    "text_content": "This annex gives a few examples of media portions from possible SDP offers and answers involving an MSMTSI client and/or MSMTSI MRF. It is not feasible to cover all possible variants of different communication scenarios and MSMTSI capabilities and hence these examples should be regarded as just a few examples of many possible alternatives. For brevity, these examples do not make use of all functionality (like robustness etc) or list all codecs that could be used in a real SDP offer/answer, and for the same reason also limits the number of supported streams compared to what could be used in a real SDP offer/answer.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "T.1.2\tQuality of Service examples",
                    "description": "",
                    "summary": "",
                    "text_content": "This clause describes how the QoS bandwidth is reserved for MMCMH sessions based on the codec and bandwidth information in the SDP answer, the number of conference participants, and the topology of the multi-party session.\nWhen determining the QoS bandwidth to reserve for the MMCMH session, the SDP answer is examined for the following:\n-\tWhen simulcast is included, the bandwidth reserved for the transmission of the media (on either the uplink or downlink) is enough to cover the simulcast.  If multiple media formats are sent concurrently then the reserved bandwidth is enough to carry the sum of their bandwidth requirements. If media formats are sent alternatively, then the reserved bandwidth is enough to carry the bandwidth requirements of the highest codec rate that can be used.\n-\tIf multiple active media lines are included, the reserved bandwidth is enough to carry the sum of the bandwidth requirements of each active media line.\nTable T.0 provides examples of the QoS bandwidth that could be reserved for the example SDP answers listed in the rest of this Annex.\nTable T.0: Example QoS bandwidth reservations for example SDP answers\n\n",
                    "tables": [
                        {
                            "description": "Table T.0: Example QoS bandwidth reservations for example SDP answers",
                            "table number": 228,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "T.2\tMSMTSI video offer/answer examples",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "T.2.1\tMSMTSI offer/answer towards an MTSI client",
                    "description": "",
                    "summary": "",
                    "text_content": "This offer includes sending two different simulcast streams for the main video, receiving two thumbnail videos, both sending and receiving screenshare video, and has support for BFCP to control screenshare and (possibly) main video, which are all features that can be supported by MSMTSI but that are not supported by a regular MTSI client. All audio is omitted in this example, for brevity, but could be added according to the other examples (e.g., in Clause T.3) in this annex.\nVideo levels are in this example aligned with the maximum size of the video stream, and the maximum receive bandwidth limit is set by the \"b=\"-line rather than just implicitly by the video level bandwidth limit.\nThe main video is listed as the first video \"m=\"-line and is also explicitly identified through \"a=content:main\".\nOne subsequent \"m=\"-line is explicitly identified as screenshare video, using \"a=content:slides\".\nThe rest of the video \"m=\"-lines indicate support for two additional, receive-only video thumbnails.\nAll video \"m=\"-lines offer support for RTP level pause/resume, indicated through \"a=rtcp-fb:* ccm pause\". The \"nowait\" parameter is set, indicating that the MSMTSI client expects the RTP media streams to be sent point-to-point on RTP level. That can for example be either between MSMTSI clients in terminal, or between an MSMTSI client in terminal and an MSMTSI MRF. In either case, the \"nowait\" parameter indicates it is not expected that multiple receivers of the RTP streams are able to send RTCP back to request RTP level pause/resume.\nSupport for reduced-size RTCP (see clause 7.3.6 and [87]) is offered for all video \"m=\"-lines, to save bandwidth for RTCP feedback messages listed on \"a=rtcp-fb\"-lines.\nBFCP support is offered with client role.\nBlank lines are here added in the SDP for improved readability, but are not included in an actual SDP. SDP lines specifically interesting to this example are highlighted in bold, which would also not be the case in an actual SDP.\nTable T.1: Example SDP offer from MSMTSI towards MTSI\n\nTable T.2: Example SDP answer from MTSI towards MSMTSI\n\nThe answerer, being an MTSI client, knows of no MSMTSI features, but has correctly disabled all of them in the SDP answer, according to generic SDP offer/answer rules, keeping unsupported \"m=\"-lines with port set to zero, leaving the session effectively identical to a regular MTSI session with a single video and mono audio.\n",
                    "tables": [
                        {
                            "description": "Table T.1: Example SDP offer from MSMTSI towards MTSI",
                            "table number": 229,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table T.2: Example SDP answer from MTSI towards MSMTSI",
                            "table number": 230,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "T.2.2\tMSMTSI answer from an MSMTSI MRF",
                    "description": "",
                    "summary": "",
                    "text_content": "This example assumes the same offer as in Table T.1, which is thus not repeated here, but the answerer is here an MSMTSI MRF, supporting all of the offered MSMTSI-specific features. All audio is omitted in this example, for brevity, but could be added according to any of the other examples in this annex.\nNote that the \"isFocus\" tag, identifying this answer as an MRF, is included as part of SIP headers and is thus not visible in the SDP in this example.\nThe MSMTSI MRF accepts to receive the two offered simulcast streams for the main video. Then, the MSMTSI MRF can send video for the two supported thumbnails, and can also control both main video and screenshare video through BFCP.\nIt can be noted that the MSMTSI MRF needs to keep all payload type formats that it accepts to use for simulcast on the \"m=\"-line in the answer.\nThe MSMTSI MRF is, by including the RTP-level \"nowait\" parameter on the \"a=rtcp-fb:* ccm pause\" line in the SDP answer, confirming that exchange of RTP level pause/resume messages will be point-to-point and no hold-off period will therefore be necessary when resuming paused streams (see [156]).\nSupport for reduced-size RTCP (see clause 7.3.6 and [87]) is accepted for all video \"m=\"-lines, to save bandwidth for RTCP feedback messages listed on \"a=rtcp-fb\"-lines.\nThe \"a=label\" lines are added by the MSMTSI MRF to support identification of BFCP-controlled \"m=\"-lines, relating BFCP floor identifications to \"m=\"-lines through \"a=floorid\" lines under the BFCP \"m=\"-line. In this example, both the main video and the screenshare video \"m=\"-lines are floor controlled. The thumbnail videos are however not floor controlled, so there are no \"a=label\" lines for those \"m=\"-lines.\nBlank lines are here added in the SDP for improved readability, but are not included in an actual SDP. SDP lines specifically interesting to this example are highlighted in bold, which would also not be the case in an actual SDP.\nTable T.3: Example SDP answer from MSMTSI MRF towards MSMTSI\n\n",
                    "tables": [
                        {
                            "description": "Table T.3: Example SDP answer from MSMTSI MRF towards MSMTSI",
                            "table number": 231,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "T.2.3\tMSMTSI answer from an MSMTSI client in terminal",
                    "description": "",
                    "summary": "",
                    "text_content": "This example assumes the same offer as in clause T.2, which is thus not repeated here, but the answerer is here an MSMTSI client in terminal, supporting all of the offered MSMTSI-specific features, although not all of them are feasible to use between MSMTSI clients in terminal. All audio is omitted in this example, for brevity, but could be added according to any of the other examples in this annex.\nNote that the \"isFocus\" tag is here not included as part of the SIP headers (compare to annex T.3). This information is used by the answering MSMTSI client to construct an appropriate SDP answer.\nThe answering MSMTSI client has no reason to send any thumbnail videos to another MSMTSI client in terminal, and has thus disabled them. There is no need for simulcast, meaning that the simulcast attribute and the corresponding \"a=rid\" attributes are removed from the SDP and simulcast will not be used. It can however act as BFCP server and can also support simultaneous main video and screen sharing, which are both kept.\nBlank lines are here added in the SDP for improved readability, but are not included in an actual SDP. SDP lines specifically interesting to this example are highlighted in bold, which would also not be the case in an actual SDP.\nTable T.4: Example SDP answer from MSMTSI towards another MSMTSI\n\n",
                    "tables": [
                        {
                            "description": "Table T.4: Example SDP answer from MSMTSI towards another MSMTSI",
                            "table number": 232,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "T.2.4\tMSMTSI simulcast offer using a single payload type",
                    "description": "",
                    "summary": "",
                    "text_content": "This example offer is an excerpt of just the first \"m=\" block from the example in clause T.2.1 and effectively offers the same functionality, but does not make use of different payload types to distinguish the simulcast formats. Instead different \"a=rid\" constraints parameters are used. Because there is only a single format listed on the \"m=\" line containing the \"a=simulcast\" line, the \"a=rid\" lines contains constraints parameters (here max-width and max-height) to differentiate the simulcast formats.\nSDP lines specifically interesting to this example are highlighted in bold, which would not be the case in an actual SDP.\nTable T.4a: Example SDP simulcast offer from MSMTSI using a single payload type\n\n",
                    "tables": [
                        {
                            "description": "Table T.4a: Example SDP simulcast offer from MSMTSI using a single payload type",
                            "table number": 233,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "T.2.5\tMSMTSI simulcast offer using two codecs",
                    "description": "",
                    "summary": "",
                    "text_content": "This example offer is an excerpt of just the first \"m=\" block from the example in clause T.2.1 and effectively offers the same functionality, but makes use of simulcast with different video codecs, H.264 and H.265, in addition to the simulcast used for main video thumbnail in clause T.2.1.\nSDP lines specifically interesting to this example are highlighted in bold, which would not be the case in an actual SDP.\nTable T.4b: Example SDP simulcast offer from MSMTSI using two codecs\n\n",
                    "tables": [
                        {
                            "description": "Table T.4b: Example SDP simulcast offer from MSMTSI using two codecs",
                            "table number": 234,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "T.3\tMSMTSI audio offer/answer examples",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "T.3.1\tMSMTSI offer with multi-stream audio support",
                    "description": "",
                    "summary": "",
                    "text_content": "This offer includes multi-stream audio, sending simulcast with multiple codecs for the main audio, receiving two additional audio participants for local rendering, and receiving codec simulcast for all received audio streams. All video is omitted in this example, for brevity, but could be added according to any of the other examples in this annex.\nThree different codecs are offered as audio simulcast in the send direction, separated by semicolons. In the simulcast receive direction, a single stream is offered, explicitly accepting three different alternative simulcast formats, separated by comma, which means that the used audio codec (RTP payload format) is allowed to change from one RTP packet to the next.\nBlank lines are here added in the SDP for improved readability, but are not included in an actual SDP. SDP lines specifically interesting to this example are highlighted in bold, which would also not be the case in an actual SDP.\nTable T.5: Example SDP offer from MSMTSI multi-stream audio\n\n",
                    "tables": [
                        {
                            "description": "Table T.5: Example SDP offer from MSMTSI multi-stream audio",
                            "table number": 235,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "T.3.2\tMSMTSI answer with multi-stream audio support",
                    "description": "",
                    "summary": "",
                    "text_content": "This answer builds on the offer in annex T.3.1, includes multi-stream audio, accepting to receive simulcast with multiple codecs for the main audio, sending two additional audio participants for local rendering, and sending codec simulcast for all received audio streams. All video is omitted in this example, for brevity, but could be added according to any of the other examples in this annex.\nThe three different codecs from the offer are accepted as audio simulcast in the receive direction, separated by semicolons. In the simulcast send direction, a single stream is accepted, explicitly listing three different alternative simulcast formats, separated by comma, which means that the used audio codec (RTP payload format) may change from one RTP packet to the next.\nAs in annex T.2.2, it can be noted that the MSMTSI MRF needs to keep all payload type formats that it accepts to use for simulcast on the \"m=\"-line in the answer.\nBlank lines are here added in the SDP for improved readability, but not included in an actual SDP. SDP lines specifically interesting to this example are highlighted in bold, which would also not be the case in an actual SDP.\nTable T.6: Example SDP answer from MSMTSI MRF accepting multi-stream audio\n\n",
                    "tables": [
                        {
                            "description": "Table T.6: Example SDP answer from MSMTSI MRF accepting multi-stream audio",
                            "table number": 236,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "T.3.3\tMSMTSI CCCEx SDP offer/answer example",
                    "description": "",
                    "summary": "",
                    "text_content": "Table T.7 shows example concurrent codec combinations supported at the terminal. All video is omitted in this example, for brevity, but could be added according to any of the other examples in this annex. As shown in Table T.7, the terminal may have identified three possible CCCEx combinations through profiles (shown for 6 participants). SDP offer examples from the terminal to the MRF for profile A is shown in Table T.8. The MSMTSI MRF may then send an SDP answer as shown using the simulcast attribute and multiple m-lines in Table T.9 enabling a multi-stream multiparty conference (among 6 participants).\nTable T.7: Example concurrent codec capability configurations in MSMTSI terminals\n\nTable T.8: Example SDP offer for CCCEx example configuration from MSMTSI terminal A\n\nTable T.9: Example SDP answer from MSMTSI MRF accepting multi-stream audio and enabling a conference with 6 participants (for SDP offer in Table T.8)\n\nTable T.10 shows an example, where the MSMTSI MRF identifies that there are only four participants in the conference and it therefore disables the two \"m=\"lines.\nTable T.10: Example SDP answer from MSMTSI MRF accepting multi-stream audio and enabling a conference with 4 participants (for SDP offer in Table T.8)\n\n",
                    "tables": [
                        {
                            "description": "Table T.7: Example concurrent codec capability configurations in MSMTSI terminals",
                            "table number": 237,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table T.8: Example SDP offer for CCCEx example configuration from MSMTSI terminal A",
                            "table number": 238,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table T.9: Example SDP answer from MSMTSI MRF accepting multi-stream audio and enabling a conference with 6 participants (for SDP offer in Table T.8)",
                            "table number": 239,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table T.10: Example SDP answer from MSMTSI MRF accepting multi-stream audio and enabling a conference with 4 participants (for SDP offer in Table T.8)",
                            "table number": 240,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "T.3.3a\tMSMTSI offer/answer examples using the compact CCC SDP attribute",
                    "description": "",
                    "summary": "",
                    "text_content": "Table T.3a1 shows an example SDP offer using the compact ccc_list SDP attribute to simultaneously describe the three media configurations listed for N=6 in Table T.7.  Note that the media configuration for the codec is broader than all the concurrent codec configurations that can be supported by the offering MSMTSI terminal. Similar to table T.8, all video is omitted in this example for brevity, but could be added according to any of the other examples in this annex.\nTable T.3a1: Example SDP offer from an MSMTSI terminal\n\nAn answering MSMTSI MRF that supports the ccc_list attribute may then send an SDP answer as shown Table T.x2, including the ccc_list attribute and using the simulcast attribute and multiple m-lines to enable a multi-stream multiparty conference among 6 participants. The included ccc_list attribute indicates the full capabilities of the MRF to concurrently switch multiple audio streams (10 EVS, 5 AMR-WB, 5 AMR-NB, etc…) towards the offering MSMTSI terminal eventhough the selected media configurations in the answer are only using a subset of the MRF’s capabilities.\nTable T.3a2: Example SDP answer from the MSMTSI MRF accepting multi-stream audio and enabling a conference with 6 participants (for SDP offer in Table T.3a1)\n\n",
                    "tables": [
                        {
                            "description": "Table T.3a1: Example SDP offer from an MSMTSI terminal",
                            "table number": 241,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table T.3a2: Example SDP answer from the MSMTSI MRF accepting multi-stream audio and enabling a conference with 6 participants (for SDP offer in Table T.3a1)",
                            "table number": 242,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "T.3.4\tSIP OPTIONS request for multi-stream audio support",
                    "description": "",
                    "summary": "",
                    "text_content": "This offer includes multi-stream audio, sending simulcast with multiple codecs for the main audio, receiving two additional audio participants for local rendering, and receiving codec simulcast for all received audio streams. All video is omitted in this example, for brevity, but could be added according to any of the other examples in this annex.\nBlank lines are here added in the SDP for improved readability, but are not included in an actual SDP. SDP lines specifically interesting to this example are highlighted in bold, which would also not be the case in an actual SDP.\nTable T.11 shows an example SIP OPTIONS request from an MRF or a conference initiator. Table T.12 shows an example SIP OPTIONS response from a conference participant to the MRF or the initiator. The SIP OPTIONS response includes the SDP Offer of the conference participant. From Table T.12, the conference participant can allow for three concurrent encoding and three concurrent decoding of audio streams.\nTable T.11: Example SIP OPTIONS request from an MRF or a conference initiator\n\nTable T.12: Example SIP OPTIONS response from a conference participant to the MRF or the initiator\n\n",
                    "tables": [
                        {
                            "description": "Table T.11: Example SIP OPTIONS request from an MRF or a conference initiator",
                            "table number": 243,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table T.12: Example SIP OPTIONS response from a conference participant to the MRF or the initiator",
                            "table number": 244,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "U.1\tIntroduction",
            "description": "This Annex provides the media type registration information that is referenced from the IANA registry at .\n\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "U.2\tapplication/ccce",
            "description": "\nTo:\nSubject: Registration of media type \"application/cccex\"\nType name: application\nSubtype name: cccex\nRequired parameters: None\nOptional parameters: None\nEncoding considerations:\ncccex content is UTF-8 format text.\nSecurity considerations:\nSee clause S.5.7.2 of TS 26.114\nInteroperability considerations:\nSee clause S.5.7.2 of TS 26.114\nPublished specification:\nSee TS 26.114\nApplications usage:\nVoice over IP, video teleconferencing, streaming media, among others.\nAdditional information:\nMagic number(s):   None\nFile extension(s): The extension \".c3ex\"\nMacintosh File Type Code(s): \"c3ex\"\nIntended usage: COMMON\nContact Person:\nContact Name: 3GPP Specifications Manager\nContact Email Address:\nAuthor/Change Controller (for standards tree registrations, this is typically the standards body): 3GPP SA Working Group 4\n\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "V.1\tGeneral",
            "description": "End-to-end delay and jitter performance plays an important role in determining MTSI quality of experience. MTSI sender and MTSI receiver may perform adaptation based on delay budget adjustments, including jitter buffer size adaptation at the receiver, air interface delay adjustments at both sender and receiver using RAN delay budget reporting as specified in TS 36.331 [160] for E-UTRA and TS 38.331 [163] for NR. MTSI sender and MTSI receiver may also exchange delay budget information (DBI) with each other as described in clause 7.3.8, to signal available delay budget as well as to request delay budget.\nThis clause provides various example informative signalling flows on delay adaptation using these mechanisms.\nFigure V.2.1 presents a signaling flow example for RAN delay budget reporting usage for voice in MTSI without DBI signalling.\nFigure V.2.2 and V.2.3 present signaling flow examples for RAN delay budget reporting usage in MTSI involving uni-directional DBI signalling with only indication of available delay budget from MTSI receiver to MTSI sender.\nFigure V.2.4 presents a signaling flow example for RAN delay budget reporting usage in MTSI involving bi-directional DBI signalling with indication of available delay budget from MTSI receiver to MTSI sender and requested delay budget from MTSI sender to MTSI receiver.\nFigure V.2.5 presents a signalling flow example on usage of RAN delay budget request in MTSI with bi-directional DBI signalling and with jitter buffer adjustment.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "V.2\tExample Signaling Flows on Delay Adaptation",
            "description": "In Figure V.2.1, a signaling flow for RAN delay budget reporting usage for voice in MTSI without DBI signalling is presented.\nFigure V.2.1 illustrates the signaling flow on the usage of RAN delay budget reporting in MTSI without DBI signaling. The figure depicts the various stages of the process, including the initial request from the UE, the processing and response from the network, and the feedback to the UE. Key components include the eNodeB, the RAN, and the core network. The figure highlights the importance of efficient management of the RAN delay budget to ensure optimal performance and reliability in MTSI networks.\nFigure V.2.1: Signaling flow on usage of RAN delay budget reporting in MTSI without DBI signalling.\nStep 1: UE-1 sends UE-2 rate request via CMR or RTCP-APP for voice at bitrate R0. The \"Request\" message here is a generalized application level rate request message that corresponds to CMR or RTCP-APP for voice.\nStep 2: UE-2 sends RTP media flow for voice with bitrate R0.\nStep 3: UE-1 detects good radio conditions locally, e.g., eNB-1 sends a DL access network bitrate recommendation (ANBR) of bitrate R1 > R0 to UE-1, and UE-1 measures low block error rate (BLER) over the local radio link based on the monitoring of successful downlink packet transmissions, and it may also measure downlink throughput over the radio air interface that is much higher than the received bitrate (after accounting for the relevant headers). In the meantime, UE-1 detects high packet losses after monitoring reception of RTP packets (also by monitoring RTCP sender and receiver reports) and applying the highest possible jitter buffer according to the reference Jitter Buffer Management (JBM) in clause 8 (subject to the JBM compliance requirement of MTSI). Hence, UE1 concludes that UE2's local radio conditions are poor.\nStep 4: UE-1 sends a UEAssistanceInformation message as specified in TS 36.331 [160] to eNB-1 with type-1 to turn off cDRX. It is assumed that eNB-1 grants this request and turns off cDRX for UE-1. Turning off cDRX is relevant only when PLR is high, which is the conclusion of UE-1 in this example, as per Step 3. It should however be noted that UE-1 can increase the JBM depth to compensate the delay for high jitter. In this scenario, delay budget request from UE-1 to eNB-1 is not necessary and UEAssistanceInformation message may not be sent. Moreover, due to other considerations, UE-1 may choose not to turn cDRX off, e.g., when saving battery power is critical.\nStep 5: UE-2 detects high packet losses on its uplink due to poor coverage conditions, e.g., it may measure high BLER over its local radio link based on the monitoring of successful uplink packet transmissions, e.g., by monitoring the HARQ acknowledgements received. UE-2 requests additional delay budget from eNB-2 in order to perform additional re-transmissions to increase the reliability of its UL transmissions. When requesting this additional delay budget, UE-2 may also consider end-to-end RTT measured based on RTCP reports. It is assumed that eNB-2 grants this request. Because UE-1 has already turned its cDRX off, it is unlikely that the JBM constraint at UE-1 will lead to packet losses in response to the increase air interface delay over the RAN corresponding to UE-2.\nStep-6: UE-1 measures reduced packet losses and improved voice quality.\nIt should be noted that the actions of UE-1 in Steps 3-4 above and actions of UE-2 in Step 5 above are completely independent and these are not necessarily sequential, as there is no coordination between the two UEs in this example.\nIn Figure V.2.2, another signaling flow example for RAN delay budget reporting usage in MTSI involving delay budget information (DBI) signalling as described in clause 7.3.8 is presented. In this example, uni-directional DBI signalling is depicted with only indication of available delay budget from MTSI receiver to MTSI sender.\nFigure V.2.2 illustrates the signaling flow on the usage of RAN delay budget reporting with uni-directional DBI signaling in MTSI. The figure depicts the various components involved, including the eNB, UE, and RRC connection setup procedure. It showcases the process of reporting delay budget usage and the subsequent actions taken by the network to optimize performance. The figure highlights the importance of efficient signaling and resource management in maintaining high-quality communication in a multi-tenant RAN environment.\nFigure V.2.2: Signaling flow on usage of RAN delay budget reporting with uni-directional DBI signaling in MTSI.\nSteps 1-4: These are identical to the earlier signalling flow in Figure V.2.1.\nStep 5: If delay budget information signalling is supported between UE-1 and UE-2, UE-1 sends an RTCP feedback (RTCP-FB) message as specified in clause 7.3.8 to UE-2 indicating the availability of additional delay budget due to cDRX being turned off. A concrete delay number may also be reported as part of the RTCP-FB message that corresponds to the air interface delay reduction on UE-1's RAN after turning off cDRX, which would essentially be available for UE-2 to improve the reliability of its uplink transmissions. The reported delay number may also be determined considering UE1's JBM constraints and can be based on its assessment of how much additional delay it can tolerate.\nStep 6: UE-2 detects high packet losses on its uplink due to poor coverage conditions. UE-2 requests additional delay budget from eNB-2 in order to perform further re-transmissions to increase the reliability of its UL transmissions. When requesting the additional delay budget from eNB-2, UE-2 may also consider the RTCP-FB message it received from UE-1 on the availability of delay budget from UE-1's perspective. It is assumed that eNB-2 grants this request.\nStep-7: UE-1 measures reduced packet losses and improved voice quality.\nIn this example, the available delay budget may be computed by the UE-1 (MTSI receiver) based on network delay, jitter, packet loss rate (PLR) and potentially other parameters. It may also take into account constraints on JBM (i.e., based on reference JBM in clause 8). In this respect, the following observations can be made on the expected UE behaviour:\na)\tAllowing UE-2 to use more retransmission will increase the jitter. This may potentially cause more packets dropped at the JBM for UE-1.\nb)\tOn the other hand, more retransmission also allows UE-2 to reduce packet losses in its RAN uplink and this means more end-to-end reliability. So there is a fine balance here, while it would also be expected that the end-to-end performance is limited by the high packet losses on the UL, and hence more retransmissions will help improve the end-to-end quality and delay performance.\nc)\tUE-1 turning off cRDX will help to reduce end-to-end delay. In the meantime, if UE-1 needs to save on battery power and it is critical that cDRX is kept on for this purpose, then UE-1 may choose not to turn cDRX off. Even with cDRX off, if UE-1 decides that it can tolerate any further delay or jitter at its JBM, it may indicate this available delay budget via the RTCP-FB message for DBI signalling as defined in clause 7.3.8.\nd)\tIt is up to UE-1 to signal any additional delay budget to UE-2. If UE-1 figures that it is already close to its JBM constraint and cannot tolerate any additional delay or jitter (as this would lead to more packets being dropped), it may not signal additional delay availability to UE-2.\nThe signalling flow example in Figure V.2.2 relies on DBI signalling between the MTSI sender and MTSI receiver whereas the signalling flow in Figure V.2.1 does not include such signalling. The following can be observed when DBI signalling is not present:\n1)\tWhile the MTSI sender and MTSI receiver UEs may both be independently able to adjust their air interface delays based on the information in their MTSI clients, they are never aware of the capabilities or actions of the other UE. For example, while an MTSI receiver in good coverage may turn off cDRX to create delay budget for an MTSI sender, it may be the case that the MTSI sender does not even support delay budget reporting, or that the MTSI sender's eNB may not grant the additional delay budget to the MTSI sender, so the effort of the MTSI receiver may not deliver any end-to-end performance gain, and end up wasting the battery power of the MTSI receiver UE. Likewise, an MTSI sender in poor coverage may increase its air interface delay in an attempt to perform further retransmissions to mitigate against packet losses, without any knowledge of the possible detrimental impacts on the MTSI receiver, e.g., packets being dropped at the jitter buffer management (JBM) level.\n2)\tWhen UE-1 and UE-2 independently adjust their air interface delays, they rely on the end-to-end measurements available at their MTSI clients, e.g., by monitoring reception of RTP packets and RTCP sender and receiver reports, and knowledge of their local radio conditions. Purely relying on this information, an MTSI receiver may not be able to correctly detect the need for additional delay budget at the MTSI sender, e.g., as it may be the case that the losses are caused in the network. An explicit indication from the MTSI sender as would be enabled by DBI signaling can help the MTSI receiver make the right conclusion. Moreover, the MTSI receiver may not be able to determine exactly how much additional delay budget is needed on the air interface for the MTSI sender UE. Likewise, an MTSI sender may not be able to determine exactly how much additional delay budget it could ask from its eNB in the absence of any DBI signaling.\n3)\tWith the use of DBI signaling, delay budget adaptation and consequent larger number of retransmissions can be done faster via the real time exchange of delay budget information using RTP/RTCP signalling compared to the case when DBI signalling is absent, which would have to rely on measurements and inference at the UEs based on packet statistics, collection of which requires a certain observation period and averaging window.\n\nFigure V.2.3 illustrates the utilization of RAN delay budget reporting with uni-directional DBI signaling in MTSI. The figure depicts the flow of data packets through the radio access network (RAN), highlighting the importance of efficient resource management. It showcases the process of reporting delay budgets and utilizing uni-directional dynamic bandwidth allocation (DBI) to optimize network performance. The figure emphasizes the role of synchronization in maintaining a high quality of service (QoS) for mobile communication systems.\nFigure V.2.3: Another signaling flow on usage of RAN delay budget reporting with uni-directional DBI signalling in MTSI.\nThe signaling flow in Figure V.2.3 is identical to the one in Figure V.2.2, except that in step 7, UE-1 still observes high packet loss rate and the following additional steps are taken:\nStep 8: UE-1 sends UE-2 rate request via CMR or RTCP-APP for voice at bitrate R2 < R0. Other kinds of adaptation may also be invoked, for instance the use of application layer redundancy or transitioning to a more robust codec mode based on the negotiated codecs (e.g., channel-aware mode for EVS), in case the receiver side detects major packet loss but delay and jitter are within desired bounds.\nStep 9: UE-2 sends RTP media flow for voice with bitrate R2.\nFigure V.2.4 illustrates the signaling flow on the usage of RAN delay budget reporting in MTSI with bi-directional DBI signaling. The figure depicts the various stages of the signaling process, including the exchange of messages between the network elements, the calculation of delay budget, and the reporting of the results. Key components include the eNodeB, MME, and HSS, which are responsible for managing the signaling process and ensuring efficient communication. The figure highlights the importance of accurate delay reporting in maintaining the quality of service in mobile networks.\nFigure V.2.4: Signaling flow on usage of RAN delay budget reporting in MTSI with bi-directional DBI signalling.\nThe signalling flow in Figure V.2.4 is a variant of the one in Figure V.2.2, where UE-2 requests additional delay budget from UE-1 during the media flow (as depicted by Step 2b in Figure V.2.4), e.g., via the use of an RTCP-FB message for DBI signalling as defined in clause 7.3.8, after having detected poor radio conditions (e.g., high BLER) over the local RAN. The presence of this request message may further inform UE-1 that the radio conditions on UE-2's side are poor (in addition to its own detection, e.g., based on monitoring of RTP receive statistics). Another benefit of the bi-directional exchange of delay budget information between the two UEs is that this could help in identifying the scenario where the packet losses are introduced by neither of the RANs of UE1 and UE2 (i.e., both UEs enjoying good radio conditions) but rather by the network. In the meantime, it should be noted that the dominant cause of packet losses is expected to be from RAN impediments and the likelihood that the packet losses are caused by the network is quite small.\nWhen DBI signalling is present as in examples provided in Figures V.2.2, V.2.3 and V.2.4, the frequency of the DBI signaling needs to be limited such that terminals do not continuously have to expect new delay budget signaling, i.e., RTCP-FB message frequencies for both available delay budget and requested delay budget signalling need to be limited.\nFigure V.2.5 illustrates the signaling flow on the usage of RAN delay budget reporting in MTSI with bi-directional DBI signaling and jitter buffer adjustment. The figure depicts the various components involved, including the eNodeB, MME, and PDN Gateway, and how they interact to manage and optimize network resources. The figure highlights the importance of real-time reporting and adjustment to maintain efficient communication and minimize latency.\nFigure V.2.5: Signaling flow on usage of RAN delay budget reporting in MTSI with bi-directional DBI signalling and jitter buffer adjustment.\nThe signalling flow in Figure V.2.5 is a case of jitter buffer adjustment where UE-2 is suffering from poor network performance, e.g. under continuous weak coverage. UE-2 requests additional delay budget from UE-1 during the media flow (Step 3 in Figure V.2.5), e.g., via the use of an RTCP-FB message for DBI signalling as defined in clause 7.3.8, where a certain amount of expected extra delay is indicated. After receiving the request, jitter buffer in UE-1 may be extended (Step 4 in Figure V.2.5) to allow the sender to perform more uplink retransmissions and feedback to UE-2 how much additional delay is available for the uplink retransmissions after jitter buffer adjustment (Step 5 in Figure V.2.5). When UE-2 detects radio performance improved, it could notify UE-1 that it does not need an additional delay via another RTCP-FB message for DBI signalling to request a negative delay budget value (Step 7 in Figure V.2.5) and then UE-1 can shorten the jitter buffer accordingly (Step 8 in Figure V.2.5).\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "V.3\tSDP Examples on DBI Signaling Capability",
            "description": "Table V.3.1 demonstrates an example SDP offer with Delay Budget Information (DBI) signalling capability for speech, based on the procedures specified in clause 6.2.8. The offer for DBI is indicated in the last line. The use of RTCP feedback messages carrying ‘DBI’ is negotiated with the ‘3gpp-delay-budget’ parameter.\nTable V.3.1: Example SDP offer with DBI\n\nAn example SDP answer is shown in Table V.3.2, where the DBI signalling capability is also supported by the answerer, as indicated by the last line.\nTable V.3.2: Example SDP answer with DBI\n\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table V.3.1: Example SDP offer with DBI",
                    "table number": 245,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table V.3.2: Example SDP answer with DBI",
                    "table number": 246,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "W.1\tGeneral",
            "description": "The robustness of media to packet loss can be affected by the following factors in the MTSI terminal:\n-\tcodec\n-\tcodec mode\n-\tapplication layer redundancy\n-\tpacket loss concealment implementation\n-\tdejitter buffer implementation\nThe above factors are considered to be part of the codec configuration.\nThe level of robustness can affect the coverage area of the service in a network.  Furthermore, communicating the level of robustness of the media to the network enables the eNB/gNB to use this information to determine a threshold for when the terminal should be handed off to another cell, domain (circuit-switched vs. packet-switched), or radio access technology.\nThe MTSI terminal may support the coverage and handover enhancements using the multimedia error robustness (CHEM) feature specified in this clause.  When CHEM is supported by terminals, the terminals exchange packet loss rate (PLR) information via specified SDP parameters.  A PCF/PCRF may use these SDP PLR values to set handover thresholds in their local eNB/gNBs.\nIn the procedures specified in the rest of this clause, whenever the UE estimates the packet loss rate at the media receiver, the estimate can be measured either pre-dejitter buffer or post-dejitter buffer.  When packet loss rate is measured post-dejitter buffer, presentation of partial redundancy information (e.g., in EVS channel aware mode) does not count towards a correctly received packet.  Unless specifically configured using the OMA-DM Management Objects, the post-de-jitter buffer PLR estimate shall be used.\nThe PLR_adapt attribute to be used for this feature is specified using the following ABNF:\nName: PLR_adapt\nValue: [plr-adapt-value]\nUsage Level: media\nCharset Dependent: no\nSyntax:\nplr-adapt-value = %s\"ALR\" / token\nExamples:\na=PLR_adapt\na=PLR_adapt:ALR\nThe \"ALR\" parameter is optional and may be omitted when use of Application-Level Redundancy is not supported.\nThe semantics of the above attribute and parameter are specified below.  Unsupported parameters of the PLR_adapt attribute may be ignored.\nThe IANA registration information for the PLR_adapt SDP attribute is provided in Annex M.9.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "W.2\tAdaptation to Packet Losses without application layer redundancy",
            "description": "An MTSI terminal supporting the CHEM feature without using application layer redundancy for a media type (e.g., speech or video) shall support the following procedures:\n-\twhen sending an SDP offer, the MTSI client shall include the PLR_adapt attribute in the media description for that media type in the SDP offer\n-\t when sending an SDP answer, the MTSI client shall include the PLR_adapt attribute in the media description for that media type in the SDP answer regardless of whether the PLR_adapt attribute was received in an SDP offer\n-\tif, and only if, the MTSI client receives the PLR_adapt attribute in either an SDP offer or SDP answer then,\n-\twhen the MTSI client receiving media detects packet losses higher than tolerable by the current codec mode/configuration in use and a more robust codec mode/configuration is available for the same codec, the MTSI client shall send a CMR request to the media sender to use a more robust codec mode/configuration of the same codec\n-\twhen the MTSI client receiving media detects a packet loss rate low enough to support a codec mode/configuration of the same codec that provides better media quality than the current codec mode/configuration, and switching to the new codec mode/configuration will not cause oscillating between more robust and less robust codec modes/configurations, then the MTSI client should send a CMR request to the media sender to use the codec mode/configuration of the same codec that provides better media quality\nClause X.2.2 provides examples of how the PLR_adapt attribute without application layer redundancy is used in SDP.\nRobustness adaptation without application layer redundancy can involve switching to a codec mode/configuration with partial-redundancy (e.g., EVS Channel Aware mode for speech), better error correction, or lower bit rate.  In the last scenario this can benefit the resulting media quality if the terminal is near the edge of coverage and the link can better support transport of lower rate codec modes/configurations.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "W.3\tAdaptation to Packet Losses using Application Layer Redundancy",
            "description": "An MTSI terminal supporting the CHEM feature supporting use of application layer redundancy to improve robustness for a media type (e.g., speech or video) shall support the following procedures:\n-\twhen sending an SDP offer, the MTSI client shall include the ALR parameter in the PLR_adapt attribute in the media description for that media type in the SDP offer\n-\t when sending an SDP answer, the MTSI client shall include the ALR parameter in the PLR attribute in the media description for that media type in the SDP answer only if the ALR parameter in the PLR_adapt attribute was received in an SDP offer\nIn addition to requesting the media sender to adapt codec mode/configuration as described in clause W.2, the MTSI terminal may request the media sender to use non-zero application layer redundancy to improve robustness to packet loss.  Clause X.2.3 provides examples of how the PLR_adapt attribute and ALR parameter (i.e., with application layer redundancy) is used in SDP.\nWhen using CMR to request application layer redundancy the following CMR code points shall be used only if the MTSI client receives the ALR parameter in the PLR_adapt attribute in either an SDP offer or SDP answer:\nTable W.3.1: Code points for AMR\n\nTable W.3.2: Code points for AMR-WB\n\nTable W.3.3: Code points for EVS\n\nTo enable use of application layer redundancy the max-red SDP parameter should be selected in the SDP offer and answer to give at least some room for application layer redundancy adaptation and in accordance with clauses 6.2.2.2 and 6.2.2.3.  The recommended redundancy offset for application layer redundancy should be 3 frames.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table W.3.1: Code points for AMR",
                    "table number": 247,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table W.3.2: Code points for AMR-WB",
                    "table number": 248,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table W.3.3: Code points for EVS",
                    "table number": 249,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "W.4\tNegotiation of End-to-End and Uplink/Downlink PLR",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "W.4.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "In addition to the negotiated codecs and codec modes, the end-to-end quality and robustness to packet loss of a service can depend on the MTSI client implementation of functions such as packet loss concealment (PLC) and de-jitter buffer management (JBM).\nA set of end-to-end and link-by-link PLR parameters is specified to provide the following:\n-\tenable MTSI clients to indicate for each RTP payload type the effective maximum tolerable PLR resulting from the codec, codec mode, packet loss concealment, de-jitter buffer management and other implementation considerations.\n-\tenable MTSI clients to negotiate with each other and suggest to the PCRF/PCFs how the maximum tolerable end-to-end PLR budget can be distributed across the uplink and downlink in a media transport path.  In the absence of any additional negotation or information from the terminals, the PCRF/PCFs may default to distributing the maximum tolerable end-to-end PLR equally (50-50) across the uplink and downlink.  The link-specific PLR parameters enable the terminals to suggest to the PCRF/PCFs an unequal distribution, e.g. 60% of the maximum end-to-end PLR allowed on the uplink and 40% allowed on the downlink before the terminals are handed off.\n-\tindicate to the PCRFs/PCFs what PLR values may be used on the local uplink and downlink to the MTSI clients.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "W.4.2\tOffering MTSI Client",
                    "description": "",
                    "summary": "",
                    "text_content": "SDP PLR attributes and parameters are defined for use with each payload type.  For each RTP payload type, an offering MTSI client supporting the CHEM feature may include the following SDP attribute in its SDP offer:\nName: MAXimum-e2e-PLR(maximum end-to-end PLR of the media decoder in the MTSI client)\nValue: MAX-e2e-PLR-value\nUsage Level: media\nCharset Dependent: no\nSyntax:\nMAX-e2e-PLR-value = payload-type SP maxe2e-PLR [“:”maxDL-PLR] [“/”maxUL-PLR]\npayload-type = zero-based-integer\nmaxe2e-PLR = plr-value\nmaxDL-PLR = plr-value\nmaxUL-PLR = plr-value\nplr-value = integer\n: integer taken from IETF RFC 4566\nThe IANA registration information for the MAXimum-e2e-PLR SDP attribute is provided in Annex M.10.\nThe maxe2e-PLR represents the maximum end-to-end packet loss rate that can be properly received by the media decoder in the offering MTSI client (including effects of codec mode, packet loss concealment, de-jitter buffering, etc…) indicated by the RTP payload type number payload-type (as used in an “m=” line).\nThe maxDL-PLR parameter indicates the maximum packet loss rate that the offering MTSI client is able to handle on its local downlink and shall not exceed the maxe2e-PLR value in the SDP offer.  If the parameter is not included then the default value from the offering MTSI client is set to ½ of the maxe2e-PLR value included in the SDP offer.\nThe maxUL-PLR parameter indicates the maximum packet loss rate that the offering MTSI client is able to handle on its local uplink.  If the parameter is not included then the default value from the offering MTSI client is set to ½ of  maxe2e-PLR value the answering MTSI client will include in its corresponding SDP answer.\nIf maxe2e-PLR is not included in the SDP answer then its value is set to a recommended value for the codec and mode (e.g., obtain value from Annex Y if available).\nThe plr-value represents 1/100th of a percent (i.e. 10E-4) of packet loss as an integer.\nThe following table W.4.2-1 summarizes the SDP offer parameters.\nTable W.4.2-1 SDP offer attributes and parameters\n\nClause X.2.4 provides examples of how the MAXimum-e2e-PLR attribute is used in the SDP offer.\n",
                    "tables": [
                        {
                            "description": "Table W.4.2-1 SDP offer attributes and parameters",
                            "table number": 250,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "W.4.3\tAnswering MTSI Client",
                    "description": "",
                    "summary": "",
                    "text_content": "For each RTP payload type, an answering MTSI client supporting the CHEM feature may include the SDP attribute from sub-clause W.4.2 in its SDP answer with the following semantics of the parameters.\nThe maxe2e-PLR represents the maximum end-to-end packet loss rate that can be properly received by the media decoder in the answering MTSI client (including effects of codec mode, packet loss concealment, de-jitter buffering, etc…) indicated by the RTP payload type number payload-type (as used in an “m=” line).\nIf maxe2e-PLR is not included in the SDP offer then its value is set to a recommended value for the codec and mode (e.g., obtain value from Annex Y if available).\nThe maxDL-PLR parameter included in the SDP answer indicates the maximum packet loss rate that the answering MTSI client is able to handle on its local downlink and shall not exceed the maxe2e-PLR value in the SDP answer.\nIf the maxUL-PLR value included in the SDP offer is no greater than ½ the maxe2e-PLR value included by the answering MTSI client in the SDP answer, then maxDL-PLR in the SDP answer shall be set to no greater than (maxe2e-PLR value included in the SDP answer minus maxUL-PLR value included in the SDP offer).  Otherwise (the maxUL-PLR value included in the SDP offer is greater than ½ the maxe2e-PLR value included in the SDP answer) the maxDL-PLR in the SDP answer should be set to no greater than (maxe2e-PLR value included in the SDP answer minus maxUL-PLR value included in the SDP offer).  If the answerer sets the maxDL-PLR in the SDP answer to be greater than (maxe2e-PLR value included in the SDP answer minus maxUL-PLR value included in the SDP offer), the answerer shall not set maxDL-PLR greater than ½ maxe2e-PLR value included in the SDP answer.\nIf the maxDL-PLR parameter is not included in the SDP answer then the default value from the answering MTSI client is set to ½ of the maxe2e-PLR value included in the SDP answer.\nThe maxUL-PLR parameter included in the SDP answer indicates the maximum packet loss rate that the answering MTSI client is able to handle on its local uplink and shall not exceed the maxe2e-PLR value in the SDP offer.\nIf the maxDL-PLR value included in the SDP offer is no greater than ½ the maxe2e-PLR value included by the offering MTSI client in the SDP offer, then maxUL-PLR in the SDP answer shall be set to no greater than (maxe2e-PLR value included in the SDP offer minus maxDL-PLR value included in the SDP offer).  Otherwise (if the maxDL-PLR value included in the SDP offer is greater than ½ the maxe2e-PLR value included in the SDP offer), ten maxUL-PLR in the SDP answer should be set to no greater than (maxe2e-PLR value included in the SDP offer minus maxDL-PLR value included in the SDP offer).  If the answerer sets the maxUL-PLR in the SDP answer to be greater than (maxe2e-PLR value included in the SDP offer minus maxDL-PLR value included in the SDP offer), the answerer shall not set maxUL-PLR greater than ½ maxe2e-PLR value included in the SDP offer.\nIf the maxUL-PLR parameter is not included then the default value from the answering MTSI client is set to ½ of the maxe2e-PLR value included in the SDP offer.\nThe plr-value represents 1/100th of a percent (i.e. 10E-4) of packet loss as an integer.\nThe table W.4.3-1 below summarizes the usage of the SDP answer attributes and parameters.\nTable W.4.3-1 Usage of the SDP answer attributes and parameters\n\nClause X.2.4 provides examples of how the MAXimum-e2e-PLR attribute is used in the SDP answer.\n\n",
                    "tables": [
                        {
                            "description": "Table W.4.3-1 Usage of the SDP answer attributes and parameters",
                            "table number": 251,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "X.1\tMaximum Packet Loss Rate (Max. PLR) for Speech",
            "description": "Based on the 3GPP EVS Selection and Characterization results that included AMR-WB, AMR-WB with G718IO, and EVS codec, this clause provides an example set of Max. PLR operating points that the terminal may indicate to the PCRF/PCF.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "X.1.1\tMax. PLR recommendation without Application Layer Redundancy",
                    "description": "",
                    "summary": "",
                    "text_content": "Table X.1 provides example Maximum PLR operating points based on the EVS Selection and Characterization experiment results in TR 26.952 [168] and TR 26.959 [169].\nTable X.1: Example Maximum End-to-end Packet Loss Rate (PLR) per link for AMR-WB and EVS\n\n",
                    "tables": [
                        {
                            "description": "Table X.1: Example Maximum End-to-end Packet Loss Rate (PLR) per link for AMR-WB and EVS",
                            "table number": 252,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "X.1.2\tMax. PLR recommendation with Application Layer Redundancy",
                    "description": "",
                    "summary": "",
                    "text_content": "Application layer redundancy can work in conjunction with any of the aforementioned codec modes in Table X.1.\nTable X.2 provides example Maximum PLR operating points with and without application layer redundancy applicable to EVS codec based on informal objective and subjective results in Annex A of TR 26.959 [169].\nThe example in Table X.2 includes 100% application layer redundancy with offset 2, resulting in (2 x Bitrate). It should be noted that the relationship to path loss when operating at twice the bit rate (with 100% application layer redundancy) is not accounted in the Max. PLR recommendation in Table X.2.\nTable X.2: Example Max. End-to-end Packet Loss Rate (PLR) with application layer redundancy for EVS codec\n\n",
                    "tables": [
                        {
                            "description": "Table X.2: Example Max. End-to-end Packet Loss Rate (PLR) with application layer redundancy for EVS codec",
                            "table number": 253,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "X.2\tSDP Examples of the CHEM Feature (informative)",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "X.2.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "The following examples illustrate the use of the SDP attributes and parameters specified for the CHEM feature.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "X.2.2\tExample of Adaptation to Packet Losses without Application Layer Redundancy",
                    "description": "",
                    "summary": "",
                    "text_content": "The example in TableX.2.2-1 demonstrates how, as specified in clause W.2, the receiver in the offering MTSI client supports and offers to request adaptation to different codec configurations to provide different levels of packet loss robustness without using application layer redundancy.\nTable X.2.2-1: SDP offer supporting adaptation to packet loss without using application layer redundancy\n\nThe example in Table X.2.2-2 is one possible response to the offer in Table X.2.2-1 and demonstrates how, as specified in clause W.2, the receiver in the answering MTSI client also supports and negotiates requesting adaptation to different codec configurations to provide different levels of packet loss robustness without using application layer redundancy.  During the ensuing session both the offerer MTSI client and answerer MTSI client request robustness adaptation without application layer redundancy.  The PCRF/PCFs should choose to use more robust handover thresholds that do not rely on application layer redundancy in both the uplink and downlink directions.\nTable X.2.2-2: SDP answer supporting adaptation to packet loss without using application layer redundancy\n\nThe example in Table X.2.2-3 is another possible response to the offer in Table X.2.2-1 and demonstrates how, as specified in clause W.2, the receiver in the answering MTSI client does not support requesting adaptation to different codec configurations to provide different levels of packet loss robustness.  In the ensuing session, media robustness adaptation is not enabled in either direction of media transmission so the PCRF/PCFs should not use more robust handover thresholds in either the uplink or downlink direction.\nTable X.2.2-3: SDP answer not supporting adaptation to packet loss\n\n",
                    "tables": [
                        {
                            "description": "Table X.2.2-1: SDP offer supporting adaptation to packet loss without using application layer redundancy",
                            "table number": 254,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table X.2.2-2: SDP answer supporting adaptation to packet loss without using application layer redundancy",
                            "table number": 255,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table X.2.2-3: SDP answer not supporting adaptation to packet loss",
                            "table number": 256,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "X.2.3\tExample of Adaptation to Packet Losses with Application Layer Redundancy",
                    "description": "",
                    "summary": "",
                    "text_content": "The example in Table X.2.3-1 demonstrates how, as specified in clause W.3, the receiver in the offering MTSI client supports and offers to request adaptation to different codec configurations to provide different levels of packet loss robustness using application layer redundancy.\nTable X.2.3-1: SDP offer supporting adaptation to packet loss using application layer redundancy and the in-band RTP CMR code points specified in clause W.3\n\nThe example in Table X.2.3-2 is one possible response to the offer in Table X.2.3-1 and demonstrates how, as specified in clause W.3, the receiver in the answering MTSI client also supports and negotiates requesting adaptation to different codec configurations to provide different levels of packet loss robustness using application layer redundancy.  During the ensuing session both the offerer MTSI client and answerer MTSI client request robustness adaptation and can use the in-band RTP CMR codepoints specified in clause W.3 to request application layer redundancy.  The PCRF/PCFs should choose to use more robust handover thresholds (both using application layer redundancy or not) in both the uplink and downlink directions.\nTable X.2.3-2: SDP answer supporting adaptation to packet loss using application layer redundancy and the in-band RTP CMR code points specified in clause W.3\n\nThe example in Table X.2.3-3 is another possible response to the offer in Table X.2.3-1 and demonstrates how, as specified in clause W.2 and clause W.3, the receiver in the answering MTSI client supports requesting adaptation to different codec configurations but not using application layer redundancy.  During the ensuing session both the offerer MTSI client and answerer MTSI client request robustness adaptation without application layer redundancy.  The PCRF/PCFs should choose to use more robust handover thresholds that do not rely on application layer redundancy in both the uplink and downlink directions.\nTable X.2.3-3: SDP answer supporting adaptation to packet loss without use of application layer redundancy\n\n",
                    "tables": [
                        {
                            "description": "Table X.2.3-1: SDP offer supporting adaptation to packet loss using application layer redundancy and the in-band RTP CMR code points specified in clause W.3",
                            "table number": 257,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table X.2.3-2: SDP answer supporting adaptation to packet loss using application layer redundancy and the in-band RTP CMR code points specified in clause W.3",
                            "table number": 258,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table X.2.3-3: SDP answer supporting adaptation to packet loss without use of application layer redundancy",
                            "table number": 259,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "X.2.4\tExample of Maximum End-to-End Packet Loss Rate",
                    "description": "",
                    "summary": "",
                    "text_content": "The example in Table X.2.4-1 demonstrates how, as specified in clause W.4.2, the media receiver in the offering MTSI terminal receiver can handle up to 3.50% end-to-end PLR for the EVS codec, proposes to use 1.50% PLR on its downlink and 2.00% for its uplink, and can handle up to 2.00% end-to-end PLR for the AMR-WB codec, proposes to use 0.75% PLR on its downlink and 1.25% for its uplink.  The example does not use application layer redundancy but could easily apply to sessions using application layer redundancy by including the ALR parameter in the PLR_adapt attribute as specified in clause W.3.\nTable X.2.4-1: SDP offer with maximum end-to-end PLR attribute and parameters\n\nThe example in Table X.2.4-2 is one possible response to the offer in Table X.2.4-1 and demonstrates how, as specified in clause W.4.3, the receiver in the answering MTSI terminal supports up to 4.00% end-to-end PLR for the EVS codec, proposes to use 2.00% PLR on both its downlink and uplink.  This leaves 1.50% for the downlink and 2.00% for the uplink to the offerering MTSI terminal which matches what was proposed in the SDP offer.\nTable X.2.4-2: SDP answer with maximum end-to-end PLR attribute and parameters agreeing to what was proposed in the SDP offer\n\nThe example in Table X.2.4-3 is another possible response to the offer in Table X.2.4-1 and demonstrates how, as specified in clause W.4.3, the receiver in the answering MTSI terminal supports up to 3.50% end-to-end PLR for the EVS codec, proposes to use 1.75% PLR on both its downlink and uplink.  This leaves 1.75% for each of the uplink and downlink to the offerering MTSI terminal which is higher than the downlink PLR (i.e., the answerer is being more generous to the offerer) and lower than the uplink PLR (i.e., the answerer not agreeing to let the offerer be greedy) proposed in the SDP offer.\nTable X.2.4-3: SDP answer with maximum end-to-end PLR attribute and parameters not agreeing to what was proposed in the SDP offer\n\n\n",
                    "tables": [
                        {
                            "description": "Table X.2.4-1: SDP offer with maximum end-to-end PLR attribute and parameters",
                            "table number": 260,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table X.2.4-2: SDP answer with maximum end-to-end PLR attribute and parameters agreeing to what was proposed in the SDP offer",
                            "table number": 261,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "Table X.2.4-3: SDP answer with maximum end-to-end PLR attribute and parameters not agreeing to what was proposed in the SDP offer",
                            "table number": 262,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "Y.1\tGeneral",
            "description": "The MTSI terminal may support the Immersive Teleconferencing and Telepresence for Remote Terminals (ITT4RT) feature as defined in this clause. MTSI clients supporting the ITT4RT feature shall be referred to as ITT4RT clients.\nITT4RT functionality for MTSI enables support of an immersive experience for remote terminals joining teleconferencing and telepresence sessions. It addresses scenarios with two-way audio and one-way immersive 360-degree video, e.g., a remote single user wearing an HMD participating in a conference will send audio and optionally 2D video (e.g., of a presentation, screen sharing and/or a capture of the user itself), but receives stereo or immersive voice/audio and immersive 360-degree video captured by an omnidirectional camera in a conference room connected to a fixed network.\nSince immersive 360-degree video support for ITT4RT is unidirectional, ITT4RT clients supporting immersive 360-degree video are further classified into two types to distinguish between the capabilities for sending or receiving immersive video: (i) ITT4RT-Tx client, which is an ITT4RT client only capable of sending immersive 360-degree video, and (ii) ITT4RT-Rx client, which is an ITT4RT client only capable of receiving immersive 360-degree video. Such a classification does not apply for ITT4RT clients supporting immersive speech/audio, since the support for immersive speech/audio is expected to be bi-directional. It should also be noted that a terminal containing ITT4RT-Tx or ITT4RT-Rx client capabilities may also contain further MTSI client capabilities to support bi-directional 2D video.\nMTSI gateways supporting ITT4RT functionality are referred to as ITT4RT MRF, which is an ITT4RT client implemented by functionality included in the ITT4RT MRF. An ITT4RT MRF supporting immersive 360-degree video contains both ITT4RT-Tx and ITT4RT-Rx clients.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Y.2\tArchitecture and Interfaces",
            "description": "Definitions, reference and coordinate systems, video signal representation and audio signal representation as described in clause 4.1 of TS 26.118 [180] are applicable.\nFigure Y.1 provides a possible sender architecture that produces the RTP streams containing 360-degree video and immersive speech/audio as applicable to an ITT4RT client in terminal. VR content acquisition includes capture of 360-degree video and immersive speech/audio, as well as other relevant content such as overlays. Following VR content pre-processing and encoding of 360-degree video and immersive speech/audio components, the corresponding elementary streams are generated. For 360-degree projected video, pre-processing may include video stitching, rotation or other translations, and the pre-processed 360-degree video is then passed into the projection functionality in order to map 360-degree video into 2D textures using a mathematically specified projection format. Optionally, the resulting projected video may be further mapped region-wise onto a packed video. For 360-degree fisheye video, circular videos captured by fisheye lenses are not stitched, but directly mapped onto a 2D texture, without the use of the projection and region-wise packing functionalities (as described in clause 4.3 of ISO/IEC 23090-2 [179]). In this case, pre-processing may include arranging the circular images captured by fisheye lenses onto 2D textures, and the functionality for projection and mapping is not needed. For audio, no stitching process is needed, since the captured signals are inherently immersive and omnidirectional. Followed by the HEVC/AVC encoding of the 2D textures and EVS encoding of immersive speech/audio along with the relevant immersive media metadata (e.g., SEI messages), the consequent video and audio elementary streams are encapsulated into respective RTP streams and transmitted.\nFigure Y.1 illustrates the reference sender architecture for an ITT4RT client in a terminal, showcasing the various components involved in the communication process. The figure depicts the sender's side, including the ITT4RT client, which is responsible for sending data to the receiver. The sender's components are shown as a series of interconnected nodes, with the ITT4RT client at the center. This client is responsible for processing the data and sending it through the network.\n\nThe figure also shows the receiver's side, which is connected to the sender through a series of communication channels. These channels are represented by lines connecting the sender and receiver, and they are responsible for transmitting the data from the sender to the receiver. The figure also includes a series of nodes that represent the various components of the communication network, such as routers, switches, and other devices that are involved in the data transmission process.\n\nOverall, Figure Y.1 provides a comprehensive overview of the reference sender architecture for an ITT4RT client in a terminal, highlighting the various components involved in the communication process and their roles in transmitting data between the sender and receiver.\nFigure Y.1: Reference sender architecture for ITT4RT client in terminal\nFigure Y.2 provides an overview of a possible receiver architecture that reconstructs the 360-degree video and immersive speech/audio in an ITT4RT client in terminal. Note that this figure does not represent an actual implementation, but a logical set of receiver functions. Based on one or more received RTP media streams, the UE parses, possibly decrypts and feeds the elementary video stream into the HEVC/AVC decoder and the speech/audio stream into the EVS decoder. The HEVC/AVC decoder obtains the decoder output signal, referred to as the \"2D texture\", as well as the decoder metadata. Likewise, the EVS decoder output signal contains the immersive speech/audio. The decoder metadata for video contains the Supplemental Enhancement Information (SEI) messages, i.e., information carried in the omnidirectional video specific SEI messages, to be used in the rendering phase. In particular, the decoder metadata may be used by the Texture-to-Sphere Mapping function to generate a 360-degree video (or part thereof) based on the decoded output signal, i.e., the texture. The viewport is then generated from the 360-degree video signal (or part thereof) by taking into account the pose information from sensors, display characteristics as well as possibly other metadata.\nFor 360-degree video, the following components are applicable:\n-\tThe RTP stream contains an HEVC or an AVC bitstream with omnidirectional video specific SEI messages. In particular, the omnidirectional video specific SEI messages as defined in ISO/IEC 23008-2 [119] and ISO/IEC 14496-10 [24] may be present.\n-\tThe video elementary stream(s) are encoded following the requirements in clause Y.3\nFigure Y.2 illustrates the reference receiver architecture for ITT4RT-client in terminal, showcasing the various components involved in the system. The figure depicts the client terminal, which is connected to the network via a cable, and the receiver, which is responsible for decoding the transmitted signals. The architecture also includes a modem, which facilitates the communication between the client terminal and the network. The figure highlights the importance of each component in ensuring a seamless and efficient communication process.\nFigure Y.2: Reference receiver architecture for ITT4RT- client in terminal\nFigure Y.2: Reference receiver architecture for ITT4RT- client in terminal The output signal, i.e., the decoded picture or \"texture\", is then rendered using the Decoder Metadata information in relevant SEI messages contained in the video elementary streams as well as the relevant information signalled at the RTP/RTCP level (in the viewport-dependent case). The Decoder Metadata is used when performing rendering operations such as region-wise unpacking, projection de-mapping and rotation for 360-degree projected video, or fisheye video information for 360-degree fisheye video) toward creating spherical content for each eye.  Details of such sample location remapping process operations are described in clause D.3.41.7 of ISO/IEC 23008-2 [119].\nViewport-dependent 360-degree video processing could be supported for both point-to-point conversational sessions and multiparty conferencing scenarios and can be achieved by sending from the ITT4RT-Rx client RTCP feedback  messages with  viewport information and then encoding and sending the corresponding viewport by the ITT4RT-Tx client or by the ITT4RT-MRF. This is expected to deliver resolutions higher than the viewport independent approach for the desired viewport. The transmitted RTP stream from the ITT4RT-Tx client or ITT4RT-MRF may also include the information on the region of the 360-degree video encoded in higher quality as the video generated, encoded and streamed by the ITT4RT-Tx client may cover a larger area than the desired viewport. Viewport-dependent processing is  realized via RTP/RTCP based protocols that are supported by ITT4RT clients. The use of RTP/RTCP based protocols for viewport-dependent processing is further described in clause Y.7.2.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Y.3\tImmersive 360-Degree Video Support",
            "description": "ITT4RT-Rx clients in terminals offering video communication shall support decoding capabilities based on:\n-\tH.264 (AVC) [24] Constrained High Profile, Level 5.1 with the following additional restrictions and requirements on the bitstream:\n-\tthe maximum VCL Bit Rate is constrained to be 120 Mbps with cpbBrVclFactor and cpbBrNalFactor being fixed to be 1250 and 1500, respectively.\n-\tthe bitstream does not contain more than 10 slices per picture.\n-\tH.265 (HEVC) [119] Main 10 Profile, Main Tier, Level 5.1.\nIn addition, ITT4RT-Rx clients in terminals may support:\n-\tH.265 (HEVC) [119] Screen-Extended Main 10 Profile, Main Tier, Level 5.1.\n-\tH.265 (HEVC) [119] Screen-Extended Main 4:4:4 10 Profile, Main Tier, Level 5.1.\nITT4RT-Tx clients in terminals offering video communication shall support encoding up to the maximum capabilities (e.g., color bit-depth, luma samples per second, luma picture size, frames per second) compatible with decoders compliant with the following on the bitstream:\n-\tH.264 (AVC) [24] Constrained High Profile, Level 5.1 with the following additional restrictions and requirements:\n-\tthe maximum VCL Bit Rate is constrained to be 120 Mbps with cpbBrVclFactor and cpbBrNalFactor being fixed to be 1250 and 1500, respectively.\n-\tthe bitstream does not contain more than 10 slices per picture.\n-\tH.265 (HEVC) [119] Main 10 Profile, Main Tier, Level 5.1.\nIn addition, ITT4RT-Tx clients in terminals may support:\n-\tH.265 (HEVC) [119] Screen-Extended Main 10 Profile, Main Tier, Level 5.1.\n-\tH.265 (HEVC) [119] Screen-Extended Main 4:4:4 10 Profile, Main Tier, Level 5.1.\nHence, for a Bitstream conforming to the H.264 (AVC) [24] Constrained High Profile, Level 5.1 delivered from an ITT4RT-Tx client to the ITT4RT-Rx client, the following restrictions apply:\n-\tThe profile_idc shall be set to 100 indicating the High profile.\n-\tThe constraint_set0_flag, constraint_set1_flag, constraint_set2_flag and constraint_set3_flag shall all be set to 0, and constraint_set4_flag and constraint_set5_flag shall be set to 1.\n-\tThe value of level_idc shall not be greater than 51 (corresponding to the level 5.1) and should indicate the lowest level to which the Bitstream conforms.\nFurthermore, for a Bitstream conforming to the H.265 (HEVC) [119] Main 10 Profile, Main Tier, Level 5.1 delivered from an ITT4RT-Tx client to the ITT4RT-Rx client, the following restrictions apply:\n-\tThe general_profile_idc shall be set to 2 indicating the Main10 profile.\n-\tThe general_tier_flag shall be set to 0 indicating the Main tier.\n-\tThe value of level_idc shall not be greater than 153 (corresponding to the Level 5.1) and should indicate the lowest level to which the Bitstream conforms.\nFor 360-degree video delivery across ITT4RT clients, the following components are applicable:\n-\tThe RTP stream shall contain an HEVC or an AVC bitstream with possible presence of omnidirectional video specific SEI messages. In particular, the omnidirectional video specific SEI messages as defined in clause D.2.41 of ISO/IEC 23008-2 [119] or ISO/IEC 14496-10 [24] may be present for the respective HEVC or AVC bitstreams.\n-\tThe video elementary stream(s) shall be encoded following the requirements in the Omnidirectional Media Format (OMAF) specification ISO/IEC 23090-2 [179], clauses 10.1.2.2 (viewport-independent case) or 10.1.3.2 (viewport-dependent case) for HEVC bitstreams and clause 10.1.4.2 for AVC bitstreams. Furthermore, the general video codec requirements for AVC and HEVC in clause 5.2.2 of TS 26.114 also apply.\nITT4RT-Rx clients are expected to be able to process the VR metadata carried in SEI messages for rendering 360-degree video according to the relevant processes. Relevant SEI messages contained in the elementary stream(s) with decoder rendering metadata may include the following information for the relevant processes as per clause D.3.41 of ISO/IEC 23008-2 [119] and ISO/IEC 14496-10 [24]:\n-\tProjection mapping information (indicating the projection format in use, e.g., Equirectangular projection (ERP) or Cubemap projection (CMP)), for the projection sample location remapping process as specified in clauses 7.5.1.3 and 5.2 of ISO/IEC 23090-2 [179]\n-\tRegion-wise packing information (carrying region-wise packing format indication, any coverage restrictions or padding/guard region information in ithe packed picture), for the inverse processes of the region-wise packing as specified in clauses 7.5.1.2 and 5.4 of ISO/IEC 23090-2 [179]\n-\tSphere rotation information (indicating the amount of sphere rotation, if any, applied to the sphere signal before projection and region-wise packing at the encoder side), for the coordinate axes conversion process as specified in clause 5.3 of ISO/IEC 23090-2 [179]\n-\tFrame packing arrangement (indicating the frame packing format for stereoscopic content), for the processes as specified in D.3.16 of ISO/IEC 23008-2 [119]\n-\tFisheye video information (indicating that the picture is a fisheye video picture containing a number of active areas captured by fisheye camera lens), for the fisheye sample location remapping process as specified in clause D.3.41.7.5 of ISO/IEC 23008-2 [119]\nThe exchange of SEI messages carrying VR metadata for rendering 360-degree video or fisheye video shall be performed using bitstream-level signalling as follows.\nSEI messages shall be present in the respective video elementary streams corresponding to the HEVC or AVC bitstreams carrying 360-degree video or fisheye video from the ITT4RT-Tx client to the ITT4RT-Rx client, as per ISO/IEC 23008-2 [119] or ISO/IEC 14496-10 [24]. As expressed more clearly below, the mandatory inclusion of the specific SEI messages in the bitstream by the ITT4RT-Tx client and their decoder and rendering processing by the ITT4RT-Rx client is conditional upon successful SDP-based negotiation of the corresponding 360-degree video or fisheye video capabilities.\nIn particular, the ITT4RT-Tx client supporting 360-degree video for viewport-independent processing shall signal in the bitstream the equirectangular projection SEI message (payloadType equal to 150) to the ITT4RT-Rx client, with the erp_guard_band_flag set to 0.\nIf viewport-dependent processing (VDP) capability is successfully negotiated by the ITT4RT-Tx client and ITT4RT-Rx client for the exchange of 360-degree video, then, the ITT4RT-Tx client shall signal in the bitstream to the ITT4RT-Rx client either:\n-\tthe equirectangular projection SEI message (payloadType equal to 150) with the erp_guard_band_flag set to 0, or\n-\tthe cubemap projection SEI message (payloadType equal to 151).\nIn order to optimize the spatial resolution of specific viewports, the ITT4RT-Tx client and ITT4RT-Rx client may negotiate the use of region-wise packing as part of the exchange of 360-degree video. If this is the case, the region-wise packing SEI message (payloadType equal to 155) shall also be signalled by the ITT4RT-Tx client to the ITT4RT-Rx client in the bitstream.\nIf stereoscopic video capability is successfully negotiated by the ITT4RT-Tx client and ITT4RT-Rx client as part of the exchange of 360-degree video, then the frame packing arrangement SEI message (payloadType equal to 45) shall also be signalled by the ITT4RT-Tx client to the ITT4RT-Rx client in the bitstream, with the following restrictions:\n-\tThe value of frame_packing_arrangement_cancel_flag is equal to 0.\n-\tThe value of frame_packing_arrangement_type is equal to 4.\n-\tThe value of quincunx_sampling_flag is equal to 0.\n-\tThe value of spatial_flipping_flag is equal to 0.\n-\tThe value of field_views_flag is equal to 0.\n-\tThe value of frame0_grid_position_x is equal to 0.\n-\tThe value of frame0_grid_position_y is equal to 0.\n-\tThe value of frame1_grid_position_x is equal to 0.\n-\tThe value of frame1_grid_position_y is equal to 0.\nFurthermore, ITT4RT-Tx clients supporting 360-degree fisheye video shall signal the fisheye video information SEI message (payloadType equal to 152) to the ITT4RT-Rx clients in the bitstream.\nThe bitstream delivered from an ITT4RT-Tx client to the ITT4RT-Rx client shall contain the corresponding SEI message and ITT4RT-Rx client shall process the VR metadata carried in the signalled SEI message(s) for rendering 360-degree video (provided the successful SDP-based negotiation of the corresponding 360-degree video or fisheye video capabilities associated with the SEI messages).\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Y.4\tImmersive Voice/Audio Support",
            "description": "ITT4RT-Rx and ITT4RT-Tx clients in terminals offering speech communication shall support super-wideband communication as specified in clause 5.2.1.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Y.5\tOverlay Support",
            "description": "An overlay is defined as a piece of visual media, rendered over omnidirectional video or on the viewport. An ITT4RT-Tx client supporting the ‘Overlay’ feature shall add real-time overlays on top of a 360-degree background and offer this capability in the SDP as part of the the initial offer-answer negotiation. An overlay in ITT4RT is characterized by the overlay source and its rendering configuration. ITT4RT supports both 2D and spherical overlays.\nAn overlay source specifies the image or video to be used as the content for the overlay. The overlay source is a bitstream that may be delivered as an overlay video encoded and delivered as an RTP stream.\nITT4RT clients supporting the ‘Overlay’ feature have the following requirements:\n-\tan ITT4RT-Tx client may be capable to provide a bitstream consisting of an overlay with a video source that conforms to the requirements of Y.3 or the video bitstream requirements of MTSI.\n-\tan ITT4RT-Tx client may be capable of providing HEVC encoded images/image sequence that conform to HEVC bitstream requirements of Y.3. The signalling for such a stream shall comply to 6.2.11 and 7.4.8.\n-\tan ITT4RT-Rx client may be capable to decode and render a 360-degree video bitstream and further decode and render one or more overlay streams on top of the 360-degree video.\nThe rendering configuration defines how the overlay is to be rendered in the spherical scene. It is possible for an overlay to be delivered without any rendering configuration, in which case, the ITT4RT-Rx client should render the content as per the default configuration described in section Y.6.4.3. Alternatively, the rendering configuration for one or more overlays may be negotiated during session establishment to ensure uniform operation for different receivers.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Y.6\tMedia configuration",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "Y.6.1\tGeneral",
                    "description": "",
                    "summary": "",
                    "text_content": "Based on the architecture described in clause Y.2, an SDP framework for immersive video and immersive voice/audio exchange for ITT4RT is presented to negotiate codec support, SEI messages for decoder rendering metadata, as well as RTP/RTCP signaling necessary for viewport dependent processing.\nThe SDP attributes 3gpp_360video, 3gpp_fisheye, 3gpp_overlay shall be used to indicate respectively a 360-degree projected video stream, a 360-degree fisheye video stream, and a spherical overlay. ITT4RT-Tx clients that support both 360-degree projected video and 360-degree fisheye video may include both 3gpp_360video and 3gpp_fisheye attributes as alternatives in the SDP offer, but an ITT4RT-Rx client willing to receive 360-degree video shall include only one attribute (either 3gpp_360video or 3gpp_fisheye, based on support or selection) in the SDP answer. The 3gpp_overlay attributes may be included in the SDP answer independent on whether projected or fisheye video is selected, since spherical overlays are applicable to both types of 360-degree video streams. The detailed definition and usage of these SDP attributes are presented in the clauses below.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "Y.6.2\tMain 360-degree video",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "Y.6.2.1\tGeneral",
                            "text_content": "A new SDP attribute 3gpp_360video is defined with the following ABNF syntax:\natt-field = \t\t\t\"3gpp_360video\"\natt-value = \t\t\tPT [optparams]\nPT =\t\t\t\t1*DIGIT\noptparams =\t\t\t[SP FOV] [SP FOV_CENTER] [SP \"Stereo\"] [SP VDP] [SP viewportfb_trigger]\nFOV =\t\t\t\t\"fov=\" 1*(fovset)\nfovset =\t\t\t\"[x=\" azimuthrange \",y=\" elevationrange \"]\"\nazimuthrange =\t\tdeg0to360\nelevationrange =\tdeg0to180\n\nFOV_CENTER =\t\t\"fov_center=[x=\" centerazimuth \",y=\" centerelevation \"]\"\ncenterazimuth =\t\tdegminus180to180\ncenterelevation =\tdegminus90to90\n\nVDP =\t\t\t\t\"VDP\" [SP SLVL] [SP Projection] [SP PPM] SP viewport_ctrl SP viewport_size\nSLVL =\t\t\t\t\"VL\"/\"VL,SL\"/\"SL\"\nProjection =\t\t\"projection=\" proj-type *(\",\" proj-type)\nPPM =\t\t\t\t\"ppm=\" ppm-list\nviewport_ctrl =\t\t\"viewport_ctrl=\" vc-value *2(\",\" [SP] vc-value)\nviewport_size =\t\t\"viewport=\" azimuthrange \"x\" elevationrange\n;sub-rules of Projection\nproj-type =\t\t\t\"ERP\"/\"CMP\"\n;sub-rules of PPM\nppm-list =\t\t\tppm-value *(\"/\" ppm-value)\nppm-value =\t\t\t\"1\"/\"2\"/packing\npacking =\t\t\t\"[\" PPWHQ \",\" PPHHQ \",\" TRHQ \",\" PPWLQ \",\" PPHLQ \",\" TRLQ \"]\"\nPPWHQ =\t\t\t\tpos-integer\nPPHHQ =\t\t\t\tpos-integer\nTRHQ =\t\t\t\ttransform-value\nPPWLQ =\t\t\t\tpos-integer\nPPHLQ =\t\t\t\tpos-integer\nTRLQ =\t\t\t\ttransform-value\ntransform-value =\t\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\"\n; transform values as per Table Y.6.1\n;sub-rules of viewport_ctrl\nvc-value =\t\t\t\"0\"/\"1\"/\"2\"\n; viewport control values as per Table Y.6.2\n\nviewportfb_trigger =D_spherical/(\"[\" D_azimuth \",\" D_elevation \"]\")\nD_spherical =\t\tdeg0to180minus1\nD_azimuth =\t\t\tdegminus180to180\nD_elevation =\t\tdegminus90to90\n\n;generic sub-rules\ndeg0to360 =\t\t\t\"0\"\n/ POS-DIGIT *6DIGIT\n/ \"1\" 7DIGIT\n/ \"2\" (\"0\"/\"1\"/\"2\") 6DIGIT\n/ \"23\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\") 5DIGIT\n/ \"235\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\"/\"8\") 4DIGIT\n/ \"2359\" (\"0\"/\"1\") 3DIGIT\n/ \"23592\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\"/\"8\") 2DIGIT\n/ \"235929\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\") DIGIT\n/ \"23592960\"\n; 0 to 23 592 960, inclusive\ndeg0to180 =\t\t\t\"0\"\n/ POS-DIGIT *6DIGIT\n/ \"10\" 6DIGIT\n/ \"11\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\") 5DIGIT\n/ \"117\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\"/\"8\") 4DIGIT\n/ \"1179\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\") 3DIGIT\n/ \"11796\" (\"0\"/\"1\"/\"2\"/\"3\") 2DIGIT\n/ \"117964\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\") 1DIGIT\n/ \"11796480\"\n; 0 to 11 796 480, inclusive\ndegminus180to180 =\t\"0\"\n/ [\"-\"] POS-DIGIT *6DIGIT\n/ [\"-\"] \"10\" 6DIGIT\n/ [\"-\"] \"11\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\") 5DIGIT\n/ [\"-\"] \"117\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\"/\"8\") 4DIGIT\n/ [\"-\"] \"1179\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\") 3DIGIT\n/ [\"-\"] \"11796\" (\"0\"/\"1\"/\"2\"/\"3\") 2DIGIT\n/ [\"-\"] \"117964\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\") 1DIGIT\n/ \"-11796480\"\n; -11 796 480 to 11 796 479, inclusive\ndegminus90to90 =\t\"0\"\n/ [\"-\"] POS-DIGIT *5DIGIT\n/ [\"-\"] (\"1\"/\"2\"/\"3\"/\"4\") 6DIGIT\n/ [\"-\"] \"5\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\") 5DIGIT\n/ [\"-\"] \"58\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\"/\"8\") 4DIGIT\n/ [\"-\"] \"589\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\") 3DIGIT\n/ [\"-\"] \"5898\" (\"0\"/\"1\") 2DIGIT\n/ [\"-\"] \"58982\" (\"0\"/\"1\"/\"2\"/\"3\") DIGIT\n/ [\"-\"] \"5898240\"\n; -5 898 240 to 5 898 240, inclusive\ndeg0to180minus1 =\t\"0\"\n/ POS-DIGIT *6DIGIT\n/ \"10\" 6DIGIT\n/ \"11\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\") 5DIGIT\n/ \"117\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\"/\"8\") 4DIGIT\n/ \"1179\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\") 3DIGIT\n/ \"11796\" (\"0\"/\"1\"/\"2\"/\"3\") 2DIGIT\n/ \"117964\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\"/\"6\"/\"7\") 1DIGIT\n; 0 to 11 796 479, inclusive\npos-integer =\t\tPOS-DIGIT * DIGIT\nPOS-DIGIT =\t\t\t%x31-39\t\t\t; 1-9\n\nNOTE:\tIf the SDP negotiations become too complex, defining profiles can be considered.\nThe semantics of the above attribute and parameters is provided below. Unsupported parameters of the 3gpp_360video attribute may be ignored. The payload type is the RTP payload type number of the media stream associated with the 3gpp_360video attribute.\nAn ITT4RT client supporting the 3gpp_360video attribute shall support the following procedures:\n-\twhen sending an SDP offer, the ITT4RT client includes the 3gpp_360video attribute in the media description for video in the SDP offer,\n-\twhen sending an SDP answer, the ITT4RT client includes the 3gpp_360video attribute in the media description for video in the SDP answer if the 3gpp_360video attribute was received in an SDP offer,\n-\tafter successful negotiation of the 3gpp_360video attribute in the SDP, for the video streams based on the HEVC or AVC codec, the ITT4RT clients exchange an RTP-based video stream containing an HEVC or AVC bitstream with omnidirectional video specific SEI messages as defined in Annex Y.3.\nAn ITT4RT client supporting the 3gpp_360video attribute supporting use of viewport-dependent processing (VDP) shall include the VDP parameter in the SDP offer and answer. Depending on the value indicated by the VDP parameter, the ITT4RT client shall further support the following procedures:\n-\tthe RTCP feedback (FB) message described in Annex Y.7.2 of type 'Viewport' to carry requested viewport information during the RTP streaming of media (signalled from the ITT4RT-Rx client to the ITT4RT-Tx client).\nAn ITT4RT client shall not include VDP parameter in the SDP answer if the SDP offer contains the 3gpp_360video attribute without the VDP parameter.\nAn ITT4RT-Tx client that supports VDP may use viewport margins to maintain consistent quality during small head motion and also to reduce the need for frequent viewport updates. Viewport margins can be extended on all or some sides of the viewport and may be at the same quality (or resolution) as the viewport or at a quality (or resolution) lower than the viewport but higher than the background. Viewport margins may be extended around the viewport evenly or unevenly depending on head motion or network quality.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "Y.6.2.2\tProjection",
                            "text_content": "An ITT4RT- client supporting the 3gpp_360video attribute with VDP supporting projection may include the Projection parameter indicating the types of projection (e.g. ERP, CMP) it prefers (in the order of preference) in the SDP. An ITT4RT client may respond to an SDP offer with multiple options indicated in the Projection parameter with the agreed option. An ITT4RT-Tx client is not required to provide the preferred form of projection indicated by an ITT4RT-Rx client but may do so when possible.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "Y.6.2.3\tField Of View (FOV)",
                            "text_content": "An ITT4RT-Tx client may support sending a limited 360-degree video.\ni.\tAn ITT4RT-Tx client supporting the 3gpp_360video attribute capable of sending a limited 360-degree video shall include the parameter FOV in its SDP offer to indicate the cfov (Capture FoV) as the extent (range) of the 360-degree video with respect to the unit sphere. The range is expressed in units of 2–16 degrees with an x parameter for azimuth range and a y parameter for elevation range, sent as a comma-seperated tuple. The values for azimuth range shall be in the range of 0 to 360 * 216 (i.e., 23 592 960), inclusive, and the values for elevation range shall be in the range of 0 to 180 * 216 (i.e., 11 796 480), inclusive. In the absence of cfov, the default value of x and y are 360 and 180 degrees, respectively.\nii.\tAn ITT4RT-Rx client supporting the 3gpp_360video attribute capable that wants to receive a limited 360-degree video shall include the parameter FOV in its SDP offer/answer to indicate the pfov (Preferred FoV), where pfov <= cfov in one or both the x and y dimensions when cfov is known. The pfov range is expressed in units of 2–16 degrees with an x parameter for azimuth range and a y parameter for elevation range, sent as a comma-seperated tuple. The values for azimuth range shall be in the range of 0 to 360 * 216 (i.e., 23 592 960), inclusive, and the values for elevation range shall be in the range of 0 to 180 * 216 (i.e., 11 796 480), inclusive. In the absence of pfov, the default value of x and y are 360 and 180 degrees, respectively.\niii.\tAn ITT4RT-Tx client that has received an SDP offer from an ITT4RT-Rx client with the parameter FOV shall include in its SDP answer the parameter FOV to indicate the range of the 360-degree video it will provide. The value is the same as the FOV in the SDP offer or different based on the ITT4RT-Tx client capabilities.\nAn ITT4RT client supporting the 3gpp_360video attribute with the FOV parameter may include the paramater FOV_CENTER in the SDP. FOV_CENTER is expressed as a comma-separated tuple (x,y), where x is the azimuth (in units of 2–16 degrees) and y is the elevation (in units of 2–16 degrees) with respect to the global coordinates such that the range defined FOV bypasses through the coordinates defined by FOV_CENTER. The values for azimuth shall be in the range of −180 * 216 (i.e., −11 796 480) to 180 * 216 − 1 (i.e., 11 796 479), inclusive, and the values for elevation shall be in the range of −90 * 216 (i.e., −5 898 240) to 90 * 216 (i.e., 5 898 240), inclusive. The imageattr attribute indicates the resolution of the delivered content based on the cfov and pfov options.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "Y.6.2.4\tPicture Packing",
                            "text_content": "An ITT4RT client supporting mixed-quality tiled encoding, mixed-resolution tiled encoding and/or a 360-degree low-quality background frame-packed with an overlapping high-quality viewport shall include the PPM parameter in the 3gpp_360video attribute of the SDP offer.\n\nA list of all supported options as defined by ppm-list in Annex Y.6.2.1  shall be included in the SDP offer, where:\n-\tA ppm-value of 1 indicates mixed-quality tiled encoding\n-\tA ppm-value of 2 indicates mixed-resolution tiled encoding\n-\tA ppm-value set to the comma-separated list ‘packing’ indicates low-quality viewport-independent background 360-degree video frame-packed with a high-quality viewport (possibly with margins) such that the two regions have overlapping content\nAn ITT4RT client that receives an SDP offer with a ppm-list of more than one ppm-value shall include only one preferred/supported ppm-value in the SDP answer. An ITT4RT-Rx client that includes the PPM parameter in its SDP offer with the ppm-value set to ‘packing’ (as defined above in the PPM syntax) shall set all values of the ‘packing’ to zero. An ITT4RT-Tx client that receives the PPM parameter in an SDP offer with the ppm-value set to ‘packing’ (as defined above in the PPM syntax) shall set all values of the ‘packing’ appropriately in the response.\nTiled encoding may be used to deliver the full 360-degree video or a high-quality video which includes the viewport and may include viewport margins.\nThe ppm-value ‘packing’ consists of the following six fields:\n-\tPPWHQ defines packed_picture_width of the high-quality region in pixels\n-\tPPHHQ defines packed_picture_height of the high-quality region in pixels\n-\tTRHQ defines transform operations applied on the high-quality region.\n-\tPPWLQ defines packed_picture_width of the low-quality region in pixels\n-\tPPHLQ defines packed_picture_height of the low-quality region in pixels\n-\tTRLQ defines transform operations applied on the low-quality region\nThe transform operations have a value of 0-7 as defined in Table Y.6.1:\nTable Y.6.1: Transform values\n\nAn ITT4RT-Rx client shall render the high-quality viewport region where these two regions are overlapping. The PPM parameter for defining the HQ and LQ regions should be used when the information remains constant during the session. When the packed regions are not overlapping, the high-quality and low-quality regions do not need to be explicitly defined and SEI messages for region-wise packing may be used instead of the SDP PPM parameter.\nNOTE:\tThe size of the viewport and fov attributes define the size of projected regions. [It should be considered if the two values should be included explicitly here].\nY.6.2.5 Viewport Control\nAn ITT4RT client that supports the 3gpp_360video with VDP shall in its SDP offer include the parameter viewport_ctrl with one or more of the following control options:\n-\tdevice_controlled if ITT4RT-Tx client will provide VDP based on the requested viewport indicated by the RTCP feedback (FB) message type ‘Viewport’ sent by the corresponding ITT4RT-Rx client.\n-\trecommended_viewport if ITT4RT-Tx client will provide VDP with the help of a recommendation/prediction engine.\n-\tpresenter_viewport if ITT4RT_Tx will provide VDP based on the viewport of an ITT4RT-Rx client other than the one the SDP offer is being sent to.\nTable Y.6.2 provides a mapping between viewport control values and viewport control options.\nTable Y.6.2: Viewport control values\n\nMultiple options are provided as a comma-separated list. An ITT4RT client that receives an SDP offer with multiple viewport_ctrl options may include its preferred viewport_ctrl option in the SDP answer. If no options are given in the answer, the sender shall use the first option in the list.  If the recommended_viewport is successfully negotiated as viewport_ctrl, the ITT4RT-Rx client should not use viewport prediction when sending the RTCP feedback (FB) message type ‘Viewport’ to avoid any conflicts with the prediction engine of the ITT4RT-Tx client.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table Y.6.1: Transform values",
                                    "table number": 263,
                                    "summary": "",
                                    "name": ""
                                },
                                {
                                    "description": "Table Y.6.2: Viewport control values",
                                    "table number": 264,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "Y.6.2.6\tOverlay and 360-degree video",
                            "text_content": "An ITT4RT client that sends an SDP message with at least one 360-degree video/audio and at least one overlay shall include in SDP the attribute itt4rt_group before any media lines. The itt4rt_group attribute is used to group 360-degree media and overlay media using the mid attribute and the syntax for the SDP attribute is:\na=itt4rt_group: <group-1> / … / <group-N>\n\nwhere <group-X> shall include at least one mid associated with 360-degree media and at least one mid associated with an overlay as defined by the mid attribute in the corresponding media description.\nThe ABNF syntax for this attribute is the following:\natt-field =\t\t\"itt4rt_group\"\natt-value =\t\trest-group *[\" /\" rest-group]\nrest-group =\t2*(SP identification-tag)\n; identification-tag is defined in RFC 5888\n\nAn ITT4RT-Tx client and an ITT4RT-Rx client may negotiate the overlays that can be associated with the 360-degree video offered by the ITT4RT-Tx client using the itt4rt_group attribute. An ITT4RT client shall indicate in an offer the overlays to be grouped with the 360-degree video using the itt4rt_group attribute. The overlays that are acceptable shall be retained in the answer and the ones that are not acceptable shall be removed. An ITT4RT-Tx client may offer overlay configuration options using the 3gpp_overlay attribute based on the list of media lines (i.e., potential overlay sources) provided in the itt4rt_group attribute in an SDP offer initiated by an ITT4RT-Rx client. The 3gpp_overlay attribute is offered in an SDP renegotiation.\nThe order of the media included in the itt4rt_group indicates the synchronization source with the first media always being the synchronization anchor when synchronization is required.\nNOTE:\t2D video received from an ITT4RT-Rx clients may be offered as an overlay by the ITT4RT MRF to other ITT4RT-Rx clients. The ITT4RT MRF (acting as the ITT4RT-Tx client) would be the source of overlay media in this case.\nY.6.2.7 Viewport Size\nAn ITT4RT client that includes the 3gpp_360video with the VDP parameter shall also include in SDP the parameter viewport_size to indicate the size of the device viewport using the azimuth and elevation ranges expressed in degrees. An ITT4RT-Tx client may include the viewport_size of the ITT4RT-Rx client when this is known (e.g., in response to an SDP offer from an ITT4RT-Rx client) or include \"viewport=0x0\" and the value can be ignored by the ITT4RT-Rx client.\nNOTE:\tThe viewport size defines the size of the viewport of the ITT4RT-Rx client UE. An ITT4RT-Tx client provides VDP based on this viewport size. The capture and preferred FOV, on the other hand, defines the range of the 360-degree content, which should be larger than the viewport size and can be negotiated even for viewport-independent processing.\nY.6.2.8 Viewport-only VDP and Image attributes\nAn ITT4RT-Tx client supporting VDP may deliver only the viewport or viewport with viewport margins and not the full captured/preferred field-of-view of the 360-degree video. If the viewport region (with or without a viewport margin) is extracted from a projected picture (e.g., ERP), the resolution would change depending on where the viewport is located on the picture. To avoid this, the ITT4RT-Tx client may rotate the desired viewport region to the centre of the ERP before cropping it to the desired size as indicated by imageattr. The delivered bitstream shall contain the rotation SEI and the region-wise packing SEI message if the ITT4RT-Rx client is expected to do sphere-locked rendering by reversing the rotation of the received image before rendering.\nAn ITT4RT client may support viewport-locked VDP for delivering the viewport region only. A viewport-locked VDP bit stream should include only the viewport region and should not include rotation SEI messages. An ITT4RT client that supports viewport-locked VDP shall include in its SDP offer the parameter SLVL as defined in Annex Y.6.2.1.The value \"SL\" refers to sphere-locked rendering, which requires the receiver to render the received picture according to the global coordinate axes. The value \"VL\" refers to viewport-locked rendering, which require the receiver to render the received picture such that the center of the received picture is aligned to the center of the current viewport.\nAn ITT4RT client that supports only viewport-locked VDP shall include \"VL\" in its SDP offer. An ITT4RT client that supports both viewport-locked VDP and a sphere-locked type of VDP shall include \"VL,SL\".  An ITT4RT client that receives an SDP offer with \"VL\" shall include it in its response if it supports viewport-locked VDP and chooses to use it. An ITT4RT client that receives an SDP offer with \"VL\" shall remove the VDP parameter in its response if it does not support viewport-locked VDP or does not wish to use it; the 360-degree video is then delivered using viewport-independent processing. An ITT4RT client that receives an SDP offer with \"SL\" shall include it in its response if it supports sphere-locked VDP and chooses to use it. An ITT4RT client that receives an SDP offer with \"SL\" shall remove the VDP parameter in its response if it does not support sphere-locked VDP or does not choose to use it; the 360-degree video is then delivered using viewport-independent processing. An ITT4RT client that receives an SDP offer with \"VL,SL\" shall include either \"SL\" or \"VL\" in the SDP response based on its preferred mode. Alternatively, if it does not support nor choose either VL or SL it shall remove the VDP from the 3gpp_360video attribute in the response.\nY.6.2.9 Viewport Feedback Trigger\nAn ITT4RT client include the parameter viewportfb_trigger in the 3gpp_360video attribute to define the minimum view port change to initiate an early or event-based RTCP feedback. The syntax for viewportfb_trigger is defined in Annex Y.6.2.1. D_azimuth and D_elevation are the minimum number of degrees that the viewport may change in the horizontal or vertical direction, respectively. The value D_spherical is the minimum spherical distance in degrees between the center of the old and the new viewport. The values for D_spherical shall be in the range 0 to 180 * 216 − 1 (i.e., 11 796 479). Spherical distance between the centre of a first viewport (x1,y1) and second viewport (x2,y2), is calculated as:\n\n\nwhere x1 and x2 is the azimuth in radians and y1 and y2 is the elevation in radians. The value c is in radians and must be converted to degrees for use with D.\nThe viewport feedback trigger value is estimated by the ITT4RT-Tx client based on the viewport margin configuration it intends to use. An ITT4RT-Rx client supporting RTCP viewport feedback shall use periodic RTCP viewport feedback. The frequency of the periodic feedback should be such that it does not exceed the allocated RTCP bandwidth as defined in RFC 4585. An ITT4RT-Rx client may use immediate/early RTCP feedback in addition to the periodic feedback as long as the allocated RTCP bandwidth requirements are met. An ITT4RT-Tx may define a viewport feedback trigger value for an early/immediate feedback and signal this value to the ITT4RT-Rx client in the SDP. The ITT4RT-Tx client should select a threshold value that is suitable for the margin configuration that it intends to use for that stream. The threshold value should be defined within the viewport margin region such that the ITT4RT-Tx client would update the high-quality region (viewport and viewport margin) if the viewport breaches this threshold.\nIf an ITT4RT-Rx client does not have the capability to provide an RTCP viewport feedback at the viewport feedback threshold value provided by the ITT4RT-Tx client in an SDP offer, it may respond with the the minimum threshold value it can support. The ITT4RT-Tx client may adjust its viewport margin configuration based on the threshold value in the answer. If an ITT4RT-Rx client only supports periodic feedback, it shall remove the viewportfb_trigger parameter from the response.\nAn ITT4RT-Rx client that supports a viewport feedback trigger shall include the parameter viewportfb_trigger with the minimum threshold value it can support in an SDP offer. The ITT4RT-Tx client may remove the parameter if it does not support this value or respond with an acceptable value that is equal or higher than the one in the ITT4RT-Rx’s offer.\nIf both sides acknowledge the support of viewportfb_trigger, the ITT4RT-Rx client shall use event-driven/early viewport feedback in addition to periodic feedback. If viewportfb_trigger is not defined by the ITT4RT-Tx client, the ITT4RT-Rx client may still use immediate/early feedback. An ITT4RT-Rx client may use the velocity of the viewport during head motion and the viewport margin (if known) to trigger an immediate feedback. Alternatively, it may use the spherical distance between the viewport in the last feedback and the current viewport to trigger an immediate feedback. The spherical distance can be selected based on viewport margins (if known). An ITT4RT-Rx client may suppress an immediate/early feedback if the time to the next periodic viewport feedback is less than an application-defined threshold.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "Y.6.3\tStill Background",
                    "description": "",
                    "summary": "",
                    "text_content": "Still image backgrounds may be supported by ITT4RT clients. The format and signaling shall follow the static image format and signaling as defined in clauses 5.2.4, 6.2.11, and 7.4.8.  An ITT4RT-Tx client should send the image/image sequence as a video bitstream if still images are not supported.\nThe signaling in clause Y.6.2 shall apply to indicate that the still background is 360 degree. The 3gpp_360video or 3gpp_fisheye attribute shall be used for that purpose.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "Y.6.4\tOverlays",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "Y.6.4.1\tGeneral",
                            "text_content": "ITT4RT clients supporting the ‘Overlay’ feature may define an overlay source and overlay configuration in the SDP. An ITT4RT client that supports overlays shall support a video or image stream indicated by a media line in the SDP as the source of an overlay.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "Y.6.4.2\tVisual Media",
                            "text_content": "Any visual media that is defined with the ‘m=video’ line, includes the attribute mid and does not have the attribute a=3gpp_360video in the SDP may be rendered as an overlay by an ITT4RT-Rx client. An ITT4RT client shall include the attribute mid in the overlay media description. If an overlay is to be associated with a particular overlay configuration, the mid shall be used to associate the overlay media description to the the overlay configuration, which is later described in clause Y.6.4.3.\nVisual media may consist of an encoded video bitstream or HEVC encoded images/image sequences, both of which are defined with the ‘m=video’ line in SDP. ITT4RT clients that support images shall use the “a=imageseq” attribute as defined in clause 6.2.11.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "Y.6.4.3\tOverlay Configuration",
                            "text_content": "ITT4RT clients may support the following types of rendering for overlays, as defined in the OMAF specification [179] clause 7.14.\n-\tviewport-relative overlay, specifying that the overlay is displayed on a rectangular area at an indicated position relative to the top-left corner of the viewport;\n-\t[sphere-relative projected omnidirectional overlay, specifying that the overlay is displayed on a sphere surface at an indicated position within or on the unit sphere];\n-\tsphere-relative 2D overlay, specifying that the overlay is displayed on a plane at an indicated position within the unit sphere.\nAn ITT4RT client supporting overlays may include in its SDP media description the attribute 3gpp_overlay to define one or more parameters for configuring the rendering properties of an overlay. The 3gpp_overlay attribute has the following syntax:\natt-field =\t\"3gpp_overlay\"\natt-value =\t[free_overlay SP] overlay_id SP type SP overlay_config\n[SP overlay_info] [SP overlay_overlap_flag]\n\nfree_overlay =\t\t\t\"free_ovelay=\" BIT\noverlay_id = \t\t\ttoken\n; token is defined in RFC 4566\ntype =\t\t\t\t\tBIT\noverlay_config =\t\t(sph_rel_overlay_config / vp_rel_overlay_config)\noverlay_info =\t\t\t\"overlay_info=\" 5BIT\noverlay_overlap_flag =\t\"overlap=\" BIT\n\n;sub-rules for sphere_relative_overlay_config\nsph_rel_overlay_config =\t\"[\" Overlay_azimuth \",\" Overlay_elevation \",\" Overlay_tilt\n\",\" Overlay_azimuth_range \",\" Overlay_elevation_range\n\",\" Overlay_rot_yaw \",\" Overlay_rot_pitch \",\" Overlay_rot_roll\n\",\" region_depth_minus1 \",\" timeline_change_flag \"]\"\nOverlay_azimuth =\t\t\tdegminus180to180\nOverlay_elevation =\t\t\tdegminus90to90\nOverlay_tilt =\t\t\t\tdegminus180to180\nOverlay_azimuth_range =\t\tdeg0to360\nOverlay_elevation_range =\tdeg0to180\nOver_rot_yaw =\t\t\t\tdegminus180to180\nOver_rot_pitch =\t\t\tdegminus90to90\nOver_rot_roll =\t\t\t\tdegminus180to180\nregion_depth_minus1 =\t\tpctin2tominus16\ntimeline_change_flag =\t\tBIT\n\n;sub-rules for viewport_relative_overlay_config\nvp_rel_overlay_config =\t\"[\" Overlay_rect_left_percent \",\" Overlay_rect_top_percent\n\",\" Overlay_rect_width_percent \",\" Overlay_rect_height_percent\n\",\" Relative_disparity_flag\t\",\" Disparity\n\",\" media_alignment \",\" layering_order \",\" opacity\n\",\" overlay_priority \"]\"\n\nOverlay_rect_left_percent =\t\tpctIn2ToMinus16\nOverlay_rect_top_percent =\t\tpctIn2ToMinus16\nOverlay_rect_width_percent =\tpctIn2ToMinus16\nOverlay_rect_height_percent =\tpctIn2ToMinus16\nRelative_disparith_flag =\t\tBIT\nDisparity =\t\t\t\t\t\t(Disparity_in_percent / Disparity_in_pixels)\nDisparity_in_percent =\t\t\tpctIn2ToMinus16\nDisparity_in_pixels =\t\t\tinteger\nmedia_alignment =\t\t\t\t\"0\"/pos-integer\nlayering_order =\t\t\t\tpos-integer\nopacity =\t\t\t\t\t\t\"0\"/pos-integer\noverlay_priority =\t\t\t\tpos-integer\n\n;generic sub-rules\ninteger =\t\t\t\t\t\"0\"/[\"-\"]pos-integer\npctin2tominus16 =\t\t\t\"0\"\n/ POS-DIGIT *4DIGIT\n/ \"6\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\") 3DIGIT\n/ \"65\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\") 2DIGIT\n/ \"655\" (\"0\"/\"1\"/\"2\") 1DIGIT\n/ \"6553\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\")\n; 0 to 65 535, inclusive\n; pos-integer, degminus180to180, degminus90to90, deg0to360 and deg0to180 are from Y.6.2.1\n\nThe 3gpp_overlay attribute is included as part of the 360-degree video media description. More than one 3gpp_overlay attribute may exist as part of the media description if more than one overlay is to be configured. The overlay_id in 3gpp_overlay is set to the mid of the media description of the overlay source for which the configuration is provided. An ITT4RT-Tx client may include more than one 3gpp_overlay attributes with the same non-zero overlay_id (associated with an overlay source) in an SDP offer. The overlay configurations are listed in order of preference. An ITT4RT-Rx client that receives an SDP offer with multiple 3gpp_overlay attributes with the same non-zero overlay_id shall reply with only one acceptable 3gpp_overlay line for one acceptable overlay source. If an overlay source is rejected, all 3gpp_overlay attribute lines with the overlay_id associated with that source are excluded in the SDP answer.\nAn ITT4RT-Tx client may set the free_overlay flag to indicate that no media source is associated with this overlay configuration by the ITT4RT-Tx client and the corresponding overlay region in the video may be used by the ITT4RT-Rx client to overlay any media including external media sources (e.g., a text notification from an external application, an external video overlay or a source describing an occlude-free region that any overlay on top would not result in any significant loss of information). The overlay_id in 3gpp_overlay in case of overlays with the free_overlay flag with a value of 1 shall not be equal to any mid in the SDP media description. In case of overlay_id which is not associated with an overlay source (to identify an external source overlay and/or an occlude-free region), the free_overlay flag shall be included with a value equal to 1. If the free_overlay flag is not present or the free_overlay flag has a value of 0, the overlay_id shall be a value which corresponds to at least one mid of the media description of the overlay source. An ITT4RT-Tx client may include more than one 3gpp_overlay attributes with the same non-zero overlay_id and with the free_overlay flag set to 1 in an SDP offer. The implementation details for use of overlay region with the free_overlay flag set to 1 is left to the application.\nAn ITT4RT-Rx client that sends an SDP offer to receive 360-degree media and overlay source media shall not include the 3gpp_overlay attribute. An ITT4RT-Tx client that receives such an offer may initiate an SDP renegotiation offer to configure the overlays for the overlay sources as indicated by the itt4rt_group attribute.\nAn ITT4RT client that receives an SDP offer including overlay sources without the 3gpp_overlay attribute may decline the offer and send a renegotiation offer with the 3gpp_overlay attribute.\nThe type shall have the value ‘0’ for viewport-relative overlays and ‘1’ for sphere-relative overlays. Depending on the value of type, the 3gpp_overlay attribute may further include the corresponding configuration information sph_rel_overlay_config (type = ‘1’) or the vp_rel_overlay_config (type = ‘0’).\nA set of flags describing interactivity of the overlay may be included in the optional overlay_info parameter defined in Annex Y.6.4.3.4.\nNOTE 1:\tOther overlay definitions in OMAF are not excluded from ITT4RT. Which overlay definition(s) from OMAF are adopted for overlays in ITT4RT is currently TBD. Optional user interactivity flags such as for definining moveability, resizing of the overlay may be added later to the 3gpp_overlay parameter.\nNOTE 2:\tThere should be a default configuration for overlay when explicit configuration is not provided to ensure that multiple receivers have similar experience.\nAn ITT4RT client supporting the 3gpp_overlay attribute to configure a sphere-relative overlay shall set parameter type = ‘1’ and additionally include the parameter sph_rel_overlay_config defined as follows:\nsph_rel_overlay_config = [Overlay_azimuth, Overlay_elevation, Overlay_tilt, Overlay_azimuth_range, Overlay_elevation_range, Overlay_rot_yaw, Overlay_rot_pitch, Overlay_rot_roll, region_depth_minus1, timeline_change_flag]\n\n-\tOverlay_azimuth: Specifies the azimuth angle of the centre of the overlay region on the unit sphere in units of 2−16 degrees relative to the global coordinate axes.\n-\tOverlay_elevation: Specifies the elevation angle of the centre of the overlay region on the unit sphere in units of 2−16 degrees relative to the global coordinate axes.\n-\tOverlay_tilt: Specifies the tilt angle of the offered overlay region, in units of 2−16 degrees, relative to the global coordinate axes.\n-\tOverlay_azimuth_range: Specifies the azimuth range of the region corresponding to the 2D plane on which the overlay is rendered through the centre point of the overlay region in units of 2−16 degrees.\n-\tOverlay_elevation_range: Specifies the elevation range of the offered region corresponding to the 2D plane on which the overlay is rendered  through the centre point of the overlay region in units of 2−16 degrees.\n-\tOverlay_rot_yaw, Overlay_rot_pitch, and Overlay_rot_roll specify the rotation of the 2D plane on which the overlay is rendered. Prior to rendering the 2D plane, it may be rotated as specified by overlay_rot_yaw, overlay_rot_pitch and overlay_rot_yaw and placed on a certain distance as specified by region_depth_minus1. The rotations are relative to the coordinate system as specified in clause 5.1 of ISO/IEC 23090-2 in which the origin of the coordinate system is in the centre of the overlay region, the X axis is towards the origin of the global coordinate axes, the Y axis is towards the point on the plane that corresponds to cAzimuth1 in Figure 7-4 of ISO/IEC 23090-2, and the Z axis is towards the point on the plane that corresponds to cElevation2 in Figure 7-4 of ISO/IEC 23090-2. overlay_rot_yaw expresses a rotation around the Z axis, overlay_rot_pitch rotates around the Y axis, and overlay_rot_roll rotates around the X axis. Rotations are extrinsic, i.e., around X, Y, and Z fixed reference axes. The angles increase clockwise when looking from the origin towards the positive end of an axis. The rotations are applied starting from overlay_rot_yaw, followed by overlay_rot_pitch, and ending with overlay_rot_roll.\n-\tregion_depth_minus1 - indicates the depth (z-value) of the region on which the overlay is to be rendered. The depth value is the norm of the normal vector of the overlay region. region_depth_minus1 + 1 specifies the depth value relative to a unit sphere in units of 2−16.\n-\ttimeline_change_flag equal to ‘1’ specifies that the overlay content playback shall pause if the overlay is not in the user's current viewport, and when the overlay is back in the user's viewport the overlay content playback shall resume with the global presentation timeline of the content. The content in the intermediate interval is skipped. timeline_change_flag equal to ‘0’ specifies that the overlay content playback shall pause if the overlay is not in the user's current viewport, and when the overlay is back in the user's viewport the overlay content playback resumes from the paused sample. This prevents loss of any content due to the overlay being away from the user's current viewport.\nAn ITT4RT client supporting the 3gpp_overlay attribute to configure a viewport-relative overlay shall set parameter type = ‘0’ and additionally include the parameter vp_rel_overlay_config defined as follows:\nvp_rel_overlay_config = [Overlay_rect_left_percent, Overlay_rect_top_percent, Overlay_rect_width_percent, Overlay_rect_height_percent, Relative_disparity_flag, Disparity, media_alignment, layering_order, opacity, overlay_priority]\n\n-\tOverlay_rect_left_percent: Specifies the x-coordinate of the left corner of the rectangular region of the overlay to be rendered on the viewport in per cents relative to the width of the viewport. The values are indicated in units of 2-16 in the range of 0 (indicating 0%), inclusive, up to but excluding 65536 (that indicates 100%).\n-\tOverlay_rect_top_percent: Specifies the y-coordinate of the top corner of the rectangular region of the overlay to be rendered on the viewport in per cents relative to the height of the viewport. The values are indicated in units of 2-16 in the range of 0 (indicating 0%), inclusive, up to but excluding 65536 (that indicates 100%).\n-\tOverlay_rect_width_percent: Specifies the width of the rectangular region of the overlay to be rendered on the viewport in per cents relative to the width of the viewport. The values are indicated in units of 2-16 in the range of 0 (indicating 0%), inclusive, up to but excluding 65536 (that indicates 100%).\n-\tOverlay_rect_height_percent: Specifies the height of the rectangular region of the overlay to be rendered on the viewport in per cents relative to the height of the viewport. The values are indicated in units of 2-16 in the range of 0 (indicating 0%), inclusive, up to but excluding 65536 (that indicates 100%).\nNOTE 1:\tThe size of overlay region over the viewport changes according to the viewport resolution and aspect ratio. However, the aspect ratio of the overlaid media is not intended to be changed.\n-\tRelative_disparity_flag: Indicates whether the disparity is provided as Disparity_in_percent which is a percentage value of the width of the display window for one view (when the value is equal to 1) or as Disparity_in_pixels which is a number of pixels (when the value is equal to 0).\n-\tDisparity_in_percent: Specifies the disparity, in units of 2−16, as a fraction of the width of the display window for one view. The value may be negative, in which case the displacement direction is reversed. This value is used to displace the region to the left on the left eye view and to the right on the right eye view. This applies for the case when there is a monoscopic overlay and stereoscopic background visual media.\n-\tDisparity_in_pixels: Indicates the disparity in pixels. The value may be negative, in which case the displacement direction is reversed. This value is used to displace the region to the left on the left eye view and to the right on the right eye view. This applies for the case when there is a monoscopic overlay and stereoscopic background visual media.\n-\tMedia_alignment: Specifies the default intended scaling of the overlay source depending on the dimensions of the specified rectangular region and the intended placement of the scaled overlay source relative to the specified rectangular region.\n-\tLayering_order: Indicates the default layering order among the overlays that are relative to the viewport, and separately among each set of overlays that have the same depth. Viewport-relative overlays are overlaid on top of the viewport in descending order of layering_order, i.e., an overlay with a smaller layering_order value shall be in front of an overlay with a greater layering_order value. The layering order for overlays of the 360-degree video should be decided by the ITT4RT-Tx client.\n-\tOpacity: Indicates an integer value that specifies the default opacity that is to be applied for the overlay and assigned by the ITT4RT-Tx client. Value 0 is fully transparent, and value 100 is fully opaque with a linear weighting between the two extremes. Values greater than 100 are reserved.\n-\tOverlay_priority: Indicates which overlay should be prioritized in the case the ITT4RT-Rx client does not have enough decoding capacity to decode all overlays. A lower overlay_priority indicates higher priority. The value of overlay_priority, when present, shall be equal to 0 for overlays that are essential for displaying. More than one overlay may have the same overlay_priority and an ITT4RT-Rx client that does not support all overlays with the same priority may choose any subset of these.\nNOTE 2:\tOther overlay definitions in OMAF are not excluded from ITT4RT. Which overlay definition(s) from OMAF are adopted for overlays in ITT4RT is currently TBD.\nNOTE 3:\tFor both of the above overlay types from OMAF, incorporate from the spec further details about the order of operations for overlay rendering (in particular order of translation and rotation).\nThe parameter overlay_info is a bit field consisting of flags describing the type of overlay interactivity recommended:\noverlay_info= ‘overlay_info=’b4b3b2b1b0\n-\tb0 = ‘0’: changing the position of the overlay is not recommended, overlay position is fixed\nb0 = ‘1’: changing the position of the overlay is allowed, ITT4RT-Rx client may change position\n-\tb1 = ‘0’: switching the overlay on/off is not recommended\nb1 = ‘1’: switching the overlay on/off is allowed, ITT4RT-Rx client may switch overlay off\n-\tb2 = ‘0’: rotating the overlay is not recommended \nb2 = ‘1’: rotating the overlay is allowed\n- \tb3 = ‘0’: resizing the overlay is not recommended \nb3 = ‘1’: resizing the overlay is allowed\n- \tb4 = ‘0’: changing the opacity of the overlay is not recommended\nb4 = ‘1’: changing the opacity of the overlay is allowed\nAn ITT4RT client supporting the 3gpp_overlay attribute to configure a sphere-relative overlay or viewport-relative overlay may include the following additional parameter for overlay support:\noverlay_overlap_flag: Indicates if the ITT4RT-Rx client is allowed to overlap overlays from the ITT4RT-Tx client. If set to 1, the ITT4RT-Rx client may overlap overlays shared by the ITT4RT-Tx client.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "Y.6.4.4\tCaptured Content Replacement",
                            "text_content": "To prevent the degradation of presentation material (e.g., slides, screen share, video, notes) that may be captured from a display (screen or projector) with a 360-degree camera, the captured content in the 360-degree video can be replaced with the original presentation material. Such replacement implies decoding the content (360-degree video and presentation material), identifying the position of the presentation material in the 360-degree video, replacing the captured presentation content at the display coordinates in the 360-degree video, and finally encoding the new 360-degree video (i.e., with the same encoding parameters as the original 360-degree video). The replacement could either be performed in the ITT4RT-Tx client in terminal which is sending the 360-degree video or in the ITT4RT-MRF.\nWhen replacement is to be performed, the availability of the original presentation content must be signalled by the source of the content to the client performing the replacement (that is, the ITT4RT-Tx client in terminal or the ITT4RT-MRF) using the SDP attribute “a=content:slides” [81] which may include different content, for example slides, screen share, video, notes.  The client performing the replacement shall determine an appropriate configuration for performing the content replacement in the 360-degree video, unless overlay parameters are given by the source of the original presentation content (e.g., configuration in terms of sphere-relative overlay coordinates as defined in Anex Y.6.4.3.2).\nWhen the SDP negotiation is initiated by the ITT4RT-Tx client in terminal, the ITT4RT-Tx client in terminal shall include the attribute “a=3gpp_360video_replacement” in its SDP offer to indicate that the content captured in the 360-degree video can be replaced.  If the ITT4RT-MRF supports content replacement and receives an SDP offer with the attribute “a=3gpp_360video_replacement”, then the ITT4RT-MRF shall include the attribute “a=3gpp_360video_replacement” in its SDP answer and shall perform content replacement.\nIf the ITT4RT-Tx client in terminal includes the attribute “a=3gpp_360video_replacement” in its SDP offer but does not receive the attribute in the SDP answer (that is, replacement is not supported in the ITT4RT-MRF) then the ITT4RT-Tx client in terminal may send the original presentation content using a different process than ITT4RT-MRF replacement (e.g., the presentation can be sent as an overlay as defined in Annex Y.6.4., or inserted into the 360-degree video by the ITT4RT-Tx client in terminal as described above).\nIf the ITT4RT-MRF does not receive the attribute “a=3gpp_360video_replacement” in an SDP offer, it shall not perform any replacement and will not include the attribute in its SDP answer.\nWhen replacement is to be performed by the ITT4RT-MRF and the SDP negotiation is initiated by the ITT4RT-MRF, the offer sent by the ITT4RT-MRF to the ITT4RT-Tx client in terminal shall include the attribute “a=3gpp_360video_replacement”. If the ITT4RT-Tx client in terminal accepts the offer by the MRF to perform replacement, the ITT4RT-Tx client in terminal shall include the attribute “a=3gpp_360video_replacement” in the SDP answer and the ITT4RT-MRF shall perform content replacement.\nIf the ITT4RT-MRF does not receive the attribute “a=3gpp_360video_replacement” in the SDP answer of the ITT4RT-Tx in terminal (i.e., the content captured in the 360-degree video cannot be replaced), the ITT4RT-MRF shall not perform any replacement.\nIf the ITT4RT-MRF does not support content replacement, it shall not include the attribute “a=3gpp_360video_replacement” in an SDP offer, it will not perform any replacement, and the ITT4RT-Tx client in terminal may send the original presentation content using a different process (e.g., the presentation can be sent as an overlay as defined in Annex Y.6.4, or inserted into the 360-degree video by the ITT4RT-Tx client in terminal as described above). In the case that the ITT4RT-MRF does not send the attribute “a=3gpp_360video_replacement” in an offer, the ITT4RT-Tx client in terminal shall not send the attribute “a=3gpp_360video_replacement” in an answer.\nAfter an accepted offer/answer between ITT4RT-Tx in terminal and ITT4RT-MRF with both offer and answer including the attribute “a=3gpp_360video_replacement”, the ITT4RT-MRF shall perform content replacement once the original presentation content is available from the source of the content and the replacement configuration is determined.\nIf the replacement configuration of the content is analysed and determined by the ITT4RT-Tx in terminal, the client shall include the configuration as sphere-relative overlay coordinates (defined in AnnexY.6.4.3.2) in the SDP offer/answer while negotiating the stream with the ITT4RT-MRF. If the sphere-relative overlay coordinates are not signalled in the SDP offer/answer by the ITT4RT-Tx, the ITT4RT-MRF shall analyse and determine an appropriate configuration for performing the content replacement in the 360-degree video.\nThe ABNF syntax for the replacement attribute is as follows:\natt-field = “3gpp_360video_replacement”\natt-value = [sph_rel_overlay_config]\n\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "Y.6.5\tFisheye Video",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "Y.6.5.1\tIdentifying the 360-degree fisheye video stream",
                            "text_content": "The SDP attribute 3gpp_fisheye is used to indicate a 360-degree fisheye video stream.\nThe semantics of the above attribute and parameters is provided below.\nITT4RT clients supporting 360-degree fisheye video shall support the 3gpp_fisheye attribute and shall support the following procedures:\n-\twhen sending an SDP offer, the ITT4RT-Tx client includes the 3gpp_fisheye attribute in the media description for video in the SDP offer\n-\twhen sending an SDP answer, the ITT4RT-Rx client includes the 3gpp_fisheye attribute in the media description for video in the SDP answer if the 3gpp_fisheye attribute was received in an SDP offer\n-\tafter successful negotiation of the 3gpp_fisheye attribute in the SDP, the MTSI clients exchange an RTP-based video stream containing an HEVC or AVC bitstream with fisheye omnidirectional video specific SEI messages as defined in clause Y.3\nITT4RT-Tx clients that support both 360-degree projected video and 360-degree fisheye video may include both 3gpp_360video and 3gpp_fisheye attributes as alternatives in the SDP offer, but an ITT4RT-Rx client shall include only one attribute (either 3gpp_360video or 3gpp_fisheye, based on support or selection) in the SDP answer.\nY.6.5.2\t360-degree fisheye video SDP attribute parameters\nMedia-line level parameters are defined in order to aid session establishment between the ITT4RT-Tx and ITT4RT-Rx clients for 360-degree fisheye video, as well as to describe the fisheye video stream as identified by the 3gpp_fisheye attribute.\nThe syntax for the SDP attribute is:\na=3gpp_fisheye: <fisheye> <fisheye-img> <maxpack>\n\n-\tTotal number of fisheye circular videos at the capturing terminal.\nDepending on the camera configuration of the sending terminal, the 360-degree fisheye video may be comprised of multiple different fisheye circular videos, each captured through a different fisheye lens.\n-\t<fisheye>: this parameter inside an SDP offer sent by an ITT4RT-Tx client indicates the total number of fisheye circular videos output by the camera configuration at the terminal.\n-\tFisheye circular video static parameters.\nIn order to enable the quick selection of desired fisheye circular videos by the ITT4RT-Rx client during SDP negotiation, the following static parameters are defined for each fisheye circular video.  These parameters are defined from the video bitstream fisheye video information SEI  message as defined in ISO/IEC 23008-2 [119] and ISO/IEC 23090-2 [179].\n-\t<fisheye-img> = <fisheye-img-1> … <fisheye-img-N>\n-\t<fisheye-img-X> = [<id-X> <azi> <ele> <til> <fov>] for 1 ≤ X ≤ N where:\n-\t<id>: an identifier for the fisheye video.\n-\t<azi>, <ele>: azimuth and elevation indicating the spherical coordinates that correspond to the centre of the circular region that contains the fisheye video, in units of 2-16 degrees.  The values for azimuth shall be in the range of −180 * 216 (i.e., −11 796 480) to 180 * 216 − 1 (i.e., 11 796 479), inclusive, and the values for elevation shall be in the range of −90 * 216 (i.e., −5 898 240) to 90 * 216 (i.e., 5 898 240), inclusive.\n-\t<til>: tilt indicating the tilt angle of the sphere regions that corresponds to the fisheye video, in units of 2−16 degrees. The values for tilt shall be in the range of −180 * 216 (i.e., −11 796 480) to 180 * 216 − 1 (i.e., 11 796 479), inclusive.\n-\t<fov>: specifies the field of view of the lens that corresponds to the fisheye video in the coded picture, in units of 2−16 degrees.  The field of view shall be in the range of 0 to 360 * 216 (i.e., 23 592 960), inclusive.\n-\tStream packing of fisheye circular videos\nDepending on the terminal device capabilities and bandwidth availability, the packing of fisheye circular videos within the stream can be negotiated between the sending and receiving terminals.\n-\t<maxpack>: this parameter inside an SDP offer indicates the maximum supported number of fisheye videos which can be packed into the video stream by the ITT4RT-Tx client. The value of this parameter inside an SDP answer indicates the number of fisheye videos to be packed, as selected by the ITT4RT-Rx client.\nThe ABNF syntax for this attribute is the following:\natt-field\t= “3gpp_fisheye”\natt-value = [SP fisheye] SP fisheye-img SP maxpack\n\nfisheye\t= pos-integer\n\nfisheye-img\t=\t1*fisheye-img-X\nfisheye-img-X =\t\"[\" \"id=\" idvalue \",\" \"azi=\" azivalue \",\" \"ele=\" elevalue \",\" \"til=\" tilvalue\n\",\" \"fov=\" fovvalue \"]\"\n;sub-rules for fisheye-img-X\nidvalue\t=\t\tbyte-string\t\t; byte-string defined by RFC 4566\nazivalue =\t\tdegminus180to180\nelevalue =\t\tdegminus90to90\ntilvalue =\t\tdegminus180to180\nfovvalue =\t\tdeg0to360\n\nmaxpack\t= pos-integer\n\n;pos-integer, degminus180to180, degminus90to90 and deg0to360 are from Y.6.2.1\nAn example SDP offer is shown in table Y.6.5.2-1.\nTable Y.6.5.2-1: Example SDP offer with 360-degree fisheye video attribute parameters\n\nAs an example, a receiving terminal which only receives 360-degree fisheye video (and possibly sends a 2D video to the sender) replies with an SDP answer containing only the selected fisheye videos equal to the number as selected by the value of maxpack in the corresponding m-line, which is set to recvonly.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table Y.6.5.2-1: Example SDP offer with 360-degree fisheye video attribute parameters",
                                    "table number": 265,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "Y.6.5.3\tViewport dependent delivery of fisheye video",
                            "text_content": "By exposing the coverage information of each fisheye circular video using the parameters in section Y.6.5.2, the collective multitude of which makes up the whole 360-degree video, a ITT4RT-Rx client can opt to select only the required fisheye circular videos needed to render the current viewport of the user.\nThrough the parameters defined in section Y.6.5.2, a ITT4RT-Rx client can select the desired fisheye packing configuration of the video stream during SDP negotiation, as well as the initial desired fisheye videos using the id parameter.\nOnce a session is established, dynamic delivery of the desired fisheye videos depending the ITT4RT-Rx client user’s viewport can be enabled using RTCP-based signalling, specifically with the RTCP feedback message with type “Viewport” as defined in Y.7.2.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "Y.6.6\tCamera Calibration for Network-based Stitching",
                    "description": "",
                    "summary": "",
                    "text_content": "Network-based stitching in the context of ITT4RT refers to generation of 360-degree videos in the ITT4RT MRF based on 2D video captures received from MTSI clients. This clause describes SDP-based signalling of camera calibration parameters for this purpose using the a=3gpp-camera-calibration attribute and SDP-based grouping of the corresponding 2D video captures using the a=stitch_group attribute.\nThe SDP syntax for a=3gpp-camera-calibration is defined with the following semantics (detailed ABNF presented at the end of the clause):\n3gpp-camera-calibration = \"a=3gpp-camera-calibration:\" [SP \"Param 1\" SP \"Param 2\" SP ……. SP \"Param K\"]\n\nwhere “Param 1”, …. , “Param K” express the set of intrinsic and extrinsic camera parameters as specified below.\nIf the ITT4RT-Tx client in the ITT4RT MRF intends to perform network-based stitching to generate 360-degree video from a particular set of 2D video captures received from an MTSI sender, it shall use the SDP session-level attribute a=stitch_group before any media lines that correspond to the particular 2D video captures during the SDP negotiation of the corresponding media. Likewise, an MTSI sender capable of capturing 2D videos for 360-degree video generation shall use the session-level a=stitch_group attribute in the SDP before any media lines that correspond to the particular 2D video captures. The a=stitch_group attribute is used to group the corresponding to-be-stitched 2D video captures using the mid attribute as defined according to the ABNF below:\natt-field =\t\"stitch_group\"\natt-value =\tmid *[SP mid]\nmid = \t\ttoken\n; token is defined in RFC 4566\n\nThe mid attribute with the appropriate value as defined in the other parts of the SDP shall be included in the media description for the relevant 2D video captures when the a=stitch_group attribute is used. Furthermore, for each of these 2D video captures, the MTSI sender shall also include the SDP attribute 3gpp-camera-calibration in the SDP under the relevant m= line for that particular video to signal the relevant camera calibration information. The order of the media included in the a=stitch_group indicates the synchronization source with the first media always being the synchronization anchor when synchronization is required.\nMore specifically, detailed camera calibration parameters based on ISO/IEC 23008-2 [3] are provided as follows, considering the multi-view acquisition information SEI message for HEVC. With these specifications, a 3-dimensional world point, wP = [ x y z ] is mapped to a 2-dimensional camera point, cP[ i ] = [ u v 1 ], for the i-th camera according to:\ns * cP[ i ] = A[ i ] * R−1[ i ] * ( wP − T[ i ] )\t(eqn. Y.6.6.1)\nwhere A[ i ] denotes the intrinsic camera parameter matrix, R−1[ i ] denotes the inverse of the rotation matrix R[ i ], T[ i ] denotes the translation vector, and s (a scalar value) is an arbitrary scale factor chosen to make the third coordinate of cP[ i ] equal to 1.\nEquation Y.6.6.1 can be extended to incorporate the entrance pupil variation to correct the incidence ray of  cP[ i ] = [ u v 1 ] such that it always passes through the camera optical center, thereby removing distortion. The resulting entrance pupil coefficients E[i] may be incorporated into Equation Y.6.6.1 as\ns * cP[ i ] = A[ i ] * R−1[ i ] * ( (wP + E) − T[ i ] )\t(eqn. Y.6.6.2)\nwhere wP + E[i]) = [ x y z+E ], E = e1* 𝞡3 + e2* 𝞡5 + e3* 𝞡7 + e4* 𝞡9, 𝞡 is the incidence angle pertaining to each ray formed by the pixel cP[ i ] = [ u v 1 ], and [e1, e2, e3, e4] are entrance pupil coefficients. In addition, the accuracy of these entrance pupil parameters have an influence of the accuracy of estimated extrinsic parameters and thus improve the future imaging tasks. If not available, vector E is considered as 0 and a fallback to eqn. Y.6.6.1 is expected.\nAccordingly, the following intrinsic camera parameters can be signalled in the SDP for each 2D video capture using the a=3gpp-camera-calibration attribute:\nfocalLengthX[ i ] specifies the focal length of the i-th camera in the horizontal direction as a signed floating-point number.\nfocalLengthY[ i ] specifies the focal length of the i-th camera in the vertical direction as a signed floating-point number.\nprincipalPointX[ i ] specifies the principal point of the i-th camera in the horizontal direction as a signed floating-point number.\nprincipalPointY[ i ] specifies the principal point of the i-th camera in the vertical direction as a signed floating-point number.\nskewFactor[ i ] specifies the skew factor of the i-th camera as a signed floating-point number.\nThe intrinsic matrix A[ i ] for i-th camera is represented by:\n\nIt is possible that the intrinsic camera parameters are equal for all of the cameras. In that case, only one set of values based on the above parameters would need to be signalled, e.g., via SDP signalling at the session level.\nFurthermore, the following extrinsic camera parameters can be signalled in the SDP for each camera as per ISO/IEC 23008-2 [3]:\nrE[ i ][ j ][ k ] specifies the ( j, k ) component of the rotation matrix for the i-th camera as a signed floating-point number.\nThe rotation matrix R[ i ] for i-th camera is represented as follows:\n\ntE[ i ][ j ] specifies the j-th component of the translation vector for the i-th camera as a signed floating-point number.\nThe translation vector T[ i ] for the i-th camera is represented by:\n\nFor the i-th camera, E[ i ][ j ] specifies the j-th component of the entrance pupil coefficient [e1, e2, e3, e4] where j=1,…4. The parameters are represented as a signed floating-point number, as per eqn (2) above.\nThe syntax for the \"a=3gpp-camera-calibration\" attribute shall conform to the following ABNF:\natt-field =\t\t\"3gpp-camera-calibration\"\natt-value =\tPT 1*WSP attr-list\n\nPT = \t\t1*DIGIT / \"*\"\nattr-list =\t( set *(1*WSP set) ) / \"*\"\n;  WSP and DIGIT defined in [RFC5234]\n;sub-rules for set\nset =\t\"[\" \"focalLengthX=\" sfloatvalue \",focalLengthY=\" sfloatvalue\n\",skewFactor=\" sfloatvalue \",principalPointX=\" sfloatvalue\n\",principalPointY=\" sfloatvalue \",rotation00=\" sfloatvalue\n\",rotation01=\" sfloatvalue \",rotation02=\" sfloatvalue \",rotation10=\"\nsfloatvalue \",rotation11=\" sfloatvalue \",rotation12=\" sfloatvalue\n\",rotation20=\" sfloatvalue \",rotation21=\" sfloatvalue \",rotation22=\"\nsfloatvalue \",translation0=\" sfloatvalue \",translation1=\"\nsfloatvalue \",translation2=\" sfloatvalue \",epupil1=\" sfloatvalue\n\",epupil2=\" sfloatvalue \",epupil3=\" sfloatvalue \",epupil4=\"\nsfloatvalue \"]\"\nsfloatvalue =\t[sign] sizevalue [\".\" 6*DIGIT]\nsign = \t\"-\"\nsizevalue =\tPOS-DIGIT *5DIGIT\n; POS-DIGIT is defined in Y.6.2.1\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "Y.6.7\tSupport for Stream Pausing/Resuming",
                    "description": "",
                    "summary": "",
                    "text_content": "An ITT4RT-Tx client shall use the a=rtcp-fb ccm pause attribute and parameter values as specified in [43] and [156] to indicate the capability to support receiving and acting on PAUSE and RESUME requests targeted for RTP streams it sends.  The optional parameter setting of a=rtcp-fb ccm pause config=3 could be used by the ITT4RT-Tx client to indicate that it will only receive and react to PAUSE and RESUME requests but will not send them.\nAn ITRT4RT-Rx client shall use the a=rtcp-fb ccm pause attribute and parameter values as specified in [43] and [156] to indicate the capability to support sending PAUSE and RESUME requests targeted for RTP streams it receives.  The optional parameter setting of a=rtcp-fb ccm pause config=2 could be used by the ITT4RT-Rx client to indicate that it will only send PAUSE and RESUME requests but does not support receiving these requests.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "Y.6.8\tMultiple 360-degree videos",
                    "description": "",
                    "summary": "",
                    "text_content": "An ITT4RT conference may contain multiple 360-degree videos which originate from multiple conference rooms at the conference location, or from remote participants.  When multiple 360-degree videos are present in an ITT4RT conference, an ITT4RT MRF shall negotiate an SDP session with every remote participant.\nIn the SDP offer from the ITT4RT MRF, 360-degree video is identified by either the a=3gpp_360video or a=3gpp_fisheye media line attributes.  When multiple 360-degree videos are present in the SDP offer, the ITT4RT MRF shall include the a=content attribute under the media lines for 2D or 360-degree video originating from the conference location.  For media streams originating from the main default conference room, the content attribute is set to a=content:main.  For media streams originating from other conference rooms, the content attribute is set to a=content:alt.  2D and 360-degree video from remote participants shall not include the a=content attribute under their corresponding media lines.\nWhen there are multiple 360-degree videos from multiple sources available to the ITT4RT MRF, the ITT4RT MRF may include the  ‘itt4rt_group’ attribute (as defined in Y.6.2.6) to define one or more restricting groups, each group containing at least one mid associated with a 360-degree video media line, and at least one mid associated with an overlay.\nOn receipt of an SDP offer containing multiple 360-degree videos from the ITT4RT MRF, an ITT4RT-Rx client shall select to receive only one 360-degree video media together with possible 2D video media from other sources, rejecting the other 360-degree video media.\nExample SDP offers for multiple 360-degree video with and without group restrictions are shown in clause Y.8.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "Y.6.8.2\tExcluding other participants’ overlays",
                            "text_content": "When an ITT4RT-Tx client in terminal sends a 360-degree video media stream to the MRF, it may include an attribute \"a= no_other_overlays\", which indicates that the MRF shall not group the 360-degree media stream from that ITT4RT-Tx client with overlay media streams from other ITT4RT clients. In this case, the MRF shall group the 360-degree video media stream and one or more overlays of that ITT4RT-Tx client in a separate <rest-group> in the itt4rt_group attribute when describing them to any ITT4RT-Rx client.\nThe ABNF syntax for this attribute is the following:\natt-field\t= \"no_other_overlays\"\nNOTE: If multiple itt4rt_group are created, an ITT4RT-Rx client in terminal would need to re-negotiate the session to switch to media streams from other itt4rt_group. However, doing so may add further burden on the signaling nodes.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                },
                {
                    "title": "Y.6.9\tScene Description-Based Overlays",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "Y.6.9.1\tGeneral",
                            "text_content": "ITT4RT clients that support the “Overlay” feature may support the scene description as defined in [183] for signaling the overlay configuration.\nIf scene description-based overlays are supported, the following subset of the MPEG-I scene description extensions and features shall be supported:\n-\tThe MPEG_media extension: used to reference the media streams.\n-\tThe MPEG_accessor_timed and the MPEG_buffer_circular: used to bind timed media.\n-\tThe MPEG_texture_video: used to define video textures for the overlay and the 360 video.\n-\tThe scene description update mechanism as defined in clause 5.2.4 of [183].\nIf scene description-based overlays are used in an ITT4RT session with multiple participants, then the ITT4RT MRF shall be used for the session and shall own the scene description.\nIf scene description-based overlays are used, then the ITT4RT-TX client in the ITT4RT MRF shall:\n-\tCreate a sphere or cubemap mesh node (depending on the selected projection) in the scene description for each 360 video stream in the ITT4RT session. The source of the node's texture shall reference the ITT4RT media stream of the corresponding 360 video as signaled by the SDP.\n-\tCreate a rectangular or spherical mesh node in the scene description for each overlay stream in the ITT4RT session. The source of the node's texture shall reference the media stream of the corresponding overlay stream as signaled by the SDP.\n-\tThe location of the overlay shall be indicated by the transformation of the corresponding overlay node in the scene description.\nNOTE:\tIn a scene description-based overlay solution, the scene camera corresponds the viewer’s position and it tracks the user’s 3DoF movements. The camera’s projection determines the field of view of the user.\nThe URL format as specified in 23090-14 Annex C shall be used to reference media streams in the ITT4RT session.\nFor participants that support scene description, the overlay information and positioning that is provided as part of the scene description shall take precedence over any information provided as part of the 3gpp_overlay attribute.\nAn ITT4RT-Tx client in terminal that offers overlays may select to signal the overlay either through the 3gpp_overlay attribute or through a scene update that adds the overlay node. The scene update mechanism is described in [183]. In case the ITT4RT-Tx uses the 3gpp_overlay attribute to describe its overlays, the ITT4RT-Tx client in the ITT4RT MRF shall generate the scene description or scene description update document that signals the presence and position of that overlay.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "Y.6.9.2\tOffer/Answer Negotiation",
                            "text_content": "An ITT4RT-Tx client that desires to use scene description-based overlays, shall offer a data channel with a data channel indicating the “mpeg-sd” sub-protocol. The ITT4RT-Rx client in the MRF that supports scene-based overlays may answer by accepting the scene description data channel.\nIf the offer is accepted, the ITT4RT MRF shall generate and send the scene description to the offerer upon establishment of the data channel.\nIf the ITT4RT MRF receives an offer that does not contain a data channel with the “mpeg-sd” sub-protocol, it shall assume that the offering ITT4RT client does not support scene description-based overlays.  In such case, the answering ITT4RT MRF shall not add a data channel with the “mpeg-sd” sub-protocol and may describe any overlays using the 3gpp_overlay attribute.\n",
                            "figures_meta_data": [],
                            "tables": []
                        },
                        {
                            "title": "Y.6.9.3\tSDP Signaling",
                            "text_content": "An ITT4RT-Tx in the ITT4RT MRF that supports scene description-based overlays, shall support MTSI data channel media and act as a DCMTSI client. The stream id of the data channel with the sub-protocol “mpeg-sd” shall be in the range allocated for bootstrap data channels, i.e. below 1000, excluding values in Table 6.2.10.1-2. A single data channel with sub-protocol “mpeg-sd” shall be present in the offer/answer SDP. If multiple data channels with the “mpeg-sd” sub-protocol are detected, the one with the lowest stream ID shall be used. The scene description data channel shall be configured as ordered, reliable, with normal SCTP multiplexing priority.\nWhen scene description-based overlays are offered, the ITT4RT-Tx in the ITT4RT MRF shall offer a data channel with a stream id that indicates the “mpeg-sd” subprotocol in the dcmap attribute. The “mpeg-sd” messages shall be JSON formatted in UTF-8 coding without BOM.\nScene description-based overlay descriptions, including complete scene descriptions and scene updates, shall be delivered through the same data channel.\n",
                            "figures_meta_data": [],
                            "tables": []
                        }
                    ]
                }
            ]
        },
        {
            "title": "Y.7\tMedia transport",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "Y.7.1\tRTP",
                    "description": "",
                    "summary": "",
                    "text_content": "RTP signaling impacts are FFS.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "Y.7.2\tRTCP",
                    "description": "",
                    "summary": "",
                    "text_content": "When viewport-dependent processing (VDP) of 360-degree video is successfully negotiated between the ITT4RT-Tx client and ITT4RT-Rx client as per the SDP-based procedures described in clause Y.6.2, the RTCP feedback (FB) message type ‘Viewport’ shall carry requested viewport information during the RTP transmission of media signalled from the ITT4RT-Rx client to the ITT4RT-Tx client.\nThe signalling of ‘Viewport’ requests shall use RTCP feedback messages as specified in IETF 4585. The RTCP feedback message is identified by PT (payload type) = PSFB (206) which refers to payload-specific feedback message.  FMT (feedback message type) shall be set to the value assigned by IANA for Viewport feedback messages.  The IANA registration information for the FMT value for ‘Viewport’ is provided in Annex R.3 of TS 26.114. The RTCP feedback method may involve signalling of viewport information in both of the immediate feedback and early RTCP modes.\nThe FCI (feedback control information) format for Viewport shall be as follows. The FCI shall contain exactly one viewport. The signalled desired viewport information in the RTCP feedback message for ‘Viewport’ is composed of the following parameters (as defined as shape type value equal to 0 in clause 7.5.6 of ISO/IEC 23090-2 [179]):):\n-\tViewport_azimuth: Specifies the azimuth of the centre point of the sphere region corresponding to the requested viewport in units of 2−16 degrees relative to the global coordinate axes expressed in signed 32-bit integer format, in the range of −180 * 216 to 180 * 216 − 1, inclusive..\n-\tViewport_elevation: Specifies the elevation of the centre point of the sphere region corresponding to the requested viewport in units of 2−16 degrees relative to the global coordinate axes expressed in signed 32-bit integer format, in the range of −90 * 216 to 90 * 216, inclusive.\n-\tViewport_tilt: Specifies the tilt angle of the sphere region corresponding to the requested viewport, in units of 2−16 degrees, relative to the global coordinate axes expressed in signed 32-bit integer format, in the range of −180 * 216 to 180 * 216 − 1, inclusive.\n-\tViewport_azimuth_range: Specifies the azimuth range of the sphere region corresponding to the requested viewport through the centre point of the sphere region in units of 2−16 degrees expressed in unsigned 32-bit integer format, in the range of 0 to 180 * 216, inclusive.\n-\tViewport_elevation_range: Specifies the elevation range of the sphere region corresponding to the requested viewport through the centre point of the sphere region in units of 2−16 degrees expressed in unsigned 32-bit integer format, in the range of 0 to 180 * 216, inclusive.\nThe RTCP feedback message for ‘Viewport’ shall contain all of the parameters Viewport_azimuth, Viewport_elevation, Viewport_tilt, Viewport_azimuth_range and Viewport_elevation_range. The values for the each of the parameters Viewport_azimuth, Viewport_elevation, Viewport_tilt, Viewport_azimuth_range and Viewport_elevation_range shall each be indicated using four bytes.\nThe FCI for the RTCP feedback message for ‘Viewport’ shall follow the following format:\n0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n| \t\t\t\t\t\t\t\t\t  Viewport_azimuth            |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|   \t\t\t\t\t\t\t\t  Viewport_elevation          |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n| \t\t\t\t\t\t\t\t\t  Viewport_tilt\t               |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|\t\t\t\t\t\t\t\t\t  Viewport_azimuth_range      |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|\t\t\t\t\t\t\t\t\t  Viewport_elevation_range    |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\nFor each 4-byte indication of the Viewport_azimuth, Viewport_elevation, Viewport_tilt, Viewport_azimuth_range and Viewport_elevation_range, the bytes will be ordered in the order of importance such that high bytes shall be followed by the low bytes, where the highest byte holds the most significant bits and lowest byte holds the least significant bits.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "Y.8\tSDP Examples (informative)",
            "description": "An example SDP offer for multiple 360-degree video is shown in table Y.8.1.\nTable Y.8.1: Example SDP offer with multiple 360-degree video\n\nAn example SDP offer for multiple 360-degree video with group restrictions is shown in table Y.8.2.\nTable Y.8.2: Example SDP offer with multiple 360-degree video containing group restrictions\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table Y.8.1: Example SDP offer with multiple 360-degree video",
                    "table number": 266,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table Y.8.2: Example SDP offer with multiple 360-degree video containing group restrictions",
                    "table number": 267,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "Y.9\t  Recommended audio mixing gains",
            "description": "An ITT4RT-Tx client may specify recommended gains for mixing of its transmitted audio streams and update these recommended gains during a session. An ITT4RT-Rx client may or may not use such recommended mixing gains to scale the audio streams prior to mixing.\nAn ITT4RT-Tx client may for example send the recommended mixing gains r0, r1, .., rN for the audio sources a0 (360 video) and a1, a2, .., aN (overlay videos) of that sender to recommend a mix at the receivers to be r0*a0+r1*a1+……+rN*aN.\nIf an ITT4RT-Rx client negotiated to receive recommended audio mixing gains and the ITT4RT-Tx client chooses to send these mixing gains, the ITT4RT-Tx client shall indicate each audio mixing gain value to the ITT4RT-Rx client using RTP header-extensions (see clause Y.9.1).\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "Y.9.1\tRTP header extension for audio mixing gain",
                    "description": "",
                    "summary": "",
                    "text_content": "The format for sending a recommended audio mixing gain using the RTP header extension shall be as follows:\n0                   1\n0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|  ID   | len=0 |audio-mixing-gain|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\nAudio mixing gain using One-Byte Header Format\nThe 4-bit ID is the local identifier of this element. The 4-bit length is the number, minus one, of data bytes of this header extension element following the one-byte header. The URI for declaring the audio mixing gain header extension in a Session Description Protocol (SDP) extmap attribute [95] and mapping it to a local identifier is:\nurn:3gpp:audio-mixing-gain\n\nThe audio mixing gain is expressed in dB as a signed integer in the range \"-127\" to \"0\" (hence the numerical values directly represent the gain in dB). A value of “-128” indicates muting the channel. The meaning of positive values other than 0 is undefined and shall be ignored if received.\nAn ITT4RT-Tx client may repeat the header extension over multiple RTP packets to improve the likelihood of successful transmission as described in [RFC 8285]. The number of header extension transmissions (for the same recommended mixing gain) should therefore depend on the probability of delivery.\n\n\n\n\n",
                    "tables": [
                        {
                            "description": "",
                            "table number": 268,
                            "summary": "",
                            "name": ""
                        },
                        {
                            "description": "",
                            "table number": 269,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        }
    ]
}