{
    "document_name": "26223-i00.docx",
    "content": [
        {
            "title": "Foreword",
            "description": "This Technical Specification has been produced by the 3rd Generation Partnership Project (3GPP).\nThe contents of the present document are subject to continuing work within the TSG and may change following formal TSG approval. Should the TSG modify the contents of the present document, it will be re-released by the TSG with an identifying change of release date and an increase in version number as follows:\nVersion x.y.z\nwhere:\nx\tthe first digit:\n1\tpresented to TSG for information;\n2\tpresented to TSG for approval;\n3\tor greater indicates TSG approved document under change control.\ny\tthe second digit is incremented for all changes of substance, i.e. technical enhancements, corrections, updates, etc.\nz\tthe third digit is incremented when editorial only changes have been incorporated in the document.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "1\tScope",
            "description": "The present document specifies a client for the IMS-based telepresence service supporting conversational speech, video and text transported over RTP. Telepresence is defined as a conference with interactive audio-visual communications experience between remote locations, where the users enjoy a strong sense of realism and presence between all participants (i.e. as if they are in same location) by optimizing a variety of attributes such as audio and video quality, eye contact, body language, spatial audio, coordinated environments and natural image size. A telepresence system is defined as a set of functions, devices and network elements which are able to capture, deliver, manage and render multiple high quality interactive audio and video signals in a telepresence conference. An appropriate number of devices (e.g. cameras, screens, loudspeakers, microphones, codecs) and environmental characteristics are used to establish telepresence.\nThe media handling capabilities of a telepresence client (TP UE) are specified in the present document. A TP UE supports Multimedia Telephony Service for IMS (MTSI) UE media handling capabilities [2], but it also supports more advanced media handling capabilities. The media handling aspects of a TP UE within the scope of the present document include media codecs, media configuration and session control, data transport, audio/video parameters, and interworking with MTSI.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "2\tReferences",
            "description": "The following documents contain provisions which, through reference in this text, constitute provisions of the present document.\n-\tReferences are either specific (identified by date of publication, edition number, version number, etc.) or non-specific.\n-\tFor a specific reference, subsequent revisions do not apply.\n-\tFor a non-specific reference, the latest version applies. In the case of a reference to a 3GPP document (including a GSM document), a non-specific reference implicitly refers to the latest version of that document in the same Release as the present document.\n[1]\t3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".\n[2]\t3GPP TS 26.114: \"IP Multimedia Subsystem (IMS); Multimedia telephony; Media handling and interaction\".\n[3]\t3GPP TS 22.228: \"Service requirements for the Internet Protocol (IP) multimedia core network subsystem (IMS); Stage 1\".\n[4]\t3GPP TS 24.229: \"IP multimedia call control protocol based on Session Initiation Protocol (SIP) and Session Description Protocol (SDP); Stage 3\".\n[5]\t3GPP TS 24.147: \"Conferencing using the IP Multimedia (IM) Core Network (CN) subsystem; Stage 3\".\n[6]\t3GPP TS 24.103: \"Telepresence using the IP Multimedia (IM) Core Network (CN) Subsystem (IMS); Stage 3\".\n[7]\tIETF RFC 8845 (January 2021): \"Framework for Telepresence Multi-Streams\".\n[8]\tIETF RFC 8850 (January 2021): \"Controlling Multiple Streams for Telepresence (CLUE) Protocol Data Channel\".\n[9]\tIETF RFC 8848 (January 2021): \"Session Signaling for Controlling Multiple Streams for Telepresence (CLUE)\".\n[10]\tIETF RFC 8846 (January 2021): \"An XML Schema for the Controlling Multiple Streams for Telepresence (CLUE) Data Model\".\n[11]\tIETF RFC 8847 (January 2021): \"Protocol for Controlling Multiple Streams for Telepresence (CLUE)\".\n[12]\tVOID\n[13]\tIETF RFC 8841 (January 2021): \"Session Description Protocol (SDP) Offer/Answer Procedures for Stream Control Transmission Protocol (SCTP) over Datagram Transport Layer Security (DTLS) Transport\".\n[14]\tIETF RFC 8864 (January 2021): \"Negotiation Data Channels Using the Session Description Protocol (SDP)\".\n[15]\tVOID\n[16]\tITU-T Recommendation H.264 (04/2013): \"Advanced video coding for generic audiovisual services\".\n[17]\tITU-T Recommendation H.265 (04/2013): \"High efficiency video coding\".\n[18]\tIETF RFC 6184 (2011): \"RTP Payload Format for H.264 Video\", Y.-K. Wang, R. Even, T. Kristensen, R. Jesup.\n[19]\tIETF RFC 7798 (2016): \"RTP Payload Format for High Efficiency Video Coding (HEVC)\", Y.-K. Wang, Y. Sanchez, T. Schierl, S. Wenger, M. M. Hannuksela.\n[20]\tIETF RFC 3264 (2002): \"An Offer/Answer Model with the Session Description Protocol (SDP)\", J. Rosenberg and H. Schulzrinne.\n[21]\tIETF 8853 (January 2021): \"Using Simulcast in Session Description Protocol (SDP) and RTP Sessions\".\n[22]\tRecommendation ITU-T H.241 (02/2012): \"Extended video procedures and control signals for ITU-T H.300-series terminals \".\n[23]\tIETF RFC 6236 (2011): \"Negotiation of Generic Image Attributes in the Session Description Protocol (SDP) \", I. Johansson and K. Jung.\n[24]\tRecommendation ITU-T H.245 (05/2011): \"Control protocol for multimedia communication\".\n[25]\tIETF RFC 4566 (2006): \"SDP: Session Description Protocol\", M. Handley, V. Jacobson and C. Perkins.\n[26]\tIETF RFC 6464: \"A Real-time Transport Protocol (RTP) Header Extension for Client-to-Mixer Audio Level Indication\".\n[27]\t3GPP TS 26.441: \"Codec for Enhanced Voice Services (EVS); General Overview\".\n[28]\t3GPP TS 26.442: \"Codec for Enhanced Voice Services (EVS); ANSI C code (fixed-point)\".\n[29]\t3GPP TS 26.445: \"Codec for Enhanced Voice Services (EVS); Detailed Algorithmic Description\".\n[30]\t3GPP TS 26.450: \"Codec for Enhanced Voice Services (EVS); Discontinuous Transmission (DTX)\".\n[31]\t3GPP TS 26.171: \"Speech codec speech processing functions; Adaptive Multi-Rate - Wideband (AMR-WB) speech codec; General description\".\n[32]\t3GPP TS 26.190: \"Speech codec speech processing functions; Adaptive Multi-Rate - Wideband (AMR-WB) speech codec; Transcoding functions\".\n[33]\t3GPP TS 26.173: \"ANCI-C code for the Adaptive Multi Rate - Wideband (AMR-WB) speech codec\".\n[34]\t3GPP TS 26.204: \"Speech codec speech processing functions; Adaptive Multi-Rate - Wideband (AMR-WB) speech codec; ANSI-C code\".\n[35]\t3GPP TS 26.071: \"Mandatory Speech Codec speech processing functions; AMR Speech CODEC; General description\".\n[36]\t3GPP TS 26.090: \"Mandatory Speech Codec speech processing functions; Adaptive Multi-Rate (AMR) speech codec; Transcoding functions\".\n[37]\t3GPP TS 26.073: \"ANSI C code for the Adaptive Multi Rate (AMR) speech codec\".\n[38]\t3GPP TS 26.104: \"ANSI-C code for the floating-point Adaptive Multi Rate (AMR) speech codec\".\n[39]\tRecommendation ITU-T F.734 (10/2014): \"Definitions, requirements, and use cases for Telepresence Systems\".\n[40]\tRecommendation ITU G.1091 (10/2014): \"Quality of Experience requirements for telepresence services\".\n[41]\tRecommendation ITU-T H.TPS-AV (02/2015): \"Audio/video parameters for telepresence systems \".\n[42]\tRecommendation ITU-T H.420 (10/2014): \"Telepresence System Architecture\".\n[43]\tRecommendation ITU-T H.323 (12/2009): \"Packet-based multimedia communication systems\".\n[44]\t3GPP TS 26.093: \"Mandatory speech codec speech processing functions; Adaptive Multi-Rate (AMR) speech codec; Source controlled rate operation\".\n[45]\t3GPP TS 26.193: \"Speech codec speech processing functions; Adaptive Multi-Rate - Wideband (AMR-WB) speech codec; Source controlled rate operation\".\n[46]\t3GPP TS 26.446: \"Codec for Enhanced Voice Services (EVS); AMR-WB Backward Compatible Functions\".\n[47]\t3GPP TS 26.443: \"Codec for Enhanced Voice Services (EVS); ANSI C code (floating-point)\".\n[48]\tIETF RFC 4574: \"The Session Description Protocol (SDP) Label Attribute\".\n[49]\t3GPP TS 26.452: \"Codec for Enhanced Voice Services (EVS); ANSI C code; Alternative fixed-point using updated basic operators\".\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "3\tDefinitions and abbreviations",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "3.1\tDefinitions",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the terms and definitions given in 3GPP TR 21.905 [1] and the following apply. A term defined in the present document takes precedence over the definition of the same term, if any, in 3GPP TR 21.905 [1].\nConference: An IP multimedia session with two or more participants. Each conference has a \"conference focus\". A conference can be uniquely identified by a user. Examples for a conference could be a Telepresence or a multimedia game, in which the conference focus is located in a game server.\nIM session: An IP multimedia (IM) session is a set of multimedia senders and receivers and the data streams flowing from senders to receivers. IP multimedia sessions are supported by the IP multimedia CN Subsystem and are enabled by IP connectivity bearers (e.g. GPRS as a bearer). A user may invoke concurrent IP multimedia sessions.\nTelepresence: A conference with interactive audio-visual communications experience between remote locations, where the users enjoy a strong sense of realism and presence between all participants by optimizing a variety of attributes such as audio and video quality, eye contact, body language, spatial audio, coordinated environments and natural image size.\nTelepresence System: A set of functions, devices and network elements which are able to capture, deliver, manage and render multiple high quality interactive audio and video signals in a Telepresence conference. An appropriate number of devices (e.g. cameras, screens, loudspeakers, microphones, codecs) and environmental characteristics are used to establish Telepresence.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "3.2\tAbbreviations",
                    "description": "",
                    "summary": "",
                    "text_content": "For the purposes of the present document, the abbreviations given in 3GPP TR 21.905 [1] and the following apply. \nAn abbreviation defined in the present document takes precedence over the definition of the same abbreviation, if any, in 3GPP TR 21.905 [1].\nAS\tApplication Server\nAVC\tAdvanced Video Coding\nBFCP\tBinary Floor Control Protocol\nCBP\tConstrained Baseline Profile\nCHP\tConstrained High Profile\nCLUE\tControLling mUltiple streams for tElepresence\nDTLS\tDatagram Transport Layer Security\nFIR\tFull Intra Request\nHEVC\tHigh Efficiency Video Coding\nICE\tInteractivity Connectivity Establishment\nIDR\tInstantaneous Decoding Refresh\nIRAP\tIntra Random Access Point\nMCC\tMultiple Content Capture\nMIME\tMultipurpose Internet Mail Extensions\nMRFC\tMultimedia Resource Function Controller\nMRFP\tMultimedia Resource Function Processor\nMTSI\tMultimedia Telephony Service for IMS\nPPS\tPicture Parameter Set\nRTP\tReal-time Transport Protocol\nSCTP\tStream Control Transmission Protocol\nSDP\tSession Description Protocol\nSEI\tSupplemental Enhancement Information\nSPS\tSequence Parameter Set\nSSRC\tSynchronization Source Identifier\nTP\tTelepresence\nTP UE\tTelePresence User Equipment\nVPS\tVideo Parameter Set\nXML\tEXtensible Markup Language\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "4\tSystem Description",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "4.1\tOverview",
                    "description": "",
                    "summary": "",
                    "text_content": "The use cases and requirements on IMS-based telepresence are defined in TS 22.228 [3] to enable telepresence support in IMS applications.\nEnabling telepresence support involves updating and enhancing the existing IMS procedures for point-to-point calls as specified in 3GPP TS 24.229 [4] and for multiparty conferences as specified 3GPP TS 24.147 [5]. This has been addressed in 3GPP TS 24.103 [6], which incorporates IETF's ControLling mUltiple streams for tElepresence (CLUE) framework [7]-[10] with the Session Initiation Protocol (SIP), Session Description Protocol (SDP) and Binary Floor Control Protocol (BFCP) to facilitate controlling multiple spatially related media streams in an IM session supporting telepresence.\nIn order to provide a \"being there\" experience for conversational audio and video telepresence sessions between remote locations, where the users enjoy a strong sense of realism and presence, capabilities and preferences need to be co-ordinated and negotiated between local and remote participants such as:\n-\taudio and video spatial composition information; e.g. spatial relationship of two or more objects (audio/video sources) in the same room to allow for accurate reproduction on the receiver side\n-\tcapabilities of cameras, screens, microphones and loudspeakers, and their relative spatial relationships\n-\tmeeting description, such as view information, language information, participant information, participant type, etc.\nCLUE achieves media advertisement and configuration to facilitate controlling and negotiating multiple spatially related media streams in an IMS conference supporting telepresence, taking into account capability information, e.g. screen size, number of screens and cameras, codecs, etc., so that sending system, receiving system, or intermediate system can make decisions about transmitting, selecting, and rendering media streams. With the establishment of the CLUE data channel, the participants have consented to use the CLUE protocol mechanisms to determine the capabilities of the each of the endpoints with respect to multiple streams support, via the exchange of an XML-based data format. The exchange of CLUE messages of each participant's \"advertisement\" and \"configure\" is to achieve a common view of media components sent and received in the IM session supporting telepresence.\nTS 24.103 [6] specifies procedures to deal with multiple spatially related media streams according to the CLUE framework to support telepresence and to interwork with IM session as below:\n1)\tInitiation of telepresence using IMS, which includes an initial offer/answer exchange establishes a basic media session and a CLUE channel, CLUE exchanges to \"advertisement\" and \"configure\" media components used in the session, then followed by an SDP offer/answer in Re-INVITE request to complete the session establishment (see more for the general idea in IETF RFC 8845 [7]);\n2)\tRelease or leaving of an IM session supporting telepresence, which needs remove the corresponding CLUE channel;\n3)\tUpdate of an ongoing IM session supporting telepresence, triggered by CLUE exchanges modifying existing CLUE information. For example: a new participant at an endpoint may require the establishment of a specific media stream;\n4)\tPresentation during an IM session supporting telepresence, which may also be initiated by the exchange of CLUE messages and possibly need an updated SDP offer/answer and activation of BFCP for floor control; and\n5)\tInterworking with normal IM session, this is to let the normal IMS users be able to join telepresence using IMS.\n\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "4.2\tTP UE",
                    "description": "",
                    "summary": "",
                    "text_content": "A TP UE shall support functional components and user plane protocol stack of an MTSI client as specified in clause 4.2 of TS 26.114 [2]. Moreover, a TP UE shall support the data channel capabilities of a DCMTSI client as described in clause 6.2.10 of TS 26.114 [2]. However, the DCMTSI client support for ‘bootstrap data channels’ described in clause 6.2.10 of TS 26.114 [2] is not expected from TP UEs.\nA TP UE shall use the IMS data channel capability of a DCMTSI client for the exchange of CLUE messages based on DTLS/SCTP (Datagram Transport Layer Security over Stream Control Transmission Protocol) [13] negotiated via the initial SDP offer and answer, in order to open the CLUE data channel based on a SCTP stream in each direction, following IETF RFC 8864 [14].\nA TP UE offers a DTLS/SCTP association together with the media format indicating the use of a data channel in the first SDP offer or subsequent SDP offers. A TP UE can further open the data channel via the SDP-based \"SCTP over DTLS\" data channel negotiation mechanism to indicate specific non-conversational application (e.g. CLUE protocol) over it.\nThe protocol stack of a TP UE with CLUE data channel is shown in Figure 4.1.\n\nThe figure depicts a protocol stack of a TP UE, illustrating the various components involved in the communication process. The diagram includes a base station (gNB), a user equipment (UE), and a network layer (NL), with a detailed representation of the protocol stack. This figure is crucial for understanding the communication process and the role of each component in the network.\nFigure 4.1: Protocol stack of a TP UE\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "5\tMedia Codecs",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "5.1\tSpeech",
                    "description": "",
                    "summary": "",
                    "text_content": "TP clients in terminals offering speech communication shall support super-wideband and full-band audio as per below.\nTP clients in terminals offering speech communication shall support,\n-\tsuper-wideband and full-band through EVS codec (3GPP TS 26.441 [27], 3GPP TS 26.442 [28], 3GPP TS 26.452 [49], 3GPP TS 26.445 [29] and 3GPP TS 26.443 [47]) including functions for discontinuous transmission (3GPP TS 26.450 [30]).\nTo support transcoder-free interworking with MTSI clients, a TP UE shall additionally offer lower bandwidth (e.g. NB, WB) speech communication as per below.\nTP clients in terminals offering speech communication shall support,\n-\twideband through EVS AMR-WB IO mode (3GPP TS 26.446 [46]) or AMR-WB codec (3GPP TS 26.171 [31], 3GPP TS 26.190 [32], 3GPP TS 26.173 [33] and 3GPP TS 26.204 [34]) including all 9 modes and source controlled rate operation ‎3GPP TS 26.193 [45].\n-\tnarrowband through AMR speech codec (3GPP TS 26.071 [35], 3GPP TS 26.090 [36], 3GPP TS 26.073 [37] and 3GPP TS 26.104 [38]) including all 8 modes and source controlled rate operation ‎3GPP TS 26.093 [44].\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "5.2\tVideo",
                    "description": "",
                    "summary": "",
                    "text_content": "TP clients in terminals offering video communication shall support:\n-\tH.264 (AVC) [16] Constrained High Profile (CHP), Level 3.1\nTo support transcoder-free interworking with MTSI clients, TP clients in terminals offering video communication shall also support:\n-\tH.264 (AVC) [16] Constrained Baseline Profile (CBP), Level 1.2\nIn addition, TP UEs shall support:\n-\tH.265 (HEVC) [17] Main Profile, Main Tier, Level 4.1\nFurthermore, TP UEs should support:\n-\tH.265 (HEVC) [17] Screen-Extended Main, Main Tier, Level 4.1\n-\tH.265 (HEVC) [17] Screen-Extended Main 4:4:4, Main Tier, Level 4.1\nH.264 (AVC) CHP shall be used, without requirements on output timing conformance (annex C of [16]). Each sequence parameter set of H.264 (AVC) shall contain the vui_parameters syntax structure including the num_reorder_frames syntax element set equal to 0.\nH.265 (HEVC) Main, Screen-Extended Main, and Screen-Extended Main 4:4:4 profiles shall be used with general_progressive_source_flag equal to 1, general_interlaced_source_flag equal to 0, general_non_packed_constraint_flag equal to 1, general_frame_only_constraint_flag equal to 1, and sps_max_num_reorder_pics[ i ] equal to 0 for all i in the range of 0 to sps_max_sub_layers_minus1, inclusive, without requirements on output timing conformance (annex C of [17]).\nFor both H.264 (AVC) and H.265 (HEVC), the decoder needs to know the Sequence Parameter Set (SPS) and the Picture Parameter Set (PPS) to be able to decode the received video packets. A compliant H.265 (HEVC) bitstream includes a Video Parameter Set (VPS), although the VPS may be ignored by the decoder in the context of the present specification. When H.264 (AVC) or H.265 (HEVC) is used it is recommended to transmit the parameter sets within the SDP description of a stream, using the relevant MIME/SDP parameters as defined in RFC 6184 [18] for H.264 (AVC) and in [19] for H.265 (HEVC), respectively. Each media source (SSRC) shall transmit the currently used parameter sets at least once in the beginning of the RTP stream before being referenced by the encoded video data to ensure that the parameter sets are available when needed by the receiver. If the video encoding is changed during an ongoing session such that the previously used parameter set(s) are no longer sufficient then the new parameter sets shall be transmitted at least once in the RTP stream prior to being referenced by the encoded video data to ensure that the parameter sets are available when needed by the receiver. When a specific version of a parameter set is sent in the RTP stream for the first time, it should be repeated at least 3 times in separate RTP packets with a single copy per RTP packet and with an interval not exceeding 0,5 seconds to reduce the impact of packet loss. A single copy of the currently active parameter sets shall also be part of the data sent in the RTP stream as a response to FIR. Moreover, it is recommended to avoid using a sequence or picture parameter set identifier value during the same session to signal two or more parameter sets of the same type having different values, such that if a parameter set identifier for a certain type is used more than once in either SDP description or RTP stream, or both, the identifier always indicates the same set of parameter values of that type.\nThe video decoder in a multimedia TP client in terminal shall either start decoding immediately when it receives data, even if the stream does not start with an IDR/IRAP access unit (IDR access unit for H.264, IRAP access unit for H.265) or alternatively no later than it receives the next IDR/IRAP access unit or the next recovery point Supplemental Enhancement Information (SEI) message, whichever is earlier in decoding order. The decoding process for a stream not starting with an IDR/IRAP access unit shall be the same as for a valid video bit stream. However, the TP client in terminal shall be aware that such a stream may contain references to pictures not available in the decoded picture buffer. The display behaviour of the TP client in terminal is out of scope of the present document.\nA TP client in terminal offering video support other than H.264 CHP Level 3.1 shall also offer H.264 CHP Level 3.1.\nA TP UE client in terminal offering H.265 (HEVC) shall support negotiation to use a lower Level than the one in the offer, as described in [19] and [20].\nTo support interworking with MTSI clients, a TP UE shall offer both H.264 CBP Level 1.2 and H.264 CHP Level 3.1 (with preference for the latter) and should also offer H.264 CBP Level 3.1.\nIn case a codec profile is offered with a Level higher than the required Level, no separate offer for the required Level is needed.\nA TP client in terminal offering H.264 (AVC) CHP support at a level higher than Level 3.1 shall support negotiation to use a lower Level as described in [18] and [20].\nA TP client in terminal offering H.264 (AVC) CBP support at a level higher than Level 1.2 shall support negotiation to use a lower Level as described in [18] and [20].\nA TP client in terminal offering H.264 (AVC) CBP support at a level higher than Level 3.1 shall support negotiation to use a lower Level as described in [18] and [20].\nNOTE 1:\tAll levels are minimum requirements. Higher levels may be supported and used for negotiation.\nNOTE 2:\tTP clients in terminals may use full-frame freeze and full-frame freeze release SEI messages of H.264 (AVC) to control the display process. For H.265 (HEVC), MTSI clients may set the value of pic_output_flag in the slice segment headers to either 0 or 1 to control the display process.\nNOTE 3:\tAn H.264 (AVC) encoder should code redundant slices only if it knows that the far-end decoder makes use of this feature (which is signalled with the redundant-pic-cap MIME/SDP parameter as specified in RFC 6184 [18]). H.264 (AVC) encoders should also pay attention to the potential implications on end-to-end delay. The redundant slice header is not supported in H.265 (HEVC).\nNOTE 4:\tIf a codec is supported at a certain level, it implies that on the receiving side, the decoder is required to support the decoding of bitstreams up to the maximum capability of this level. On the sending side, the support of a particular level does not imply that the encoder will produce a bitstream up to the maximum capability of the level. This method can be used to set up an asymmetric video stream. For H.264 (AVC), another method is to use the SDP parameters 'level-asymmetry-allowed' and 'max-recv-level' that are defined in the H.264 payload format specification, [18]. For H.265 (HEVC) it is possible to use the SDP parameter 'max-recv-level-id' defined in the H.265 payload format specification, [19], to indicate a higher level in the receiving direction than in the sending direction.\nNOTE 5:\tFor H.264 (AVC) and H.265 (HEVC), respectively, multiple sequence and picture parameter sets can be defined, as long as they have unique parameter set identifiers, but only one sequence and picture parameter set can be active between two consecutive IDRs and IRAPs, respectively.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "5.3\tReal-time Text",
                    "description": "",
                    "summary": "",
                    "text_content": "The real-time text requirements for MTSI clients in terminals specified in TS 26.114 [2], clause 5.2.3, also apply for TP UEs.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "5.4\tStill Images",
                    "description": "",
                    "summary": "",
                    "text_content": "The still images requirements for MTSI clients in terminals specified in TS 26.114 [2], clause 5.2.4, also apply for TP UEs.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "6\tMedia Configuration",
            "description": "The media configuration requirements for MTSI clients in terminals specified in TS 26.114 [2], clause 6, also apply for TP UEs.\nTo enable devices to participate in an IMS-based telepresence call, selecting the sources they wish to view, receiving those media sources and displaying them in an optimal fashion, CLUE involves two principal and inter-related protocol negotiations. SDP, conveyed via SIP, is used to negotiate the specific media capabilities that can be delivered to specific addresses on the TP UE. Meanwhile, a CLUE protocol [11], transported via a CLUE data channel [8], is used to negotiate the Capture Sources available, their attributes and any constraints in their use, along with which Captures the far end provides a TP UE wishes to receive. The CLUE protocol messages follow the XML format and comply with the XML schema in [10].\nThe CLUE data channel [8] is a bidirectional SCTP over DTLS channel used for the transport of CLUE messages. This channel shall be established before CLUE protocol messages can be exchanged and CLUE-controlled media can be sent.\nBeyond negotiating the CLUE channel, SDP is also used to negotiate the details of supported media streams and the maximum capability of each of those streams. As the CLUE Framework [7] defines a manner in which the Media Provider expresses their maximum encoding capabilities, SDP is also used to express the encoding limits for each potential Encoding.\nBackwards-compatibility with MTSI is an important consideration and it is vital that a CLUE-capable TP UE contacting a terminal that does not support CLUE is able to fall back to a fully functional non-CLUE call governed by the requirements on MTSI in 3GPP TS 26.114 [2].\nCLUE support shall be offered in the first SDP offer, as follows. At the beginning of a CLUE-based telepresence session over IMS, the support for CLUE shall be negotiated via the SDP between two TP UEs. The CLUE extension shall be indicated using an SDP session-level 'group' attribute. Each SDP media \"m\" line that is included in this group, using SDP media-level \"mid\" attributes, is CLUE-controlled, by a CLUE data channel also included in this CLUE group. A CLUE group should include the \"mid\" of the \"m\" line for one (and only one) CLUE data channel. For interoperability with non-CLUE devices, a CLUE-capable device sending an initial SDP offer shall not include any \"m\" line for CLUE-controlled media beyond the \"m\" line for the CLUE data channel (this is unless the remote terminal's CLUE support was already indicated at the SIP level using the \"sip.clue\" media feature tag), and includes at least one non-CLUE-controlled media \"m\" line.\nFor audio and video, the first SDP offer shall also contain the basic (i.e. non-CLUE-controlled) media streams with the set of mandatory codecs for TP UEs, i.e. namely EVS-SWB and H.264/AVC CHP Level 3.1. For each of the offered basic (i.e. non-CLUE-controlled) media streams indicated in an 'm=' line, one mandatory codec of the same media type that is specified in 3GPP TS 26.114 [2] shall also be included toward ensuring interworking with MTSI terminals. The preference in the codec order should favour the mandatory codecs for TP UEs, i.e. namely EVS-SWB and H.264/AVC CHP Level 3.1.\nIf the TP UE intends to negotiate multiple streams for audio and/or video, the first SDP offer from the TP UE should contain all of them in the basic (i.e., non-CLUE controlled) stream offered with the multi-stream capabilities for MSMTSI clients as specified in Annex S of 3GPP TS 26.114 [2] and demonstrated by the SDP examples in Annex T of 3GPP TS 26.114 [2] towards realizing more efficient group audio/video communications and avoiding transcoding as far as possible in multiparty calls. If the CLUE negotiation is successful however, the subsequent SDP offers shall be made such that for each media type the additional streams other than the basic stream shall be offered as CLUE-controlled streams and MSMTSI client capabilities shall no longer be offered.\nIf the CLUE negotiation is successful and the remote terminal is also a CLUE-capable TP UE, then the subsequent offers for all media streams, including basic streams and CLUE-controlled media, shall contain the mandatory codecs for TP UEs, namely EVS-SWB and H.264/AVC CHP Level 3.1, and shall contain at least one RTP payload type of the corresponding codec for each media line. Accordingly, the SDP answers from TP UEs shall also accept these codecs and contain the corresponding RTP payload types, and also shall conform to the requirements established in Tables 6.3a and 6.3b of 3GPP TS 26.114 [2].\nA TP UE receiving an SDP offer from an MTSI UE or a non-3GPP access client that does not support CLUE capabilities shall fall back to operate as an MTSI client and answer the SDP offer as per the requirements established in 3GPP TS 26.114 [2]. If the received SDP offer does not support CLUE, but contains multi-stream capabilities for MSMTSI clients as specified in Annex S of 3GPP TS 26.114 [2] and demonstrated by the SDP examples in Annex T of 3GPP TS 26.114 [2], then the TP UE shall accept such an offer and fall back to operate as an MSMTSI client.\nTP UEs may be involved in media sessions where CLUE could be enabled or disabled during an ongoing call. If, in an ongoing non-CLUE call, an SDP offer/answer exchange completes with both sides having included a data channel \"m\" line in their SDP and with the \"mid\" for that channel in corresponding CLUE groups then the call is now CLUE-enabled; negotiation of the data channel and subsequently the CLUE protocol begin. If, in an ongoing CLUE-enabled call, an SDP offer-answer negotiation completes in a fashion in which either the CLUE data channel was not successfully negotiated or one side did not include the data channel in a matching CLUE group then CLUE for this channel is disabled. In the event that this occurs, CLUE is no longer enabled and sending of all CLUE-controlled media associated with the corresponding CLUE group shall stop.\nA TP UE offering a media session should generate an SDP offer according to the examples in Annex A.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "7\tData Transport",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "7.1\tIntroduction",
                    "description": "",
                    "summary": "",
                    "text_content": "The data transport requirements for MTSI clients in terminals specified in TS 26.114 [2], clause 7, also apply for TP UEs.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "7.2\tRTP Payload Formats for TP UEs",
                    "description": "",
                    "summary": "",
                    "text_content": "The requirements on RTP payload formats for MTSI clients as specified in clause 7.4 of TS 26.114 [2] also apply for TP UEs.\nNOTE:\tFurther requirements on data transport aspects with regards to the usage of RTP / RTCP protocols, e.g. the use of RTP multiplexing and mapping of RTP streams to CLUE media captures, are FFS.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "8\tAudio/Video Parameters",
            "description": "",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": [
                {
                    "title": "8.1\tOverview",
                    "description": "",
                    "summary": "",
                    "text_content": "The audio/video parameters provided in clauses 8.2 and 8.3 should be supported by TP UEs as part of CLUE-based signaling in IMS-based telepresence sessions both at session initiation and during a session.\nCollectively, these audio/video parameters and their associated values can be expected to provide a high quality telepresence experience for 3GPP's IMS-based telepresence services from a media handling point of view.\nClause 8.2 describes the set of the capture-related audio/video parameters for 3GPP IMS-based telepresence services, while clause 8.3 describes the audio/video parameters on the telepresence system environment. Furthermore, guidance is provided in these clauses on the need for signalling these parameters at session initiation and during a session. While most of the parameters are already part of the CLUE framework, some of them are not and further references on the suitable signalling options for such parameters are also described. Some of these parameters are not signalled neither during session initiation nor during a session, but are still recommended to be supported in TP UEs for the purposes of quality monitoring.\n",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": []
                },
                {
                    "title": "8.2\tCapture-Related Parameters",
                    "description": "",
                    "summary": "",
                    "text_content": "",
                    "tables": [],
                    "figures_meta_data": [],
                    "subsubsections": [
                        {
                            "title": "8.2.1\tGeneral Parameters",
                            "text_content": "Table 8.2.1.1: General parameters\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 8.2.1.1: General parameters",
                                    "table number": 1,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "8.2.2\tVisual Parameters",
                            "text_content": "Table 8.2.2.1: Visual parameters\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 8.2.2.1: Visual parameters",
                                    "table number": 2,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "8.2.3\tAudio Parameters",
                            "text_content": "Table 8.2.3.1: Audio parameters\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 8.2.3.1: Audio parameters",
                                    "table number": 3,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "8.2.4\tDelay Parameters",
                            "text_content": "Table 8.2.4.1: Delay parameters\n\nNOTE: Delay numbers are based on ITU-T references [39]-[41] and 3GPP-specific modifications are FFS.\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 8.2.4.1: Delay parameters",
                                    "table number": 4,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        },
                        {
                            "title": "8.2.5\tMultiple Source Capture Parameters",
                            "text_content": "Table 8.2.5.1: Multiple Source Capture parameters\n\n",
                            "figures_meta_data": [],
                            "tables": [
                                {
                                    "description": "Table 8.2.5.1: Multiple Source Capture parameters",
                                    "table number": 5,
                                    "summary": "",
                                    "name": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "title": "8.3\tTelepresence System Environment Parameters",
                    "description": "",
                    "summary": "",
                    "text_content": "Table 8.3.1: Telepresence System Environment parameters\n\n",
                    "tables": [
                        {
                            "description": "Table 8.3.1: Telepresence System Environment parameters",
                            "table number": 6,
                            "summary": "",
                            "name": ""
                        }
                    ],
                    "figures_meta_data": [],
                    "subsubsections": []
                }
            ]
        },
        {
            "title": "9\tInterworking",
            "description": "The requirements to enable transcoder-free interworking between TP UEs and MTSI UEs are specified in clause 6.\nThe interworking requirements for MTSI clients in terminals specified in TS 26.114 [2], clause 12, also apply for TP UEs, for both the basic media streams (non-CLUE-controlled) as well as the CLUE-controlled media streams, latter being applicable when the remote terminal is also CLUE-capable.\nWhen the TP UE falls back to MTSI UE (e.g. upon failure of CLUE capability negotiation during the initial SDP offer-answer exchange), TP UE shall conform to the interworking requirements established for MTSI UEs in clause 12 of TS 26.114 [2].\nThe interworking requirements for MTSI clients in terminals using fixed access specified in TS 26.114 [2], clause 18, also apply for TP UEs in terminals using fixed access, for both the basic media streams (non-CLUE-controlled) as well as the CLUE-controlled media streams, latter being applicable when the remote terminal is also CLUE-capable.\nIf the TP UE is in terminal using fixed access, and it falls back to MTSI UE using fixed access (e.g. upon failure of CLUE capability negotiation during the initial SDP offer-answer exchange), TP UE shall conform to the interworking requirements established for MTSI UEs in clause 18 of TS 26.114 [2].\nInterworking with non-3GPP telepresence systems, e.g. those based on ITU-T Telepresence [39]-[43], [22], [24] is FFS.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "10\tJitter Buffer Management",
            "description": "The jitter buffer management requirements for MTSI clients in terminals specified in TS 26.114 [2], clause 8, also apply for TP UEs.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "11\tPacket Loss Handling",
            "description": "The packet loss handling requirements for MTSI clients in terminals specified in TS 26.114 [2], clause 9, also apply for TP UEs.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "12\tMedia Adaptation",
            "description": "The media and rate adaptation requirements for MTSI and MSMTSI clients in terminals specified respectively in TS 26.114 [2], clauses 10, 17 and S.8, also apply for TP UEs.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "13\tNetwork Preference Management Object",
            "description": "The network preference management object requirements for MTSI clients in terminals specified in TS 26.114 [2], clause 15, also apply for TP UEs.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "14\tQuality of Experience",
            "description": "The quality of experience requirements for MTSI clients in terminals specified in TS 26.114 [2], clause 16, also apply for TP UEs.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "15\tImmersive Teleconferencing and Telepresence for Remote Terminals (ITT4RT)",
            "description": "A TP-UE may support ITT4RT functionality as defined in TS 26.114 [2], Annex Y. A TP-UE may be an ITT4RT-Tx client or an ITT4RT-Rx client. A TP-UE that is an ITT4RT-Tx client is capable of providing at least one immersive 360-degree video. A TP-UE that is an ITT4RT-Rx client is capable of receiving exactly one immersive 360-degree video.\nMedia requirements for ITT4RT clients as specified in TS 26.114 [2], clause Y.3 on Immersive 360-degree video, Clause Y.4 on Immersive Audio/Voice support, and clause Y.5 on Overlay support, also apply to TP UEs supporting ITT4RT functionality.\nThe media configuration requirements for the main 360-degree video for ITT4RT clients specified in TS 26.114 [2], clause Y.6.2, also apply for TP UEs that support ITT4RT functionality.\nThe media configuration requirements for the still background for ITT4RT clients specified in TS 26.114 [2], clause Y.6.3, also apply for TP UEs that support ITT4RT functionality.\nThe media configuration requirements for overlays for ITT4RT clients specified in TS 26.114 [2], clause Y.6.4.1, Y.6.4.2 and Y.6.4.3, also apply for TP UEs that support ITT4RT functionality.\nThe media configuration requirements for fisheye video for ITT4RT clients specified in TS 26.114 [2], clause Y.6.5, also apply for TP UEs that support ITT4RT functionality.\nThe media transport requirements for ITT4RT clients specified in TS 26.114 [2], clause Y.7, also apply for TP UEs that support ITT4RT functionality.If the TP UE supporting ITT4RT functionality intends to negotiate at least one 360-degree video and at least one overlay, the SDP offer from the TP UE shall contain all of them in the basic (i.e., non-CLUE controlled) stream offered with the capabilities for ITT4RT clients using the itt4rt_group attribute as specified in clauses Y.6.2.6 and Y.6.8 of 3GPP TS 26.114 [2]. If the initial SDP offer-answer is successful, the CLUE ADVERTISEMENT message should contain the list of global views ( <globalViews>) containing a global view as specified in [11] for each rest-group.\n",
            "summary": "",
            "tables": [],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.1\tTP Session Setup with CLUE-Controlled Video Support",
            "description": "The following example demonstrates the SDP offer for negotiation of a CLUE data channel – the assumption here is that TP UE1 has three cameras and three screens and TP UE2 has two cameras and two screens.\nTable A.1.1: Example SDP offer for Establishment of CLUE Data Channel\n\nIn the above SDP example and remaining SDP examples below, boldface font is used to highlight the key lines demonstrating the described SDP offer answer procedures in the context of TP sessions controlled by CLUE.\nThe SDP offer from TP UE1 in Table A.1.1 contains basic media streams (non-CLUE controlled) and an establishment request for a DTLS/SCTP association used to realize a CLUE data channel. A CLUE group is included and the data channel is shown in group (3). Since the TP UE intends to negotiate multiple streams for video, the SDP offer contains all of them in the basic (i.e., non-CLUE controlled) stream offered with the multi-stream capabilities for MSMTSI clients, as outlined in clause 6, as this helps to fall back to MSMTSI in case the remote client is not a TP UE and CLUE negotiation is not successful. Moreover, it should be observed that the multiple streams for video other than the basic streams offered for MSMTSI clients are labelled as 'sendonly' and are also not part of the CLUE group. Only the offered CLUE data channel is included in the CLUE group (identified by a=mid:3).\nThe initial SDP offer message negotiates the port and transport information for setting up the DTLS/SCTP association, via a separate SDP \"m=\" line with a UDP/DTLS/SCTP or TCP/DTLS/SCTP proto value, together with an SDP \"sctp-port\" attribute, and an SDP \"dcmap\" attribute to indicate \"CLUE\" as the application protocol running over the data channel. The procedures for establishment of the DTLS/SCTP association via SDP can be found in [13] and [8].\nFor the basic media streams, the offer contains the AMR narrowband and AMR-WB wideband codecs for audio and H.264/AVC Constrained Baseline Profile Level 1.2 (in addition to the mandatory codecs for TP UEs, namely EVS-SWB and H.264/AVC CHP Level 3.1).\nTable A.1.2: Example SDP answer for Establishment of CLUE Data Channel\n\nThe answer from TP UE2 in Table A.1.2 indicates that the CLUE data channel is accepted. Now CLUE and configure messages can be exchanged in order to negotiate on the capture and rendering capabilities for the telepresence session. Moreover, TP UE2 wishes to receive initial media, and so includes corresponding non-CLUE-controlled audio and video lines.\nWith the successful initial SDP offer-answer, TP UEs negotiate the CLUE channel via the exchange of CLUE ADVERTISEMENT and CLUE CONFIGURE messages. As described in clause 6, the CLUE protocol messages follow the XML format in [10] and various CLUE message examples can also be found in [11]. TP UE1 advertises three static Captures representing its three cameras. It also includes switched Captures suitable for two- and one-screen systems. TP UE1 also includes an Encoding Group with three Encoding IDs: \"enc1\", \"enc2\" and \"enc3\", which will appear in the subsequent SDP offer TP UE1 intends to send. TP UE2 also sends its CLUE ADVERTISEMENT message, where it advertises two static Captures representing its two cameras. It also includes a single composed Capture for single-screen systems, in which it will composite the two camera views into a single video stream. TP UE2 also includes a single Encoding Group with two Encoding IDs: \"foo\" and \"bar\".\nFollowing the exchange of these CLUE messages, further SDP offer-answer negotiations can occur that include CLUE-controlled encodings. Every \"m\" line representing a CLUE Encoding contains a \"label\" attribute as defined in [48] to identify the Encoding by the sender in CLUE Advertisement messages and by the receiver in CLUE Configure messages, e.g. \"enc1\", \"enc2\", \"enc3\" for TP UE1 and \"foo\" and \"bar\" for TP UE2.\nIt should be noted that, since the CLUE negotiation was successful, the subsequent SDP offers are made such that for each media type the additional streams other than the basic stream are offered as CLUE-controlled streams and MSMTSI client capabilities are no longer to be offered. As a result, several of the earlier accepted 'sendonly' video streams are now offered as part of the CLUE-controlled group in the SDP offer example below.\nTable A.1.3: Example SDP offer for Negotiating CLUE-controlled Media\n\nThe second SDP offer in Table A.1.3 from TP UE1 maintains the \"sendrecv\" audio, video and includes three additional \"sendonly\" m-lines representing the three CLUE-controlled encodings for video. Each of these m-lines contains a \"label\" corresponding to one of the encoding IDs from the CLUE advertisement from TP UE1. Each also has its \"mid\" added to the grouping attribute to show that they are controlled by the CLUE channel.\nSince it is now clear that the remote endpoint is a CLUE-capable TP UE, the offer for the basic streams contains the mandatory audio and video codecs for TP UEs, namely the EVS codec as well as the H.264/AVC Constrained High Profile Level 3.1.\nTP UE2 now has all the information he needs to decide which streams to configure. As such he now sends its CLUE CONFIGURE message. This requests the pair of switched Captures that represent TP UE1's scene, and it configures them with encoder ids \"enc1\" and \"enc2\".\nTP UE1 receives the CLUE CONFIGURE from TP UE2 and sends a CLUE RESPONSE message to acknowledge its receptions.\nTable A.1.4: Example SDP answer for Negotiating CLUE-controlled Media\n\nTP UE2 now sends its SDP answer, shown in Table 4.  Alongside the original audio, video and CLUE m-lines, it includes two active \"recvonly\" m-lines and a zeroed m-line for the third, indicating that only two of the offered CLUE-controlled encodings are accepted.  It adds their \"mid\" values to the grouping attribute to show they are controlled by the CLUE channel.\nThe constraints of offer/answer meant that TP UE2 could not include its encoder information as new m-lines in the SDP answer. As such TP UE2 now generates a third SDP offer. Along with all the accepted streams from the second offer-answer exchange, TP UE2 also includes two new \"sendonly\" streams. Each stream has a \"label\" corresponding to the Encoding IDs in the CLUE ADVERTISEMENT message from TP UE2. It also adds their \"mid\" values to the grouping attribute to show they are controlled by the CLUE channel. The resulting SDP offer is shown in Table A.1.5.\nTable A.1.5: Example SDP offer for Negotiating CLUE-controlled Media\n\nHaving received this TP UE1 now has all the information it needs to send a new CLUE CONFIGURE message. It requests the two static Captures from TP UE2, to be sent on Encodings \"foo\" and \"bar\". TP UE2 receives the CLUE CONFIGURE message from TP UE1 and sends a CLUE RESPONSE message to acknowledge its receptions.\nTP UE1 now sends an SDP answer matching two \"recvonly\" m-lines to TP UE2's new \"sendonly\" lines. It includes their \"mid\" values in the grouping attribute to show they are controlled by the CLUE channel. This is shown in Table A.1.6.\nTable A.1.6: Example SDP answer for Negotiating CLUE-controlled Media\n\nBoth sides of the call are now sending multiple video streams with their sources defined via CLUE negotiation.  As the call progresses either side can send new CLUE Advertisement or Configure message or new SDP negotiation to add, remove or change what they have available or want to receive.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.1.1: Example SDP offer for Establishment of CLUE Data Channel",
                    "table number": 7,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.1.2: Example SDP answer for Establishment of CLUE Data Channel",
                    "table number": 8,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.1.3: Example SDP offer for Negotiating CLUE-controlled Media",
                    "table number": 9,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.1.4: Example SDP answer for Negotiating CLUE-controlled Media",
                    "table number": 10,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.1.5: Example SDP offer for Negotiating CLUE-controlled Media",
                    "table number": 11,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.1.6: Example SDP answer for Negotiating CLUE-controlled Media",
                    "table number": 12,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.2\tTP Session Setup with CLUE-Controlled Audio Support",
            "description": "The following example is similar to the example in clause A.1, but demonstrates CLUE-controlled audio support channel – the assumption here is that TP UE1 has three microphones and three speakers and TP UE2 has two microphones and two speakers. No video communication is assumed in this example.\nTable A.2.1: Example SDP offer for Establishment of CLUE Data Channel\n\nThe SDP offer from TP UE1 in Table A.2.1 contains the basic audio stream (non-CLUE controlled) and an establishment request for a DTLS/SCTP association used to realize a CLUE data channel. A CLUE group is included and the data channel is shown in group (3).\nFor the basic media streams, the offer contains the AMR narrowband, AMR-WB wideband and EVS codecs, with the former two included for the purposes of interworking with MTSI clients.\nSince the TP UE intends to negotiate multiple streams for audio, the SDP offer contains all of them in the basic (i.e., non-CLUE controlled) stream offered with the multi-stream capabilities for MSMTSI clients, as outlined in clause 6, as this helps to fall back to MSMTSI in case the remote client is not a TP UE and CLUE negotiation is not successful. Moreover, it should be observed that the multiple streams for audio other than the basic streams offered for MSMTSI clients are labelled as 'sendonly' and are also not part of the CLUE group. Only the offered CLUE data channel is included in the CLUE group (identified by a=mid:3).\nTable A.2.2: Example SDP answer for Establishment of CLUE Data Channel\n\nThe answer from TP UE2 in Table A.2.2 indicates that the CLUE data channel is accepted. Now CLUE and configure messages can be exchanged in order to negotiate on the capture and rendering capabilities for the telepresence session. Moreover, TP UE2 wishes to receive initial media, and so includes corresponding non-CLUE-controlled audio lines, accepting the use of the EVS codec.\nWith the successful initial SDP offer-answer, TP UEs negotiate the CLUE channel via the exchange of CLUE ADVERTISEMENT and CLUE CONFIGURE messages. TP UE1 advertises three static Captures representing its three microphones. It also includes switched Captures suitable for two- and one-speaker systems. TP UE1 also includes an Encoding Group with three Encoding IDs: \"enc1\", \"enc2\" and \"enc3\", which will appear in the subsequent SDP offer TP UE1 intends to send. TP UE2 also sends its CLUE ADVERTISEMENT message, where it advertises two static Captures representing its two microphones. It also includes a single composed Capture for single-speaker systems, in which it will composite the two microphone views into a single audio stream. TP UE2 also includes a single Encoding Group with two Encoding IDs: \"foo\" and \"bar\".\nFollowing the exchange of these CLUE messages, further SDP offer-answer negotiations can occur that include CLUE-controlled encodings. Every \"m\" line representing a CLUE Encoding contains a \"label\" attribute as defined in [48] to identify the Encoding by the sender in CLUE Advertisement messages and by the receiver in CLUE Configure messages, e.g. \"enc1\", \"enc2\", \"enc3\" for TP UE1 and \"foo\" and \"bar\" for TP UE2.\nIt should be noted that, since the CLUE negotiation was successful, the subsequent SDP offers are made such that for each media type the additional streams other than the basic stream are offered as CLUE-controlled streams and MSMTSI client capabilities are no longer to be offered. As a result, several of the earlier accepted 'sendonly' audio streams are now offered as part of the CLUE-controlled group in the SDP offer example below.\nTable A.2.3: Example SDP offer for Negotiating CLUE-controlled Media\n\nThe second SDP offer in Table A.2.3 from TP UE1 maintains the \"sendrecv\" audio and includes three additional \"sendonly\" m-lines representing the three CLUE-controlled encodings for audio. Each of these m-lines contains a \"label\" corresponding to one of the encoding IDs from the CLUE advertisement from TP UE1. Each also has its \"mid\" added to the grouping attribute to show that they are controlled by the CLUE channel.\nTP UE2 now has all the information it needs to decide which streams to configure. As such it now sends its CLUE CONFIGURE message. This requests the pair of switched Captures, and it configures them with encoder ids \"enc1\" and \"enc2\".\nTP UE1 receives the CLUE CONFIGURE from TP UE2 and sends a CLUE RESPONSE message to acknowledge its receptions.\nTable A.2.4: Example SDP answer for Negotiating CLUE-controlled Media\n\nTP UE2 now sends its SDP answer, shown in Table A.2.4. Alongside the original audio and CLUE m-lines, it includes two active \"recvonly\" m-lines and a zeroed m-line for the third, indicating that only two of the offered CLUE-controlled encodings are accepted. It adds their \"mid\" values to the grouping attribute to show they are controlled by the CLUE channel.\nThe constraints of offer/answer meant that TP UE2 could not include its encoder information as new m-lines in the SDP answer. As such, TP UE2 now generates a third SDP offer. Along with all the accepted streams from the second offer-answer exchange, TP UE2 also includes two new \"sendonly\" streams. Each stream has a \"label\" corresponding to the Encoding IDs in the CLUE ADVERTISEMENT message from TP UE2. It also adds their \"mid\" values to the grouping attribute to show they are controlled by the CLUE channel. The resulting SDP offer is shown in Table A.2.5.\n\nTable A.2.5: Example SDP offer for Negotiating CLUE-controlled Media\n\nHaving received this TP UE1 now has all the information it needs to send a new CLUE CONFIGURE message. It requests the two static Captures from TP UE2, to be sent on Encodings \"foo\" and \"bar\". TP UE2 receives the CLUE CONFIGURE message from TP UE1 and sends a CLUE RESPONSE message to acknowledge its receptions.\nTP UE1 now sends an SDP answer matching two \"recvonly\" m-lines to TP UE2's new \"sendonly\" lines. It includes their \"mid\" values in the grouping attribute to show they are controlled by the CLUE channel. This is shown in Table A.2.6.\nTable A.2.6: Example SDP answer for Negotiating CLUE-controlled Media\n\nBoth sides of the call are now sending multiple audio streams with their sources defined via CLUE negotiation. As the call progresses either side can send new CLUE Advertisement or Configure message or new SDP negotiation to add, remove or change what they have available or want to receive.\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.2.1: Example SDP offer for Establishment of CLUE Data Channel",
                    "table number": 13,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.2.2: Example SDP answer for Establishment of CLUE Data Channel",
                    "table number": 14,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.2.3: Example SDP offer for Negotiating CLUE-controlled Media",
                    "table number": 15,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.2.4: Example SDP answer for Negotiating CLUE-controlled Media",
                    "table number": 16,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.2.5: Example SDP offer for Negotiating CLUE-controlled Media",
                    "table number": 17,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.2.6: Example SDP answer for Negotiating CLUE-controlled Media",
                    "table number": 18,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        },
        {
            "title": "A.3\tInterworking between TP UE and MTSI UE",
            "description": "The following example is similar to the example in clause A.1, but demonstrates the case of interworking between TP UE and MTSI UE.\nTable A.3.1: Example SDP offer for Establishment of CLUE Data Channel\n\nThe SDP offer from TP UE in Table A.3.1 contains basic media streams (non-CLUE controlled) and an establishment request for a DTLS/SCTP association used to realize a CLUE data channel. A CLUE group is included and the data channel is shown in group (3). Since the TP UE intends to negotiate multiple streams for video, the SDP offer contains all of them in the basic (i.e., non-CLUE controlled) stream offered with the multi-stream capabilities for MSMTSI clients, as outlined in clause 6, as this helps to fall back to MSMTSI in case the remote client is not a TP UE and CLUE negotiation is not successful. Moreover, it should be observed that the multiple streams for video other than the basic streams offered for MSMTSI clients are labelled as 'sendonly' and are also not part of the CLUE group. Only the offered CLUE data channel is included in the CLUE group (identified by a=mid:3).\nFor the basic video stream, the offer contains H.264/AVC Constrained Baseline Profile Level 1.2 (in addition to the mandatory video codec for TP UEs, namely H.264/AVC CHP Level 3.1) for the purposes of interworking with MTSI clients.\nFor the basic audio stream, the offer contains the mandatory EVS-SWB codec with bit rate range [13.2 to 24.4 kbps] for TP session media establishment and AMR/AMR-WB in bandwidth efficient and octet-aligned formats for enabling transcoder-free interworking with potential legacy MTSI client that does not support EVS-SWB in the TP session.\nTable A.3.2: Example SDP answer for Establishment of CLUE Data Channel\n\nThe answer from MTSI UE shown in Table A.3.2. Since the MTSI UE is not CLUE capable, it does not recognize the CLUE semantic for grouping attribute nor does it support the CLUE data channel. Accordingly, the SDP answer indicates that the CLUE data channel is not accepted. Moreover, since the MTSI UE does not support multi-stream capabilities in MSMTSI clients, the additionally offered 'sendonly' video streams are also not accepted.\nIn the meantime, the MTSI UE accepts the offered basic audio and video streams that are based on RTP payloads that it supports, in this case based on EVS-SWB and H.264/AVC CHP Level 3.1. Consequently, the TP UE can fall back to the non-CLUE operation governed by MTSI client capabilities and exchange the basic media streams with the MTSI UE.\n\n\n\n\n\n",
            "summary": "",
            "tables": [
                {
                    "description": "Table A.3.1: Example SDP offer for Establishment of CLUE Data Channel",
                    "table number": 19,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "Table A.3.2: Example SDP answer for Establishment of CLUE Data Channel",
                    "table number": 20,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "",
                    "table number": 21,
                    "summary": "",
                    "name": ""
                },
                {
                    "description": "",
                    "table number": 22,
                    "summary": "",
                    "name": ""
                }
            ],
            "figures_meta_data": [],
            "subsections": []
        }
    ]
}